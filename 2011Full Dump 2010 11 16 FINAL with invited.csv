TS,username,salutation,realname,contacttitle,workaffiliation,address1,phone,fax,email,Talk_Title,presentingauthor,presenter1Firstname,presenter1middle,presenter1lastname,presenter1affiliation,presenter2Firstname,presenter2middle,presenter2lastname,presenter2affiliation,presenter3Firstname,presenter3middle,presenter3lastname,presenter3affiliation,presenter4Firstname,presenter4middle,presenter4lastname,presenter4affiliation,presenter5Firstname,presenter5middle,presenter5lastname,presenter5affiliation,presenter6Firstname,presenter6middle,presenter6lastname,presenter6affiliation,presenter7Firstname,presenter7middle,presenter7lastname,presenter7affiliation,presenter8Firstname,presenter8middle,presenter8lastname,presenter8affiliation,presenter9Firstname,presenter9middle,presenter9lastname,presenter9affiliation,presenter10Firstname,presenter10middle,presenter10lastname,presenter10affiliation,abstract,IMS_Session,ENAR_ASA_IMS_Conflict,Expr1,COPSS_Conflict,SC_T_R_Conflict,OtherConflict,OtherConflictText,category,student_oral_poster,invitedpaper_organizer,specialcontributedpaper_organizer,overheadprojector,slideprojector_35mm,no_equipment,willing_to_serve_as_a_chair_for_a_session,FirstCategory,SecondCategory,OtherSpecify,,,,,,15-Nov-10,aamaty2@uic.edu,,Anup,,University of Illinois at Chicago,1601 W taylor St,9543307776,,aamaty2@uic.edu,Sample Size determination for Clustered cound data,1,Anup,K,Amatya,University of Illinois at Chicago,Dulal,K,Bhaumik,University of Illinois at Chicago,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In this talk we will discuss how to determine sample size for correlated count data. Multi-center randomized clinical trials are extensively used inlarge-scale studies to evaluate the effects of medical interventionson health outcomes. The observations within each cluster are usuallypositively correlated. Sample size determination for testing efficacyor the safety of an intervention for such correlated count data inclinical trials is an important yet often overlooked problem. When theoutcome is count some form of Poisson regression model is typicallyused to analyze this type of  data.  We will present  novel and innovativestatistical methodologies  for sample size determinationfor comparing the event rates in two groups in order to detect apre-specified difference between these two rates with an adequatepower. Simple and direct expressions to compute required number ofclusters in cluster specific and cluster averaged models will be provided.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Clustered data methods,Applied data analysis,Sample Size determination,,,,,,10-Nov-10,aaron-t-porter@uiowa.edu,,Aaron Porter,,University of Iowa,636 Westgate St.,319.855.8592,,aaron-t-porter@uiowa.edu,An Individual Level SEIR Model for Infectious Diseases using General Distributions on the Latent Period,1,Aaron,T,Porter,University of Iowa Department of Biostatistics,Jacob,,Oleson,University of Iowa Department of Biostatistics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Bayesian SEIR model methodology is becoming increasingly popular inthe literature.  These tend to be population based models, and arefrequently subject to the exponential assumption, which states thatthe latent period for an infectious disease is exponentiallydistributed.  Because of the memoryless property of the exponentialdistribution, this assumption is typically not realistic for diseaseswith short latent periods, such as mumps or smallpox.   Throughsimulations, we show the shortcomings of the exponential assumptionswhen analyzing data coming from a more realistic gamma or weibulldistribution for the latent period.  We then propose an individuallevel model, rather than the traditional marginal model, which has theflexibility of utilizing other distributions of the latent period. Finally, we demonstrate the improvement with regards to inference ofsuch a model on diseases with short latent periods.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Infectious disease models,Epidemiologic methods,,,,,,,13-Oct-10,ab179@stat.duke.edu,,Anirban Bhattacharya,,PhD candidate,"Department of Statistical Science, 214 Old Chemistry Building, Box 90251, Duke University",(919)684-8821,,ab179@stat.duke.edu,Simplex factor models for multivariate unordered categorical data,1,Anirban,,Bhattacharya,"PhD candidate, Department of Statistical Science, Duke University",David,,Dunson,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Gaussian latent factor models are routinely used for modeling ofdependence in continuous, binary and ordered categorical data. Forunordered categorical variables, Gaussian latent factor models lead tochallenging computation and overly complex modeling structures. As analternative that is more natural for unordered categorical data, wepropose a novel class of simplex factor models. In the single factorcase, the model treats the different categorical outcomes asindependent with unknown marginals. The model can characterize highlyflexible dependence structures parsimoniously with few factors, and asfactors are added, any multivariate categorical data distribution canbe accurately approximated. Using a Bayesian approach for computationand inferences, a highly efficient Gibbs sampler is proposed thatscales well with increasing dimension. We develop an efficientproposal for updating the base probability vector in hierarchicalDirichlet models. Theoretical properties are described and we evaluatethe approach through simulation examples.  Applications are describedfor modeling dependence in nucleotide sequences and prediction fromhigh-dimensional categorical features.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Latent variables,Nonparametric methods,,,,,,,15-Nov-10,ab229@stat.duke.edu,,Anjishnu Banerjee,,Duke University,2748 Campus Walk Avenue,9196726761,,ab229@stat.duke.edu,Joint Nonparametric Bayes Modeling via Factor Partition Models,1,Anjishnu,,Banerjee,Duke University,David,B,Dunson,Duke University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"There is increasing interest in a broad variety of biostatisticalapplicatios in defining flexible joint models for data having avariety of measurement scales, while also allowing data of complextypes, such as functions, images and SNPs.  We provide ageneral class of nonparametric Bayes factor partition (FP) mixturemodels for joint modeling of data of different types.  The proposedframework is based on first defining a separate probabilistic modelcontaining subject-specific random effects for each type of data.  Therandom effects are then clustered separately, with an infinite simplexfactor model specified for the joint distribution of the clusterindices.  Properties of the proposed model are described, includinglarge support in modeling of joint and conditional distributions andposterior consistency.  Relationships with mixed membership models andtensor decompositions are discussed. Efficient methods are developedfor posterior computation via MCMC, and the methods are illustratedthrough several simulated and real data applications.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Bayesian methods,Nonparametric methods,,,,,,,11-Nov-10,abrisbin@gmail.com,,Abra Brisbin,Research Fellow,Mayo Clinic,Mayo Clinic Department of Health Sciences Research,507-538-3884,,abrisbin@gmail.com,Utilizing gene pathway-based priors in Bayesian association studies,1,Abra,,Brisbin,"Department of Health Sciences Research, Mayo Clinic, Rochester, MN 55905, USA",Liewei,,Wang,"Department of Molecular Pharmacology and Experimental Therapeutics, Mayo Clinic, Rochester, MN 55905, USA",Brooke,L,Fridley,"Department of Health Sciences Research, Mayo Clinic, Rochester, MN 55905, USA",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Gene pathways encode a wealth of information that could be used to improve power in genetic association studies.  For example, researchers may wish to utilize the prior belief that more closely connected genes have more correlated effects on the trait.  In this work, we explore a range of possible Bayesian models to encode gene network structure as prior knowledge in a study associating phenotype with the expression levels of genes in the network.  We find that a model with shrinkage inversely related to each gene's degree in the pathway has the best detection rate for simulated effects at 'hub' genes, while the exponential and Gaussian decay models, which directly incorporate spatial dependence, provide the best balance of detection rates for effects at both 'hub' and 'spoke' genes.  We use our models to analyze the effects of gene expression on IC50 for gemcitabine and thiopurine pharmacogenomic studies.  We find that NT5C3 plays an important role in increasing resistance to gemcitabine, and NT5E decreases resistance to mercaptopurine.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Statistical genetics,Bayesian methods,,,,,,,04-Nov-10,achatter@stat.ufl.edu,,Arkendu,,Student,4100 SW 20th Avenue,352-284-5141,,achatter@stat.ufl.edu,Posterior predictive loss for model selection in incomplete  longitudinal data,1,Arkendu,S,Chatterjee,"Graduate Student, Department Of Statistics, University Of Florida",Michael,J,Daniels,"Chair and Professor, Department Of Statistics, University Of Florida",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We explore the use of posterior predictive loss for model selection for incomplete longitudinal data. We show that a straightforward extension to incomplete data introduces an extra term (in addition  to the goodness of t and penalty terms) that compromises the criterion. We propose an alternative and explore its properties via simulations and on a real dataset.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Longitudinal data,Bayesian methods,,,,,,,08-Nov-10,achatter@westga.edu,,Ayona Chatterjee,Dr.,University of West Georgia,1601 Maple Street,+1 678-839-4142,,achatter@westga.edu,A Hierarchical Bayesian Mixture Model for Repeated Dietary Records,1,Ayona,,Chatterjee,University of West Georgia,Graham,,Horgan,"Biomathematics and Statistics of Scotland and Rowett Institute of Nutrition and Health at the University of Aberdeen, UK",Chris,,Theobald,"Biomathematics & Statistics Scotland and University of Edinburgh, UK",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Many dietary consumption variables show strong positive skewness andmay also have large proportions of zeros. Attempts to normalize datahaving these characteristics by using transformations such as powersand logarithms can be unsuccessful: this results in poor estimates oftheir probability distributions, and hence of the proportion of thepopulation whose consumption is outside recommended limits. As analternative to such transformations, the use of finite mixtures ofstandard distributions offers flexible modeling of data having skewedor multi-modal distributions, such as data on dietary consumption. In many dietary studies, individuals are asked to report theirconsumptions on several days. The use of finite-mixture models forsuch repeated data requires generalization to take account of theresulting hierarchical structure in the data. We first consider howfinite mixture models might be extended to data with repeated records,and then apply a Bayesian version of one such extension to data on theconsumption of retinol (Vitamin A) by British adults over sevenconsecutive days. We also illustrate how factors such as sex and agemay be included in the model. The mixture-model approach is found toprovide more accurate estimates than alternative methods of theproportions of the population whose daily or longer-term consumptionsare outside recommended limits.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Other,Health services research,Food Risk Assessment,,,,,,15-Nov-10,acorreia@hsph.harvard.edu,,Andrew Correia,,Harvard University School of Public Health,94 Wenham Street,7748887091,,acorreia@hsph.harvard.edu,The Effect of Air Pollution Control on Life Expectancy in the United States: A Population-Based Analysis of Major Metropolitan Areas,1,Andrew,W,Correia,Harvard University,Francesca,,Dominici,Harvard University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Over the past few decades, there have been substantial and measurableimprovements in ambient air quality in the United States, which are atleast partly due to air pollution regulations.  There have also beenimprovements in population survival, primarily as a result of declinein cardiovascular disease (CVD) mortality, although the change in lifeexpectancy has been highly variable across U.S. counties. Given thedifferential changes in air pollution and life expectancy, we aim toconduct analyses that will directly estimate the benefits of lower airpollution on survival, adjusting for temporal trends in other keypredictors of mortality. Our objective is to determine quantitativelythe impacts of trends in selected criteria pollutants oncause-specific mortality and life expectancy in a population-basedstudy.  Here, we focus on the re-analysis of two recent publicationsand discuss potential areas for improvement in current methodology.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Environmental and ecological applications,Spatial/temporal modeling,,,,,,,15-Nov-10,adam.branscum@oregonstate.edu,,Adam Branscum,Associate Professor,Oregon State University,Department of Public Health,502-370-5037,,adam.branscum@oregonstate.edu,HIV-malaria co-infection: effects of malaria on the prevalence of HIV in East sub-Saharan Africa,2,Diego,,Cuadros,University of Kentucky,Adam,,Branscum,Oregon State University,Philip,,Crowley,University of Kentucky,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We examined the association between malaria and HIV prevalence in Eastsub-Saharan Africa using nationally representative samples of 19,735sexually active adults from the 2003-04 HIV/AIDS indicator surveysconducted in Kenya, Malawi and Tanzania, and the atlas malariaproject.  The data were analyzed, stratified by sex, using a logisticregression mixed model to study the relationship between malaria andHIV prevalence, adjusting for important socioeconomic and biologicalcovariates.  The results indicated that individuals who live in areaswith high Plasmodium falciparum parasite rate (PfPR > 0.42) hadincreased estimated odds of being HIV-positive than individuals wholive in areas with low Plasmodium falciparum parasite rate (PfPR <=0.10) (men: estimated odds ratio 2.24, 95% CI 1.62-3.12; women:estimated odds ratio 2.44, 95% CI 1.85-3.21).   This is the firststudy to report malaria as a risk factor of concurrent HIV infectionat the population level.  Our work emphasizes the need for fieldstudies focused on quantifying the interaction among parasiticinfections and risk of HIV infection, and studies to explore theimpact of control interventions.",FALSE,FALSE,,FALSE,FALSE,FALSE,,contributedposter,,,,FALSE,FALSE,FALSE,FALSE,Epidemiologic methods,Applied data analysis,,,,,,,15-Nov-10,adridornelles@gmail.com,,Adriana Dornelles,,Tulane University,1564 STEEPLE CHASE LN,5043671240,,adridornelles@gmail.com,"Does work environment affect weight status? A spatial analysis to assess the availability of local food store among elementary schools employees in New Orleans, LA.",1,Adriana,C,Dornelles,Tulane University,Rice,,Rice,Tulane University,Larry,,Webber,Tulane University,Rose,,Diego,Tulane University,,,,,,,,,,,,,,,,,,,,,,,,,"Obesity has become a national concern and has reached epidemic proportions. Environmental factors may contribute to the increasing prevalence of obesity. To date, most of the studies assessing the relationship between weight and aspects of food environment have focused on residential neighborhood food environments.  On a daily basis, most individuals spend more time at work than at home; therefore, people are more exposed to the food availability of their worksite environments. The main goal of this project is to explore the impact of the proximity of food outlets to school environments and weight outcome, using elementary school employees in a suburban parish in southeastern Louisiana. We focused on school employees rather than students, because schools are also worksites.  In addition, schools have two well-defined food environments: inside (vending machines and cafeterias) and outside schools. A cross-sectional design will be used to associate the built environments and body mass index. Spatial and multilevel analysis will be utilized in order to explore the impact of predictors at the individual and environmental levels.",FALSE,FALSE,,FALSE,FALSE,FALSE,,contributedposter,,,,FALSE,FALSE,FALSE,FALSE,Spatial/temporal modeling,Hierarchical models,,,,,,,15-Nov-10,adunning@alumni.washington.edu,,Andrew J Dunning,,Sanofi Pasteur,PO Box 275,570 730 3214,,adunning@alumni.washington.edu,Experimental Designs for Post-Licensure Immunological Correlates of Protection,1,Andrew,J,Dunning,Sanofi Pasteur,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"With more stringent ethical standards making vaccine efficacy trials less favored, and the increasing number of different vaccines routinely administered, the need for reliable immunological correlates of protection - threshold levels of immunological assays associated with protection from clinical disease - has assumed increasing importance.  In particular, after a vaccine has been licensed, clinical trials to assess non-interference by concomitant administration of other vaccines, comparative non-inferiority trials, and studies to extend the indication to other populations, rely almost entirely on comparing proportions of subjects with immunological titers exceeding some threshold. Yet many established thresholds are based on opportunistic or haphazard scientific data and unsophisticated statistical methods.  We outline some studies and methods used in the past, and propose criteria, designs and methods for determining post-licensure immunological correlates of protection in a scientifically rigorous manner.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Biomarkers/surrogate markers,Clinical trials,,,,,,,15-Nov-10,aeloyan@jhsph.edu,,Ani Eloyan,Post Doctoral Fellow,Bloomberg School of Public Health Johns Hopkins Un,1101 Saint Paul St. apt 302,9196377187,,aeloyan@jhsph.edu,Bayesian Independent Component Analysis,1,Ani,,Eloyan,"Bloomberg School of Public Health, Johns Hopkins University",Sujit,K.,Ghosh,North Carolina State University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Independent component analysis has been used as a data reconstruction tool for blind source separation in many fields of statistics including signal processing, statistical genetics, neuroimaging, etc. The estimation is based on the assumption that the underlying sources are independent and as nongaussian as possible.  In this talk, a novel Bayesian approach to ICA is presented. A flexible set of gaussian mixture densities is used to specify priors for the densities of the underlying sources. To ensure that the model is fully identifiable a set of moment constraints on the mixture densities is used. In addition, the prior density of the mixing matrix is constructed to maintain the assumption that the mixing matrix is nonsingular. The method is compared with other source separation methods using simulated datasets. Finally, the performance of the method is illustrated using an fMRI data analysis example.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Bayesian methods,High dimensional data,,,,,,,11-Nov-10,aghoward@email.unc.edu,,Annie Green Howard,,University of North Carolina at Chapel Hill,439 Summerwalk Circle,(205)329-4169,,aghoward@email.unc.edu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,FALSE,FALSE,,FALSE,FALSE,FALSE,,,,,,FALSE,FALSE,FALSE,FALSE,,,,,,,,,14-Nov-10,aherring@bios.unc.edu,,Amy Herring,Associate Professor,UNC:  Chapel Hill,CB 7420,919-843-6368,,aherring@bios.unc.edu,Joint Modeling of High-Dimensional Epidemiologic Data,1,Amy,H.,Herring,UNC: Chapel Hill,David,B.,Dunson,Duke University,Andrew,F.,Olshan,UNC: Chapel Hill,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Although most implementations of logistic regression in epidemiology applications rely on maximum likelihood estimation, the MLE can perform poorly in settings involving high-dimensional and correlated predictors, motivating an increasingly rich literature on shrinkage methods, which place a penalty on large values of the coefficients.  These types of approaches have been used in many settings, including the study of risk factors for a wide variety of birth defects.  Because the cause of over 70% of birth defects is unknown, investigators often wish to evaluate large numbers of potential risk factors and interactions between these risk factors.  In most applications, including birth defects epidemiology, it is quite unlikely that most risk factors under study have a very large impact on the risk of a malformation.  We propose a nonparametric Bayes shrinkage structure that automatically accounts for multiplicities and dimensionality through an intrinsic Bayes correction via a hierarchical modeling structure.  We extend the method to allow borrowing of information across mechanistically related birth defects using a novel multi-task learning approach.  The method is applied to data from the National Birth Defects Prevention Study, the largest study of causes of birth defects in the United States.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Bayesian methods,Joint models for longitudinal and survival data,,,,,,,12-Nov-10,ajolly@emory.edu,,Anna Blackstock,,"Rollins School of Public Health, Emory University",2247 Cloverdale Drive SE,404-310-3580,,ajolly@emory.edu,Segmentation and Clustering of MS Features to Study Aging,1,Anna,,Blackstock,Emory University,Tianwei,,Yu,Emory University,Amita,,Manatunga,Emory University,Youngja,,Park,Emory University,Keith,,Mansfield,Harvard University,Quinlyn,,Soltow,Emory University,Dean,,Jones,Emory University,,,,,,,,,,,,,,FALSE,FALSE,,FALSE,FALSE,FALSE,,,,,,FALSE,FALSE,FALSE,FALSE,,,,,,,,,15-Nov-10,aklein25@uwo.ca,,Andreas G. Klein,Professor,Univ. of Western Ontario,"SSC, Dept. of Psychology",5196612111 82721,,aklein25@uwo.ca,A new approach for the analysis of surrogacy for dichotomous variables,1,Andreas,G,Klein,"Univ. of Western OntarioDept of Psychology",Holger,,Brandt,"Univ. of Western OntarioDept of Psychology",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"This paper proposes a procedure to analyze surrogacy that is based onpotential outcome notation. The concept of principal stratification isemployed to define surrogacy, and a parametric model is introduced.The procedure is based on a monotonicity assumption and provides aminimum estimate for a model parameter that represents surrogacy.Relationship of the procedure to a log-linear modeling framework isexplained. Sensitivity of violation of assumptions is brieflydiscussed, and an empirical example is presented.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Biomarkers/surrogate markers,Experimental design,,,,,,,12-Nov-10,alan@stat.duke.edu,,alan Gelfand,professor,Department of Statistical Science,Duke University,919-668-5229,,alan@stat.duke.edu,Point pattern modeling for degraded presence-only data over large spatial regions,1,Alan,E,Gelfand,"Dep't of Statistical Science, Duke University",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Explaining species distribution using local environmental features isa long standing ecological problem. Often, available data is collectedas a set of presence locations only thusprecluding the possibility of a presence-absence analysis. We proposethat it is natural toview presence-only data for a region as a point pattern over thatregion and to use localenvironmental features to explain the intensity driving this pointpattern. This suggestshierarchical modeling, treating the presence data as a realization ofa spatial point processwhose intensity is governed by environmental covariates. Spatialdependence in the intensitysurface is modeled with random effects involving a zero mean Gaussianprocess. Highlyvariable and typically sparse sampling effort as well as landtransformation degrades thepoint pattern so we augment the model to capture these effects. TheCape Floristic Region(CFR) in South Africa provides a rich class with such species data.The potential, i.e.,nondegraded presence surfaces over the entire area are of interestfrom a conservation andpolicy perspective.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Spatial/temporal modeling,Bayesian methods,,,,,,,14-Oct-10,alanh@uchicago.edu,,Alan Huang,,Graduate Student,200 W. Hill St,7738652875,,alanh@uchicago.edu,A Semiparametric Extension of Generalized Linear Models in the Multi-way Layout,1,Alan,,Huang,University of Chicago,Paul,J,Rathouz,University of Wisconsin-Madison,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"An exponential tilt regression model (Rathouz & Gao, 2009) is a semiparametric generalization of generalized linear models in which the error distribution is left as a completely unspecified infinite-dimensional parameter in the likelihood function. It will be shown that exponential tilt regression models for the multi-way layout can be implemented in practice via an empirical likelihood-type approach. The subsequent profile empirical likelihood provides a basis for asymptotically calibrated tests of parameters in the mean model, thereby extending the results of Fokianos et. al. (2001). Small-sample simulations and examples demonstrate that exponential tilt regression models can be a flexible and robust alternative to classical generalized linear models for data analysis.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Empirical likelihood,Generalized linear models,,,,,,,10-Nov-10,albertp@mail.nih.gov,,Paul S. Albert,,Eunice Kennedy Shriver National Institute of Child,6100 Executive Blvd room 7B05F,3014965582,,albertp@mail.nih.gov,Estimating Diagnostic Accuracy from Designs with no Gold Stand,1,Paul,S,Albert,"Biostatistics and Bioinformatics BranchEunice Kennedy Shriver National Institute of Child Health and Human Development",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Interest often focuses on estimating sensitivity and specificity of a group of raters or a set of new diagnostic tests in situations where gold standard evaluation is invasive or expensive. In a typical situation a group of raters or a series of diagnostic tests assess disease status on a group of individuals. For situations in which no gold standard evaluation is available, various authors have proposed latent class modeling approaches for estimating diagnostic accuracy and prevalence. We demonstrate that these approaches lack robustness to the assumed model for the conditional dependence between tests and it is difficult to distringuish between these different models in practical situtions. As an alternative to modeling without a gold standard, we show that incorporating gold standard information on even a small percentage of individuals or using an imperfect reference standard with estimated values of sensitivity and specificity improves inferences substantially.. We illustrate the methodological work with examples from published medical studies.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Diagnostic and screening tests,Latent variables,,,,,,,15-Nov-10,alexaj@umich.edu,,Alexandra Jauhiainen,Dr,"Department of Statistics, University of Michigan",439 West Hall,734-3557464,,alexaj@umich.edu,Transcriptional and Metabolic Data Integration and Modeling for Pathway Identification,1,Alexandra,,Jauhiainen,"Department of Statistics,University of Michigan,Ann Arbor, MI,USA",Olle,,Nerman,"Chalmers University of Technology and the University of Gothenburg,Gšteborg,Sweden",George,,Michailidis,"Department of Statistics,University of Michigan,Ann Arbor, MI,USA",Rebecka,,Jšrnsten,"Chalmers University of Technology and the University of Gothenburg,Gšteborg,Sweden",,,,,,,,,,,,,,,,,,,,,,,,,"With the growing availability of 'omics' data generated to describedifferent cells and tissues, the modeling and interpretation of suchdata has become increasingly important. Pathways are sets of reactionsinvolving genes, metabolites, and proteins highlighting functionalmodules in the cell. Therefore, to discover activated or perturbedpathways when comparing two conditions, for example two differenttissues, it makes sense to use several types of 'omics' data. Wepresent a model that integrates transcriptomic and metabolomic data inorder to make an informed pathway level decision.  We view the geneexpression data as explanatory for the metabolite data model, sincemetabolites can be seen as end-points of perturbations happening atthe gene level. With real data, we show that the transcript profilescan be used to explain the metabolite data, and with simulations thatthe proposed model offers a better performance in identifying activepathways than for example enrichment methods performed separately onthe transcript and metabolite data.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,High dimensional data,Variable subset selection/model selection,,,,,,,12-Nov-10,anainesvs@gmail.com,,Ana Ines,,"University of Alabama at Birmingham, SSG",1665 University Boulevard,2059759268,,anainesvs@gmail.com,Whole genome enabled prediction of liability to cancer related outcomes,1,Ana,I,Vazquez,"University of Alabama, Birmingham, SSG",Gustavo,,de los Campos,"University of Alabama, Birmingham, SSG",Guilherme,J.M.,Rosa,"University of Wisconsin, Madison",Daniel,,Gianola,"University of Wisconsin, Madison",Yann,C.,Klimentidis,"University of Alabama, Birmingham, SSG",Kent,A.,Weigel,"University of Wisconsin, Madison",David,B.,Allison,"University of Alabama, Birmingham, SSG",,,,,,,,,,,,,"Many studies attempt to develop models for predicting complex humantraits and diseases using genetic markers. Commonly, a predictivemodel includes a small number of markers with stringent cut-offs forp-values from single marker regression. This is based on theassumption that genetic predisposition is controlled by a small numberof genes. However, it is inappropriate for complex traits, since thesemay be affected by a large number of small-effect genes. A predictivemodel for cancer liability was constructed, in which thousands ofmarkers were fit concurrently. Data from the Framingham Heart Studywere fitted with standard covariates only, or the latter plus 40,000SNP markers. Bayesian regression models were employed. Predictiveability was evaluated by measuring false and true positive rates, areaunder the receiver operating characteristic curve (AUC), precision,sensitivity and specificity. Predictive ability increased when markerswere included in the model. The increment of the AUC incross-validation obtained by including markers ranged from 5 to 29%depending on the trait and regression model. These results indicatethat certain components of genetic predisposition to cancer can bepredicted using dense genetic markers; and that it is possible tosignificantly improve predictive ability for cancer liability usinggenotypes.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Statistical genetics,High dimensional data,,,,,,,12-Nov-10,ana-maria_staicu@ncsu.edu,,Ana-Maria Staicu,,Department of Statistics,2311 Stinson Drive,919 469 1804,,ana-maria_staicu@ncsu.edu,Skewed Functional Processes and their Applications,1,Ana-Maria,,Staicu,"Department of Statistics, North Carolina State University, NC",Ciprian,M,Crainiceanu,,Danniel,,Reich,,David,,Ruppert,,,,,,,,,,,,,,,,,,,,,,,,,,"We propose a novel class of models for the analysis of functional data that displayspatially heterogeneous skewness. These models generalize the Karhunen-Loeve expansion, provide an inferential framework for estimating potentially asymmetric marginal quantiles, and are computationally feasible. More importantly, they provide a new set of tools for increasingly complex data collected in medical and public health studies. Our methods were motivated by and applied to a state-of-the-art study of neuronal tracts in multiple sclerosis patients and healthy controls. However our models are general and willbe relevant to data sets where the object of inference are functions, which have distributional shape characteristics that vary across point locations.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Functional data analysis,Longitudinal data,,,,,,,14-Nov-10,ananda@math.asu.edu,,Anandamayee,,Arizona State University,7421 Frankford Rd 2822,2145565486,,ananda@math.asu.edu,A generalized convolution model for multivariate spatial models,1,Anandamayee,,Majumdar,Arizona State University,Debashis,,Paul,U. C. Davis,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We examine a flexible class of nonstationary stochastic models formultivariate spatial data. This covariance model is based onconvolutions of spatially varying covariance kernels with centerscorresponding to the centers of ``local stationarity'. A Bayesianmethod for estimation of the parameters in the model based on a Gibbssampler is applied to simulated data to check for model sensitivity.The effect of a perturbation of the model in terms of kernel centersis also examined. Finally, the method is applied to a bivariate soilchemistry data. Prediction bias, prediction standard deviation andpredictive coverage are examined for different candidate models. Inaddition, a comparison with the bivariate stationary coregionalizationmodel introduced by {Wackernagel (2003) is carried out. A variant ofthe model with random kernel centers, is examined. Cross validationcan be used as a way of finding the best model with an appropriatenumber of kernels.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Spatial/temporal modeling,Bayesian methods,,,,,,,15-Nov-10,anb61@pitt.edu,,Andriy Bandos,Assistant Professor,"Department of Biostatistics, University of Pittsbu",312 Parran Hall,412 3835738,,anb61@pitt.edu,Calibration of ROC curves in multireader studies,1,Andriy,,Bandos,"Department of Biostatistics, Graduate School of Public Health, University of Pittsburgh",Howard,E,Rockette,"Department of Biostatistics, Graduate School of Public Health, University of Pittsburgh",David,,Gur,"Department of Radiology, School of Medicine, University of Pittsburgh",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Receiver Operating Characteristics (ROC) analysis is a conventional approach for analyzing performance assessment studies in many fields. Many of these studies include multiple readers, centers or other similar constructs, the performance characteristics of each of which is summarized in an overall analysis. These analyses often require an assumption (frequently implicit) of the specific calibration mechanism for determining which points on reader-specific curves are combined in order to obtain a point on the overall ROC curve.           Ideally the adopted calibration method should yield a practically interpretable ROC curve which summarizes change in performance characteristics of readers in response to specific changes in diagnostic conditions. Currently, calibration assumptions are frequently used without due considerations of relevance or consequences of their misspecification. Neither of the common assumptions is appropriate for all scenarios, and misspecification of the adopted calibration could substantially affect conclusions.           We discuss several calibration mechanisms that are implied by the conventional approaches, and formulate additional practically plausible calibrations. For these unconventional calibration approaches we develop methods of analysis based on the area under the overall ROC curve (AUC). We investigate the impact of misspecification of the calibration approach on AUC-based inferences using empirical data and a simulation study.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,ROC analysis,Diagnostic and screening tests,,,,,,,20-Oct-10,andraca@gmail.com,,Eugenio Andraca-Carrera,,FDA,10903 New hamsphire Avenue B21 R4673,3017960825,,andraca@gmail.com,This is a test,1,Eugenio,,Andraca-Carrera,This is a test,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,This is a test,FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Adaptive design/adaptive randomization,Agreement,,,,,,,12-Nov-10,andrei@biostat.wisc.edu,,Adin-Cristian Andrei,Assistant Professor,University of Wisconsin-Madison,600 Highland Avenue,608-263-6797,,andrei@biostat.wisc.edu,Gap time modeling using pseudo-values with an application to breast cancer,1,Adin-Cristian,,Andrei,University of Wisconsin-Madison,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In numerous medical studies, participants may experience a succession of landmark events. In cystic fibrosis, repeated pulmonary exacerbation episodes are an example of same-type events. In a cancer clinical trial, a sequence consisting of therapy initiation time, end of the toxicity period (TOX), end of the disease-free period (DF) and death represents a series of different-type events. Regardless of the event nature, the inter-event times are usually referred to as gap times. Conditional  modeling of the gap times is oftentimes challenging and practical implementation in mainstream statistical packages is not easily available. We propose a flexible, computationally efficient modeling strategy based on jackknife pseudo-observations (POs). This construct requires an (approximately) unbiased nonparametric estimator for the joint distribution of the gap times. In essence, the problem is translated into the more accommodating realm of generalized linear models. Simulation studies show that the method proposed produces virtually unbiased covariate effect estimates, even for moderate sample sizes. A breast cancer trial example further illustrates the practical advantages of this new approach.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Survival analysis,Applied data analysis,,,,,,,15-Oct-10,ann_mwangi@brown.edu,,Ann,,Brown University,Box G-S121-7,4018639243,,ann_mwangi@brown.edu,"Causal Inference for Survival Times with Informative Censoring & Missing Exposure, with Application to Treatment of TB/HIV Coinfection in Western Kenya",1,Ann,W,Mwangi,"Brown University, Providence RI and Moi University School of Medicine, Eldoret, Kenya",Joseph,W,Hogan,"Brown University, Providence RI",Rami,,Kantor,"Brown University, Providence RI",Jane,,Carter,"Brown University, Providence RI",Abraham,,Siika,"Moi University School of Medicine, Eldoret, Kenya",,,,,,,,,,,,,,,,,,,,,"Timing of initiation of combination anti-retroviral treatment (cART)is a major concern for patients co-infected with HIV and TB. Data fromrandomized trials are still limited. We use observational data from alarge cohort of HIV/TB co-infected patients in Western Kenya toquantify the causal effect of cART initiation time on one-year mortality. Complications associated with observational data include nonrandomallocation totreatment and informative drop out.  Dropout in our cohort led tocensoring of exposure, outcome, or both. We grouped patients into 5categories of cART initiation time: (0,2], (2,8], (8,16], (16,35] and35+ weeks; a marginal structural proportional hazards model is used toestimate causal effects of cART timing.  Inverse probability weightingadjusts for nonrandom allocation of cART timing and informativedropout.  To handle censored exposure times we propose asemiparametric imputation strategy. Data on 4908 HIV/TB co-infected adults are analyzed; we find thattiming of cART has a pronounced causal effect on mortality:  relativeto starting cART in (0,2], hazard of death ranges from 1.1 for (2,8]up to 2.0 for 35+.   Standard Cox regression gives opposite results;however, inferences from our model agree with recent randomizedtrials.  Our imputation method incorporates data on 1060 individualswith censored cART initiation times.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Causal inference,Survival analysis,,,,,,,14-Oct-10,Annalisa.VanderWyden@case.edu,,Annalisa VanderWyden Piccorelli,,Case Western Reserve University,515 North Rocky River Drive,4404524827,2163684223,Annalisa.VanderWyden@case.edu,Joint modeling the relationship between longitudinal and survival data subject to left truncation with applications to cystic fibrosis,1,Annalisa,,VanderWyden Piccorelli,Case Western Reserve University,Mark,D,Schluchter,Case Western Reserve University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Methods for joint analysis of longitudinal measures of a continuous outcome y and a time-to-event outcome T have recently been developed either to focus on the longitudinal data y while correcting for nonignorable dropout, to predict the survival outcome T using the longitudinal data y, or to examine the relationship between y and T. The motivating problem for our work is in joint modeling the serial measurements of pulmonary function (FEV1 % predicted) and survival in cystic fibrosis (CF) patients using registry data, where an additional complexity is that some patients have not been followed from birth, and thus their survival times are left truncated. We assume a linear random effects model for FEV1 % predicted, where the random intercept and slope of FEV1 % predicted, along with a specified transformation of the age at death follow a trivariate normal distribution. We develop an EM algorithm for maximum likelihood estimation of parameters, which takes left truncation as well as right censoring of survival times into account. The methods are illustrated using simulation studies and using data from CF patients in a registry followed at our institution.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Joint models for longitudinal and survival data,Longitudinal data,,,,,,,15-Nov-10,annie.lin@duke.edu,,Min Annie Lin,Assistant Professor,Duke University,"2424 Erwin Road, Suite 1102",919-668-4602,919-668-5888,annie.lin@duke.edu,On Center Grouping in Multicenter Clinical Trials,1,Min,A.,Lin,Duke University,Tsung-Cheng,,Hsieh,National Taiwan University,Shein-Chung,,Chow,Duke University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"A multicenter trial is often conducted to expedite the patient recruitment process to accrue sufficient number of patients in order to achieve a desired power within a pre-determined time frame in clinical development. In practice, however a multicenter trial with too many centers may result in a number of small centers after the completion of the study. Treatment imbalance (unequal number of patients per arm within a center) and center imbalance (unequal number of patients per center) will certainly decrease the desired power of the intended study. In addition, too many small centers may increase the chance of observing a significant treatment-by-center interaction. As a result, no overall conclusion regarding the treatment effect can be drawn. In this case, it is necessary to perform center grouping to obtain valid statistical inference on the treatment effect. In this paper, we not only propose a rule of thumb for selection of the number of centers, but also examine the impact of treatment and center imbalance in terms of power. In addition, a procedure for center grouping based on the relative improvement of power is proposed. An example is given to illustrate the proposed method for center grouping.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Clinical trials,Experimental design,,,,,,,27-Oct-10,anniequ@illinois.edu,,Annie Qu,Associate Professor,University of Illinois at Urbana-Champaign,307 Pond Ridge Ln,217-244-8334,217-244-7190,anniequ@illinois.edu,Variable selection in high dimensional varying coefficient models with global optimality,2,Lan,,Xue,Oregon State University,Annie,,Qu,University of Illinois at Urbana-Champaign,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The varying coefficient model is flexible and powerful for modeling thedynamic changes of regression coefficients. Here the response variablesdepend on covariates through linear regression, but the regressioncoefficients can vary and are modeled as a nonparametric function of otherpredictors. It is important to identify significant covariates associatedwith response variables, especially for high dimension setting where thenumber of covariates can be larger than the sample size, but the number ofsignal terms is relatively smaller than the sample size. We consider modelselection in such setting and adopt difference convex programming toapproximate the L0 penalty, and investigate global optimality propertiesof the varying coefficient estimator. The challenge of the variableselection problem here is that the dimension of the nonparametric form forthe varying coefficient modeling could be infinite, in addition to dealingwith the high-dimensional linear covariates. We show that the proposedvarying coefficient estimator is consistent, enjoys the oracle property andachieves an optimal convergence rate for the non-zero nonparametriccomponents for high-dimensional data. Oursimulations and numerical examples indicate that the difference convexalgorithm is extremely efficient and effective using the coordinate decentalgorithm compared to the SCAD aproach.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Variable subset selection/model selection,High dimensional data,,,,,,,15-Nov-10,ar2946@columbia.edu,,Arindam,Assistant Professor,Columbia University,"722 W 168th St., 6th Floor",607-262-6261,,ar2946@columbia.edu,"Composite Likelihood Estimation with Dependent Loci, and Its Application to Forensic Genetics",1,Arindam,,RoyChoudhury,"Department of Biostatistics, Columbia University",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In a sample of individuals, the allele counts in nearby genetic lociare usually not independent of each other. However, in somestatistical analyses are made simpler if the allele-counts are treatedas independent data points. One such example arises from forensic genetics. Suppose that we aretesting for the presence of an individuals DNA from a pool of mixtureof DNA. Here one can do a likelihood test using independent markerloci only. However, the power would increase considerably if all(potentially dependent) marker loci are considered.We present an approach where we treat the dependent loci asindependent (ignoring their dependence), and compute a compositelikelihood for this setup. We outline two composite likelihood basedlarge sample tests. These tests have better power than properlikelihood based tests, as they are able to use many more data points. We will also present a modification of our methods for missing data.This modification will make our method directly applicable to theforensic genetics problem mentioned above.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Genomics,Estimating equations,,,,,,,15-Nov-10,arijit.sinha1981@gmail.com,,Arijit Sinha,,PhD Student,Department of Statistics,8603672574,,arijit.sinha1981@gmail.com,Bayesian Semiparametric Inference of Nonproportional Hazard Models with Gamma Process prior,1,Arijit,,Sinha,"Department of Statistics, University of Connecticut",Ming-Hui,,Chen,"Department of Statistics, University of Connecticut",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"For fitting right-censored survival data, we may face situations whenthe proportionality assumption of the hazard ratiosin the Cox's regression model is not appropriate.One way to remedy this problem is to consider a nonproportional hazards regression model.Recently, a class of nonproportional hazards models known as generalized odds-rate class has been discussed in Banerjee et al. (2007) under the Bayesian framework.We investigate the properties of this new class of models when the prior distribution of the baseline cumulative hazard function is a Gamma process.The Conditional Predictive Ordinate (CPO) based Bayesian measure is derived for these complex modelswith Gamma process prior. A new Gibbs sampling algorithm via several sets of latent variables is developed to carry out all posterior computations.Analysis of the data from a prostate cancer study shows that the new class of models performs better than Cox's model under the same Bayesian set up.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Survival analysis,Bayesian methods,,,,,,,15-Nov-10,armins@hsph.harvard.edu,,Armin Schwartzman,Assistant Professor,Harvard School of Public Health,Dana-Farber Cancer Institute,617-632-2466,,armins@hsph.harvard.edu,Empirical null and false discovery rate analysis in neuroimaging,1,Armin,,Schwartzman,Harvard School of Public Health,Robert,F,Dougherty,Stanford University,Jongho,,Lee,National Institutes of Health,Dara,,Ghahremani,"University of California, Los Angeles",Jonathan,E,Taylor,Stanford University,,,,,,,,,,,,,,,,,,,,,"Current strategies for thresholding voxelwise statistical parametricmaps in neuroimaging include control of the family-wise error rate andcontrol of the false discovery rate. Correct inference using any ofthese criteria depends crucially on the specification of the nulldistribution of the test statistics. We show examples from fMRI andDTI data where the theoretical null distribution does not match wellthe observed distribution of the test statistics. As a solution, weintroduce the use of an empirical null, a null distributionempirically estimated from the data itself, allowing for globalcorrections of theoretical null assumptions. The theoretical nulldistributions considered are normal, t, chi square and F, all commonlyencountered in neuroimaging. As in its original application togenomics, the empirical null estimate is accompanied by an estimate ofthe proportion of non-active voxels in the data and an estimate of thefalse discovery rate for all thresholds.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Multiple testing,Imaging,,,,,,,12-Nov-10,asano-junichi@pmda.go.jp,,Junichi Asano,,"Pharmaceuticals and Medical Devices Agency, Japan",asano-junichi@pmda.go.jp,+81-3-3506-9456,+81-3-3506-9461,asano-junichi@pmda.go.jp,Covariate Selection Method in Mixture Cure Model for Survival Data,1,Junichi,,Asano,"Biostatistics Group, Center for Product Evaluation, Pharmaceuticals and Medical Devices Agency, Japan",Akihiro,,Hirakawa,"Biostatistics Group, Center for Product Evaluation, Pharmaceuticals and Medical Devices Agency, Japan",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"A mixture cure model which is a survival model incorporating a cure fraction assumes that the population is mixture of uncured and cured individuals. In the mixture cure model, Cox proportional hazards model (PHM) and logistic regression model (LRM) are frequently used to estimate covariate effects for hazard of uncured individuals and for cured probability, respectively. We develop a method of covariate selection for PHM and LRM in the mixture cure model using Akaike information criteria. The performance of the proposed method was examined based on the probability of selecting true model through simulation studies. According to the results of simulation studies, the proposed method achieved fairly high probability of selecting the true model. The probability of selecting the true model when assuming exponential distribution to survival distribution was better than that when assuming the log-logistic and log-normal distribution. The application of the proposed method to real data was presented.",FALSE,FALSE,,FALSE,FALSE,FALSE,,contributedposter,,,,FALSE,FALSE,FALSE,FALSE,Survival analysis,Variable subset selection/model selection,,,,,,,12-Nov-10,ashok.panneerselvam@novartis.com,,Ashok Panneerselvam,Senior Biostatistician,Novartis Pharmaceuticals Corporation,6302 Wynbrook Dr,8627786925,,ashok.panneerselvam@novartis.com,A Joint Model of Longitudinal Data and Time to Event Data with Latent Subclasses,1,Ashok,,Panneerselvam,Novartis Pharmaceuticals Corporation,Mark,D,Schluchter,Case Western Reserve University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"A joint model to analyze longitudinal data and time to event data in the presence of latent subclasses is developed.  In the model, the probability of a subject to be in a latent subclass is modeled using a logit function, and the longitudinal data are modeled using separate linear mixed effects model for each latent subclass.  In each latent subclass the random effects of the longitudinal data and a suitable transformation of time to event is assumed to have a multivariate normal distribution. EM algorithm is formulated to estimate the parameters of the model and the standard errors are obtained from bootstrapping and numerical methods. The application of the model is presented on an example dataset. The BIC criterion is used for model selection between a joint model with no latent subclasses and a joint model with two latent subclasses.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Joint models for longitudinal and survival data,Longitudinal data,,,,,,,27-Sep-10,ashokkrish@gmail.com,,Ashok Krishnamurthy,Postdoctoral Researcher,University of Colorado at Denver,"1175 Albion St., Apt 409",7202896494,,ashokkrish@gmail.com,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,FALSE,FALSE,,FALSE,FALSE,FALSE,,,,,,FALSE,FALSE,FALSE,FALSE,,,,,,,,,11-Nov-10,asnavely@hsph.harvard.edu,,Anna Snavely,,Harvard University,"Department of Biostatistics, Harvard School of Public Health",336-207-0479,,asnavely@hsph.harvard.edu,Semiparametric Latent Variable Transformation Models for Multiple Outcomes,1,Anna,,Snavely,Harvard University,Yi,,Li,Harvard University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Often there are multiple intracorrelated outcomes of varying typesavailable and of interest in a given setting, rather than a singleprimary outcome.  Particularly in the biomedical area, a survival time(or other failure time) is frequently one of such outcomes. When we dohave multiple outcomes, we would like to use all of the informationprovided in those outcomes in order to make some conclusion, orprovide additional information, about a treatment or some othercovariate.  In this paper we propose a semiparametric latent variablenormal transformation model that allows for the estimation of atreatment (or other covariate) effect in the presence of multipleoutcomes, including failure times.  Multiple outcomes in this modelare assumed to be governed by an unobserved (latent) variable, whichin turn may depend on covariates such as treatment.  As an extensionof traditional latent variable approaches, our method allows therelationship between the outcomes and latent variables to beunspecified and allows for outcomes of mixed types which includesaccounting for potentially censored outcomes.  The method is appliedto a study of head and neck cancer patients from Dana-Farber CancerInstitute in which multiple outcomes are available to characterizedysphagia.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Multivariate methods,Latent variables,,,,,,,05-Nov-10,astephen@hsph.harvard.edu,,Alisa Stephens,,Graduate Student,655 Huntington Ave,201-294-6331,,astephen@hsph.harvard.edu,Augmented GEE for efficiency improvement in cluster randomized trials by leveraging individual- and cluster- level covariates,1,Alisa,J,Stephens,Harvard School of Public Health,Eric,J,Tchtegen Tchetgen,Harvard School of Public Health,Victor,G,DeGruttola,Harvard School of Public Health,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Recent methodological advances in covariate adjustment in RCTs haveused semiparametric theory to improve efficiency of inferences byincorporating baseline covariates; these methods have focused onindependent outcomes.  We modify one of these approaches, augmentationof standard GEE estimators, for use within cluster randomized trialsin which treatments are assigned to groups of individuals, therebyinducing correlation.  We demonstrate the potential for imbalancecorrection and efficiency improvement through consideration of bothcluster- and individual-level covariates.  To improve small-sampleestimation, we consider several variance adjustments.  We evaluatethis approach for continuous and binary outcomes through simulation,and apply it to data from a cluster randomized trial of a communitybehavioral intervention related to HIV prevention in Tanzania.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Clustered data methods,Clinical trials,,,,,,,03-Nov-10,atamhane@northwestern.edu,,Ajit C. Tamhane,Professor,Northwestern University,Department of IEMS,847-491-3577,847-491-8005,atamhane@northwestern.edu,Mixture Gatekeeping Procedures with Clinical Trial Applications,1,Ajit,C,Tamhane,Northwestern University,Alex,,Dmitrienko,Eli Lilly,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Gatekeeping procedures address the problems of testing hierarchically ordered and logically related null hypotheses that arise in clinical trials involving multiple endpoints, multiple doses, noninferiority-superiority tests, subgroup analyses etc. Recently, Dmitrienko and Tamhane (2010) proposed a powerful method for constructing these procedures, called the mixture method. This talk will review this method and give examples of its applications in clinical trials.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Multiple testing,Clinical trials,,,,,,,25-Oct-10,azhou@uw.edu,,Xiao-Hua Andrew Zhou,Professor,"Department of Biostatistics, University of Washing",1705 Pacific Street,2062773588,,azhou@uw.edu,Evaluation of Diagnostic Accuracy in Detecting Ordered Symptom  Statuses in Absent of a Gold Standard,1,Xiao-Hua,A,Zhou,"Department of BiostatisticsUniversity of Washington",Zheyu,,Wang,"Department of BiostatisticsUniversity of Washington",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Our research is motivated by two methodological problems inassessing diagnostic accuracy of traditional Chinese medicinedoctors in detecting a particular symptom whose true status has an ordinal scale and is unknown - imperfect gold standard bias and ordinal-scale symptom status.  In this talk, we propose a nonparametric maximum likelihood method for estimating and comparing the accuracy of different doctors in detecting a particular symptom without a gold standard when the true symptom  status had an ordered multiple-class.  In addition, we extended the concept of the area under the ROC curve (AUC) to a hyper-dimensional overall accuracyfor diagnostic accuracy and alternative graphs for displaying avisual result.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,ROC analysis,Missing data,,,,,,,15-Nov-10,b.saville@vanderbilt.edu,,Benjamin Saville,,Vanderbilt University School of Medicine,S-2323 Medical Center North,615-343-3624,,b.saville@vanderbilt.edu,Estimating Covariate-Adjusted Incidence Density Ratios for Multiple Time Intervals in Clinical Trials using Nonparametric Randomization Based ANCOVA,1,Benjamin,,Saville,Vanderbilt University School of Medicine,Lisa,,LaVange,University of North Carolina at Chapel Hill,Gary,,Koch,University of North Carolina at Chapel Hill,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Current methods for estimating incidence density ratios acrossmultiple intervals with covariate/stratification adjustment generallyrely on strong parametric assumptions regarding underlyingdistributions.  Some nonparametric methods exist for such settings,but these methods focus on incidence densities for each patientseparately and have the limitation of not taking into account theextent to which some patients provide more information than others. Alternatively, the proposed nonparametric methodology captures themean number of events and the mean person-time for each time intervalfor each treatment group within each stratum, together with the meanfor the vector of covariables and the corresponding covariance matrix. After stratum adjustment, nonparametric randomization based ANCOVA isapplied to produce covariate-adjusted estimates for the log incidencedensity ratios through forcing the difference in means for covariablesto zero.  Such covariance adjustment can be invoked either directlyfor the log incidence density ratios, or for thestratification-adjusted mean number of events and mean person-time,from which the log incidence density ratios are determined.  Themethod is illustrated on exacerbation data from a clinical trial ofchronic lung disease.",FALSE,FALSE,,FALSE,TRUE,TRUE,T5: Essentials for Success in Research,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Biopharmaceutical research,Clinical trials,,,,,,,08-Nov-10,bandyopd@musc.edu,,Dipankar Bandyopadhyay,,Assistant Professor,"135 Cannon Street, Ste 303",8438761603,8438761126,bandyopd@musc.edu,A zero-inflated Markov random field model with applications to asthma mortality,1,Dipankar,,Bandyopadhyay,"Division of Biostatistics and Epidemiology, Medical University of South Carolina, Charleston, SC 29425",Luis,E.,Nieto-Barajas,"Department of Statistics, ITAM, Mexico",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In this talk, we introduce a novel discrete Gamma Markov random field (MRF) prior for modeling spatial relations among regions in geo-referenced health data. Our propositionis incorporated into a generalized linear mixed model zero-inflated Poisson (ZIP) framework that accounts for excess zeroes not explained by usual Poisson assumptions. The ZIP framework categorizes subjects into low-risk and high-risk groups. Zeroes arising from the low-risk group contributesto structural zeroes, while the high-risk members contributes to random zeroes. We aim to identify explanatory covariates that might have significant effect on (i) the probability of subjects in low-risk group, and (ii) intensity of the Poisson risk, given that subjects are from the high-risk group, after controlling for spatial association and subject-specific heterogeneity. Model fitting and parameter estimation are carried out in a Bayesian paradigm through Markov chain Monte Carlo (MCMC) schemes. Simulation studies and application to a real data on ambulatory asthma compares our model fit with the widely used conditionally autoregressive (CAR)propositions.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Bayesian methods,Hierarchical models,,,,,,,14-Nov-10,baner009@umn.edu,,Sudipto Banerjee,Associate Professor,University of Minnesota,"420 Delaware St SE, MMC-303",612-624-0624,612-626-0660,baner009@umn.edu,On hierarchical modeling strategies for large spatial datasets,1,Sudipto,,Banerjee,University of Minnesota,Andrew,O.,Finley,Michigan State University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We discuss Bayesian hierarchical statistical methods for modelingrelationships among health outcomes and atmospheric and climatepredictors for large spatially referenced datasets. We accommodatedisparate sources and types of spatial-temporal data for modelingexposure, climate and health outcome data that integrates methods forpoint-level spatially misaligned data and change of support regressionusing Bayesian hierarchical spatial models. We show how dimensionreducing stochastic processes (the predictive process andmodifications thereof) can be embedded within hierarchical models toachieve our analytical goals. Illustrations will be provided withoutcomes such as asthma hospitalizations and incidence of non-melanomaskin cancer.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Spatial/temporal modeling,Bayesian methods,,,,,,,19-Oct-10,banerjee@temple.edu,,Bhramori Banerjee,Graduate Student,Temple University,70 Holly Court,609-672-7602,,banerjee@temple.edu,On Controlling Pairwise-False Discovery Rate,1,Bhramori,,Banerjee,Temple University,Sanat,K,Sarkar,Temple University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Sarkar (2008) proposes controlling the pairwise false discovery rate(Pairwise-FDR), which inherently takes into account the dependenceamong the p-values, thereby making it a more robust, less conservativeand more powerful under dependence than the usual notion of FDR. Amethod that controls the Pairwise-FDR for independent or positivelydependent p-values was suggested in that paper. In this paper, wefurther investigate the performance of Pairwise-FDR under a dependentmixture model where  the correlation between any two p-value is thesame (exchangeable). We consider a step-up method to control thePairwise-FDR under this model, and suggest improving this method byincorporating an estimate of the number of pairs of true nullhypotheses developed under this model.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Multiple testing,High dimensional data,,,,,,,13-Nov-10,banks@stat.duke.edu,,David Banks,Professor,Duke University,"Dept. of Stat. Science, Box 90251",919-684-3743,,banks@stat.duke.edu,Panel on Research Ethics,1,David,,Banks,"Dept. of Statistical Science, Duke University",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"I am part of a panel of research ethics.  As a panelist, I don'treally have an abstract.  But I shall be prepared to discuss some ofthe recent history in this area, and issues that arise across manysituations.",FALSE,FALSE,,FALSE,TRUE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Other,Clinical trials,ethics,,,,,,28-Oct-10,baojiang.chen@unmc.edu,,Baojiang Chen,,University of Nebraska Medical Center,984357 Nebraska Medical Center,402-559-8407,,baojiang.chen@unmc.edu,Doubly Robust Estimates for Binary Longitudinal Data Analysis with Missing Response and Missing Covariates,1,Baojiang,,Chen,"Department of Biostatistics, College of Public Health, University of Nebraska Medical Center",Xiao-Hua,,Zhou,"Department of Biostatistics, University of Washington",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Longitudinal studies often feature incomplete response and covariatedata. Likelihood-based methods such as the EM algorithm give consistentestimators for model parameters when data are missing at random provided that the responsemodel and the missing covariate model are correctly specified; butwe do not need to specify the missing data mechanism. An alternative method is the weightedestimating equation which gives consistent estimators if the missingdata and response models are correctly specified; but we do not need to specify the distribution of thecovariates that have missing values. In this paper we develop a doubly robustestimation method for longitudinal data with missing response andmissing covariate when data are missing at random. This method isappealing in that it can provide consistent estimators if either themissing data model or the missing covariate model is correctlyspecified. Simulation studies demonstrate that this method performswell in a variety of situations.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Missing data,Longitudinal data,,,,,,,12-Nov-10,bc2425@columbia.edu,,Bibhas Chakraborty,Assistant Professor,Columbia University,"722 W 168th Street, 6th Floor",2123059107,,bc2425@columbia.edu,Estimating Optimal Dynamic Treatment Regimes with Shared Decision Rules across Stages: An Extension of Q-learning,1,Bibhas,,Chakraborty,Columbia University,Erica,,Moodie,McGill University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Dynamic treatment regimes (DTRs) are individually tailored treatments.They offer a framework to operationalize the adaptive multistagedecision making in clinical practice, thus providing an opportunity toimprove such decision making. Formally, a DTR is a set of decisionrules, one per stage; each decision rule takes a patient's treatmentand covariate history as input, and outputs a recommended treatment.In some studies, these decision rules are shared across stages oftreatment, i.e. the decision rule at each stage is the same functionof the history available at that stage. Because of this sharingphenomenon, recursive methods like Q-learning that move backwardthrough stages are not suitable; simultaneous estimation techniquesare necessary. In this paper, we propose a novel simultaneousestimation procedure for the optimal DTR with shared decision rules,adjusting for non-regularity via thresholding. We compare theperformance of the proposed method to other approaches throughextensive simulations. Finally, we apply our proposed method toanalyze data from a clinical trial on depression.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Causal inference,Clinical trials,,,,,,,28-Oct-10,bcaffo@jhsph.edu,,Brian S Caffo,Associate Professor,Johns Hopkins University Department of Biostatisti,615 N Wolfe Street,410.955.3504,,bcaffo@jhsph.edu,Indirect estimation of kinetic parameters in dual isotope single photon emission computed tomography studies of microbicide lubricants,1,Brian,S,Caffo,Johns Hopkins University Department of Biostatistics,Jeffrey,,Goldsmith,Johns Hopkins University Department of Biostatistics,Craig,,Hendrix,Johns Hopkins University Department of Medicine,Ciprian,,Crainiceanu,Johns Hopkins University Department of Biostastics,,,,,,,,,,,,,,,,,,,,,,,,,"We consider the problem of indirect estimation of kinetic parameters for in vivo investigations of microbicide lubricants. The lubricants are imaged using single photon emission computed tomography (SPECT) with accompanying X-ray computed tomographic imaging. The experiment considers two isotopes; one a surrogate for the lubricant with the other representing seminal fluid. Novel registration, curve fitting and tube estimation methods are introduced to estimate distance by concentration curves. Intricacies involving scanner physics and imaging limitations will be discussed along with statistical solutions.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Imaging,Pharmacokinetic/pharmacodynamics (PK/PD) modeling,,,,,,,11-Nov-10,berge319@umn.edu,,Tracy L Bergemann PhD,Assistant Professor,University of Minnesota,"A460 Mayo Building, MMC 303",612-625-9142,,berge319@umn.edu,Case-Parent Triad Studies of Genetic Association and Gene-Gene Interaction in the Presence of Missing Data,1,Tracy,L,Bergemann,"Division of Biostatistics, School of Public Health, University of Minnesota",Matt,,Deyo-Svendsen,University of Minnesota Medical School  Duluth Campus,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Triad genotypes are analyzed with a variety of available methods, butwe use log-linear models because they test for genetic association and estimate the relative risks of transmission. Our research addressestwo concerns, (1) accounting for missing data without inflating type Ierror and (2) correcting bias when triad genotype combinations havezero counts.  We perform a Multinomial-Poisson transformation and thenoptimize a trimmed likelihood.  Maximum likelihood estimates giverelative risks and their information matrix. A likelihood ratio testdetermines significance. Simulations demonstrate that these newmethods properly maintain the type I error in a wide variety ofscenarios.  The trimmed likelihood successfully reduces bias inrelative risk estimates when the minor allele frequency is small. These result are especially important for the determination ofinteraction terms.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Statistical genetics,Missing data,,,,,,,12-Nov-10,bethjab@email.unc.edu,,Bethany Jablonski Horton,,UNC Chapel Hill Biostatistics graduate student,202 Creeks Edge,919-259-6492,,bethjab@email.unc.edu,The Effect of Water Disinfection By-products on Pregnancy Outcomes in Two Southeastern U.S. Communities,1,Bethany,J,Horton,"Department of Biostatistics, University of North Carolina Gillings School of Global Public Health, Chapel Hill, North Carolina, USA",Thomas,J,Luben,"National Center for Environmental Assessments, Office of Research and Development, U.S. Environmental Protection Agency, Research Triangle Park, North Carolina, USA",Amy,H,Herring,"Department of Biostatistics, University of North Carolina Gillings School of Global Public Health, Chapel Hill, North Carolina, USA  andCarolina Population Center, Chapel Hill, North Carolina, USA",David,A,Savitz,"Departments of Community Health and Obstetrics and Gynecology, Brown University, Providence, Rhode Island, USA",Philip,C,Singer,"Department of Environmental Sciences and Engineering, University of North Carolina Gillings School of Global Public Health, Chapel Hill, North Carolina, USA",Howard,S,Weinberg,"Department of Environmental Sciences and Engineering, University of North Carolina Gillings School of Global Public Health, Chapel Hill, North Carolina, USA",Katherine,E,Hartmann,"Department of Obstetrics and Gynecology, Vanderbilt University, Nashville, Tennessee, USA",,,,,,,,,,,,,"Objective: To determine if exposure to DBPs during gestation increasedthe risk of adverse birth outcomes, specifically term small forgestational age (SGA), preterm birth (PTB), and very PTB (<32 weeksgestation).  Methods: We used weekly water quality data (totaltrihalomethanes (TTHMs), 5 haloacetic acids (HAA5), and total organichalides (TOX)) collected from two distribution systems to evaluate theassociations between DBP concentrations and term SGA, PTB and very PTBusing logistic regression. Results: We found no associations betweenDBPs and term-SGA.  In one site with higher concentrations ofbromine-containing DBPs, we found an association between TOX and PTB;this association was larger, though less precise, for very PTB. Conclusions: Our results do not support an association between TTHMsor HAA5 and the birth outcomes investigated.  We found an associationbetween increased TOX and PTB.",FALSE,FALSE,,FALSE,FALSE,TRUE,T5: Essentials for Success in Research (Tuesday 1:45-3:30),contributedposter,,,,FALSE,FALSE,FALSE,FALSE,Epidemiologic methods,Environmental and ecological applications,,,,,,,05-Nov-10,beverly.schnell@cchmc.org,,Beverly M. Schnell,Senior Biostatistician,Cincinnati Children's Hospital Medical Center,"3333 Burnet Ave., ML 5041",(513) 803-2710,(513) 636-7509,beverly.schnell@cchmc.org,A Design-Based Analysis of Complex Survey Data on Chronic Kidney Disease,1,Beverly,M,Schnell,"Division of Biostatistics and EpidemiologyCincinnati Children's Hospital Medical Center",Mekibib,,Altaye,"Division of Biostatistics and EpidemiologyCincinnati Children's Hospital Medical Center",Jane,C,Khoury,"Division of Biostatistics and EpidemiologyCincinnati Children's Hospital Medical Center",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The proliferation of statistical software has enabled statisticians and non-statisticians alike to analyze public use data quickly and easily. For example, anyone who has Internet access can download data from various surveys conducted by the U.S. National Center for Health Statistics.  It is very tempting to perform readily available statistical methods to analyze such data without considering how they were collected.  Caution must be exercised when analyzing data from complex surveys, i.e., sample surveys characterized by differential inclusion probabilities, stratification, and multi-stage sampling of clustered units.  Using the National Health and Nutrition  Examination Surveys (NHANES) 1999-2008, this presentation will illustrate how to appropriately analyze complex survey data on chronic kidney disease among women 50 years and older. To estimate population parameters of interest, sampling weights will be used to address the different inclusion probabilities of individuals in the sample.  To obtain correct standard error estimates while protecting the confidentiality of survey participants, masked identifiers for strata and primary sampling units will be incorporated.  Comparisons will be made between incorrect analyses and correct analyses, the latter taking into account proper sample weights and complex survey design features.",FALSE,FALSE,,FALSE,TRUE,FALSE,"SC2: Modeling and Data Analysis for Complex SurveysRT4: Flourishing in a Collaborative Environment",presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Survey research data,Epidemiologic methods,,,,,,,15-Nov-10,bhattacharjees@mail.nih.gov,,Samsiddhi Bhattacharjee,,National Cancer Institute,"6120 Executive Blvd, EPS 8047",4125135166,,bhattacharjees@mail.nih.gov,Subset based meta-analysis in presence of heterogeneity,1,Samsiddhi,,Bhattacharjee,National Cancer Institute,Nilanjan,,Chatterjee,National Cancer Institute,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Meta-analysis is a common tool for combining association signalsacross different genome-wide association studies. To achieve largestpossible sample size, meta-analysis often involves combiningheterogeneous studies with different population and environmentalbackgrounds. If the extent of heterogeneity is high, standard fixed orrandom-effect meta-analysis may lose power significantly. We study anagnostic, subset-based approach for conducting meta-analysis ofheterogeneous studies. It involves exploration of the subset space toidentify the strongest association signal and then appropriatelyevaluating the statistical significance of the signal after accountingfor the multiple testing incurred due to subset search. We also studytwo-sided tests to allow for both disease predisposing and protectiveeffects. To avoid computationally intensive resampling-basedprocedures, we develop fast analytic approximations for the p-valuesof our proposed statistics. We demonstrate using simulations that ourmethods retain substantial power advantage over standard meta-analysisin many realistic scenarios. Some applications of the proposedapproach to real data are also discussed.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Statistical genetics,Genomics,,,,,,,15-Nov-10,biernacka.joanna@mayo.edu,,Joanna Biernacka,,Mayo Clinic,200 1st Street SW,5075385274,,biernacka.joanna@mayo.edu,Detection of genetic marginal and interaction effects using random forests,1,Joanna,M,Biernacka,"Division of Biomedical Statistics and Informatics, Mayo Clinic",Xin,,Wang,"Division of Biomedical Statistics and Informatics, Mayo Clinic",Mariza,,de Andrade,"Division of Biomedical Statistics and Informatics, Mayo Clinic",Robert,R,Freimuth,"Division of Biomedical Statistics and Informatics, Mayo Clinic",Colin,,Colby,"Division of Biomedical Statistics and Informatics, Mayo Clinic",Marianne,,Huebner,"Division of Biomedical Statistics and Informatics, Mayo Clinic",,,,,,,,,,,,,,,,,"Genome-wide association studies (GWAS) typically assess the association of the phenotype with each single nucleotide polymorphism (SNP) individually. Key limitations of this approach include assessment of SNP effects in the absence of other genetic effects and ignoring potential interactions between genetic risk factors. Random forests (RFs) have been proposed as a way to overcome these limitations, as they are expected to detect interacting risk factors. Although RFs are not designed to test for significance of specific effects, they can be used to rank predictors based on 'variable importance'.  We explored the ability of RFs to detect interactions in a highly dimensional setting encountered in genetic studies. We also investigated RF parameter settings needed to achieve stable estimates of variable importance, and compared features of top-ranked SNPs based on marginal tests of association and RF-based analyses. We demonstrate that as the total number of predictors increases, the ability of RFs to detect effects of interacting SNPs declines much more rapidly than the ability to detect SNPs that contribute additively to log-odds of the disease. The findings from these analyses motivated the development of new variable importance measures that may be more appropriate for genetic data analysis.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,TRUE,Statistical genetics,Machine learning,,,,,,,03-Nov-10,bin.huang@cchmc.org,,Bin Huang,Associate Prof.,Cincinnati Children's Hospital Medical Ctr,3333 Burnet,513-636-7612,,bin.huang@cchmc.org,Estimating Proportion of Treatment Effect Explained for Categorical Endpoints,1,Bin,,Huang,"Cincinnati Children's Hospital Medical Ctr., Cincinnati, OH 45229",Chen,,Chen,"Univeristy of Cincinnati, Cincinnati, OH 45220",Todd,G,Nick,"Arkansas Children's Hospital, Little Rock, AR 72202",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Different methods have been proposed to estimate proportion of treatment effect explained by a surrogate endpoint  or mediator. These different methods converge when both the clinical and surrogate endpoints are normal. However, when either or  both are categorical endpoints, different methods often lead to different results. This study conducted extensive simulation studies to 1) understanding the impact of dichotomizing or categorizing on the assessment of proportion of treament effect explained by a surrogate endpint or mediator; 2) comparing performances of different estimation approaches when either clinical or surrogate endpoints or both are categorical. The study offers practical recommendations and cautions against the use of categorization for a continuous variable.",FALSE,FALSE,,FALSE,TRUE,TRUE,Round Table R5.,presentation_or_poster,,,,FALSE,FALSE,FALSE,TRUE,Other,Epidemiologic methods,Surrogate Endpoint or Mediation Analyses,,,,,,15-Nov-10,bingqing.zhou@yale.edu,,Bingqing Zhou,Assistant Professor,Yale University School of Public Health,"60 college St, LEPH 213",(919) 260-0282,,bingqing.zhou@yale.edu,Change point survival models: an application to Acute Kidney Injury data,2,Jane,H,Zhang,"WEST HAVEN Cooperative Studies Program, VA Connecticut HCS",Bingqing,,Zhou,"School of Public Health, Yale University;WEST HAVEN Cooperative Studies Program, VA Connecticut HCS",Peter,,Guarino,"WEST HAVEN Cooperative Studies Program, VA Connecticut HCS",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Acute kidney injury (AKI) is a life-threatening complication of acuteillness. Commonly in clinical practice, an AKI event is viewed asconsisting of an acute phase and a post-recovery phase. Currentlythere is not yet reason to delineate the acute phase duration or theAKI evaluation time since statistical/data support has beeninsufficient. In a randomized trial conducted with 1124 AKI patients,a steep, rapid initial descent in the hazard  function was observed,followed by a plateau, which may confirm the existence of a criticalchange point between the two phases. The objective of this paper is todevelop and apply piecewise parametric models to locate the changepoint and estimate AKI survival. We use a restricted piecewise Weibullmodel with an exponential 2nd phase due to the constant post-changepoint hazard, as well as a piecewise linear model to examine patientsurvival. . Utilizing the likelihood function, we obtained the maximumlikelihood estimate for the change time and other parameters andestimate the standard error of these estimates through bootstrappingmethods.  These models are also extended to include covariatesassociated with patient survival.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Clinical trials,Survival analysis,,,,,,,15-Nov-10,bjackson@live.unthsc.edu,,Bradford Jackson,,UNTHSC,1000 Boxcar Blvd Apt#428,512-809-1176,,bjackson@live.unthsc.edu,abc,1,aa,,ggg,erawa,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,aaaaaaaaaaaaaaaaaaaa,FALSE,FALSE,,FALSE,FALSE,FALSE,,contributedposter,,,,FALSE,FALSE,FALSE,FALSE,Applied data analysis,Health policy applications,,,,,,,01-Nov-10,bklingen@williams.edu,,Bernhard Klingenberg,,Williams College,Dept. of Mathematics and Statistics,4135972467,,bklingen@williams.edu,Comparing margins of multivariate binary data,1,Bernhard,,Klingenberg,"Dept. of Mathematics and StatisticsWilliams College",Ville,,Satopaa,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We investigate methods for forming asymptotic simultaneous confidenceintervals for differences or ratios of marginal proportions between atreated and a control group when the response consists of severalcorrelated binary observations. To improve on Bonferroni or Sidakadjusted intervals we inverting a maximum test using (adjusted) Waldor score statistics and incorporating their correlation when findingthe critical value. We use the proposed methodology to compare adverseevents from a vaccine safety study.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Multivariate methods,Multiple testing,,,,,,,11-Nov-10,bleiby@mail.jci.tju.edu,,Benjamin Leiby,,Thomas Jefferson University,1015 Chestnut St.,215-503-3803,,bleiby@mail.jci.tju.edu,Evaluation of Bayesian latent class models for predicting colorectal cancer recurrence using longitudinal biomarker measurements,1,Benjamin,E,Leiby,"Division of BiostatisticsDepartment of Pharmacology and Experimental TherapeuticsThomas Jefferson University",Mary,D,Sammel,"Department of Biostatistics and EpidemiologyUniversity of Pennsylvania",Terry,,Hyslop,"Division of BiostatisticsDepartment of Pharmacology and Experimental TherapeuticsThomas Jefferson University",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The development of models which utilize longitudinal biomarkermeasurements to inform time-to-event analysis is an exciting frameworkwith great potential for biomedical research. The ability to use thelongitudinal trajectory of a biomarker to predict a future event canlead to improved estimation of individual risk and a moreindividualized approach to treatment.  Imposing latent classes is oneway to capture heterogeneity in a longitudinal trend over time.  It iscommon when jointly modeling longitudinal and time-to-event outcomesusing latent classes to assume conditional independence between thetwo outcomes.  While this assumption can be relaxed, the impact ofincorrect modeling is not well-understood.  Using a Bayesian approachto estimation, we investigate the impact of the conditionalindependence versus dependence assumption on prediction via simulationand data analysis.  Our research is motivated by a prospectivemulti-center study of the ability of a longitudinal biomarker topredict colorectal cancer recurrence.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Joint models for longitudinal and survival data,Bayesian methods,,,,,,,14-Nov-10,blitz@fas.harvard.edu,,Joseph Blitzstein,,Harvard University,1 Oxford St,6174962985,,blitz@fas.harvard.edu,Conditioning Non-Statisticians to Think Conditionally,1,Joseph,,Blitzstein,"Statistics Department, Harvard University",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Many of the most famous and infamous paradoxes and common mistakes inprobability and statistics arise from misunderstandings of conditionalprobability. These paradoxes are often glossed over, perhaps becausethey do not lend themselves to cookbook-style plugging into formulas.These common mistakes are often glossed over, perhaps because they aremistakes. At the same time, thinking conditionally is an essentialpart of scientific and statistical reasoning, and is at the heart ofmodel building. We argue that far more emphasis should be placed onthinking conditionally than most courses do. Paradoxes, commonmistakes, and real-world examples can be used in tandem to show howpowerful, insightful, and non-formulaic thinking conditionally is.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Statistical education,Health services research,,,,,,,02-Nov-10,bliu4@ncsu.edu,,Bo Liu,,NCSU,"3006 Kings CT, Apt. A",9196735698,,bliu4@ncsu.edu,Efficient Estimation in AFT Frailty Model for Clustered Survival Data,1,Bo,,Liu,NCSU Dept. of Statistics,Wenbin,,Lu,NCSU Dept. of Statistics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Clustered survival data frequently arise in many applications, where event times of interest are clustered into groups such as families or geographical units. In this article we consider the accelerated time failure time (AFT) frailty model for clustered survival data and develop a kernel-smoothing aided nonparametric maximum likelihood estimation method for inference. We prove that with proper choice of kernel bandwidth, our proposed estimator for regression coefficients is consistent, asymptotic normal and semi-parametric efficient. We also develop a numerical differentiation method for computing the variance of our estimator based on the empirical profile likelihood function. Simulation studies were conducted to evaluate the finite sample performance of the proposed estimator under practical settings and to compare with the weighted log-rank estimator for clustered survival data. Our method was further illustrated with an application to the Diabetic Retinopathy data set.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Multivariate survival,Nonparametric methods,,,,,,,31-Oct-10,bo.huang@pfizer.com,,Bo Huang,Ph.D.,Pfizer Inc.,175 Hawthorne Drive Apt 25J,8607322626,,bo.huang@pfizer.com,Optimal two-stage designs in randomized comparative phase II clinical trials with long-term endpoints,1,Bo,,Huang,Pfizer Inc.,Neal,,Thomas,Pfizer Inc.,Pei Fen,,Kuan,University of North Carolina Chapel Hill,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Phase II trials are often designed with an interim analysis so thatthey can be stopped early. When the endpoint of interest is binarywith relatively long evaluation window, one problem with interimanalysis is incomplete follow-up for some patients. Case and Morgan(2003) and Huang et al. (2010) proposed optimal designs usingtime-to-event approach to conduct a futility analysis withoutsuspension of accrual in the single-arm setting. We extend these ideasto clinically more important randomized comparative studies when therequired sample size is much larger. An optimal design with an interimanalysis to stop either for futility or superiority is proposed tominimize the expected sample size or the expected total studyduration. Flexible accrual distribution and error spending are allowedfor practical use of the design. An R package is created to implementthe optimal designs and simulate their properties to check asymptoticapproximations and robustness of the design performance.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Adaptive design/adaptive randomization,Biopharmaceutical research,,,,,,,12-Nov-10,bo@math.ntnu.no,,Bo Lindqvist,,Norwegian Univeristy of Science and Technology,Department of Mathematical Sciences,004707589418,,bo@math.ntnu.no,Competing risks in health surveys,1,Bo,H,Lindqvist,"Department of Mathematical Sciences, Norwegian University of Science and Technology, Trondheim, Norway",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The idea of competing risks is particularly suitable whenaddressing problems within health risks, as such problems will most often involve more than one possible outcome. This may for example be different causes of death, but it can equally well be different methods of treatment. The present talk is based on an analysis of data from a health survey called HUNT in the county of Nord-Tr¿ndelag in Norway. This is an extensive health survey which is composed of three studies, HUNT 1(1984-1987), HUNT 2 (1995-1997) and HUNT 3 (2006-2008). In the present research 74943 participants in HUNT 1 (which included approximately 80% of the population in the county of Nord-Tr¿ndelag) have been followed up until 2004 with respect to death and cause of death. Altogether 22284 of the participants had died at the end of the study in 2004. The mainobjective of the study was to investigate the effect of different risk variables on a set of death causes such as heart failure, stroke and certain cancer types. The talk will mainly concern the modelling of the competing death causes by regression models, with a discussion of different approaches depending on assumptions and the aims of the study.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Survey research data,Survival analysis,,,,,,,08-Nov-10,bof5@pitt.edu,,Bo Fu,,"Department of Biostatistics, University of Pittsbu",5030 Centre Ave. Apt. 555,240-671-3259,,bof5@pitt.edu,Comparison of the C-statistic and Information Gain,1,Bo,,Fu,"Department of Biostatistics, University of Pittsburgh",Chenyu,,Gao,"Department of Statistical Science, Cornell University",Chung-Chou,H.,Chang,"Department of Medicine and Department of Biostatistics, University of Pittsburgh",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Consider a binary outcome variable Y with two disease categories(0=nondisease, 1=disease) and a predicting variable X that is eithercontinuous or categorical.  The c-statistic, which is usually used inbiostatistics, is a measure of how well a prediction model based on Xcan correctly rank-order patients by their risk scores.  Informationgain (IG), which is more commonly used in biomedical informatics, is ameasure of the reduction in uncertainty about the value of Y after thevalue of X is known.  The uncertainty about the value of Y is measuredby its entropy.  Although either the c-statistic or the IG can be usedto assess the ability of X to predict Y, previous studies have notcompared the relationship between these measures.  When we usedmathematical derivations and simulations, we found similaritiesbetween the two measures but not under all distribution scenarios.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Applied data analysis,ROC analysis,,,,,,,05-Nov-10,bohrmann@ufl.edu,,Thomas F Bohrmann,Graduate Student,University of Florida,415 McCarty Hall C,727-252-4441,,bohrmann@ufl.edu,Predicting a New Time Series Using Multiple Partially Observed Time Series,1,Thomas,,Bohrmann,University of Florida,Andrew,,Hein,University of Florida,Forrest,,Stevens,University of Florida,Mollie,,Brooks,University of Florida,Joseph,,Lucchetti,University of Florida,Mary,,Christman,University of Florida,Benjamin,,Bolker,McMaster University,Craig,,Osenberg,University of Florida,Hilary,,Swain,Archbold Biological Station,,,,,"Often covariates that inform a time series of measurements are readilyavailable whereas the measurements themselves are scarce.  In such acase, researchers may wish to use the available covariates to predictthe outcome at times and for units where it was not measured.  Timeseries models provide a framework for prediction when such a processis autocorrelated in time.  However, the problem of predicting theoutcome on an observational unit between measurements and predictionof a complete series on a new unit are different.  We propose a methodextending the autoregressive order one (AR(1)) model with Normalerrors for predicting a process through time when and where nomeasurements of that process were made but when and where covariateinformation exists.  The method involves fitting an AR(1)-derivedmodel using only weighted past covariates as predictors and not pastmeasurements of the process.  Thus, model fitting accounts for thelack of availability of response observations in a new place or time.  Additional to model fitting, we describe checks for model validationand predictive capability.  As an example, we fit the model to anenvironmental data set of pond depth observations with weather andphysical landscape covariates.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Environmental and ecological applications,Spatial/temporal modeling,,,,,,,15-Nov-10,bomolo@uscupstate.edu,,Bernard Omolo,,University of South Carolina Upstate,800 University Way,864-503-5362,864-503-5930,bomolo@uscupstate.edu,A Bayesian Hierarchical Model for Correlated Microarray Datasets,1,Bernard,,Omolo,University of South Carolina - Upstate,Ming-Hui,,Chen,University of Connecticut,Haitao,,Chu,University of Minnesota,Joseph,G,Ibrahim,University of North Carolina - Chapel Hill,,,,,,,,,,,,,,,,,,,,,,,,,"Assessment of gene-specific correlation between two independent expression datasets may help in deciding whether to use an original expression data or one updated with additional samples, for differential gene expression analysis. This can be accomplished through modeling the parameters measuring association between variables, for instance, the correlation coefficient. Typically, the correlation coefficients are obtained from the mean expression value for each common gene and cell-line between the two datasets. However, this approach does not utilize the replicated expression values for each gene and instead averages over them, thereby ignoring the effect of multiple probes per gene.        We propose a three-level Bayesian hierarchical model for the gene-specific correlation coefficient between two independent datasets that utilizes replicated expression values for each gene. A comparison with the standard approach indicates that the Bayesian approach performs better and hence is more preferable for differential gene expression analysis.Key words: Bayesian hierarchical model; cell-line; correlation coefficient; differential gene expression; probe.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,TRUE,Microarray analysis,Bayesian methods,Genomics,,,,,,15-Nov-10,bondell@stat.ncsu.edu,,Howard Bondell,,NC State University,Box 8203,919-515-1914,,bondell@stat.ncsu.edu,A Perturbation Approach to Improved Variable Selection in High-Dimensional Data,1,Howard,D,Bondell,NC State University,Chen-Yen,,Lin,NC State University,Hao Helen,,Zhang,NC State University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"For high-dimensional data, particularly when the number of predictors greatly exceeds the sample size, selection of relevant predictors for regression is a challenging problem. Methods such as sure screening, forward selection, or penalized regressions such as LASSO or SCAD are commonly used. By varying the number of variables included in the screening, the number of steps in forward selection, or the tuning parameter in the penalized regression, variables enter the model sequentially. One view of variable selection is to create this ordering, and then further decide on the stopping rule. Focusing on the ordering step, we propose a perturbation approach to obtain a better ranking of the predictors. By repeating a sequential procedure on perturbed responses, we generate a stable ordering on which a stopping rule can then be applied. The approach is empirically shown to improve upon standard methods in ranking of the predictors. We further propose a stopping criterion that is shown to perform well even when the dimension greatly exceeds the sample size.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Variable subset selection/model selection,High dimensional data,Invited,,,,,,15-Nov-10,boris.zaslavsky@fda.hhs.gov,,Boris Zaslavsky,Dr,FDA,1401 Rockville Pike,3018278587,30182752189,boris.zaslavsky@fda.hhs.gov,Bayesian Sample Size Estimates  in Clinical Trials with Dichotomous and Countable Outcomes,1,Boris,G,Zaslavsky,FDA,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We present a Bayesian approach to sample size determination in binomial and Poisson clinical trials. We use exact methods and Bayesian methodology. Our sample size estimations are based on power calculations under the one-sided alternative hypothesis that a new treatment is better than a control by a clinically important margin. The method resembles a standard frequentist problem formulation and, in the case of conjugate prior distributions with integer parameters, is similar to the frequentist approach. We evaluate type I and II errors through the use of credible limits in Bayesian models and through the use of confidence limits in frequentist models. Particularly, for conjugate priors with integer parameters, credible limits are identical to frequentist confidence limits with adjusted numbers of events and sample sizes. We consider conditions under which the minimal Bayesian sample size is less than the frequentist one and vice versa.",FALSE,FALSE,,FALSE,TRUE,TRUE,SC7,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Bayesian methods,Clinical trials,,,,,,,01-Nov-10,brad@biostat.umn.edu,,Bradley P. Carlin,Professor and Head,University of Minnesota,"Division of Biostatistics, MMC 303",612-624-6646,612-626-0660,brad@biostat.umn.edu,Multilevel Bayesian models for zero-inflated longitudinal patient-reported outcomes and survival times in mesothelioma,4,Laura,A.,Hatfield,University of Minnesota,Mark,E.,Boye,Eli Lilly and Company,Michelle,D.,Hackshaw,Merck and Company,Bradley,P.,Carlin,University of Minnesota,,,,,,,,,,,,,,,,,,,,,,,,,"Malignant pleural mesothelioma (MPM) is a rapidly fatal form ofpulmonary cancer usually associated with asbestos exposure. Previous studies have established pemetrexed (Alimta R) plus cisplatin, compared with cisplatin alone, as effective in prolonging progression-free survival (PFS) in the first-line setting.  In this paper we reinterpret the benefits of this survival by jointly modeling it with longitudinal patient-reported outcomes (PROs). Such joint models can reduce bias and increase inferential efficiency, as well as add value to traditional clinical trial endpoints, especially in settings where the survival benefit of the treatment is modest.  We build hierarchical Bayesian models that combined zero-inflated betadistributions for the PROs with proportional hazards Weibull models for the right-censored PFS values, with correlations aremodeled using latent random variables. The results indicate significantly decreased patient-reported lung symptom severity over time and increased PFS may be associated in the pemetrexed/cisplatin group. We observe both correlation between the individual probability of non-zero PRO and severity of non-zero PROs, and associations between the PRO latent variables and PFS. The underlying latent variables also serve to incorporate individual-level differences in PRO histories and PFS times, sensibly adjusting the fitted trajectories for individuals.",FALSE,FALSE,,FALSE,TRUE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Joint models for longitudinal and survival data,Bayesian methods,,,,,,,14-Nov-10,bret.hanlon@gmail.com,,Bret Hanlon,Professor,University of Wisconsin,Statistics  1241 MSC,608-262-2539,,bret.hanlon@gmail.com,High Dimensional Variable Selection for Grouped Covariates with Applications in Cancer Genomics,1,Bret,,Hanlon,University of Wisconsin,Ji,,Zhu,University of Michigan,Yi,,Li,Harvard School of Public Health,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In many scientific applications, parameters can be naturally grouped;for example, assayed genes can be grouped by biological pathways. Wewill discuss variable selection methods which utilize groupinformation to effectively identify important variables. Ourscientific motivation is to utilize pathway information to select agene signature, which is predictive for cancer patients' response totherapy. The goal is to use this predictive signature to make betterinformed decisions for patient treatment. Under the framework ofpenalized likelihood methods for model selection, for a generalcollection of likelihood functions and penalty functions, we provethat our estimator possesses the oracle property under the setting ofa diverging number of groups and parameters. Simulations and dataanalysis from a myeloma study illustrate the utility of the proposedmethods.",FALSE,FALSE,,FALSE,FALSE,TRUE,"I am Chairing the invited session:High Dimensional Data Analysis with Applications in the Biosciences",invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,High dimensional data,Variable subset selection/model selection,,,,,,,03-Nov-10,brian.egleston@fccc.edu,,Brian L. Egleston,Assistant Research Professor,Fox Chase Cancer Center,Biostatistics Facility,215-214-3917,215-728-2553,brian.egleston@fccc.edu,Evaluation of treatments with heterogeneous effects using principal strata latent survival classes,1,Brian,L.,Egleston,"Fox Chase Cancer CenterBiostatistics Facility333 Cottman Ave.Philadelphia, PA 19111",Mark,,Buyyounouski,"Fox Chase Cancer CenterRadiation OncologyFox Chase Cancer Center 333 Cottman Ave.Philadelphia, PA 19111",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Combination radiotherapy and androgen deprivation therapy (ADT) is commonly used in the treatment of prostate cancer.  While survival is typically long, there is growing concern that ADT may increase the risk of intercurrent death due to effects on the heart.  We present a method for estimating the effect of treatment on five and ten year survival outcomes using a principal stratification approach. We use Cox proportional hazards regressions and estimators of the baseline survivor function to estimate individual survival probabilities at 5 and 10 years under different treatments assignments.  We then use a number of conditional independence assumptions to estimate the probability of being in latent survival classes that would benefit from treatment and be harmed by treatment.  A sensitivity analysis approach is presented that depicts how deviations from at least one conditional independence assumption affects our estimates.  We present a data example of androgen deprivation therapy for the treatment of prostate cancer in which we find that more men benefit from therapy than are harmed, but the proportion who are harmed might be quite sizable.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,TRUE,Causal inference,Survival analysis,,,,,,,12-Nov-10,brian.pittman@yale.edu,,Brian Pittman,Statistician,Yale University School of Medicine,"34 Park Street, 3rd floor - CNRU",203 974 7789,,brian.pittman@yale.edu,The Poisson-Normal Model as an Alternative Approach for Analyzing Psychopharmacologic Challenge Study Data,1,Brian,,Pittman,Yale University School of Medicine,John,H,Krystal,Yale University School of Medicine,Ralitza,,Gueorguieva,Yale University School of Medicine,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Psychopharmacologic challenge studies commonly evaluate drug efficacy by estimating the extent to which symptoms of the illness are mitigated.  Complex, multivariate repeated measures designs are frequently utilized and data are often highly skewed with floor/ceiling effects.  Further, the distribution and shape of the data are often dose-dependent.  Analysis of these data presents multiple statistical challenges.  Historically, repeated measures ANOVAs, linear mixed models, GEE models for ordinal data, and nonparametric methods for repeated measures data have been considered for analysis of such data, but each have notable drawbacks. A general linear model based on the mixture Poisson-Normal distribution is a potentially favorable alternative which overcomes the weaknesses inherent in the approaches above.  Specifically, the model allows for modeling of dose-specific inflated variance, estimation of easily interpretable mean effects, and seamless inclusion of covariates.  Further, the model is flexible in modeling missing data.  The model can readily be fitted using PROC NLMIXED in SAS.  Application of the proposed model to data from a published clinical study will be presented.  Simulations used to characterize and compare the proposed approach to each of the alternative methods in terms of power, Type-I error, and estimated effect sizes will also be reported.",FALSE,FALSE,,FALSE,FALSE,FALSE,,contributedposter,,,,FALSE,FALSE,FALSE,FALSE,Generalized linear models,Random effects,,,,,,,15-Nov-10,brisa@umich.edu,,Brisa N Sanchez,Assistant Professor,University of Michigan,1415 Washington Heights,734-763-2451,,brisa@umich.edu,Latent variable approach to studies of gene-environment interactions in the presence of multiple correlated exposures,1,Brisa,N,Sanchez,"Department of Biostatistics, University of Michigan",Shan,,Kang,"Department of Biostatistics, University of Michigan",Howard,,Hu,"Department of Environmental Health Sciences, University of Michigan",Bhramar,,Mukherjee,"Department of Biostatistics, University of Michigan",,,,,,,,,,,,,,,,,,,,,,,,,"Many existing cohort studies initially designed to investigate the risk of developing a disease as a function of environmental exposures have collected genetic data in recent years. Such cohort studies often have multiple correlated measures of exposure, hence testing for gene-environment interaction (G x E) effects in the presence of multiple exposure markers further increases the burden of multiple testing, an issue already present in a genetic association study. We extend the latent variable (LV) model framework to characterize gene-environment interaction in presence of genotype data on single nucleotide polymorphisms (SNPs) and multiple correlated exposures.  Given that genetic variation can influence exposure dose, we postulate a hierarchy of assumptions about the LV model describing varying degrees of gene-environment dependence. Such assumptions influence inferential results on the gene-environment interaction parameters. We implement a class of shrinkage estimators to data adaptively trade-off between the most restrictive and efficient model, and the most flexible and least biased form of the gene-environment dependence assumption. We demonstrate the methods with example from the ELEMENT study of lead exposure, iron metabolism genes, and birth weight.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Latent variables,Environmental and ecological applications,,,,,,,14-Oct-10,brlecl@gmail.com,,Brian Claggett,,Harvard School of Public Health,655 Huntington Ave.,850-572-3170,,brlecl@gmail.com,Augmented Cross-Sectional Studies with Abbreviated Follow-up for Estimating HIV Incidence,1,Brian,,Claggett,Harvard School of Public Health,Stephen,W,Lagakos,,Rui,,Wang,Harvard School of Public Health,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Cross-sectional HIV incidence estimation based on a sensitive andless-sensitive test offers great advantages over the traditionalcohort study. However, its use has been limited due to concerns aboutthe false negative rate of the less-sensitive test, reflecting thephenomenon that some subjects may remain permanently negative on theless-sensitive test. Within this context, we generalize the augmentedcross-sectional design of Wang and Lagakos (2009a)  by allowing thelength of follow-up to vary and propose a new estimator based onabbreviated follow-up time (AF), which offers great practicaladvantages. We show earlier estimators to be MLEs derived from specialcases of a more general likelihood function and assess the robustnessof the estimators to the underlying assumptions. Compared to theoriginal estimator from an augmented cross-sectional study, the AFestimator allows shorter follow-up time and does not requireestimation of the mean window period, defined as the average timebetween detectability of HIV infection with the sensitive andless-sensitive tests. It is shown to perform well in a wide range ofsettings. We discuss when the AF estimator would be expected toperform well and offer design considerations for an augmentedcross-sectional study with abbreviated follow-up.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,TRUE,Epidemiologic methods,Diagnostic and screening tests,,,,,,,17-Sep-10,bruce.swihart@gmail.com,,Bruce Swihart,,Dept. Biostatistics; Johns Hopkins School of Publi,615 N. Wolfe St.,7202441126,,bruce.swihart@gmail.com,A unified approach to modeling multivariate binary data using copulas over partitions,1,Bruce,J.,Swihart,"Department of Biostatistics,Johns Hopkins Bloomberg School of Public Health, Baltimore, MD  21205, U.S.A.",Brian,S,Caffo,"Department of Biostatistics,Johns Hopkins Bloomberg School of Public Health, Baltimore, MD  21205, U.S.A.",Ciprian,M,Crainiceanu,"Department of Biostatistics,Johns Hopkins Bloomberg School of Public Health, Baltimore, MD  21205, U.S.A.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Many seemingly disparate approaches for marginal modeling have been  developed in recent years.  We demonstrate that many current  approaches for marginal modeling of correlated binary outcomes  produce likelihoods that are equivalent to the proposed copula-based  models herein.  These general copula models of underlying latent  threshold random variables yield likelihood-based models for  marginal fixed effects estimation and interpretation in the analysis  of correlated binary data.  Moreover, we propose a nomenclature and  set of model relationships that substantially elucidates the complex  area of marginalized models for binary data.  A diverse collection  of didactic mathematical and numerical examples are given to  illustrate concepts.",FALSE,FALSE,,FALSE,TRUE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Multivariate methods,Nonlinear models,,,,,,,04-Nov-10,bushi.wang@email.ucr.edu,,Bushi Wang,,"University of California, Riverside",900 University Ave,9512757784,,bushi.wang@email.ucr.edu,A New Partition Testing Strategy for Multiple Primary and Secondary Endpoints in Clinical Trials,1,Bushi,,Wang,"University of California, Riverside",Xinping,,Cui,"University of California, Riverside",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"To evaluate efficacy in multiple endpoints in confirmatory clinical trials is a challenging problem in multiple hypotheses testing. The difficulty comes from the different importance of each endpoint and their underlying correlation. Current approaches to this problem are based on closed testing or partition testing, which test the efficacy in certain dose-endpoint combinations and collate the results. Partition testing is in general a more powerful approach since it tests fewer hypotheses to avoid unnecessary power loss. Despite their different formulations, all current approaches test their dose-endpoint combinations as intersection hypotheses and apply various union-intersection tests. Likelihood ratio test is seldomly used due to the extensive computation and lacks of consistent inferences. In this article, we first generalize the decision path principle proposed by Liu and Hsu (2009) to the cases with alternative primary endpoints and co-primary endpoints. Then we propose a new partition testing approach which is based on consonance adjusted likelihood ratio test. The new procedure provides consistent inferences and yet it is still conservative and does not rely on the estimation of endpoint correlation or independence assumptions which might be challenged by regulatory agencies.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Multiple testing,Toxicology/dose-response,,,,,,,13-Nov-10,buzbas@umich.edu,,Erkan Buzbas,Dr.,University of Michigan,"Bioinformatics Program, University of Michigan  2017 Palmer Commons",5094609839,,buzbas@umich.edu,Statistical properties of Maximum likelihood and Bayesian estimates under k-allele models with selection,1,Erkan,O,Buzbas,University of Michigan,Paul,,Joyce,University of Idaho,Noah,A,Rosenberg,University of Michigan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The stationary distribution of allele frequencies under a variety ofWrightFisher k-allele models with selection and parent independentmutation is well studied. However, the statistical properties ofmaximum likelihood estimates of parameters under these models are notwell understood. Under each of these models there is a point in dataspace which carries the strongest possible signal for selection, yet,at this point, the likelihood is unbounded. This result remains valideven if all of the mutation parameters are assumed to be known.Therefore, standard simulation approaches used to approximate thesampling distribution of the maximum likelihood estimate producenumerically unstable results in the presence of substantial selection.We describe the Bayesian alternative where the posterior distributiontends to produce more accurate and reliable interval estimates for theselection intensity at a locus.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Statistical genetics,Computational methods,,,,,,,15-Nov-10,bzhang4@ncsu.edu,,Baqun Zhang,,NCSU,Department of Statistics,9199862302,,bzhang4@ncsu.edu,Robust Statistical Method for Finding Optimal Treatment Regimes,1,Baqun,,Zhang,North Carolina State University,Anastasios A.,,Tsiatis,North Carolina State University,Marie,,Davidian,North Carolina State University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"A treatment regime is a rule that assigns a treatment, among a set ofpossible treatments, to a patient as a function of his/her observedcovariates. The goal is to find the optimal treatment regime definedas that, if followed by a population of patients, would lead to thebest outcome on average.For a single treatment decision, the optimal treatment regime can befound by developing a regression model for the expected outcome as afunction of treatment and baseline covariates, where, for a given setof covariates, the optimal treatment is the one which yields thelargest expected outcome. This, however can lead to biased results ifthe regression model is misspecified. Realizing that the parameters ina regression model induce different treatment regimes, we insteadconsider estimating the mean outcome for such treatment regimesdirectly using doubly-robust augmented inverse propensity scoreestimators of the mean outcome for the parameter-induced treatmentregimes, which we then maximize across the parameter values to obtainour optimal treatment regime estimator. We also show how this problemcan be viewed as a classification problem. Simulations and anapplication are used to evaluate the performance of this method.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Adaptive design/adaptive randomization,Causal inference,,,,,,,15-Nov-10,cai@bios.unc.edu,,Cai JianWen,professor,University of North Carolina-Chapel Hill,McGavran-Greenberg Hl 135 Dauer Drive,919-966-7788,,cai@bios.unc.edu,Additive Mixed Effect Model for Clustered Failure Time Data,1,Jianwen,,Cai,"Department of Biostatistics, University of North Carolina at Chapel Hill",Donglin,,Zeng,"Department of Biostatistics, University of North Carolina at Chapel Hill",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We propose an additive mixed effect model to analyze clustered failure time data. The proposed model assumesan additive structure and include a random effect as an additional component. Our model imitates the commonly used mixed effect models in repeated measurement analysis but under the context of hazards regression; our model can also be considered as a parallel development of the gamma-frailty model in additive model structures. We develop estimating equations for parameter estimation and propose a way of assessing the distribution of the latent random effect in the presence of large clusters. We establish the asymptotic properties of the proposed estimator. The small sample performance of our method is demonstrated via a largenumber of simulation studies. Finally, we apply the proposed model to analyze data from a diabetic study and a treatment trial for congestive heart failure.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Multivariate survival,Random effects,,,,,,,11-Nov-10,cao@stt.msu.edu,,Guanqun Cao,,Michigan State University,A413 Wells Hall,517-884-1488,,cao@stt.msu.edu,Simultaneous Inference For The Mean Function Of Dense Longitudinal,1,Guanqun,,Cao,"Dept. of Statistics and ProbabilityMichigan State University",Lijian,,Yang,"Dept. of Statistics and ProbabilityMichigan State University",David,,Todem,"Dept. of  EpidemiologyMichigan State University",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We propose a polynomial spline estimator for the mean function of dense longitudinal data together with a simultaneous confidence band which is asymptotically correct. In addition, the spline estimator and its accompanying confidence band enjoy semiparametric efficiency in the sensethat they are asymptotically the same as if all random trajectories are observed entirely and without errors, a view taken in Ferraty and Vieu (2006). We also build a confidence band to test the difference of two groups of functional data. Simulation experiments provide strong evidence that corroborates the asymptotic theory while computing is efficient. The confidence band procedure is illustrated by analyzing the near infrared spectroscopy data.",FALSE,FALSE,,FALSE,TRUE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Functional data analysis,Nonparametric methods,,,,,,,03-Nov-10,caroph@email.unc.edu,,Carolina Perez-Heydrich,Dr.,"Postdoctoral Fellow UNC-CH, Department of Biostati","Carolina Population Center, University of North Carolina at Chapel Hill",919-843-0252,,caroph@email.unc.edu,"DECOMPOSING THE EFFECTS OF SPACE, ENVIRONMENT, AND SOCIAL TIES ON PLACEBO INCIDENCE IN VACCINE TRIALS",1,Carolina,,Perez-Heydrich,University of North Carolina at Chapel Hill,Sophia,,Giebultowicz,University of North Carolina at Chapel Hill,Amy,,Herring,University of North Carolina at Chapel Hill,Michael,,Emch,University of North Carolina at Chapel Hill,Mohammad,,Ali,International Vaccine Institute,,,,,,,,,,,,,,,,,,,,,"Vaccine trials conventionally define efficacy across a global scale,in which disease risk is assumed to be homogenous across targetpopulations.  Although often overlooked, geographic heterogeneity invaccine coverage can confound estimates of protective efficacy throughanalogous variations in herd immunity.  The goal of this study was todetermine how geographic factors, along with environmental and socialties to vaccinated individuals can influence indirect protectiveimmunity among unvaccinated individuals.  Using retrospective datafrom a randomized field trial of killed oral cholera vaccinesconducted by the International Centre for Diarrhoel Disease Researchin Matlab, Bangladesh, we sought to determine how placebo incidencevaried according to social and environmental ties to vaccinatedindividuals across space.   Using a zero-inflated Poisson (ZIP) modelwithin a Bayesian hierarchical framework, we evaluated the impacts ofsocial and environmental connectivity on placebo incidence, whileaccounting for spatial correlation of incidence through a conditionalautoregressive (CAR) model with structured and unstructuredheterogeneity random effects.   Through this analysis we demonstratehow variation in spatial, environmental, and social processes cancontribute to heterogeneity of placebo incidence in vaccine trials.",FALSE,FALSE,,FALSE,FALSE,FALSE,,contributedposter,,,,FALSE,FALSE,FALSE,FALSE,Environmental and ecological applications,Spatial/temporal modeling,,,,,,,13-Nov-10,carroll@stat.tamu.edu,,Raymond J. Carroll,,Texas A&M University,3143 TAMU,979 820 1816,,carroll@stat.tamu.edu,Functional and Hierarchical Data Analysis,1,Raymond,J.,Carroll,Texas A&M University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"I will review of series of examples of hierarchical and functionaldata, and comment on the tension between marginal analysis versusrandom effects-based functional data analysis. The examples includethose from colon carcinogenesis experiments, calcium ion signalingexperiments, the vocalization of bat chirps, and the detection ofaerosols. Emphasis will be on the data structures and not detailedanalysis of each structure.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Functional data analysis,High dimensional data,,,,,,,15-Nov-10,cbotts@williams.edu,,Carsten Botts,,Assistant Professor of Statistics,96 School St. #10,413-822-7204,,cbotts@williams.edu,A Modified Adaptive Accept-Reject Algorithm for Univariate Densities with Bounded Support,1,Carsten,H,Botts,Assistant Professor of Statistics at Williams College,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The need to simulate from a univariate density arises in several settings, particularly in Bayesian analysis.   An especially efficient algorithm which can be used to sample from a univariate density, f,  is the adaptive accept-reject algorithm.    To implement the adaptive accept-reject algorithm, the user has to envelope a transformation of the density, T(f),  where T is some transformation such that the density proportional to the inverse of T is easy to sample from.    Successfully enveloping T(f), however, requires that the user identify the number and location of T(f)'s inflection points.     This is not always a trivial task.    In this paper we propose an adaptive accept-reject algorithm which relieves the user of precisely identifying the location of T(f)'s inflection points.  This new algorithm is shown to be efficient and can be used to sample from any density such that its support is bounded and its log is three-times differentiable.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Computational methods,Bayesian methods,,,,,,,02-Oct-10,ccrainic@jhsph.edu,,Ciprian Crainiceanu,,Johns Hopkins University,615 N Wolfe Street,410-955-3505,,ccrainic@jhsph.edu,My first 100 terabytes of data: Statistical principles and methods,1,Ciprian,M,Crainiceanu,Johns Hopkins University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Unarguably, advancements in technology and computation have led to a rapidly increasing number of applications where measurements are functions or images. The Statistical Methods for New Technology working group at Johns Hopkins has more than 100Tb of data in many observational studies containing functions or images observed at multiple visits.  We introduce a set of new statistical methods that are computationally efficient for very large data sets:  multilevel and longitudinal principal components analysis (MFPCA and LFPCA), penalized functional regression (PFR), population value decomposition (PVD), and multilevel principal components analysis for high dimensional data (HD-MFPCA). We describe applications to studies including electroencephalograms (EEG), diffusion tensor imaging (DTI), and functional magnetic imaging (fMRI) measurements at multiple visits on hundreds or thousands of subjects.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Functional data analysis,Longitudinal data,,,,,,,14-Nov-10,cdewey@biostat.wisc.edu,,Colin Dewey,Assistant Professor,University of Wisconsin-Madison,5785 Medical Sciences Center,608-263-7610,,cdewey@biostat.wisc.edu,Local alignments as approximations for next-generation sequencing statistical models,1,Colin,,Dewey,University of Wisconsin-Madison,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Next-generation sequencing is revolutionizing a number of molecular biology applications, including gene expression quantitation, genomic binding-site prediction, and genome assembly.  In most of these applications, a fundamental step in the analysis is the local alignment of relatively short sequence reads against larger reference sequences, such as chromosomes or gene transcripts.  We have recently developed methods for analyzing next-generation sequence data that treat local alignment as a strategy for performing approximate inference with principled generative models.  We describe two of these methods: one for accurately quantifying transcript abundance from RNA-Seq data and a second for probabilistic genome assembly with next-generation sequencing reads.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Genomics,Machine learning,,,,,,,15-Nov-10,cdi@fhcrc.org,,Chongzhi Di,Assistant Member,Fred Hutchinson Cancer Research Center,1100 Fairview Ave N M2-B500,2066672093,,cdi@fhcrc.org,Principal Component Analysis for Multilevel and Multivariate Functional Data,1,Chongzhi,,Di,"Division of Public Health SciencesFred Hutchinson Cancer Research Center",Ciprian,M,Crainiceanu,"Department of BiostatisticsJohns Hopkins University",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Functional data is becoming increasingly common in health research. Asa key technique for such data, functional principal component analysis(FPCA) was designed for a sample of independent functions. In thistalk, we extend the scope of FPCA to multilevel and multivariatefunctional data. We exploit the hierarchical structure of covarianceoperators at between and within subject levels, and extract dominatingmodes of variations at each level. The decomposition also allows us toinvestigate within subject functional correlations. Our approach ismotivated by a few applications including the Sleep Heart Health Study.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Functional data analysis,Longitudinal data,,,,,,,12-Nov-10,cduarte@uab.edu,,Christine Duarte,Dr.,University of Alabama at Birmingham,RPHB 327,(205) 975-9267,,cduarte@uab.edu,High Dimensional Predictive Modeling in Pharmacogenetics: Application of Machine Learning Techniques to Predict Warfarin Dose Response in African Americans,3,Erdal,,Cosgun,University of Alabama at Birmingham,Nita,,Limdi,University of Alabama at Birmingham,Christine,W,Duarte,University of Alabama at Birmingham,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"With most complex traits and diseases having expected geneticcontributions of many hundreds or even thousands of genetic factors,and with genotyping arrays consisting of hundreds of thousands or evenmillions of SNPs, powerful high dimensional statistical techniques areneeded to comprehensively model the genetic variance.  We have appliedthree machine learning approaches: Random Forest Regression (RFR),Boosted Regression Tree (BRT), and Support Vector Regression (SVR) tothe problem of prediction of warfarin maintenance dose in a sample ofAfrican Americans.  We have developed a multi-step approach thatselects SNPs, builds prediction models, and tests the discoveredmodels in a cross-validation framework.  Preliminary results indicatethat our modeling approach gives much higher accuracy than previousmodels for warfarin dose prediction, with an average R2 betweenpredicted and actual square root of warfarin dose as measured in thetest samples of 0.682 for RFR, 0.612 for SVR, and 0.524 for BTR.  Thusthe best performance occurred with RFR, but all three techniquesshowed improvement over the currently published result of 0.43.  Insummary, machine learning approaches for high-dimensionalpharmacogenetic prediction hold great promise and warrant furtherresearch.",FALSE,FALSE,,FALSE,FALSE,TRUE,SC6:Stat Methods for Next Generation Studies in Genetic EPID,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Genomics,Machine learning,,,,,,,15-Nov-10,ch2342@columbia.edu,,Chia-Hui Huang,,Columbia University,1255 Amsterdam Ave.,9174282966,,ch2342@columbia.edu,Semiparametric Stochastic Modeling for Epidemic Data,1,Chia-Hui,,Huang,Columbia University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Epidemic models and statistical tools are developed to study the underlying mechanisms of the spread of infection. The motivation of this study is to investigate whether hospital staff could become carriers in the transmission of infectious diseases. Therefore, we proposed a statistical model to address this concern when there is a large number of independent small groups of correlated failure time events, and the occurrence of failures may become part of risk factors for the subjects who are at risk. A dynamic hazard function is built to model the probability of the susceptible individual contracting a disease based on the data-driven approach. The regression parameters consists two parts, one relates how the hazard varies in response to the individual's explanatory variables in a multiplicate scale and the other one is the relative risk of being exposed to failures in the cluster. With this set-up, the estimator of covariate effects and standard errors are able to carry out under a martingale approach. That leads to conduct a hypothesis testing on the contact effect.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Survival analysis,Infectious disease models,,,,,,,15-Nov-10,chalise.prabhakar@mayo.edu,,Prabhakar Chalise,Research Fellow,Mayo Clinic,"3912 19th Avenue NW, Apt 207",507-990-2584,,chalise.prabhakar@mayo.edu,Comparison of Performances of Penalty Functions with Sparse Canonical Correlation Analysis,1,Prabhakar,,Chalise,"Department of Health Sciences Research Mayo Clinic College of Medicine",Liewei,,Wang,Departments of Molecular Pharmacology and Experimental Therapeutics,Brooke,,Fridley,"Department of Health Sciences Research Mayo Clinic College of Medicine",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Canonical correlation analysis (CCA) is widely used multivariate method for assessing the associations between two sets of variables. However, when the number of variables far exceeds the number of subjects, such in the case of large-scale genomic studies, traditional CCA methods are not appropriate. In addition, when the variables are highly correlated the sample covariance matrices become unstable or undefined. To overcome these two issues, sparse canonical correlation analysis (SCCA) for multiple data sets has been proposed using a LASSO type penalty. But, these methods do not have direct control over the sparsity. As a result, it is difficult to get effective dimension reduction. Additional step that uses Bayesian Information Criterion (BIC) has also been suggested to further filter out unimportant features. We compare SCCA methods that use four different penalty functions including lasso, elastic net, SCAD and hard threshold followed by BIC filtering step using both real and simulated SNP and mRNA expression data. These studies indicate that SCAD penalty with BIC filter would be a preferable choice to use in SCCA methods.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Multivariate methods,High dimensional data,,,,,,,11-Oct-10,chalmers.nancy@gmail.com,,Nancy Chalmers,PhD Candidate,University of South Carolina,Department of Statistics,(803)727-4938,,chalmers.nancy@gmail.com,"Fractional Polynomials: Issues of Identifiability and Fitting, With Examples",1,Nancy,,Chalmers,University of South Carolina,Don,,Edwards,University of South Carolina,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"For some data, low-order polynomial models do not fit well.  Even ifthese models provide adequate fit, there are often problems with errorassumptions and, with quadratic models, perhaps a spurious minimum ormaximum in the fitted surface.  Non-linear models may provide a betterfit, but some are very labor-intensive.  Here, we propose the use ofsimple power transformations of the response and the predictors. Using these transformed variables, four fractional polynomial modelsare considered: a first-order model, a first-order model withcross-product terms, a second-order model, and a second-order modelwith cross-product terms.  The identifiability of these fractionalpolynomial models is also explored.  The authors have written auser-friendly R function to perform the maximum likelihood estimationof the transformation parameters.  This function allows the user tofix any of the transformation parameters, produce model diagnostics,and optionally includes a back-transformed plot of the fitted surface. In each of the examples, the best fractional polynomial model was animprovement over the untransformed polynomial model.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Nonlinear models,Applied data analysis,,,,,,,12-Nov-10,chang.yu@vanderbilt.edu,,Chang Yu,Assistant Professor,"Dept. of Biostatistics, VUMC","Dept. of Biostatistics, VUMC",615-322-8422,,chang.yu@vanderbilt.edu,Using orthogonal decomposition to correct correlated measurement errors in physical activity studies,1,Chang,,Yu,"Department of BiostatisticsVanderbilt University School of Medicine",Sanguo,,Zhang,,Charles,E.,Matthews,,Christine,,Friedenreich,,,,,,,,,,,,,,,,,,,,,,,,,,"Epidemiology studies have demonstrated that physical activityis inversely associated with numerous chronic diseases.However, measurement of physical activity using questionnaires contains asignificant amount of measurement errors. These errors lead toattenuated estimates of the underlying association. Weattempt to correct measurement errors using an alloyed goldstandard, 7-day physical activity logs. Due to the correlation between the errorsin the two measurements, the usual regression calibration method can not satisfactorily correct the errors. We propose to adjust the regression calibration byorthogonal decomposition of the errors to remove the correlation, then the usual regression calibration can be applied.Simulation studies demonstrate that our method can effectivelycorrect the bias in the estimate of the calibration factor that is induced by the correlated errors. Our method canbe applied to studies in which both the error-pronemeasurement and the alloyed gold standard measurement are obtainedmore than once in the validation study. The advantage of our method is that we do not need the third measurement in the validation study to correct the correlated errors.",FALSE,FALSE,,FALSE,FALSE,TRUE,I have to leave the meeting in the evening of March 22nd.,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Measurement error,Epidemiologic methods,,,,,,,29-Oct-10,changying8618@yahoo.com,,Changying Angela Liu,Principle Statistical Scientist,"PPD, INC",38175 Lantern Hill Court,248 892 6789,,changying8618@yahoo.com,"Futility Analysis, Conditional Power Analysis and EaSt",1,Angela,,Liu,"PPD, Inc",Jurgen,,Hummel,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Conditional Power (CP) technique is widely used in clinical trials. The standard method proposed by Lan & Wittes (1988) assumes that a study enrollment is slow and only a subset of the planned patients have been enrolled when an interim analysis is conducted. Therefore only a fraction of the maximum information is observed at the interim analysis. The example in our talk is based on a conditional power analysis for a trial where all patients were enrolled at the time of the interim analysis, but only a fraction of the patients have observed the primary endpoint (which is a binary event). Therefore the standard method for conditional power analysis can not be applied directly. Conditional on the total number of events at the end of study, the number of events in each treatment group will follow a binomial distribution. Then the total sample size will be the total number of events at the end of study, and at each interim analysis only a fraction of the primary endpoint events would be observed. This approach satisfies the assumption of Lan & Wittes algorithm and allows its implementation using the EAST software.",FALSE,FALSE,,FALSE,TRUE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Biopharmaceutical research,"Biologics, pharmaceuticals, medical devices",,,,,,,05-Oct-10,chaolong@umich.edu,,Chaolong Wang,PhD candidate,University of Michigan,"2017 Palmer Commons,",+1 734 615 9551,,chaolong@umich.edu,A Maximum Likelihood Genotype Imputation Method to Correct for Allelic Dropout in Microsatellite Data,1,Chaolong,,Wang,"Center for Computational Medicine and Bioinformatics, University of Michigan, Ann Arbor",Kari,B,Schroeder,"Department of Anthropology, University of California, Davis",Noah,A,Rosenberg,"Center for Computational Medicine and Bioinformatics, Department of Human Genetics, and Life Sciences Institute, University of Michigan, Ann Arbor",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Allelic dropout is a commonly observed source of missing data inmicrosatellite genotypes, in which one or both allelic copies at alocus fail to be amplified by the polymerase chain reaction.Especially for samples with poor DNA quality, this problem causes adownward bias in estimates of heterozygosity, due to mistakenclassifications of heterozygotes as homozygotes when one of the twocopies drops out. In this study, we propose a maximum likelihoodapproach together with an EM algorithm to jointly estimate allelicdropout rates and allele frequencies when only one set ofnonreplicated genotypes is available. Using the estimated parametersand an assumption of Hardy-Weinberg equilibrium, we correct the biasin the estimation of heterozygosity through the use of multipleimputations of alleles in cases where dropout might have occurred.With simulated data, we show that our method can (1) effectivelyreproduce the pattern of missing data and heterozygosity observed inreal data; (2) correctly estimate the dropout rates if they aresufficiently small (<15%); and (3) successfully correct the downwardbias in estimating heterozygosity. Because the datasets imputed underour model can be investigated in additional subsequent analyses, ourmethod will be useful for preparing data for applications in diversecontexts in population genetics and molecular ecology.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Missing data,Statistical genetics,,,,,,,15-Nov-10,charles.hall@einstein.yu.edu,,Charles B. Hall,Professor,Albert Einstein College of Medicine,1300 Morris Park Avenue,1-718-430-3724,1-718-430-8649,charles.hall@einstein.yu.edu,Correction of bias in estimating rates of cognitive decline using auxiliary telephone cognitive evaluation data,2,Cuiling,,Wang,Albert Einstein College of Medicine,Charles,B,Hall,Albert Einstein College of Medicine,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Background: In longitudinal studies, missing data are common due to drop out, lost to follow-up, death or missed visits. Regular analyses usually assume that the data are missing at random (MAR). This assumption is un-testable without further information, and might result in bias in the estimation of rates of cognitive decline. Methods:  In the Einstein Aging Study, participants receive cognitive assessments on the telephone and in person. Often, participants with missing in person assessments will have a telephone assessment, which provides us the ability to test the MAR assumption under auxiliary variable MAR (A-MAR), and correct the bias if it is violated. We used a random effects model to jointly model the in-house Free and Cued Selective Reminding (FCSRT) and the telephone Memory Impairment Screen (MIS). Findings:  Participants with lower MIS score were more likely to have missing FCSRT. The estimated rate of decline in FCSRT using the naive model is 0.333 (SE=0.020) points per year. In the joint model, the estimate is 0.363 (SE=0.0198) points per year.  Conclusions: Naive estimates of cognitive decline that ignore potentially informative missing data may be under-estimated. Joint modeling with auxiliary telephone data has the potential to correct some of the bias.",FALSE,FALSE,,FALSE,TRUE,TRUE,"The Jewish holiday of Purim is Sunday.Tutorial T6: Intro To the MCMC Procedure in SAS/STAT SoftwareRoundtable RT2: Emerging Issues for Neuroimaging Stat & Statisticians",presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Missing data,Epidemiologic methods,,,,,,,15-Nov-10,chava.zibman@fda.hhs.gov,,Chava Zibman,Mathematical Statistician,U.S. Food and Drug Administration,10903 New Hampshire Ave,301-796-5325,,chava.zibman@fda.hhs.gov,Validation of probability estimates produced by diagnostic devices,1,Chava,E,Zibman,U.S. Food and Drug Administration,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Several diagnostic devices exist to provide information that may be expressed as a probability.  This may be a probability that a patient may experience a particular event in the future or that a probability that the patient is currently in a given state of disease when the truth is unknown.  Most classification and risk assessment devices, however, report findings in categorical terms and, in doing so, cause information to be lost.  This presentation will begin with an overview of the advantages and disadvantages of providing a probability estimate instead of  assigning a patient to a category.  I will then review the literature on how to validate probability and discuss how current knowledge applies to the context of clinical study design.  Lastly, I will present hypothetical examples based on recent submissions to the FDA.",FALSE,FALSE,,FALSE,FALSE,FALSE,,contributedposter,,,,FALSE,FALSE,FALSE,TRUE,"Biologics, pharmaceuticals, medical devices",Clinical trials,,,,,,,15-Nov-10,chenguang.wang@fda.hhs.gov,,Chenguang Wang,,FDA/CDRH,10903 New Hampshire Avenue Bldg 66 RM2257,3017969692,,chenguang.wang@fda.hhs.gov,A Model for Transgenerational Imprinting Variation in Complex Traits,1,Chenguang,,Wang,"Center for Devices and Radiological Health, FDA",Zhong,,Wang,"Center for Statistical Genetics, Pennsylvania State University, Hershey, Pennsylvania",Daniel,R.,Prows,"Department of Pediatrics, University of Cincinnati College of Medicine, Cincinnati, Ohio",Rongling,,Wu,"Center for Statistical Genetics, Pennsylvania State University, Hershey, Pennsylvania",,,,,,,,,,,,,,,,,,,,,,,,,"Despite the fact that genetic imprinting plays a pivotal role in controlling complex traits or diseases, the origin, action and transmission mode of imprinted genes have still remained largely unexplored. We present a new strategy for studying these properties of genetic imprinting with a two-stage reciprocal F2 mating design, initiated with two contrasting inbred lines. This strategy maps quantitative trait loci that are imprinted (i.e., iQTLs) based on their segregation and transmission across different generations. By incorporating the allelic configuration of an iQTL genotype into a mixture model framework, this strategy provides a path to trace the parental origin of alleles from previous generations.  The new strategy will provide a tool for quantifying the role of imprinting effects in the creation and maintenance of phenotypic diversity and elucidating a comprehensive picture of the genetic architecture of complex traits and diseases.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Statistical genetics,Experimental design,,,,,,,19-Oct-10,chenhu@umich.edu,,Chen Hu,,"Department of Biostatistics, University of Michiga",1420 Washington Heights,734-358-2110,,chenhu@umich.edu,Semiparametric Regression Inference for Cancer Stage-Diagnosis Time Relationship in Cancer Studies,1,Chen,,Hu,"Department of Biostatistics, University of Michigan",Alex,,Tsodikov,"Department of Biostatistics, University of Michigan",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In cancer studies, it is of great interest to understand therelationship between age and cancer stage at diagnosis, as well aswhat factors affect the relationship. We address this question througha semiparametric regression model for stage-specific cancer incidence.Such data structure requires a joint model for correlated survival andbinary data. Constructed through a series of semiparametric regressionmodels with time-dependent covariates, our model can be represented asa transformation model induced by a complex non-proportional frailty.The estimation procedure and asymptotic variance of proposed estimatorcan be easily implemented and obtained numerically. The methodology isillustrated by Monte Carlo simulation studies and real prostate cancerincidence data from the Surveillance, Epidemiology and End Results(SEER) program.",FALSE,FALSE,,FALSE,TRUE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,TRUE,Cancer applications,Survival analysis,,,,,,,12-Nov-10,chenjun@mail.med.upenn.edu,,Jun Chen,,University of Pennsylvania,"206 Blockley Hall,423 Guardian Dr",2158820266,,chenjun@mail.med.upenn.edu,Network-Constrained Sparse Canonical Correlation Analysis  with Applications in Genomic and Metagenomic Data Analysis,1,Jun,,Chen,University of Pennsylvania School of Medicine,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"With the development of high throughput technology, it has becomecommon for biologists to perform two genomic measurements such as geneexpression profiling and genotyping on the same sample. Sparsecanonical correlation analysis (SCCA), which identifies  a subset offeatures from each data set that are highly correlated, has been shownto be useful in the simultaneous analysis of two genomic data sets.However, SCCA does not consider the prior structure information amongthe variables. In high dimensional setting, it is important toincorporate the prior information in the analysis so as to constrainthe space of possible solutions to those that are relevant to knowninformation, which is key in creating a meaningful analysis. In thispaper, we introduce the network-constrained SCCA (NSCCA), an extensionof SCCA that exploits the network structure among variables byimposing a network constraint. We have developed two versions of NSCCAbased on L1  penalty (NSCCA-L1) and the recently proposed maximumconcave penalty (NSCCA-MCP). We demonstrate these new methods onsimulated data as well as on a yeast genomic data set and a smallscale human gut metagenomic data set. Both simulations and real dataapplications show that NSCCA usually has more power than SCCA inidentifying relevant variables.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Variable subset selection/model selection,Genomics,,,,,,,11-Nov-10,chenyanh@umich.edu,,Yanhua Chen,,University of Michigan,1415 Washington Heights,(734) 764-5425,(734) 763-5455,chenyanh@umich.edu,Graphical Interface for Kidney Paired Donation Program,1,Yanhua,,Chen,"Department of Biostatistics, University of Michigan",Peter,X.K.,Song,"Department of Biostatistics, University of Michigan",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We develop a graphical interface to enhance the visualization of outputs from the Kidney Paired Donation (KPD) program. KPD program is largely based on micro-simulation models to evaluate and compare allocation strategies and effects of policy. There is no user friendly platform to date that allows researchers to interact easily between inputs and outputs in a KPD simulation model. Thus, the developed interface will facilitate the clinical research related to KPD program.The developed interface supports a range of functions.  Input parameters include the KPD donor/patient database, pool size, length of match-run cycle, frequency of match runs, and kidney allocation strategy for paired and altruistic donors.  Outputs include donor-recipient matches, utilities of matches, probabilities of success in match, and differential utilities among different allocation strategies with or without altruistic donors. In addition, the interface helps clinicians, donors and patients easily visualize and assess pros and cons of their chosen inputs to KPD program. The interface is developed to be scalable and tailored to be a specific regional or a national KPD program.",FALSE,FALSE,,FALSE,FALSE,FALSE,,contributedposter,,,,FALSE,FALSE,FALSE,FALSE,Health policy applications,Applied data analysis,,,,,,,15-Nov-10,chenyong1203@gmail.com,,Yong Chen,Assistant Professor,University of Texas School of Public Health,1200 Pressler St Room W932,7135009569,7135009329,chenyong1203@gmail.com,On the asymptotic behavior of the pseudolikelihood ratio test statistic with boundary problems,1,Yong,,Chen,University of Texas School of Public Health,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In this talk, we consider the asymptotic distribution of the likelihood ratio statistic $T$ for testing a subset of parameter of interest $\theta$, $\theta=(\gamma, \eta)$, $H_0: \gamma=\gamma_0$, based on the pseudolikelihood$L(\theta, \hat \phi)$, where $\hat \phi$ is a consistent estimator of infinite dimensional parameter $\phi$, the nuisance parameter. We conducted simulation studies to examine the performance of the likelihood ratio test statistics through a setting of frailty survival models.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Constrained estimation/order restricted inference,Survival analysis,,,,,,,15-Nov-10,ches@email.unc.edu,,Che Smith,,UNC Chapel Hill,3101 McGavran-Greenberg,919-279-0708,,ches@email.unc.edu,Developing a Test of Separate Hypotheses for the Linear Mixed Model,1,Che,L,Smith,"Department of Biostatistics, UNC Chapel Hill",Lloyd,J,Edwards,"Department of Biostatistics, UNC Chapel Hill",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In building linear mixed models, finding techniques for selecting anadequate model remains an important and often neglected area ofresearch. This is especially true for the case of selecting betweennonnested mixed models.  We explore the development of a test ofseparate hypotheses based on the work of David R. Cox to be applied tolinear mixed models arising from longitudinal data analysis. Weaddress the complex issue of estimating the variance of the teststatistic through the use of bootstrapping. The proper development ofthis method shows promise for expanding model selection methods forthe linear mixed model.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Longitudinal data,Variable subset selection/model selection,,,,,,,14-Nov-10,chiranjit@stat.duke.edu,,Chiranjit Mukherjee,PhD Candidate,"Department of Statistical Science, Duke University",Department of Statistical Science,919-423-3141,,chiranjit@stat.duke.edu,Novel Bayesian Models and Inference for High-Resolution Lattice Data,1,Chiranjit,,Mukherjee,"PhD candidate, Department of Statistical Science, Duke University.",Mike,,West,"Arts & Sciences Professor of Statistical Science and Director of Graduate Studies, Department of Statistical Science, Duke University.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Applied studies in multiple areas involving spatial systemsincreasingly challenge our modelling and computational abilities withhigh-resolution data and complex dependency patterns. We havedeveloped a new class of spatially-varyingsimultaneous autoregressive (SVSAR) models that neatly extends theclass of simultaneous autoregressive (SAR) models to capture spatialinhomogeneities, introducing a second-stage SAR prior for theautoregressive parameters of the first stage (data) SAR model. Thisnovel specification allows for a smooth variation in the structure ofthe local dependencies among spatial outcomes. In essence, SVSAR is aspatial analogue of the time-varying autoregressive (TVAR) extensionof traditional AR models in time series.Our new model has a number of attractive properties arising from itsbasis in Markov random fields, like fast numeric computation forsparse matrices that enables the development of full Bayesianinference even with huge datasets. This potential is evidenced in ourapplied example in atmospheric chemistry, where focus is on inverseanalysis of satellite data to infer ground-level CO emissions frommultiple candidate sources on a global scale.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Spatial/temporal modeling,Environmental and ecological applications,,,,,,,14-Nov-10,chl98@pitt.edu,,Ching-Wen Lee,Student,"Dept of Biostatistics, U of Pittsburgh",5700 Centre Ave. Apt. #714,412-251-3998,,chl98@pitt.edu,Joint modeling of a binary outcome and bivariate longitudinal markers subject to censoring due to detection limits,1,Ching-Wen,,Lee,"Department of Biostatistics, University of Pittsburgh",Lan,,Kong,"Department of Biostatistics, University of Pittsburgh",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Multiple biomarkers from the same or different pathways are often measured over time to better understand the mechanism of a disease and to aid in the development of effective treatments. Joint modeling of multiple longitudinal markers and a clinical outcome is an appealing technique to reveal the relationship between biomarker trajectories and the evolution of the disease. However; the joint analysis can be complicated by censored data in the biomarker measurements due to either lower or upper detection limits on the measurement of the biomarker.  We propose a likelihood-based joint model for a binary outcome with an adjustment for the censored longitudinal covariate processes. Specifically, we construct the logistic regression model for the binary outcome and the linear mixed model for the bivariate longitudinal markers with the censoring taken into account. The random effects in the mixed models are the shared parameters that link the two submodels.  Given the random effects, the repeated measurements are assumed to be independent within each marker and between the two markers. The maximum likelihood estimates of the parameters are obtained using the SAS procedure PROC NLMIXED. We evaluate the proposed method and compare it to the naive substitution methods through simulation studies. A numerical example is also given for illustration.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Other,Longitudinal data,Joint models for longitudinal and binary outcome data,,,,,,03-Nov-10,cho75@illinois.edu,,HYUN KEUN CHO,Ph.D candidate,UNIVERSITY OF ILLINOIS AT URBANA CHAMPAIGN,"101 Illini Hall, MC-374  725 South Wright Street",2179797896,,cho75@illinois.edu,Model selection for correlated data with diverging number of parameters,1,Hyunkeun,,Cho,University of Illinois at Urbana-Champaign,Annie,,Qu,University of Illinois at Urbana-Champaign,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Longitudinal data with high-dimensional covariates arises frequently in biomedical and bioinformatic studies. Model selection for longitudinal data is very important, yet challenging when the dimension of the parameters diverges as the sample size increases. We propose a penalized quadratic inference function (QIF) to perform model selection and estimate coefficients simultaneously in the framework of a diverging number of parameters. The penalized QIF can easily take into account correlation information from clustered data and does not require specifying the likelihood function, which is advantageous compared to existing model selection methods for discrete data with large cluster size. In addition, the proposed approach enjoys the oracle property, which is able to identify non-zero components correctly with probability tending to 1, and any valid linear combination of the estimated non-zero components also follows an asymptotic normal distribution. We propose an efficient algorithm by selecting an effective tuning parameter to solve the penalized QIF. Monte Carlo simulation studies illustrate that the proposed method selects the correct model with a high frequency even when the dimension of parameters is high. We illustrate the penalized QIF approach through analyzing periodontal disease data.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Variable subset selection/model selection,Longitudinal data,,,,,,,27-Oct-10,choh3@mail.nih.gov,,Hyunsoon Cho,Mathematical Statistician,National cancer institute,"6116 Executive Blvd, Room 5053",3014020799,,choh3@mail.nih.gov,A method to estimate non-cancer life table for US cancer patients,1,Hyunsoon,,Cho,National Cancer Institute,Angela,B,Mariotto,National Cancer Institute,Eric,J,Feuer,National Cancer Institute,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Relative survival is a standard method to estimate net cancer survival from registry data and the method depends on the assumption that other causes mortality for the cohort of patients is well represented by the respective life tables after matching by age, sex, race and calendar year. In this study, we apply survival methods for left truncated and right censored data to estimate non-cancer (other-cause) survival for different cohorts of cancer patients and to compare with US life tables. Data from the Surveillance, Epidemiology and End Results (SEER) is used to estimate survival from a death due to causes other than a diagnosed cancer. The results show that US life tables may not represent non-cancer survival for some cohorts of cancer patients (e.g. breast, lung). This has an implication that relative survival estimates which rely on life tables to represent expected other-cause survival may not be accurate for some cohorts of cancer patients.",FALSE,FALSE,,FALSE,TRUE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Cancer applications,Epidemiologic methods,,,,,,,11-Nov-10,chris_paciorek@yahoo.com,,Christopher Paciorek,,Department of Statistics,367 Evans Hall,510-842-6670,,chris_paciorek@yahoo.com,"Measurement error effects on bias and variance in two-stage regression, with application to air pollution epidemiology",1,Christopher,J,Paciorek,"Department of Biostatistics, Harvard School of Public Heath; andDepartment of Statistics, University of California, Berkeley",Adam,A,Szpiro,"Department of Biostatistics, University of Washington",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In environmental epidemiology, the health effect of an exposure isoften estimated by using predictions from a first stage model (theexposure model) as an explanatory variable in the second stage model(the health analysis).  In the context of the second stage model, theuncertainty about the true exposure produces measurement error, with acomplicated dependence structure induced by the first stage model. Wepropose a new probabilistic framework to analyze the effects ofmeasurement error in two-stage settings with a spatial context,treating the spatial locations as random and the unknown exposuresurface as deterministic.  We decompose the measurement error intoBerkson, Berkson-like, and classical-like components and analyze thebias and variance induced by the different components.  In particular,variability in regression coefficients from the first stage modelinduces both bias and variance in the second stage estimation. Wesuggest an approach to estimate this bias and variance, as well asadvice for how to fit the first stage model to reduce bias andvariance.  Finally, we  suggest a design-based bootstrap to estimateuncertainty in the second stage analysis.  We illustrate the ideas inthe context of the long-term health effects of air pollution.",TRUE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Measurement error,Epidemiologic methods,,,,,,,14-Nov-10,chungdon@stat.wisc.edu,,Dongjun Chung,,University of Wisconsin at Madison,Medical Science Center,608-469-2711,,chungdon@stat.wisc.edu,Modeling multi-reads in ChIP-seq analysis,1,Dongjun,,Chung,"Department of Statistics, University of Wisconsin, Madison, WI, USA; Department of Biostatistics and Medical Informatics, University of Wisconsin, Madison, WI, USA",Pei Fen,,Kuan,"Department of Biostatistics, University of North Carolina, Chapel Hill, NC, USA",Bo,,Li,"Department of Computer Science, University of Wisconsin, Madison, WI, USA; Department of Biostatistics and Medical Informatics, University of Wisconsin, Madison, WI, USA",Sanal,,Kumar,"Wisconsin Institutes for Medical Research, UW Carbone Cancer Center, Department of Cell and Regenerative Biology, University of WIsconsin School of Medicine and Public Health",Kun,,Liang,"Department of Statistics, University of Wisconsin, Madison, WI, USA; Department of Biostatistics and Medical Informatics, University of Wisconsin, Madison, WI, USA",Emery,,Bresnick,"Wisconsin Institutes for Medical Research, UW Carbone Cancer Center, Department of Cell and Regenerative Biology, University of WIsconsin School of Medicine and Public Health",Colin,,Dewey,"Department of Computer Science, University of Wisconsin, Madison, WI, USA; Department of Biostatistics and Medical Informatics, University of Wisconsin, Madison, WI, USA",Sunduz,,Keles,"Department of Statistics, University of Wisconsin, Madison, WI, USA; Department of Biostatistics and Medical Informatics, University of Wisconsin, Madison, WI, USA",,,,,,,,,"Current state of the art for analyzing chromatin immunoprecipitationfollowed by high-throughput sequencing (ChIP-seq) data relies on onlyusing reads that uniquely map to the relevant reference genome(uni-reads). This can lead to omission of up to 20% of alignablereads. We describe a general approach for utilizing reads that map tomultiple locations on the reference genome (multi-reads). Our approachis based on allocating multi-reads as fractional counts using aweighted alignment scheme. Using human STAT1 and mouse GATA1 ChIP-seqdatasets, we illustrate that incorporation of multi-readssignificantly increases sequencing depths of ChIP-seq data, leads todetection of novel peaks that are not otherwise identifiable withuni-reads, and assists in identification of peaks that are in mappableregions. We investigate various genome-wide characteristics of peaksdetected only by utilization of multi-reads via computationalexperiments. Overall, these peaks have similar characteristics topeaks that are identified by uni-reads with the exception that amajority of them reside in segmental duplication regions. We furthersupport detection of novel peaks with quantitative ChIP validation ofa small number of peaks detected only by utilization of multi-reads.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Statistical genetics,Genomics,,,,,,,15-Nov-10,Chung-Han.Ho@uth.tmc.edu,,Chung-Han Ho,,UT MD Anderson,Department of Epidemiology,7137452073,,Chung-Han.Ho@uth.tmc.edu,Identifying the Transition of the CBMN Biomarker in the Lung Cancer Risk Model,1,Chung-Han,,Ho,"Division of BiostatisticsUT School of Public Health;Department of EpidemiologyUT M.D. Anderson Cancer Center",Wenyaw,,Chan,"Division of BiostatisticsUT School of Public Health",Randa,,El-Zein,"Department of EpidemiologyUT M.D. Anderson Cancer Center",Carol,J.,Etzel,"Department of Epidemiology UT MD Anderson Cancer Center",,,,,,,,,,,,,,,,,,,,,,,,,"The tobacco-specific nitrosamine4-(methylnitrosamino)-1-(3-pyridyl)-1-butanone (NNK) is an obviouscarcinogen for lung cancer. Since CBMN (Cytokinesis-blockedmicronucleus) has been found to be extremely sensitive to NNK-inducedgenetic damage, it is a potential important factor to predict the lungcancer risk. However, the association between lung cancer and two CBMNstages under NNK-induced genetic damage has not been rigorouslyexamined. This research proposes to model the chromosomal changesunder NNK-induced genetic damage in a logistic regression framework inorder to predict the occurrence of lung cancer. Since thesechromosomal changes were usually not observed very long due to labcost and time, a resampling technique is applied to generate theMarkov chain of the normal and the damaged cell for each individual. Ajoint likelihood between the resampled Markov chains and the logisticregression model including transition probabilities of this chain ascovariates is established. The Maximum likelihood estimation isapplied to carry on the statistical test for comparison. The abilityof this approach to increase discriminating power to predict lungcancer will be compared to a baseline non-genetic model.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Epidemiologic methods,Cancer applications,,,,,,,03-Nov-10,chux0051@umn.edu,,Haitao Chu,Associate Professor,University of Minnesota,"A460 Mayo Building, MMC 303",6126252138,,chux0051@umn.edu,Estimation of risk ratios in cohort studies with common outcomes: A Bayesian approach,1,Haitao,,Chu,University of Minnesota at Twin Cities,Stephen,R,Cole,The Univerity of North Carolina at Chapel Hill,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In cohort studies with common outcomes, the odds ratio estimated from a logistic regression analysis is often interpreted as an indirect estimate of the risk ratio. In such settings the odds ratio will be farther from the null than the risk ratio. Direct and unbiased estimates of the risk ratio may be obtained from a log binomial model fit by maximum likelihood (ML). When the ML log binomial model fails to converge (as is common) or provides predicted probability estimates or upper confidence limits greater than 1.0, various approaches have been suggested, but each has drawbacks, as we describe. We propose a novel Bayesian approach for the estimation of the risk ratio from the log binomial model that addresses drawbacks of existing approaches. Posterior computation can be accomplished easily using the WinBUGs code provided. In addition to simulation studies, a real data analysis is provided for the estimation of the 10-year risk of clinical AIDS or death in the natural history period of HIV from the Multicenter AIDS Cohort Study.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Epidemiologic methods,Bayesian methods,,,,,,,15-Nov-10,cindy.chen@vanderbilt.edu,,Qingxia Chen,Assistant Professor,Vanderbilt University,"1161 21st Ave S, S-2323 MCN",6159368058,,cindy.chen@vanderbilt.edu,A Bayesian Approach for Biomarker Measurement with Detection-Limit with an Application to Acute Lung Injury,1,Qingxia,,Chen,Vanderbilt University,Huiyun,,Wu,Vanderbilt University,Tatsuki,,Koyama,Vanderbilt University,Richard,D,Fremont,Vanderbilt University,Lorraine,B,Ware,Vanderbilt University,,,,,,,,,,,,,,,,,,,,,"Biomarkers have potential in disease diagnosis andprognosis. Detection limit (DL), however, jeopardizes theapplication of biomarkers in research and practice. Currently,most existing methods focus on the case when outcome is subject to DL,and few studies exposure with DL. In this paper, we propose aBayesian approach for generalized linear model with exposuresubject to DL, as well as with exposure subject to both lower andupper DLs. In the simulation studies, we compare the proposedBayesian approach to four commonly used DL methods in a logisticregression model with exposure measurements subject to DL. Thesemethods include single replacement with DL/2 threshold, deletion,regular multiple imputation, regression on order statistics. Insimulation study, Bayesian outperformed other methods with thesmallest bias, root mean squared error, nominal coverage probabilityof 95% confidence interval , and correct type I error rate except whenDL fraction increases to 50% (6.5%). We also apply all five methods inthe motivating acute lung injury and found IL8 was a significantpredictor for ALI in the model based on the proposed Bayesian approach.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Biomarkers/surrogate markers,Bayesian methods,,,,,,,15-Oct-10,ckang@bios.unc.edu,,CHAERYON KANG,,"Department of Biostatistics, University of North C","Dept. of Biostatistics, University of North Carolina at Chapel Hill",9195935904,,ckang@bios.unc.edu,The Interactive Decision Committee for Chemical Toxicity data analysis.,1,CHAERYON,,KANG,"Dept. of Biostatistics, University of North Carolina at Chapel Hill",Hao,,Zhu,"Laboratory for Molecular Modeling, Division of Medicinal Chemistry and Natural Products,School of Pharmacy, UNC-CH",Fred,A,Wright,"Dept. of Biostatistics, University of North Carolina at Chapel Hill",Fei,,Zou,"Dept. of Biostatistics, University of North Carolina at Chapel Hill",Michael,R,Kosorok,"Dept. of Biostatistics, University of North Carolina at Chapel Hill",,,,,,,,,,,,,,,,,,,,,"We introduce the Interactive Decision Commiittee method to study a classification problem in the case that high-dimensional feature variables belong to a set offeature categories. The proposed method uses the interactive relationships among existing feature categories to build base classifiers in the decision committee context. A two-stage5-fold cross-validation technique is utilized to decide the total number of base classifiers to be combined. The proposed procedure is useful for classifying biochemicals on the basis oftoxicity activity, where the feature space consists of chemical descriptors and the responses are eighteen binary toxicity activities. Each descriptor belongs to at least one descriptor block. A data analysis applying our method to rats/mice/rabbits acute toxicity data are presented to demonstrate utility of the proposed method. The support vector machine algorithm isutilized as a classifier inducer. Forward selection is used to select the best combinations of the base classifiers given the number of base classifiers. In this study, the proposed methodoutperforms other decision committee methods including adaboost, bagging, random forest, and univariate decision committee methods as well as using a single classifier.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Toxicology/dose-response,Machine learning,,,,,,,12-Nov-10,ckcarr2487@gmail.com,,Caroline Carr,,Virginia Commonwealth University,2300 E Tremont Ct,5078849993,,ckcarr2487@gmail.com,Determing a Robust D-Optimal Design for Testing for Departures from Additivity in a Mixture of 4 PFAAs,1,Caroline,K,Carr,Virginia Commonwealth University,Chris,,Gennings,Virginia Commonwealth University,Barbara,D,Abbott,"NHEERL, U.S. EPA",Judy,E,Schmid,"NHEERL, U.S. EPA",Wen,,Wan,Virginia Commonwealth University,Lyle,,Burgoon,"NHEERL, U.S. EPA",Cynthia,J,Wolf,"NHEERL, U.S. EPA",Christopher,,Lau,"NHEERL, U.S. EPA",,,,,,,,,"Our objective was to determine an optimal experimental design for amixture of perfluoroalkyl acids (PFAAs) that is robust to theassumption of additivity. Of particular focus to this research projectis whether an environmentally relevant mixture of four PFAAs with longhalf-lives (PFOA, PFOS, PFNA, and PFHxS) acts synergistically. Thefirst phase involved an in vitro study with a transfected-cell modelto evaluate the ability of PFAAs to activate PPAR±. Using theresulting data, a non-linear logistic additivity model was employed topredict relative luciferase units (RLU) at an environmentally relevantmixing ratio that was estimated from NHANES (2005-2006) data. Thismodel was used in the design stage which used a maximin D-optimaldesign criterion to select an optimal design from a large set ofspecified designs. The candidate seven point designs (including onecontrol) were generated by varying the total dose locations and shapeof the dose-response curve with the additivity curve used as areference. A total of 6,006 designs and 13 dose-response shapes wereconsidered. A D-optimal design robust to misspecification of theresulting dose-response shape was found with a minimum D-efficiency of92%. The final stage of this research determined the necessary samplesize to test for additivity.(This research was partially supported by NIEHS T32ES007334 and doesnot reflect USEPA policy.)",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Experimental design,Toxicology/dose-response,,,,,,,02-Nov-10,clayton@stat.wisc.edu,,Murray Clayton,Professor,University of Wisconsin-Madison,1300 University Ave,608 262 6459,,clayton@stat.wisc.edu,Skilled Statistical Consultants are Often Skilled Leaders.  Why?,1,Murray,,Clayton,"Department of StatisticsUniversity of Wisconsin-Madison",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"My PhD is in statistics and the last biology class I took was in high school.  Regardless, I am the chair of the Department of Plant Pathology at the University of Wisconsin-Madison.  Although this is uncommon, I argue that it is not illogical -- many of the skills that are valuable in collaborative research and statistical consulting are also valuable in leadership.  I briefly review some of the essential skills for effective collaborations, and then discuss how those skills are also important for leaders.  Viewed from the other end, many of the skills discussed in the leadership literature are not foreign to consultants, although the jargon might be different.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Other,Consulting,Leadership,,,,,,12-Oct-10,cmitchel@bios.unc.edu,,Cicely Mitchell,,UNC-CH student,6517 Clarksdale Lane,919-806-6084,,cmitchel@bios.unc.edu,Discrete-time semi-Markov two-state modeling of human papillomavirus type-specific persistence,1,Cicely,E,Mitchell,"The University of North Carolina, Department of Biostatistics, Chapel Hill, NC",Michael,G,Hudgens,"The University of North Carolina, Department of Biostatistics, Chapel Hill, NC",Caroline,,King,"Centers for Disease Control and Prevention, Atlanta, GA",Susan,,Cu-Uvin,"Brown Medical School, Providence, RI",Yungtai,,Lo,"Montefiore Medical Center and Albert Einstein College of Medicine, Bronx, NY",Ann,,Rompalo,"Johns Hopkins University School of Medicine, Baltimore, MD",Jack,,Sobel,"Wayne State University School of Medicine, Detroit, MI",Jennifer,S,Smith,"The University of North Carolina, Department of Epidemiology, Chapel Hill, NC",,,,,,,,,"Multi-state modeling is often employed to describe the progression ofa disease process. In epidemiological studies of certain diseases, thedisease state is often only observed at periodic clinical visits,producing incomplete longitudinal data. In this paper we considerfitting semi-Markov two-state models to estimate the persistence ofhuman papillomavirus (HPV) type-specific infection in studies wherethe status of HPV type(s) is assessed periodically. Simulation studyresults are presented indicating the semi-Markov estimator is moreaccurate than an estimator currently used in the HPV literature. Themethods are illustrated using data from the HIV Epidemiology ResearchStudy (HERS).",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Applied data analysis,Nonparametric methods,,,,,,,26-Oct-10,cmzhang@stat.wisc.edu,,Chunming Zhang,Professor,University of Wisconsin-Madison,1300 University Avenue,608-262-0084,608-262-0032,cmzhang@stat.wisc.edu,MULTIPLE TESTING VIA FDR_L FOR LARGE SCALE IMAGING DATA,1,Chunming,,Zhang,University of Wisconsin-Madison,Jianqing,,Fan,Princeton University,Tao,,Yu,National University of Singapore,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The multiple testing procedure plays an important role in detectingthe presence of spatial signals for large scale imaging data.This paper provides empirical evidence that for a range of commonlyused control levels, the conventional FDR procedure can lack theability to detect statistical significance, even if the p-values underthe true null hypotheses are independent and uniformly distributed;more generally, ignoring the neighboring information of spatiallystructured data will tend to diminish the detection effectiveness ofthe FDR procedure. This paper first introduces a scalar quantity tocharacterize the extent to which the lack of identification phenomenon(LIP) of the FDR procedure occurs. Second, we propose a new multiplecomparison procedure, called FDR_L, to accommodate the spatialinformation of neighboring p-values.  It is shown that the FDR_Lprocedure alleviates the LIP of the FDR procedure. Simulationevaluations indicate that the FDR_L procedure improves the detectionsensitivity of the FDR procedure with little loss in detectionspecificity. The detection effectiveness of the FDR_L procedure isillustrated through a real brain fMRI dataset.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Multiple testing,Data mining/massive data sets,,,,,,,05-Nov-10,corberan@musc.edu,,Ana Corberan,Postdoctoral Fellow,Medical University of South Carolina,Division of Biostatistics and Epidemiology,843 345 1978,,corberan@musc.edu,Surveillance Conditional Predictive Ordinate: A Bayesian model-based approach for on-line spatio-temporal disease surveillance,2,Andrew,B.,Lawson,Medical University of South Carolina,Ana,,Corberan-Vallet,Medical University of South Carolina,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"When small area disease data in the form of counts are available, it is common to consider Bayesian hierarchical Poisson models with a mean which is a function of the expected counts of disease, representing the background population effects, and the unknown area-specific relative risks. In this work we build on Poisson count models for prospective spatio-temporal disease surveillance. In particular, we show how the conditional predictive ordinate, a general Bayesian diagnostic which detects observations discrepant from a given model, can be adapted in a surveillance context to detect small areas of unusual disease aggregation as quickly as possible. As a local measure, different alarms will be sounded for those areas of increased disease incidence. This will facilitate the medical interpretation of the alarms and the carrying out of preventive actions. A common prior probability that a given area signals an alarm when no change in risk takes place will be introduced into the model formulation to address the problem of multiple comparisons. In addition, our model formulation will allow us to determine the change in the relative risk pattern once an incident cluster is identified. We apply the method to monitoring of county level salmonella data from South Carolina.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Other,Spatial/temporal modeling,Surveillance epidemiology,,,,,,15-Nov-10,corina.sirbu@i3global.com,,Corina Sirbu,Principal Biostatistician,"i3 Statprobe, ingenix",4530 data ct,517-256-2739,,corina.sirbu@i3global.com,Review and comparisons of adaptive desing methods,1,Corina,,Sirbu,"i3 Statprobe, ingenix",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The need of an advanced statistical methodology and the value of adaptive designs are generally recognized by the health authority agencies in the USA and Europe. There are many scientific and ethical reasons for using adaptive designs. Many trials are designed with insufficient information on how the target patients would respond. In addition, changing patient population and medical practice often makes historical information inaccurate. Therefore the ability to evaluate mid-course assumptions made at the design stage is one of the most valuable benefits of interim analysis. As a result, the recommendation is to consider the need to check design assumptions using interim analysis. Case studies and simulations will be presented where a combination of sample size re-estimation and group sequential method is used. Various methods and software are compared.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,TRUE,Adaptive design/adaptive randomization,Power analysis/sample size,,,,,,,21-Sep-10,cpark@uga.edu,,Cheolwoo Park,Assistant Professor,University of Georgia,101 Cedar St.,706-542-3320,706-542-3391,cpark@uga.edu,Analysis of Long Period Variable Stars with Nonparametric Tests for Trend Detection,1,Cheolwoo,,Park,University of Georgia,Jeongyoun,,Ahn,University of Georgia,Martin,,Hendry,University of Glasgow,Woncheol,,Jang,University of Georgia,,,,,,,,,,,,,,,,,,,,,,,,,"In astronomy the study of variable stars - stars characterized by showing significant variation in their brightness over time - has made crucial contributions to our understanding of many fields, from stellar birth and evolution to the calibration of the extragalactic distance scale. In this talk, we perform a time series analysis of the periods between maximum brightness of a group of 378 long period variable stars. The objective of this study is to identify the stars which display certain trends in their periods, via multiple testing of a mean for non-stationary time series model. The novelty of the proposed method is two-fold: first, our approach is not only nonparametric for trends but also for covariance structure of non-stationary noise, for which functional clustering and principal component analysis are used. Another novel feature is the higher power of the proposed test for trend in each time series. The test is based on high dimensional normal mean inference, while controlling the false discovery rate to adjust multiplicity. A simulation study is also given to show the superior performance of the proposed method to other existing ones.",FALSE,FALSE,,FALSE,FALSE,FALSE,Not available on March 23 (Wednesday).,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Functional data analysis,High dimensional data,,,,,,,15-Nov-10,ctekwe@stat.tamu.edu,,Carmen Tekwe,Research Assistant Professor,"Department of Statistics, Texas A and M University",3143 TAMU,352-870-1124,,ctekwe@stat.tamu.edu,"Multiple Indicators, Multiple Causes Measurement Error Models",1,Carmen,D,Tekwe,"Department of StatisticsTexas A&M University",Randy,L,Carter,"Department of BiostatisticsUniversity at Buffalo",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Multiple Indicators, Multiple Causes (MIMIC) models are often employedby researchers studying the effects of an unobservable latent variableon a set of outcomes, when causes of the latent variable are observed. There are times however when the causes of the latent variable arenot observed because measurements of the causal variable arecontaminated by measurement error.  In this talk, I discuss (1) anextension of the classical linear MIMIC model to allow both Berksonand classical measurement errors, defining the MIMIC measurement error(MIMIC ME) model; (2) likelihood based estimation methods using the EMalgorithm with Monte Carlo approximation to the integral in the E-stepfor the MIMIC ME model; and (3) obtain data driven estimates of thevariance of the classical measurement error associated with log(DS02),an estimate of the amount of radiation dose received by atomic bombsurvivors at the time of their exposure.  The Adult Health Study (AHS)cohort of atomic bomb survivors who were exposed between 500 and 2500meters of the bomb hypocenters were studied.  The defined MIMIC MEmodel was applied to study the effects of dyslipidemia, a latentconstruct and the effect of true radiation dose on the physicalmanifestations of dyslipidemia.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Measurement error,Latent variables,,,,,,,15-Nov-10,ctfyang@uab.edu,,Celeste Yang,,UAB SOPH Biostatistics,3320 Cliff Road S Apt 12,205-563-5830,,ctfyang@uab.edu,Equivalence Testing and Multiplicity,1,Celeste,,Yang,"Department of BiostatisticsThe University of Alabama at Birmingham School of Public Health",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In certain situations it is of interest to show two treatments or moreare indistinguishable from each other.  Equivalence testing has beenused for awhile in biomedical research, and it is now beginning to beused in genetic research as well.  Using two one sided t tests (TOST),methods have been established for comparing two groups.  This paperwill look at TOST for comparing multiple groups.  We will review thecurrent literature dealing with multiplicity issues in higherdimensional data and compare the existing methods such as the unionintersection principle using simulation study as well as apply thesemethods to analyze data from a genetic experiment.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Multiple testing,High dimensional data,,,,,,,15-Nov-10,cxksma@rit.edu,,Chulmin Kim,Assistant Professor,Rochester Institute of Technology,85 Lomb Memorial Drive,585-475-7605,585-475-6627,cxksma@rit.edu,Models for the Covariance structure of Multivariate Longitudinal Data: Unconstrained Parameterization,1,Chulmin,,Kim,Rochester Institute of Technology,Dale,L.,Zimmerman,University of Iowa,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The constraint that a covariance matrix must be positive definite presents difficulties for modeling its structure. Pourahmadi proposed a parameterization of the covariance matrix for univariate longitudinal data in which the parameters are unconstrained, which is based on the modified Cholesky decomposition of the covariance matrix. We extend this approach to multivariate longitudinal data by developing a modified Cholesky block decomposition that provides an alternative unconstrained parameterization for the covariance matrix, and we propose parsimonious models within this parameterization. A Fisher scoring algorithm is developed for obtaining maximum likelihood estimates of parameters, assuming that the observations are normally distributed. The asymptotic distribution of the maximum likelihood estimators is derived. Estimation and model selection are illustrated using bivariate longitudinal data from a study of poplar growth.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Longitudinal data,Multivariate methods,,,,,,,09-Nov-10,cyuan2003@yahoo.com,,Guojun Yuan,Director,Pfizer,35 Cambridgepark Drive,617-665-8794,,cyuan2003@yahoo.com,Principal component methods for exploratory longitudinal data analysis,1,Guojun,,Yuan,Pfizer,Robert,,Pruzek,State University of New York at Albany,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"This paper proposes new uses of exploratory methods for longitudinal data analysis (ELDA) based on principal component analysis (PCA). Since no constraints are placed on profiles, the new methods can be described as non-parametric. Initial profiles are assumed to contain errors that should be addressed if an analyst is to gain improved predictability of individual profiles or an understanding of their similarities and differences. The basic method involves two kinds of smoothing: the first entails time-based pre-smoothing (especially using non-linear regression) for each profile that borrows strength from closely ordered time points; the second uses PC methods to borrow strength from co-related profiles. A second goal of the PC part of the analysis is to identify a subspace of low dimension that can provide a relatively small number of basic or generating profiles. The methods are first studied using simulated data to assess their effectiveness for recovering known longitudinal profiles in selected simulation contexts. Simulation results suggest that these methods can effectively recover initial generating profiles. Real data are also analyzed and extensive use is made of (R-based) graphics to expose similarities and differences among subsets of profiles; cluster analyses play a major roll in organizing the graphics.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Longitudinal data,Multivariate methods,,,,,,,15-Nov-10,d.afshartous@vanderbilt.edu,,David Afshartous,,Vanderbilt University,"1161 21st Ave S, S-2323 Medical Center North",615-875-3026,,d.afshartous@vanderbilt.edu,Improved Prediction of Subjective Hearing Aid Benefit via Mixed-effects Models,1,David,,Afshartous,Vanderbilt University,Benjamin,,Hornsby,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Current literature suggests that subjective measures of hearing aidbenefit (e.g., questionnaires) do not correlate well with objective(speech recognition tests) or predictive (calculated) methods ofquantifying hearing aid benefit. As such, a successful model topredict which individuals will receive hearing benefit from hearingaids, in terms ofimproved speech understanding, does not currently exist. In this study, weconsider mathematical predictions of hearing benefit based on anexisting method (ANSI S3.5 (1997) Speech Intelligibility Index). Suchmathematicalpredictions may be refined/corrected via observed measurements acrossa subset of the relevant prediction space, where this subset ofobserved measurements is used to estimate the corrections across theentire prediction space. We employ a mixed-effects model approach toestimate these corrections. The resulting corrected mathematicalpredictions are summarized via several weighting schemes and employedas predictors for two standardized subjective measures of hearing aidbenefit. Resampling techniques are employed to obtain estimates ofmodel performance on future data.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Applied data analysis,Random effects,,,,,,,03-Nov-10,d.rizopoulos@erasmusmc.nl,,Dimitris Rizopoulos,,"Dept. Biostatistics, Erasmus MC",PO Box 2040,+31107043478,+31107043014,d.rizopoulos@erasmusmc.nl,Prospective Accuracy in Joint Models for Longitudinal and Time-to-Event Data,1,Dimitris,,Rizopoulos,"Dept. Biostatistics, Erasmus Medical Center",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In longitudinal studies it is often of interest to investigate how amarker that is repeatedly measured in time is associated with a timeto an event of interest. This type of research questions has givenrise to a rapidly developing field of biostatistics research thatdeals with the joint modeling of longitudinal and time-to-event data.In this paper we consider this modeling framework and focusparticularly on the assessment of the predictive ability of thelongitudinal marker for thetime-to-event outcome. In particular, we derive accuracy measuresunder the joint modeling framework and assess how well the marker iscapable of discriminating between subjects who experience the eventwithin a medically meaningful time frame from subjects who do not. Weillustrate our proposals on a real data set on HIV infected patientsfor which we are interested in predicting the time-to-death usingtheir longitudinal CD4 cell count measurements.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Joint models for longitudinal and survival data,ROC analysis,,,,,,,15-Nov-10,dahl@stat.tamu.edu,,David B. Dahl,Associate Professor,Texas A&M University,3143 TAMU,979-845-3141,,dahl@stat.tamu.edu,A Dirichlet process mixture of hidden Markov models for protein structure prediction,2,Kristin,P,Lennox,Lawrence Livermore National Laboratory,David,B,Dahl,Texas A&M University,Marina,,Vannucci,Rice University,Ryan,,Day,University of the Pacific,Jerry,W,Tsai,University of the Pacific,,,,,,,,,,,,,,,,,,,,,"By providing new insights into the distribution of a proteins torsion angles, recent statistical models for this data have pointed the way to more efficient methods for protein structure prediction. Most current approaches have concentrated on bivariate models at a single sequence position. There is, however, considerable value in simultaneously modeling angle pairs at multiple sequence positions in a protein. One area of application for such models is in structure prediction for the highly variable loop and turn regions. Such modeling is difficult due to the fact that the number of known protein structures available to estimate these torsion angle distributions is typically small. Furthermore, the data is sparse in that not all proteins have angle pairs at each sequence position. We propose a new semiparametric model for the joint distributions of angle pairs at multiple sequence positions. Our model accommodates sparse data by leveraging known information about the behavior of protein secondary structure. We demonstrate our technique by predicting the torsion angles in a loop from the globin fold family. Our results show that a template-based approach can now be successfully extended to modeling the notoriously difficult loop and turn regions.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Proteomics,Bayesian methods,,,,,,,27-Oct-10,dai_feng@merck.com,,Dai Feng,,"Merck Co., & Inc.",RY33-300 P.O. Box 2000,732-594-7085,,dai_feng@merck.com,On the Frequentist Properties of Bayesian Credible Intervals for Intraclass Correlation Coefficients with Small Number of Raters,1,Dai,,Feng,"Merck & Co., Inc.",Vladimir,,Svetnik,"Merck & Co., Inc.",Alexandre,,Coimbra,"Merck & Co., Inc.",Richard,,Baumgartner,"Merck & Co., Inc.",,,,,,,,,,,,,,,,,,,,,,,,,"In drug development, an important task is to study reproducibility or test-retest reliability. Intraclass correlation coefficient (ICC) is a metric that has been widely used to assess the reproducibility. In particular, the ICC obtained from a mixed effects model with fixed rater effects is recommended in the situation with a small number of raters. This setup is typical in early drug development studies and it is the main interest of this work.  Various frequentist methods have been proposed to calculate confidence intervals (CIs) for the ICC. They include methods based on second and higher moment approximations and the delta method.  We propose using a Bayesian method with a Jeffreys' prior to obtain the credible sets. When there are two raters, the independent samples can be generated from constructive posteriors and obtained very quickly using vectorized computation in R. Judging by simulation studies and results on real EEG datasets, the Bayesian approach is at least comparable with and sometimes better than frequentist approaches based on different frequentist properties. The Bayesian method should be considered as an alternative for ICC CI calculation in early drug development.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,"Biologics, pharmaceuticals, medical devices",Biopharmaceutical research,,,,,,,08-Nov-10,dan87her@yahoo.com,,Michelle Danaher,"Predoctoral Fellow, IRTA","Eunice Kennedy Shriver, National Institute    of C",105 S Belle Grove Rd,240-538-8456,,dan87her@yahoo.com,Bayesian Order Restricted Inference for Hormonal Dynamics,1,Michelle,R,Danaher,"Eunice Kennedy Shriver, National Institute of Child Health and Human DevelopmentEpidemiology Branch, Division of Epidemiology, Statistics and Prevention Research",Anindya,,Roy,"University of Maryland, Baltimore County",Paul,S,Albert,"Eunice Kennedy Shriver, National Institute of Child Health and Human DevelopmentEpidemiology Branch, Division of Epidemiology, Statistics and Prevention Research",Enrique,F,Schisterman,"Eunice Kennedy Shriver, National Institute of Child Health and Human DevelopmentEpidemiology Branch, Division of Epidemiology, Statistics and Prevention Research",Zhen,,Chen,"Eunice Kennedy Shriver, National Institute of Child Health and Human DevelopmentEpidemiology Branch, Division of Epidemiology, Statistics and Prevention Research",Sunni,L,Mumford,"Eunice Kennedy Shriver, National Institute of Child Health and Human DevelopmentEpidemiology Branch, Division of Epidemiology, Statistics and Prevention Research",,,,,,,,,,,,,,,,,"Biomedical data often arise from well-understood biological processes.For example, hormone levels during the menstrual cycle of healthywomen are driven by well-established  biological relationships betweenluteinizing hormone, follicle-stimulating hormone, progesterone, andestrogen levels. For such data, incorporating the restrictions imposedby the underlying biological processes into the model can greatlyimprove statistical efficiently and provide estimates that areinterpretable in the context of the known biological relationships. Toaddress these constraints in the study of hormonal dynamics we proposea procedure that is similar to a Bayesian procedure, in which drawsfrom an unconstrained posterior distribution are projected back toconstraint space via optimization procedures.  However, while thereare general expectations about the biological relationships,deviations may occur. To address deviations, we relax some of theconstraints through a slack variable, and thus allow for theconstraints to be violated. Additionally, we propose a fully Bayesianprocedure by specifying priors on the constraint space using areparameterization via Minkowski decomposition.  We perform limitedsimulation to investigate properties of the proposed methods . Themethods are applied to data obtained from an epidemiologic study ofhormonal levels for women during two menstrual cycles.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Bayesian methods,Longitudinal data,,,,,,,12-Oct-10,danyang@wharton.upenn.edu,,Dan Yang,,"Department of Statistics, The Wharton School, Univ",3730 Walnut Street,2158981253,,danyang@wharton.upenn.edu,Optimal matching with minimal deviation from fine balance in a study of obesity and surgical outcomes,1,Dan,,Yang,"Department of Statistics, The Wharton School, University of Pennsylvania",Dylan,,Small,"Department of Statistics, The Wharton School, University of Pennsylvania",Jeffrey,H,Silber,"School of Medicine, University of Pennsylvania, The Children's Hospital of Philadelphia",Paul,R,Rosenbaum,"Department of Statistics, The Wharton School, University of Pennsylvania",,,,,,,,,,,,,,,,,,,,,,,,,"In multivariate matching, fine balance constrains the marginaldistributions of a nominal variable in treated and matched controlgroups to be identical without constraining who is matched to whom. Inthis way, a fine balance constraint can balance a nominal variablewith many levels while focusing efforts on other more importantvariables when pairing individuals to minimize the total covariatedistance within pairs. Fine balance is not always possible; that is,it is a constraint on an optimization problem, but the constraint isnot always feasible. We propose a new problem that is always feasibleand an algorithm which returns a minimum distance finely balancedmatch when one is feasible, and otherwise minimizes the total distanceamong all matched samples that minimize the deviation from finebalance. We also show how to incorporate an additional constraint. Thecase of knee surgery in the Obesity and Surgical Outcomes Studymotivated the development of this algorithm and is used as anillustration.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Causal inference,Computational methods,,,,,,,14-Nov-10,david.fardo@uky.edu,,David,,University of Kentucky,"121 Washington Ave, ste 201",859-218-2070,,david.fardo@uky.edu,Combining family- and population-based genetic association from multiple rare variants,1,David,,Fardo,University of Kentucky,Anthony,,Druen,University of Kentucky,Iuliana,,Ionita-Laza,Columbia University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Genetic association studies can be broken into two broad categories:population studies (most often of the case-control variety) thatcollect unrelated individuals, and family studies that recruit relatedpedigrees.  It is not uncommon for studies of both categories to beavailable for a particular disease.  In this situation, it is morepowerful to combine the evidence for association rather than toconduct the analyses separately.  Various aggregation approaches havebeen developed, but they have all been designed in the context ofcommon variants.Recently developed next generation sequencing technologies have madeit feasible to assess association between multiple rare variants anddisease.  This, in combination with motivation to target the so-called'missing heritability' from genome-wide association studies, has madethe study of rare variation particularly attractive.  Methods tohandle the problems due to the sparsity of rare variants generallyfocus on rules to collapse variation across some genetic unit, e.g., agene.  We present here a unified method to aggregate population andfamily data using resequencing data and assess its performance usingsimulation.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Statistical genetics,Genomics,,,,,,,15-Nov-10,davisjwa@health.missouri.edu,,J. Wade Davis,Assistant Professor,University of Missouri,DC 18.0 / Office of Med Res,573-882-0770,573-884-4196,davisjwa@health.missouri.edu,Modeling and Simulating RNA-Seq Data for Complex Experiments,1,Wade,,Davis,"Assistant ProfessorUniversity of MissouriDepartment of Health Management and InformaticsDepartment of Statistics",Ann,L,Oberg,"Associate Professor of BiostatisticsDivision of Biomedical Statistics and InformaticsMayo Clinic200 First St SWRochester, MN",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Next generation sequencing (NGS) is an exciting recent technology. A common application of NGS is RNA-Seq, which may be conceptualized asa digital version of the now ubiquitous analog gene expressionmicroarray technology. NGS data is digital in the sense that it iscount data, rather than continuous fluorescence data. RNA-Seq data hasbeen shown to have a technical error distribution which is Poisson,and a biological error distribution which is Negative Binomial. Inthis talk, we discuss our experience in modeling a complex experimentinvolving RNA-Seq data involving several fixed effects along withpaired or correlated observations. We present a variety of possibleanalytical modeling approaches, each with a different set ofbiological and statistical assumptions, and discuss the strengths andweaknesses of each technique. We conclude with recommendations for dealing with RNA-Seq analyses beyond those of the twoindependent-groups comparison.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Other,Microarray analysis,next generation sequencing,,,,,,15-Nov-10,davismat@mail.med.upenn.edu,,Matthew Davis,,University of Pennsylvania,25 W 8th St,(484) 467-7915,,davismat@mail.med.upenn.edu,Using SAS for Calculation of Prentice Constraints for GEE Analysis of Binary Data,1,Matthew,,Davis,University of Pennsylvania,Justine,,Shults,University of Pennsylvania,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"It is well known that in GEE analysis of binary data, that thecorrelations should satisfy additional constraints. We describe theconstraints in general and present simplified versions for a logisticmodel. We then demonstrate our SAS macro that can be usedto calculate the constraints. We recommend routine application ofthis macro after implementation of PROC GENMOD in GEE.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_poster,,,,FALSE,FALSE,FALSE,FALSE,Estimating equations,Applied data analysis,,,,,,,15-Nov-10,dawsonp@mail.med.upenn.edu,,Peter Dawson,,University of Pennsylvania,423 Guardian Drive,4132379725,,dawsonp@mail.med.upenn.edu,Beyond Traditional Biomarkers: Methods for Identifying a Non-Traditional Class of Biomarkers in Cancer,1,Peter,R,Dawson,University of Pennsylvania,DuPont,,Guerry,University of Pennsylvania,Phyllis,A,Gimotty,University of Pennsylvania,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The identification of new biomarkers that can accurately classify patients by diagnosis or predict patient outcomes is of the utmost importance in medicine. Currently, researchers focus on traditional biomarkers, i.e. ones that have a monotonic relationship with, for example, risk of disease or other outcomes. Standard methods based on the area under the curve (AUC) are adequate in the discovery of such traditional markers, but fail to identify potentially interesting biomarkers that violate the monotone assumption. The discovery of these non-traditional biomarkers could uncover important prognostic factors or enhance understanding of the biology underlying a disease. We propose a new method to identify non-traditional biomarkers for binary outcomes using a statistic based on the area between the empirical cumulative distribution functions (CDFs). The statistic is shown to have an asymptotic chi-square distribution. We report on simulation studies that demonstrate the attained significance and power of this statistic as a function of sample size and number of bins. We evaluate our test statistic by comparing it to alternative methods used to compare CDFs as well as a traditional method (AUC). Finally, the method will be applied to gene expression data to identify potential non-traditional biomarkers for classifying patients breast cancer stage.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Biomarkers/surrogate markers,High dimensional data,,,,,,,15-Nov-10,dbeavers@wfubmc.edu,,Daniel Beavers,Assistant Professor,Department of Biostatistical Science,Wake Forest University Health Sciences,336.713.1616,336.716.6427,dbeavers@wfubmc.edu,Bayesian Sample Size Determination for a Dual Test Diagnostic Protocol with a Binary Predictor Measured Without a Gold Standard Classifier,1,Daniel,P,Beavers,"Department of Biostatistical Science, Wake Forest University Health Sciences",James,D,Stamey,"Department of Statistical Science, Baylor University",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Statistical models that rely on data measured with misclassification yield biased relationships between explanatory and response variables.  Studies containing potentially misclassified predictors for which no gold standard exists must therefore utilize methods of measurement and analysis in the planning phases of the study that address this bias.  We investigate the relationship between a perfectly observed response and a binary predictor that is assessed with misclassification.  We discuss three methods for correcting for misclassification in the absence of a gold standard that lead to an identifiable model, and we propose a simulation-based Bayesian sample size determination algorithm for each method that relies on posterior power for achieving the optimal sample size for the effect related to the covariate.  We demonstrate our method in the context of a genetic study analyzing the relationship between a disease and genetic marker for which the gene of interest may be misclassified.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Diagnostic and screening tests,Power analysis/sample size,,,,,,,15-Nov-10,dbhaumik@uic.edu,,dulal,,uic,1601 west taylor st,708 565 1221,,dbhaumik@uic.edu,'Estimation and Classification of BOLD Responses Over Multiple,3,Kush,K,kapur,VA   Hines,Anindya,,Roy,university of Maryland Baltimore County,Dulal,K,Bhaumik,University of  Illinois at Chicago,Robert,D,Gibbons,University of Chicago,Nicole,,Lazar,University of Georgia Athens,John,A,Sweeney,University  of Illinois at Chicago,Subhash,,Aryal,University of North Texas Health Science Center,Dave,,Patterson,"Discerning Systems Inc.,Burnaby BC, Canada",,,,,,,,,"In this article, we model functional magnetic resonance imaging (fMRI) data forevent-related experiment data using a fourth degree spline to fit voxel specificblood oxygenation level-dependent (BOLD) responses. The data are preprocessed for removing long term temporal components such as drifts using waveletapproximations. The spatial dependence is incorporated in the data by the application of 3D Gaussian spatial filter. The methodology assigns an activation score to each trial based on the voxel specific characteristics of the response curve. The proposed procedure has a capability of being fully automated and it produces activation images based on overall scores assigned to each voxel. The methodology is illustrated on real data from an event-related design experiment of visually guidedsaccades (VGS).",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Data mining/massive data sets,Bayesian methods,,,,,,,15-Nov-10,dbraun@hsph.harvard.edu,,Danielle Braun,Student,"Biostatistics Department, Harvard School of Public","Department of Biostatistics and Computational Biology, CLS 11082, Dana-Farber Cancer Institute",6175827229,,dbraun@hsph.harvard.edu,Extending Carrier Probability Models to Handle Misreported Family History,1,Danielle,,Braun,Harvard University,Giovanni,,Parmigiani,,Lorenzo,,Trippa,,Hormuzd,,Katki,,,,,,,,,,,,,,,,,,,,,,,,,,"BRCAPRO is a computer program that implements a statistical model for calculating an individuals probability of carrying a deleterious mutation of BRCA1, BRCA2, neither, or both on the basis of the individuals cancer status and the history of breast and ovarian cancer among her first- and second-degree relatives (Parmigiani et al., 1998, Berry et al. 2002). Research centered on quantifying the effects of misreported family history on predictions from carrier probability models has been conducted (Katki, 2006). We propose extensions to carrier probability models, and BRCAPRO in particular, that handle misreported family history.We compare predictions from the current BRCAPRO model to those from the extended model.  We apply the proposed model to data for which both reported and verified diagnoses are available, thus allowing us to evaluate our new model.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Measurement error,Bayesian methods,,,,,,,08-Nov-10,dd23a@verizon.net,,Dennis Dixon,,"Formerly NIH, NIAID",7701 Woodmont Ave.,301-402-2306,,dd23a@verizon.net,Communications between DSMBs,1,Dennis,,Dixon,"Formerly NIH, NIAID",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Each scientific experiment, including a clinical trial, exists both as an identifiable unit of research and as a part of the larger research enterprise. When a line of research consists of a sequence of experiments occurring strictly one after another, it is natural to think of both design and interpretation of results of any one of them as reflecting what has been learned from the earlier ones and influencing the design of the later ones. Randomized trials (and most other experiments for that matter) are not sequential in this way; they overlap in time. The principle of confidentiality of interim results of randomized trials conflicts with the desirability of sharing data from ongoing trials, even between DSMBs. It is well to think ahead about what kinds of situations are appropriate and which not. The main example of advantageous communication is to investigate an early sign of unexpected harms. There is far less justification for permitting access to interim comparative efficacy results.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Clinical trials,Biopharmaceutical research,,,,,,,01-Nov-10,ddgene@gmail.com,,Xingdong Feng,Research Associate,National Institute of Statistical Sciences,19 T.W. Alexander Dr,919-685-9357,,ddgene@gmail.com,Calibration using constrained smoothing with applications to mass spectrometry data,1,Xingdong,,Feng,National Institute of Statistical Sciences,Nell,,Sedransk,National Institute of Statistical Sciences,Jessie,,Xia,National Institute of Statistical Sciences,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Linear regressions are usually used to calibrate the signal measurements in proteomic analysis. However, acclivity in data as functional proteomic experiments is not necessarily constant or even a monotonic function of concentrations as the usual calibration methods assumed.Also, in any of these cases, nonparametric smoothing methods can be used to calibrate the intensities with respect to the concentration levels.Since variations of the measured concentrations are often   larger near the boundaries of the instrument's scope measurement capability, it may imply that not only is an assumption of monotonicity required for the mean curve, but also the assumption of convexity is needed for the variation pattern across the concentration levels. An iterative method is proposed based on existing smoothing methods to account for both restrictions. This method can  achieve the global optimal rates under certain weak conditions. Also note that this iterative method works well when the convexity restriction by other restrictions.Data from Addona et al. (2009) illustrate that  the nonparametric smoothing method performs better in calibration than the commonly used linear calibration method in analytical chemistry.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Proteomics,Constrained estimation/order restricted inference,,,,,,,15-Nov-10,deschau@umich.edu,,Douglas E. Schaubel,Associate Professor,"University of Michigan, Department of Biostatisti",1415 Washington Hts,734-395-5992,,deschau@umich.edu,An Estimating Function Approach to the Analysis of Recurrent and Terminal Events,2,John,D.,Kalbfleisch,"Department of Biostatistics, University of Michigan, Ann Arbor, MI",Douglas,E.,Schaubel,"Department of Biostatistics, University of Michigan,Ann Arbor, MI",Yining,,Ye,"Amgen, South San Francisco, CA",Qi,,Gong,"Department of Biostatistics, University of Michigan,Ann Arbor, MI",,,,,,,,,,,,,,,,,,,,,,,,,"In biomedical studies, the event of interest is often recurrent(e.g., hospitalization). It is often the case that  a terminal event (e.g. death) may occur and hence stop the recurrentevent process.  We consider the recurrent/terminal event setting and modelthe dependence through a shared gamma frailty.Conditional on the frailty, a model is specified only for themarginal recurrent event process, hence avoiding the strongPoisson-type assumptions traditionally used. Analysis is based onestimating functions that allow for estimation of covariate effectson the conditional recurrent event rate (given survival) and the terminalevent hazard. The method also permits estimation of the degree of association between the two processes. Asymptoticvariance estimators are proposed. The proposed method is evaluatedthrough simulations to assess the applicability of the asymptoticresults in finite samples and the sensitivity of the method to itsunderlying assumptions. The methods can be extended instraightforward ways to accommodate multiple types of recurrent andterminal events. The methods are illustrated in an analysisof hospitalization data for patients in an internationalmulti-center study of outcomes among hemodialysis patients.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Survival analysis,Estimating equations,,,,,,,29-Oct-10,detoral@amc.edu,,Lisa DeTora,Graduate Student,Albany Medical College,136 Hudson st,732 668 5136,,detoral@amc.edu,Revisiting the P-value: a Comparison of Statistical Evidence in Clinical and Legal Medical Decision Making,2,Kelly,H,Zou,"Pfizer Inc.Specialty Care Business Unit 235 East 42nd Street, Mail Stop NYO-219/08/02New York, NY 10017Phone: (212)-733-0087Email: kelly.zou@pfizer.com",Lisa,M,DeTora,Albany Medical College,Steven,J,Haker,Harvard Medical School,Robert,V,Mulkern,Harvard Medical School,,,,,,,,,,,,,,,,,,,,,,,,,"While the use of p-values in evidence-based medicine (EBM) is consistent and well-defined, the application of statistical information in health law varies greatly. A comparative literature review of clinical and legal medical decision making using Medline (PubMed) and LexisNexis reveals large disparities in the mode and frequency with which statistical evidence is used in EBM when compared with health law. We present the historical background of the p-value in the statistical literature and legal case law, including several medical malpractice cases, and then compare the use of the p-value as statistical evidence in health law and clinical research. We suggest that health law may consider the establishment of statistical criteria for appropriate applications.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Health policy applications,Survival analysis,,,,,,,02-Nov-10,devan_mehrotra@merck.com,,Devan V. Mehrotra,,Merck Research Laboratories,351 N. Sumneytown Pike,267-305-6599,,devan_mehrotra@merck.com,Flagging Clinical Adverse Experiences: Reducing False Discoveries without Compromising Power,1,Devan,V,Mehrotra,Merck Research Laboratories,Adeniyi,,Adewale,Merck Research Laboratories,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Between-group comparisons of safety and tolerability data from a typical late-stage randomized clinical trial generate multiple p-values associated with adverse experiences (AEs) across several body systems.  A common approach is to 'flag' any AE with a p-value less than 0.05, ignoring the multiplicity problem.  Despite the fact that this flagging mechanism can notably increase false discoveries, many researchers shy away from a multiplicity adjustment in order to diminish the risk of missing true safety signals.  We develop a new flagging procedure that significantly cuts the false discovery rate (FDR) without materially compromising the power for detecting true signals relative to the common no-adjustment approach.  Our procedure is a modification (and simplification) of the two-step Mehrotra-Heyse-Tukey (2004) approach that leverages the natural clustering of AEs by body systems.  We use simulations to compare the operating characteristics of our procedure with that of the no-adjustment approach, and to quantify the considerable power advantages of the former relative to a single-step FDR approach that ignores the body system clustering.  A clinical trial example is used for illustration.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Multiple testing,Clinical trials,,,,,,,15-Oct-10,devin_koestler@brown.edu,,Devin Koestler,Ph.D. Candidate in Biostatistics,Brown University,70 Hope St.,7166736961,,devin_koestler@brown.edu,Methods for Forecasting Census in Hospital Units,1,Devin,C,Koestler,"Department of Community Health Brown University",Hernando,,Ombao,"Department of Community Health Brown University",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Current methods and models for forecasting census counts in hospital units do not use available patient-specific information. In this paper we present a methodology for forecasting the census under a framework that simultaneously incorporates both (i) arrival trends over time and (ii) patient-specific baseline and time-varying information.  The proposed model for predicting census has three components, namely: current census count, number of daily arrivals and number of daily departures. To model the number of daily arrivals, we use a seasonality adjusted Poisson Autoregressive (PAR) model where the parameter estimates are obtained via conditional maximum likelihood.  The number of daily departures are modeled using conditional logistic regression models that incorporate patient specific baseline covariate information as well as time varying patient specific covariate information. Our model is applied to predict census in the neonatal intensive care unit (NICU) at Women and Infants Hospital, Providence RI.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Other,Applied data analysis,Forecasting Models,,,,,,08-Nov-10,devrim.bilgili@unf.edu,,Devrim Bilgili,,University of North Florida,1 UNF Drive Department of Mathematics,6203703,,devrim.bilgili@unf.edu,INTERVAL MAPPING WITH A PARAMETRIC ACCELERATED FAILURE TIME CURE MODEL,1,Devrim,,Bilgili,University of North Florida,Devrim,,Bilgili,,Devrim,,Bilgili,,Devrim,,Bilgili,,Devrim,,Bilgili,,Devrim,,Bilgili,,Devrim,,Bilgili,,Devrim,,Bilgili,,Devrim,,Bilgili,,Devrim,,Bilgili,,"Many important problems in evolutionary biology begin with observations of phenotypic variation. When the primary phenotype is time to an event it is natural to use survival modelsto model the phenotype distribution. Suppose event time data are used to map quantitative trait loci(QTL) and suppose the underlying population is a mixture of susceptible(non-cured) and non-susceptible(cured) subjects. If the cured subjects are ignored or inappropriately handled we may either fail to detect the responsible genetic factors or find false significant locations. In this article, we propose an accelerated failure time cure model which takes into account cured subjects as wellto model time to an event. Having defined this model, we go on to characterize single QTL effect on both cured and non-cured subjects. Maximum likelihood estimates of the unknown parameters in the model and corresponding variances are obtained using the EM algorithm as well as the imputation method. Proposed methods are illustrated using a real data set containing survival times of mice after infection with Listeria monocytogenes. We also conduct simulations to evaluate theperformance of our methods.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,TRUE,Statistical genetics,Survival analysis,,,,,,,29-Oct-10,dhong@mtsu.edu,,Don Hong,Professor,Middle Tennessee State University,Box 34,(615)904-8339,(615)898-5422,dhong@mtsu.edu,A Nonparametric Phenotypic Coding of the Univariate Family-based Association Test Statistic in Late Times-to-onset Analysis,1,Rong,,Lu,Middle Tennessee State University,Don,,Hong,Middle Tennessee State University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In this talk,  a new nonparametric phenotype coding for the univariate family-based association test (FBAT) statistic by applying the modified Peto-Prentice weighting function will be presented. When the data set shows a left-skewed time-to-onset distribution, this new approach, which is denoted by FBAT-PP, is more sensitive and robust than the FBAT-logrank and FBAT-Wilcoxon methods. Especially when the pattern of censoring is exceptionally different in each of the groups, or the allele frequency is small, or the sample size is relatively small, the FBAT-PP shows a significantly higher power than the other two methods. Simulation study and real data analysis of Alzheimers disease are conducted and the results confirm our findings.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Applied data analysis,Nonparametric methods,,,,,,,15-Nov-10,dhpark@umbc.edu,,DoHwan Park,Assistant Professor,U of Maryland Baltimore County,1000 Hilltop Circle,410-455-2408,410-455-1066,dhpark@umbc.edu,Testing a Common Mean of a Large Number of Normal Populations,2,Junyong,,Park,U of Maryland-Baltmore County,DoHWan,,Park,U of Maryland-Baltmore County,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In this talk, we consider testing of a common mean of normal populations. There are various types of tests which are approximate chi square or F distribution.We propose two  types of tests and derive the asymptotic normality of the proposed tests for a large number of populations.  We adjust p-values from the proposed testsconsidering higher order asymptotics so that the proposed tests work well for the moderate size of k. We present numerical studies including simulations and real data examples with comparison with existing tests.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Other,Multiple testing,meta analysis,,,,,,26-Oct-10,dianemrichardson@gmail.com,,Diane Richardson,Core Investigator and Biostatistician,Center for Health Equity Research and Promotion,Philadelphia VA Medical Center,215-823-6045,,dianemrichardson@gmail.com,Does a better case-mix model produce improve physician quality scores?  A case study using longitudinal data on diabetes care.,1,Diane,M,Richardson,"Center for Health Equity Research and Promotion, Philadelphia VA Medical Center",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,FALSE,FALSE,,FALSE,FALSE,FALSE,,,,,,FALSE,FALSE,FALSE,FALSE,,,,,,,,,14-Nov-10,ding_ying@lilly.com,,Ying Ding,,Eli lilly and Company,Lilly Corporate Center,317-433-0181,,ding_ying@lilly.com,Combining Multiple Biomarkers Using U-scores to Assess Treatment Effects,1,Ying,,Ding,Eli Lilly and Company,Ming-Dauh,,Wang,Eli Lilly and Company,Alan,,Chiang,Eli Lilly and Company,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In early phase clinical studies, due to small sample size and short treatment duration, a single clinical endpoint or biomarker may not be sufficient to appropriately demonstrate the effect of a treatment. Therefore, treatment comparisons often involve multiple biomarkers and/or clinical endpoints.We have investigated a U-scores approach (Wittkowski et al., 2004) to better synthesizing information from multiple measures. We demonstrate how this method leads to a simple non-parametric statistical test for comparing treatments with respect to several ordinal outcomes, some of which may be graded. In addition, we apply U-scores to help assess treatment dose-response and correlations between biomarkers and clinical endpoints. We illustrate the usefulness of this approach through simulations, considering various combinations of correlations and underlying distributions, and compare its statistical power with Hotelling's T2 test and nonparametric rank-sum test. Finally, we apply this approach in an early phase clinical study.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Multivariate methods,Toxicology/dose-response,,,,,,,04-Nov-10,dinse@niehs.nih.gov,,Gregg Dinse,,NIEHS,Mail Drop A3-03,919-541-4931,,dinse@niehs.nih.gov,Using an EM Algorithm to Fit a 4-Parameter Logistic Model,1,Gregg,E,Dinse,NIEHS,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Researchers often use the 4-parameter logistic model, also known as the Hill model, to characterize binary dose-response data. This model generalizes the usual (2-parameter) logistic regression model to allow the lower and upper response asymptotes to be greater than zero and less than one, respectively. Though various computational methods are available, an EM algorithm is naturally suited for maximum likelihood estimation under the Hill model after conceptualizing the problem as a mixture of subpopulations in which some subjects respond regardless of dose, some fail to respond regardless of dose, and some respond with a probability that depends on dose. The EM algorithm leads to a pair of functionally independent 2-parameter optimizations and it is easy to program. Not only is this approach computationally appealing compared to simultaneous optimization with respect to all four parameters, but it also facilitates estimating covariances, incorporating predictors, and imposing constraints. The proposed EM algorithm is illustrated with data from a toxicology study, though agricultural, biological, environmental and medical applications are also described briefly.",FALSE,FALSE,,FALSE,FALSE,TRUE,I arrive late Sunday and leave early Wednesday. Some time on Monday or Tuesday would be best for me. Thanks.,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Toxicology/dose-response,Missing data,,,,,,,28-Oct-10,diqiong-xie@uiowa.edu,,Diqiong Xie,,University of Iowa,611 Hawkeye Drive,3193534904,,diqiong-xie@uiowa.edu,Survival Analysis by Cause of Death among Bariatric Surgery Patients Matched by Propensity Score,1,Diqiong,,Xie,"Department of BiostatisticsUniversity of Iowa",Michael,P,Jones,"Department of BiostatisticsUniversity of Iowa",Edward,E,Mason,"GI SurgeryUniversity of Iowa Hospital and Clinics",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Bariatric surgery has been recognized as an effective therapy formorbid obesity. There are currently two major categories of surgicalprocedures, depending on whether gastric bypass is included or not.'Simple' operations are purely restrictive, with no bypass ofdigestive tract, while 'Complex' operations bypass the duodenum and/orjejunum, and connect the stomach, the size of which is usuallydecreased, to the upper or distal part of small intestine. In additionto food intake restriction, `complex' operations include nutritionmal-absorption as a mechanism for weight loss.There have been several observational studies investigating thedifference in outcome between these two types of procedures. Thecomparisons focused on three aspects: efficiency of weight loss,post-operative complication and overall mortality. However, thequestion remains unanswered about how selection bias was adjusted inthe above mentioned observational studies, in which the treatments,i.e. operation types, were not randomly assigned, but were determinedby the surgeon and patient. In this study, we show that the choice of treatment depends heavily onpatient characteristics. Therefore, we adjust for selection bias byusing propensity scores, and analyze the effect of operation types onoverall mortality and cause-specific mortality using pair-matchedpatients.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Multivariate survival,Causal inference,,,,,,,08-Nov-10,dlam@bios.unc.edu,,Diana Lam,,UNC-Chapel Hill,Gillings School of Global Public Health The University of North Carolina at Chapel Hill,919-966-7284,,dlam@bios.unc.edu,Bayesian influence methods with missing covariates in survival analysis,1,Diana,,Lam,"University of North Carolina, Chapel Hill",Joesph,G,Ibrahim,"University of North Carolina, Chapel Hill",Hongtu,,Zhu,"University of North Carolina, Chapel Hill",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In this talk we formally develop general Bayesian local influencemethods to carry out sensitivity analyses of perturbations to survivalmodels in the presence of missing covariate data. We examine howchanges such as scale changes to the variance and the presence ofcorrelation between time windows effects the model in a piece-wiseexponential model.  We also demonstrate how these measures have theirroots in differential geometry. Simulation studies are conducted toevaluate our methods, and real datasets are analyzed to illustrate theuse of our influence measures.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Bayesian methods,Survival analysis,,,,,,,15-Nov-10,dmlong@bios.unc.edu,,Dustin Long,,UNC Chapel Hill Department of Biostatistics,383 Summerwalk Circle,9192404376,,dmlong@bios.unc.edu,Comparing Competing Risk Outcomes Within Principal Strata,1,Dustin,M,Long,University of North Carolina Department of Biostatistics,Michael,G,Hudgens,University of North Carolina Department of Biostatistics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"For many randomized trials to prevent mother-to-child transmission (MTCT) of human immunodeficiency virus (HIV), investigators are interested in comparing the cumulative risk of infection in infants who are uninfected by a certain time point, t0. Such comparisons are challenging for two reasons. First, comparisons between trial arms among the subset of infants uninfected by t0 are subject to selection bias. Second, HIV-free death is a competing risk. Building on Shepherd et al. (JASA 2007), we propose non-parametric estimates of the treatment effect on the cumulative risk of HIV infection within the principal stratum of infants who would not be infected by t0 regardless of randomization assignment.  The methods are then applied to a MTCT trial, the Breastfeeding, Antiretroviral, and Nutrition Study.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Causal inference,Survival analysis,,,,,,,12-Nov-10,dmvock@ncsu.edu,,David M Vock,,North Carolina State University,2311 Stinson Drive,312-231-3520,,dmvock@ncsu.edu,A Flexible Random Effects Density for Censored Longitudinal Data,1,David,M,Vock,North Carolina State University,Marie,,Davidian,North Carolina State University,Anastasios,A,Tsiatis,North Carolina State University,Andrew,J,Muir,Duke University,,,,,,,,,,,,,,,,,,,,,,,,,"Mixed models are commonly used to model longitudinal or repeated measures data.An additional complication arises when the response variable is censored, which frequently occurs when modeling RNA viral loads. While Gaussian random effects are routinely assumed, little work has characterized the consequences of misspecifying the random effects distribution for censored longitudinal data nor has a flexible random effects distribution been extended to this scenario. We show that, in general, maximum likelihood estimators will not be consistent when the random effects density is misspecified, and the effect of misspecification is likely to be greatest when the true random effects density deviates substantially from normality and the number of non-censored observations on each subject is small.  We develop the seminonparameteric (SNP) random effects density for censored mixed models and show how to obtain estimates using SAS Proc NLMIXED. In a simulation study with non-normal random effects, the estimators obtained from assuming the SNP representation for the random effects density were less biased and in the case of the bimodal random effects were much more efficient compared to the maximum likelihood estimator assuming Gaussian random effects. We used the viral load trajectory of hepatitis C patients undergoing standard treatment to demonstrate the method.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Random effects,Longitudinal data,,,,,,,05-Nov-10,dobbinke@uga.edu,,Kevin Dobbin,Assistant Professor,University of Georgia,500 D W Brooks Dr,7065838112,,dobbinke@uga.edu,A sample size method for training high dimensional risk predictors from right-censored survival data,1,Kevin,K,Dobbin,"College of Public HealthUniversity of GeorgiaAthens, GA",Xiao,,Song,"College of Public HealthUniversity of GeorgiaAthens, GA",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"A common objective of high dimensional studies is to develop a prognostic prediction model that will permit estimation of the hazard for an individual patient.  Such models can be useful in clinical management and treatment selection.  Ideally, a sample size calculation for building such a model should take into account existing covariates.  We present work towards developing such a sample size method.  Our approach combines nonparametric re-sampling with errors-in-variables methods.  The objective function used for sample size determination is the distance between the mean Cox regression slope of the estimated prediction model and the Cox regression slope of an optimal prediction model.  The method is shown to perform well in estimating key quantities on simulated data.   Complications and future directions are discussed.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,High dimensional data,Microarray analysis,Statistical design,,,,,,25-Oct-10,doerge@purdue.edu,,Rebecca W. Doerge,Professor,Purdue University,150 University Street,765-494-3141,765-494-0558,doerge@purdue.edu,Statistical Issues When Modeling RNA-Seq Data for Differential Expression,2,Rebecca,W.,Doerge,"Department of Statistics, Purdue University",Paul,L.,Auer,Fred Hutchison Cancer Research Center,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"This is an exciting and influential time for the field of Statistics in science.  Technological advances in genetic, genomic, and the other 'omic sciences are providing large amounts of complex data that are presenting a number of challenges for the biological community. Many of these challenges are deeply rooted statistical issues that involve both experimental design and modeling. Focusing on next-generation sequencing technology we will introduce the technology and discuss the statistical issues that are involved in testing differential expression. Applications of next-generation sequencing for testing differential expression will be presented.",FALSE,FALSE,,FALSE,FALSE,FALSE,,,,,,FALSE,FALSE,FALSE,FALSE,,,,,,,,,13-Nov-10,dok11@pitt.edu,,Dongwan Don Kang,,University of Pittsburgh,"326 Parran Hall, GSPH",412-330-9638,,dok11@pitt.edu,Meta-Diagnosis: Quantitative Quality Assessment for Inclusion/Exclusion Criteria of Genomic Meta-Analysis,1,Dongwan,D,Kang,University of Pittsburgh,George,C,Tseng,University of Pittsburgh,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Genomic meta-analyses for combining microarray studies have beenwidely applied to increase statistical power and to validate resultsfrom individual studies. Currently, the inclusion/exclusion criteriamostly depend on ad-hoc expert opinion or naive decision by samplesize or array platform. No objective evaluation is available. In thistalk, we will propose six quantitative quality control measures:  (1)internal homogeneity of co-expression structure among studies(internal quality control; IQC); (2) external consistency ofco-expression structure correlating with pathway database (externalquality control; EQC) ; (3) consistency of differential expressionranking in genes (consistency quality control; CQCg) or pathways(CQCp); (4) accuracy of biomarker detection (accuracy quality control;AQCg) or pathway identification (AQCp). For each quality controlindex, the p-values from hypothesis testing are minus log transformedand PCA biplots were applied for two-dimensional visualization andfinal inclusion/exclusion decision. We applied the proposed method tothree genomic meta-analysis examples: 7 brain cancer studies, 10prostate cancer studies, and 17 major depressive disorder (MDD)studies. We identified two brain cancer studies and three prostatecancer studies that should be excluded from genomic meta-analysis. Weconfirmed six MDD studies that have been suspected to have bad qualityfrom problematic brain tissue collection and processing.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Microarray analysis,Computational methods,Meta-Analysis,,,,,,12-Oct-10,dongx1@umbc.edu,,Xiaoyu Dong,,"University of Maryland, Baltimore County","Department of Math and Statistics,University of Maryland, Baltimore County",3477492988,,dongx1@umbc.edu,Central Tolerance Regions and Reference Regions in Multivariate Normal Populations with Applications in Laboratory Medicine,1,Xiaoyu,,Dong,"Department of Math and Stat, University of Maryland, Baltimore County, USA",Thomas,,Mathew,"Department of Math and Stat, University of Maryland, Baltimore County, USA",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Reference intervals and regions are widely used in clinical chemistry, toxicology and laboratory medicine, in order to identify the measurement range expected from a reference population. One choice for a reference region is a central tolerance region, namely, a region that will contain a given proportion or more of the central part of the population, with a specified confidence level. The construction of a central tolerance region is investigated for a multivariate normal population, and also for a multivariate normal linear regression model. The required tolerance factor has to be  numerically obtained; however, a theoretical framework is developed that will facilitate the numerical computation of the tolerance factor. For a multivariate normal population, a functional form is obtained for the tolerance factor, as a function of the sample size and the dimension, when the other quantities are specified. For the multivariate linear regression model, it turns out that the tolerance factor depends on the covariates in the model only through a scalar, and this property  has been used to obtain a functional form for the tolerance factor. Some examples from laboratory medicine are used to illustrate the applicability of the results.",FALSE,FALSE,,FALSE,TRUE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Other,Diagnostic and screening tests,Laboratory Medicine,,,,,,23-Oct-10,dr24@cornell.edu,,David Ruppert,,Cornell University,154 Ellis Hollow Creek Rd,6072737064,,dr24@cornell.edu,Generalized Additive Functional Regression,1,David,,Ruppert,Cornell University,Mathew,M,McLean,Cornell University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Linear regression with a functional predictor is now a well-studied area, but it is widely recognized that linearity will not hold in many applications.  Several nonlinear regression models with functional predictors have been proposed. For example, James and Silverman's (2005) FAME model extends projection pursuit regression to functional predictors. The functional additive model of MŸller and Yao (2008) is additive in a finite number of functional principle component scores. We take a different approach to James and Silverman and MŸller and Yao.  We work directly with the function predictor, X(t), not with projections of X(t).  In our additive model, the link-transformed mean response is the integral with respect to t of F(t,X(t)) where F is an unknown regression function.  We model F using tensor-product B-splines with roughness penalties.  In an application to tractography, X(t) is a signal from diffusion tensor imaging at position t along a tract in the brain and the response could be disease-status (case or control).  Therefore, F(t,.) describes the effect of the signal at tract location t, which is useful if, for example, one wants to locate lesions in the brain of an MS patient.  We also consider a quantile transformations G(.) to make (t,G(X(t)) nearly uniformly spaced on a rectangle.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Functional data analysis,Nonparametric methods,,,,,,,11-Nov-10,dryden@mailbox.sc.edu,,Ian L. Dryden,Professor,University of South Carolina,Department of Statistics,803-777 5893,,dryden@mailbox.sc.edu,High-dimensional proteomic data analysis using Gaussian mixture basis functions,1,Ian,L,Dryden,University of South Carolina,William,J,Browne,University of Bristol,Kelly,,Handley,University of Birmingham,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Statistical methodology for the analysis of proteomicmass-spectrometry data is proposed using mixed effects models. Eachhigh-dimensional spectrum is approximated by using anear-orthogonal low dimensional representation with a basis ofGaussian mixture functions. Linear mixed effect models are proposed inthe lower dimensional space. The methodologyis applied to a dataset from different stage melanoma patients, wheresignificant locations of peaks are identified. Since the mass spectrahave each been normalised the data can also be regarded as points on avery high dimensional sphere. We explore connections withhigh-dimensional manifold data analysis.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,High dimensional data,Proteomics,,,,,,,12-Nov-10,dunleic@baylorhealth.edu,,Dunlei Cheng,,Baylor Health Care System,8080 N. Central Expressway Suite 500,214-265-3616,,dunleic@baylorhealth.edu,Bayesian power analysis accounting for response misclassfication and covariate measurement error in epidemilogical studies,1,Dunlei,,Cheng,"Institute of Health Care Research and Improvement, Baylor Health Care System",Adam,J,Branscum,"School of Public Health, Oregon State University",James,D,Stamey,"Department of Statistical Science, Baylor University",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The main objective of this study is to quantify the impact of ignoring misclassification of a response variable and measurement error in a covariate on statistical power.  The Bayesian parametric framework is adopted.  And a Monte Carlo simulation-based procedure is developed to illustrate the differences in design requirements and inferences between analytic methods that probably account for misclassification and measurement error to those that do not in regression models for cross-sectional and cohort data.     We found that failure to account for these flaws in epidemiologic data can lead to a substantial reduction in statistical power, over 25% in some cases.  The proposed method substantially reduced bias by up to a ten-fold margin compared to naive estimates obtained by ignoring misclassification and mismeasurement.  We recommend as routine practice that researchers account for errors in measurement of both response and covariate data when determining sample size, performing power calculations, or analyzing data from epidemiological studies.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Power analysis/sample size,Epidemiologic methods,,,,,,,11-Nov-10,dunson@stat.duke.edu,,David Dunson,Professor,"Department of Statistical Science, Duke University",Box 90251,919-260-6615,,dunson@stat.duke.edu,Bayesian nonparametric modeling of non-Euclidean objects,1,David,,Dunson,"Department of Statistical Science Duke University",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"It is increasingly common in biomedical studies to collect data for complex 'objects', such as functions and images, with interest focusing on understanding relationships between different objects and in prediction, classification and clustering from object data.  We consider a general class of Bayesian nonparametric model based methods for analysis of object data, with a particular emphasis on multivariate functional data and shape data.  Novel classes of parametric sparse  latent factor models will be developed for general objects, with these models then used as components in flexible mixture models.  Theoretical properties, including large support and posterior consistency will be discussed, as will visualization and interpretation of results.  Efficient methods of computation via MCMC will be developed and applied to a variety of biomedical applications.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Bayesian methods,Functional data analysis,,,,,,,08-Nov-10,dwitten@u.washington.edu,,Daniela M. Witten,Assistant Professor,"University of Washington, Dept. of Biostatistics",F-649 Health Sciences Building,6502486323,,dwitten@u.washington.edu,A framework for feature selection in clustering,1,Daniela,M,Witten,"Department of BiostatisticsUniversity of Washington",Robert,,Tibshirani,"Department of Health Research and Policy, & StatisticsStanford University",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We consider the problem of clustering observations using a potentially large set of features. One might expect that the true underlying clusters present in the data differ only with respect to a small fraction of the features, and will be missed if one clusters the observations using the full set of features. We propose a novel framework for sparse clustering, in which one clusters the observations using an adaptively chosen subset of the features. The method uses a lasso-type penalty to select the features. We use this framework to develop simple methods for sparse K-means and sparse hierarchical clustering. A single criterion governs both the selection of the features and the resulting clusters. These approaches aredemonstrated on simulated data and on genomic data sets.",TRUE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Variable subset selection/model selection,Data mining/massive data sets,,,,,,,01-Nov-10,dzeng@bios.unc.edu,,Donglin,Associate Professor,University of North Carolina,"Department of Biostatistics, CB 7420#",9199667273,,dzeng@bios.unc.edu,Analysis of Lonigutindal Data with Informative Drop-out,2,Li,,Chen,University of Kentucky,Donglin,,Zeng,University of North Carolina,Danyu,,Lin,University of North Carolina,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We consider analysis of longitudional data subject to informative drop-out in which longitudinal outcomes are no longer observed after drop-out. We propose joint models for both lonigitudinal data and informative drop-out time. The joint distribution between lonigtudinal residual process and drop-out time is fully nonparametric. Moreover, we model drop-out timevia either accelerated failure time model or linear transformationmodels and allow longitudinal outcomes to be measured at either regular or random times. Generalized estimating equations are carefully contructed for inference to adjust for informative drop-out. The proposed estimators for regression parameters are shown to be consistent and asymptotically normal. Their small-sample performance is demonstrated via a number of simulation studies. The proposed method is finally applied to analyzing some real data.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Joint models for longitudinal and survival data,Missing data,,,,,,,15-Nov-10,dzhi@uab.edu,,Degui Zhi,Assistant Professor,Department of Biostatistics,1665 University Blvd.,205-975-9192,,dzhi@uab.edu,Bayesian analysis of rare variants with disparate effects in association studies,1,Degui,,Zhi,"Department of Biostatistics, Section on Statistical GeneticsUniversity of Alabama at BirminghamBirmingham, Alabama 35294",Nengjun,,Yi,"Department of Biostatistics, Section on Statistical GeneticsUniversity of Alabama at BirminghamBirmingham, Alabama 35294",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Rare genetic variants carry the hope to be responsible for part of the missing heritability overlooked by common variants-based genome-wide association studies. Existing association tests for common variants do not offer a sufficient power for rare variant association. Therefore, methods testing for the combined effects of multiple rare variants in a functional unit, typically a gene, have been proposed. However, existing combination methods only achieve high power when the effects of individual variants in the combination are of the same direction (i.e., all disease-causing or all protective). In reality often variants with disparate effects coexist. In this work we developed Bayesian hierarchical generalized linear models for the identification of multiple groups of rare variants. Unlike existing methods used a single rigid grouping that separate variants with estimated disparate effects, our method uses multiple groups, each contains variants with similar effects but different groups are allowed to having disparate effects. By extensive computer simulation, we show that our method can detect associations missed by existing methods.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Statistical genetics,Hierarchical models,,,,,,,13-Oct-10,eaf@mail.med.upenn.edu,,Elizabeth Handorf,,University of Pennsylvania,503 Blockley Hall,609-790-0233,,eaf@mail.med.upenn.edu,Assessing the sensitivity of treatment effect on cost to unknown confounders,1,Elizabeth,A,Handorf,"University of Pennsylvania School of Medicine, Department of Biostatistics and Epidemiology",Justin,E,Bekelman,"Hospital of the University of Pennsylvania, Department of Radiation Oncology",Daniel,F,Heitjan,"University of Pennsylvania School of Medicine, Department of Biostatistics and Epidemiology",Nandita,,Mitra,"University of Pennsylvania School of Medicine, Department of Biostatistics and Epidemiology",,,,,,,,,,,,,,,,,,,,,,,,,"Observational studies can be used to compare treatment costs, but theconclusions are potentially vulnerable to the effects of unmeasuredconfounders. Several methods have been developed to model healthcarecosts, but these methods are only reliable when the treatmentassignment is ignorable. Lin et al. (1998) developed a method todetermine the sensitivity of the treatment effect to a potentialunmeasured confounder by calculating the relationship between the trueand observed treatment effects. This allows investigators to adjustthe estimated effect and corresponding confidence intervals forhypothesized distributions of the unknown confounder. We show how thisadjustment can be used for a cost outcome, and derive the adjustmentfor confounders that follow the Poisson and Gamma distributions. Weevaluate the performance of the adjustment for costdata using simulation studies, and apply it to costs derived fromSEER-Medicare for a stage II/III muscle-invasive bladder cancercohort. We evaluate the costs for two alternative therapies and findthat the treatment effect is insensitive to unmeasured confounding.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Causal inference,Health policy applications,,,,,,,10-Nov-10,eckel@usc.edu,,Sandrah P. Eckel,,University of Southern California,"1540 Alcazar Street, CHP-220, MC-9011",323-442-2030,,eckel@usc.edu,On scaling regression coefficients by interquartile ranges for comparison,1,Sandrah,P,Eckel,University of Southern California,W. James,,Gauderman,University of Southern California,Kiros,T,Berhane,University of Southern California,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The practice of scaling regression coefficients by interquartile ranges (IQR) to enable implicit or explicit comparisons is widespread, particularly in the literature on air pollution health effects. There are critiques in the statistical literature on standardizing regression coefficients, but little discussion on IQR scaling in particular. IQR scaled regression coefficients have similar interpretations. However, we use simple linear regression to demonstrate that when predictors of interest have different distributions, comparison of the magnitudes of IQR scaled regression coefficients can be confounded by the differences in the distributions. In this case, two standard deviation scaled regression coefficients are more comparable in terms of the amount of explained variation. We discuss selection of the quantity by which to scale for effective comparison within and across studies. We illustrate the impacts of the choice of scalar using simulated data and data on traffic-related air pollution and the fractional concentration of exhaled nitric oxide in the Southern California Children's Health Study.",FALSE,FALSE,,FALSE,TRUE,TRUE,"I'd like to attend two tutorials:T3 and T5",oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Epidemiologic methods,Environmental and ecological applications,,,,,,,15-Nov-10,ecornea@bios.unc.edu,,Emil Cornea,,University of North Carolina at Chapel Hill - Depa,"Department of Biostatistics, CB#7420",(919) 412-1930,,ecornea@bios.unc.edu,Regression Models on Lie Groups,1,Emil,A,Cornea,"Department of Biostatistics, University of North Carolina at Chapel Hill, Chapel Hill, North Carolina, 27599-7420, USA",Hongtu,,Zhu,"Department of Biostatistics, University of North Carolina at Chapel Hill, Chapel Hill, North Carolina, 27599-7420, USA",Joseph,G.,Ibrahim,"Department of Biostatistics, University of North Carolina at Chapel Hill, Chapel Hill, North Carolina, 27599-7420, USA",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The aim of this paper is to develop regression models for the analysis of responses in a Lie group and their association with a set of covariates in a Euclidean space. The primary motivation and application of the proposed methodology is in the medical imaging, especially neuroimaging. The regression models are semiparametric models; they are based on conditional moment restrictions and therefore they avoid any parametric assumption regarding the elements of the Lie group. Our models use link functions to map covariates in Euclidean space to the Lie group. We develop a two-stage estimation procedure to calculate the parameter estimates and determine their asymptotic distributions. We develop diagnostic measures for assessing the model misspecification. We use the cumulative conditional residuals to construct goodness-of-fit statistics for testing possible misspecifications in the model assumptions. A resampling method is proposed to approximate the p-value of the goodness-of-fit statistics. We construct score statistics to test hypotheses on unknown parameters. Simulations studies are used to evaluate our methods and a real data set is analyzed to illustrate the use of our test statistics, diagnostic measures and goodness-of-fit statistics.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Functional data analysis,Imaging,,,,,,,13-Nov-10,ekim@stat.brown.edu,,Eunhee Kim,Assistant professor,Brown University,Center for Statistical Sciences,(401) 863-9968,,ekim@stat.brown.edu,Semiparametric ROC Analysis Using Accelerated Regression Models,1,Eunhee,,Kim,Brown University,Donglin,,Zeng,University of North Carolina at Chapel Hill,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The Receiver Operating Characteristic (ROC) curve is a widely usedmeasure to assess the diagnostic accuracy of biomarkers for diseases.When biomarker tests are affected by subject characteristics, theexperience of test performers, or the environment in which tests arecarried out, it is important to understand and determine theconditions for evaluating these biomarkers. In this presentation, wefocus onassessing the effects of covariates on the performance of the ROCcurves. In particular, we develop an accelerated ROC model by assumingthe effect of covariates relates to rescaling a baseline ROC curve.The proposed model generalizes the accelerated failure time model in thesurvival context to the ROC analysis. An innovative method isdeveloped to construct estimation and inference for model parameters. The obtained parameter estimators are shown to be asymptoticallynormal. We demonstrate the proposed method via a number of simulationstudies and apply it to analyze the data from a prostate cancer study.",FALSE,FALSE,,FALSE,TRUE,TRUE,RT8: NIH Grant Review Process for Methodology Grants,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,ROC analysis,Diagnostic and screening tests,,,,,,,10-Nov-10,elee@millikin.edu,,Eun-Joo Lee,Professor,"Mathematics, Millikin University","Department of Mathematics, Millikin University",217-424-6239,,elee@millikin.edu,A Simple Graphical Method to Check Dependence Structure Using Copula,1,Eun-Joo,,Lee,"Department of MathematicsMillikin University",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Checking dependence structure between variables is important whenmodeling multivariate data. In this paper, we investigate copulas,functions that provide a flexible methodology for modelingmultivariate dependence. In particular, copulas are useful indescribing the dependence structure of extreme values in the tails.Gauss, Student t- and Cauchy copulas are considered, among others. Wealso investigate a method for the choice of copulas. Based on thechosen copula, we demonstrate a simple graphical method with data froma study on multiple myeloma, particularly for analysis of the taildependence.",FALSE,FALSE,,FALSE,FALSE,FALSE,,contributedposter,,,,FALSE,FALSE,FALSE,FALSE,Multivariate methods,Computational methods,,,,,,,09-Nov-10,elevina@umich.edu,,Liza Levina,Associate Professor,University of Michigan,439 West Hall,734-764-3235,734-763-4676,elevina@umich.edu,Community extraction for social networks,2,Yunpeng,,Zhao,University of Michigan,Elizaveta,,Levina,University of Michigan,Ji,,Zhu,University of Michigan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Analysis of networks and in particular discovering communities withinnetworks has been a focus of recent work in several fields, withapplications ranging from citation and friendship networks to foodwebs and gene regulatory networks.  Most of the existing communitydetection methods focus on partitioning the entire network intocommunities, with the expectation of many ties within communities andfew ties between.  However, many networks contain nodes that do notfit in with any of the communities, and forcing every node into acommunity can distort results.  Here we propose a new framework thatfocuses on community extraction instead of partition, extracting onecommunity at a time.  The main idea behind extraction is that thestrength of a community should not depend on ties between members ofother communities, but only on ties within that community and its tiesto the outside world.  We show that the new extraction criterionperforms well on simulated and real networks, and establish asymptoticconsistency of our method under the block model assumption.   Themethod itself does not assume a model for the network, and isempirically shown to do well in the presence of hubs as well as underthe block model.",TRUE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Machine learning,High dimensional data,,,,,,,15-Nov-10,elizab@u.washington.edu,,Elizabeth R Brown,,University of Washington,37th and Bagley,2067785762,,elizab@u.washington.edu,A joint longitudinal and illness-death model,1,Elizabeth,R,Brown,University of Washington,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Joint longitudinal and survival models can capture many facets of the relationship between evolving longitudinal processes and risks of events. ÊRecent advances in these models include accounting for competing risks via multivariate survival models. ÊIn this talk, we propose to extend illness-death model for disease progression to incorporate longitudinally measured biomarkers of disease progression.  The proposed model includes frailties to account for the correlation between the sojourn times in the multiple states.  We also explore alternative approaches to flexibly model the baseline hazards.  An example will be given from cardiovasular disease progression.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Joint models for longitudinal and survival data,Bayesian methods,,,,,,,12-Nov-10,elmj@musc.edu,,Jordan J Elm,PhD,Medical University of South Carolina,135 Cannon St. Suite 303,843-876-1605,,elmj@musc.edu,Strategies for Adding Treatment Arms to an Ongoing Multi-arm Clinical Trial,1,Jordan,J,Elm,Medical University of South Carolina,Yuko,Y,Palesch,Medical University of South Carolina,Barbara,C,Tilley,UT Houston,Wenle,,Zhao,Medical University of South Carolina,Vanessa,,Hinson,Medical University of South Carolina,Bernard,,Ravina,,,,,,,,,,,,,,,,,,"In settings where clinical trials require many subjects, evaluatingmore than one drug against a common placebo is efficient. Yet, inpractice, drugs may be at different stages of development. Wepreviously considered analytical methods for the addition of a newdrug into an ongoing clinical trial. Here we consider the case inwhich two new treatments are added into an ongoing Phase II clinicaltrial program. As an illustration of possible methods, the FS1 andFS-TOO clinical trials (identical study designs conductedconsecutively within the same network) were re-analyzed as a singlestudy. For each treatment arm, a futility hypothesis was performedusing: (1) two-sample t-test with the data pooled across stages; (2)linear model adjusting for the design change (stage effect); (3)inverse chi-square (Fisher's) combination test; and (4) weighted-inverse normal combination test.  The probability ofrejecting the null hypothesis was compared for the different testingmethods using bootstrapping of the real clinical trial data. Thelinear model and the combination tests performed similarly and weremost consistent with the results from the original analysis of thesedata as separate studies. If a treatment arm is to be added into anongoing study, then this illustrates that either a linear modelapproach or an adaptive combination test is well suited for such asituation.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Adaptive design/adaptive randomization,Clinical trials,,,,,,,04-Oct-10,emreyes@ncsu.edu,,Eric Reyes,,North Carolina State University,1302 Salterton Ct,919.236.3513,,emreyes@ncsu.edu,Bayesian Average Error Based Approach to Sample Size Calculations for Hypothesis Testing,1,Eric,M,Reyes,North Carolina State University,Sujit,K,Ghosh,North Carolina State University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Under the classic statistical framework, sample size calculations for a hypothesis test of interest are made to adequately maintain pre-specified Type-I and Type-II error rates.  These methods often suffer from several practical limitations, including the need to posit values for the parameters of interest without accounting for the uncertainty in these estimates.  We propose a framework for hypothesis testing and sample size determination using Bayesian average errors by extending the classical framework.  We consider the approach of rejecting the null hypothesis, in favor of the alternative, when a test statistic exceeds a cutoff.  We choose the cutoff to minimize a weighted sum of Bayesian average errors and choose the sample size to bound the total error for the hypothesis test.  We then apply this methodology to determine the sample size required for a few designs common in medical studies.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,TRUE,Power analysis/sample size,Bayesian methods,,,,,,,12-Nov-10,enders.felicity@mayo.edu,,Felicity Enders,Associate Consultant,Mayo Clinic,"200 First Street, SW",507-538-4970,507-284-9542,enders.felicity@mayo.edu,Teaching Confounding and Effect Modification Conceptually,1,Felicity,Boyd,Enders,"Mayo ClinicDivision of Biomedical Statistics and InformaticsDepartment of Health Sciences Research",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Learning confounding and effect modification are critical courseoutcomes as these topics are vital for students' understanding ofstatistics in real life after the class.  For instance, graduatesshould view the concept of confounding as a potential problemfor a study, while they should know that effect modification mayhelp identify future policy options.  As such, students need tounderstand these topics as concepts rather than using rotememorization to identify them.  One way to help students move beyond aunidimensional view of these concepts is to target different learningstyles; this provides repetition of the concept with a different wayof viewing it.  Moving away from course notes based primarily onformulas can also help students who have anxiety regarding formulas tobetter grasp the concepts involved.  In this talk, I willintroduce a variety of ways to teach confounding and effectmodification with the goal of broadening students' conceptualunderstanding.",FALSE,FALSE,,FALSE,FALSE,TRUE,SC1 (Geocoded data),invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Statistical education,Biostatistics Education,,,,,,,10-Nov-10,erich.2@osu.edu,,Roger Erich,,Ohio State University PhD Student,402 Weitzel Way,334-324-2152,,erich.2@osu.edu,Regression Modeling of Time to Event Data using the Ornstein-Uhlenbeck Process,1,Roger,A,Erich,The Ohio State University PhD Student,Michael,L,Pennell,"Assistant Professor, Biostatistics, The Ohio State University",Mei-Ling,T,Lee,"Professor, Department of Epidemiology and Biostatistics, University of Maryland",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Often in biostatistical research, the goal is to identify factorsaffecting survival time or disease development.  The traditionalapproach in this setting is to apply a Cox regression model whichrequires the assumption of proportional hazards.  An alternativemodel, which doesnt require proportional hazards, is the FirstHitting Time (FHT) model where a subjects health is modeled using alatent stochastic process.  In this model, an event occurs once theprocess hits a predetermined boundary.  The parameters of the processare related to covariates through generalized link functions therebyproviding regression coefficients with clinically meaningfulinterpretations.  In this talk, we will present a FHT model based onthe Ornstein-Uhlenbeck (OU) process; a modified Wiener process whichdrifts towards a state of equilibrium or homeostasis present in manybiological applications.  We extend previous OU process models toallow the process to change according to covariate values.  We willalso discuss extensions of our methodology to include random effectsaccounting for unmeasured covariates.  We will apply these methods tosurvival data collected in a study of railroad workers exposed todiesel exhaust.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Survival analysis,Random effects,,,,,,,14-Nov-10,eschifan@hsph.harvard.edu,,Elizabeth Schifano,Postdoctoral Fellow,Harvard School of Public Health,Department of Biostatistics,617 432 4920,,eschifan@hsph.harvard.edu,SNP Set Analysis in Genome-wide Association Studies for Familial Data,1,Elizabeth,D,Schifano,"Department of Biostatistics, Harvard School of Public Health",Michael,P,Epstein,"Department of Human Genetics, Emory University School of Medicine",Xihong,,Lin,"Department of Biostatistics, Harvard School of Public Health",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Genome-wide association studies (GWAS) are now common approaches foridentifying gene variants, epistatic effects, and gene-environmentinteractions that are related to a clinical phenotype.  Thetraditional statistical analysis of such GWAS attempts to assess theassociation between each individual genotyped SNP and the observedphenotype.  Recently, kernel machine-based tests involving acollection of SNPs (SNP sets) have been proposed as a more powerfulalternative to the traditional SNP-by-SNP approach, and allow forflexible modeling of the potentially complicated SNP effects whileadjusting for additional covariate effects.  We extend the kernelmachine framework to accommodate related subjects from multiplefamilies, and provide a statistical test for assessing the associationof a given SNP set with clinical phenotype, while adjusting foradditional covariates.  We demonstrate the effectiveness of theapproach through theoretical and empirical analysis as well as dataapplications.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Other,Random effects,Genome-wide association studies,,,,,,13-Nov-10,esequera@mail.ucf.edu,,Edgard M. Maboudou,Assistant Professor,University of Central Florida,P.O. Box 162370,407-823-5532,407-823-3930,esequera@mail.ucf.edu,Monitoring the Covariance Matrix in High Dimension,1,Edgard,M,Maboudou,University of Central Florida - Statistics Department,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Multivariate control charts are essential tools in multivariate statistical process control. In real applications, when a multivariateprocess shifts, it occurs in either location or scale. Several methodshave been proposed recently to monitor the covariance matrix. Most ofthese methods deal with a full rank covariance matrix, i.e., in asituation where the number of rational subgroups is larger than thenumber of variables. In high dimensional problems, where the number offeatures is nearly as large as, or larger than, the number ofobservations, existing Shewhart-type charts do not provide asatisfactory solution because the estimated covariance matrix issingular. In this paper, we propose a new Shewhart type chart formonitoring changes in the covariance matrix of a multivariate processwhen the number of observations available is less than the number ofvariables. This chart can be used to monitor the covariance matrixeven with one observation.Key Words: Covariance matrix; penalized likelihood function; Averagerun length (ARL); Multistandardization; Lasso; Cholesky decomposition",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,High dimensional data,Multivariate methods,,,,,,,29-Oct-10,eva.dongxinxin@gmail.com,,Xinxin Dong,,University of Pittsburgh,"5230 5th Avenue, Apt. 202",412-589-2859,,eva.dongxinxin@gmail.com,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,FALSE,FALSE,,FALSE,FALSE,FALSE,,,,,,FALSE,FALSE,FALSE,FALSE,,,,,,,,,15-Nov-10,eva.petkova@nyu.edu,,Eva Petkova,Dr.,NYU,"215 Lexington Ave, 16th floor",212-263-2487,,eva.petkova@nyu.edu,Variability of placebo effects across antidepressant clinical trials,1,Eva,,Petkova,New York University,Thaddeus,,Tarpey,Wright State University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Non-specific responses to treatment (commonly known as placebo response) are pervasive when treating mental illness. Subjects treated with an active drug may respond in part due tonon-specific aspects of the treatment, i.e, those not related to the chemical effect of the drug. To determine the extent a subject responds due to the chemical effect of a drug, one must disentangle the specific drug effect from the non-specific placebo effect. Petkova et al. 2009 developed a statistical model that allows for the separate prediction of a specific effect and non-specific effects in drug treated subjects. The decomposition of the effect in the active treatment group is based on estimating the main direction of the non-specific effect using the trajectories of symptoms change in the placebo group.  Here we investigate the variability in the direction of the non-specific effect across different depression treatment studies.  The goal is to characterize the placebo effect associated with antidepressant treatment.  The relationship between failed antidepressant trials and the variability in direction of the non-specific effect will also be discussed.[E Petkova, T Tarpey, and U Govindarajulu. Predicting potential placebo effect in drug treated subjects. International Journal of Biostatistics, 5(1), 2009.]",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Clinical trials,Applied data analysis,,,,,,,15-Nov-10,evan@stat.byu.edu,,W. Evan Johnson,Assistant Professor,Brigham Young University,223 TMCB,801-422-9222,,evan@stat.byu.edu,Probabilistic approach for unbiased estimation of genome-wide methylation levels from next-generation sequencing data,1,W. Evan,,Johnson,"Department of Statistics, Brigham Young University",Spencer,,Clement,"Department of Statistics, Brigham Young University",Nathan,,Clement,"Department of Computer Science, University of Texas",Mark,,Clement,"Department of Computer Science, Brigham Young University",,,,,,,,,,,,,,,,,,,,,,,,,"Since its discovery over 60 years ago, DNA methylation has been linked to many important biological phenomena such as the suppression of gene expression, imprinting, X chromosome inactivation, epigenetic reprogramming during mammalian development, and cancer. Recently, researchers have combined 'bisulfite conversion', which is the conversion of unmethylated DNA cytocines to uracil by introducing sodium bisulfite,  with next-generation sequencing (BS-Seq) to produce the first genome-wide methylation profiles. BS-seq presents new and difficult challenges to researchers attempting to process the sequencing reads from such an experiment. Because most of the cytosines are converted to uracil (and sequenced as thymine), standard read mapping algorithms are inappropriate as they will treat any converted cytosines as `mismatched' bases. We present a method for estimating DNA methylation levels with base-level resolution in bisulfite sequencing (BS-Seq) experiments. In addition, we will use these values to develop an unbiased method for estimating base-level DNA methylation percentages. Finally, we present a likelihood ratio test for identifying bases that are significantly methylated above background which allows for stringent p-value or false discovery control.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Genomics,Cancer applications,,,,,,,08-Nov-10,li.zhu@nih.gov,,Li Zhu,,National Cancer Institute,"Suite 504, MSC 8315 6116 Executive Boulevard",(301) 594-6546,,li.zhu@nih.gov,Selecting the Optimal Window Size for Spatial Scan Statistics,1,Li,,Zhu,National Cancer Institute,Junhee,,Han,University of Arkansas,Eric,,Feuer,,David,,Stinchcomb,National Cancer Institute,Zaria,,Tatalovich,National Cancer Institute,,,,,,,,,,,,,,,,,,,,,"The scan statistics is widely used in spatial, temporal, andspatio-temporal disease surveillance to identify areas of elevatedrisk and to generate hypotheses about disease etiology. In such astatistics, the area of the scanning window is allowed to vary whichmay take any predefined shape. It is very useful when we lack a priorknowledge about the size of the area covered by the cluster. Butvarying window shapes and sizes may produce different clusteringpatterns for the same data. This talk proposes a cluster informationcriterion that takes into account of likelihood, number of parameters,and power and size to evaluate the choices of varying window sizes.Simulation studies and real cancer incidence and mortality data showthat the proposed cluster information criterion can identify theoptimal window sizes for the purpose of disease surveillance.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Spatial/temporal modeling,Variable subset selection/model selection,,,,,,,25-Oct-10,fdiaz@kumc.edu,,Francisco J. Diaz,"Ph.D., Statistics","Department of Biostatistics, The University of Kan","Department of Biostatistics, Mail Stop 1026,",(913) 945-7006,(913) 588-0252,fdiaz@kumc.edu,Mathematical and Statistical Modeling of an Experiment that Investigates the Effects of an In Vivo Factor on Lung CancerÊDrugs Effectiveness,2,Peter,,Hendricks,"The University of Kansas Cancer Center, Kansas City, KS",Francisco,J,Diaz,"Department of Biostatistics, The University of Kansas Medical Center, Kansas City, KS",Sarah,,Schmitt,"School of Engineering, The University of Kansas, Lawrence, KS",Sitta,,Sittampalam,"Department of Pharmacology, Toxicology and Therapeutics, The University of Kansas Medical Center, Kansas City, KS",Victor,S,Nirmalanandhan,"Department of Pharmacology, Toxicology and Therapeutics,   The University of Kansas Medical Center, Kansas City, KS",,,,,,,,,,,,,,,,,,,,,"In vitro screening of molecular entities for pharmacological activity is routinely carried out in cell cultures.  However, drugs administered to patients act in the presence of in vivo factors. We describe the modeling of an experiment examining the effects of a proprietary factor that mimics real life conditions on both the proliferation of two lung cancer cell lines and the ability of anti-cancer drugs to induce cytotoxicity.  Cells were treated with the drugs in the presence or absence of the factor.  The mathematical approach, which is based on a standard exponential cell growth model, allowed defining a new measure of drug effectiveness that quantifies the percentage reduction in live cell population due to drug exposure. The approach made the data amenable to a clearly justified linear regression that allowed testing the statistical significance of drug effectiveness through linear contrasts.  The investigated factor significantly reduced the proliferation of both cell lines, and lowered the effectiveness of some drugs, suggesting the need for more realistic assays for anti-tumor drug discovery. From a biostatistician point of view, a conclusion of this work is that the application of basic models from mathematical biology may help in statistical analyses and interpretation of pharmacological experimental data.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Applied data analysis,Cancer applications,,,,,,,04-Nov-10,fdominic@hsph.harvard.edu,,Francesca Dominici,Professor,Harvard School of Public Health,655 Huntington Avenue,617 - 432 - 4908,617 - 432 - 5619,fdominic@hsph.harvard.edu,Bayesian Spatially Varying Coefficient Models to Assess Long Term Health Effects of the Chemical Composition of Particulate Matter,2,Yeonseung,,Chung,"Department of BiostatisticsHarvard School of Public Health",Francesca,,Dominici,"Department of BiostatisticsHarvard School of Public Health",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The lack of national studies of the health effects of long-term exposure to ambient PM and its chemical components determining the PM toxicity represents an evidence gap for the implementation of more effective interventions. The U.S. Environmental Protection Agency (EPA) is calling for research to explain heterogeneity in health responses to air pollutants that might be explained by the compositional differences in the pollution mixtures.We have developed Bayesian spatially varying coefficient regression models to estimate long-term effects of PM2.5 on mortality while identifying the chemical composition that modifies the health effects. We will use spatio-temporal variation in health outcomes, exposure and confounders to estimate: 1) spatially varying risks associated with PM2.5; and; 2) effect modification by PM2.5 constituents. Our models will account for: 1) uncertainty in the estimation of PM2.5 exposure to chemical components; 2) unmeasured confounding; and 3) spatial misalignment of the data. We will apply our model to the Medicare Cohort Air Pollution Study of 7.9 million Medicare enrollees followed for the period of 2000-2006 in the Eastern part of the US. We will use PM2.5 data from 518 monitoring stations and chemical components data from 241 monitors located in the Eastern region of the US.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Environmental and ecological applications,Hierarchical models,,,,,,,15-Nov-10,feihan.lu@nyumc.org,,Feihan Lu,,NYU Child Study Center,"215 Lexington Avenue, 16th FL",2122632742,,feihan.lu@nyumc.org,Comparative Study of Methods for Variables Selection in the Context of Developing Diagnostic Instruments,1,Lassell (Feihan),,Lu,New York University Child Study Center,Eva,,Petkova,New York University Child Study Center,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The process of developing diagnostic or screening instruments formental disorders involves items selection from a, possibly, very largepool of items.  It is also desirable to identify interactions betweenthe items that improve the performance of the diagnostic instrument. The resulting instrument should not only accurately distinguishbetween patients and controls but also should consist of as few itemsas possible.  The data available for such instrument development oftenconsist of fewer cases than items to select from and, frequently, somecases have missing values on subsets of the items.  Variable selectionmethods, such as classification trees, Lasso, elastic net, andstability selection can be used in such situations.  Via simulationstudies we investigate how the performance of these methods depends onthe information for distinguishing between patients and controlcontained in the pool of items, the amount and pattern of missingdata, the measurement scale of the items, the covariance between theitems and the prevalence of patients in the existing data. A realexample for the development of short screening instrument for autismbased on the currently used standard Autism DiagnosticInstrument-Revised Version (ADI-R) is used for illustration.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Variable subset selection/model selection,Diagnostic and screening tests,,,,,,,21-Oct-10,fh6e@virginia.edu,,Feifang Hu,Professor,University of Virginia,Department of Statistics,434-924-3014,434-924-3076,fh6e@virginia.edu,Interim Analysis of Response-Adaptive Randomized Clinical Trials.,1,Feifang,,Hu,"Department of StatisticsUniversity of Virginia",Hongjian,,Zhu,Yale University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Clinical trials are complex and usually involvemultiple objectives such as controlling type I error rate,increasing power to detect treatment difference, assigning morepatients to better treatment, and more. In literature, bothresponse-adaptive randomization (RAR) procedures (by changingrandomization procedure sequentially) and sequential monitoring (bychanging analysis procedure sequentially) have been proposed toachieve these objectives to some degree. In this talk, we proposeto sequentially monitor response-adaptive randomized clinical trialand study it's properties. We prove that the sequential teststatistics of the new procedure converge to a Brownian motion indistribution.  These results open a door to both sequentiallymonitor and interim analyse response-adaptive randomized clinicaltrials in practice. We can also observe from the simulation studiesthat, the proposed procedure brings together the advantages of bothtechniques, in dealing with power, total sample size and total failurenumbers, while keeps the type I error. In addition, we illustrate thecharacteristics of the proposed procedure by redesigning awell-known clinical trial of maternal-infant HIV transmission.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Adaptive design/adaptive randomization,Clinical trials,,,,,,,10-Nov-10,finleya@msu.edu,,Andrew Finley,,Michigan State University,"126 Natural Resources Building, Michigan State University",517-432-7219,,finleya@msu.edu,A Bayesian functional data model for predicting forest variables using high-dimensional waveform LiDAR over large geographic domains,1,Andrew,O,Finley,"Departments of Forestry and Geography, Michigan State University",Sudipto,,Banerjee,"School of Public Health, University of Minnesota",Bruce,,Cook,"NASA, Goddard Space Flight Center",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Recent advances in remote sensing, specifically waveform LightDetection and Ranging (LiDAR) sensors, provide the data needed toquantify forest variables at a fine spatial resolution over largedomains. We define a framework to couple a spatial latent factor modelwith forest variables using a fully Bayesian functional spatial dataanalysis. Our proposed modeling framework explicitly: 1) reduces thedimensionality of signals in an optimal way (i.e., preserves theinformation that describes the maximum variability in responsevariable); 2) propagates uncertainty in data and parameters through toprediction, and; 3) acknowledges and leverages spatial dependenceamong the regressors and model residuals to meet statisticalassumptions and improve prediction.  The dimensionality of the problemis further reduced by replacing each factor's Gaussian spatial processwith a reduced rank predictive process. The proposed modelingframework is illustrated using waveform LiDAR and spatially coincidingforest inventory data collected on the Penobscot Experimental Forest,Maine.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Spatial/temporal modeling,Hierarchical models,,,,,,,12-Nov-10,fliang@mdanderson.org,,Fu-Wen Liang,,UT MD Anderson Cancer Center,7900 Cambridge St Apt#8-2C,7137944349,,fliang@mdanderson.org,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,FALSE,FALSE,,FALSE,FALSE,FALSE,,,,,,FALSE,FALSE,FALSE,FALSE,,,,,,,,,15-Nov-10,flin@bios.unc.edu,,Feng-Chang Lin,,Department of Biostatistics,"160 N. Medical Dr. Brinkhous-Bullitt Building, 2nd Floor",9198432853,,flin@bios.unc.edu,Nonparametric Estimation of the Mean Function for Recurrent Events Data with Missing Event Category,1,Feng-Chang,,Lin,"Department of Biostatistics, University of North Carolina at Chapel Hill",Jianwen,,Cai,"Department of Biostatistics, University of North Carolina at Chapel Hill",Jason,,Fine,"Department of Biostatistics, University of North Carolina at Chapel Hill",HuiChuan,,Lai,"Department of Nutritional Sciences, Department of Biostatistics and Medical Informatics, and Department of Pediatrics, University of Wisconsin at Madison",,,,,,,,,,,,,,,,,,,,,,,,,"Recurrent event data frequently arise in longitudinal studies whenstudy subjects experience more than one event. Often, such recurrentevents can be categorized. An analysis that incorporates suchcategorization is more informative than the one that aggregatesinformation across categories. However, part of the categorization maybe missing due to recording ignorance. Previous results showed that acomplete-case analysis that censors events with unknown category maystill obtain consistent coefficient estimation when the event categoryis missing completely at random under a proportional rates model. Whenthe researchers are interested in a mean function without specifyingany model form, such complete-case analysis would underestimate thetruth even when the event category is missing completely at random. Inthis research we study nonparametric estimation of the mean functionby utilizing local polynomial regression techniques. Large sampleproperties of our estimators are proved. Simulation results show thatour estimation is more consistent than the weighted estimatingequation method that needs to specify a fully parametric logit modelfor the probability of missingness. We applied our methods to thecystic fibrosis registry data when patients experience different typesof pseudomonas infection in the early age.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Survival analysis,Nonparametric methods,,,,,,,03-Nov-10,flournoyn@missouri.edu,,Nancy Flournoy,Professor,University of Missouri,146 Middlebush Hall,573 8826376,,flournoyn@missouri.edu,Issues to Consider in Selecting an Adaptive Design for Dose-finding Experiments,1,Nancy,,Flournoy,University of Missouri,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We discuss some of the many issues involved in selecting an adaptive design.  Included in these considerations are choices to go with frequentist or Bayesian, parametric or nonparametric procedures.  There is great appeal in using all the information gained to date, but in many settings, two or three stage designs have been shown to perform almost as well as fully adaptive ones.  Furthermore, with many procedures, an unfortunate string of early responses can have strong undesirable effects on estimates.  These consequences can be mitigated by using a short term memory procedure rather than a long term memory procedure.  When interest is in the MTD, placing subjects around the MTD is symbiotic with efficiently estimating the MTD; this is not so when interest is in finding a dose that is efficacious without toxicity.   The compromise between designing to optimize for ethical treatment versus optimizing for efficiency in estimating best dose should be given serious attention in practice; although it has been stated that adaptive designs let one do both, this simply is not the case.  Finally, we briefly consider issues related to stopping for toxicity and lack of efficacy, sample size recalculation and dropping or adding treatments.  How flexible should a clinical trial be?  Are analysts prepared for the negative impact such flexibility has on estimates of effect size?",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Toxicology/dose-response,Adaptive design/adaptive randomization,,,,,,,15-Nov-10,foulkes@schoolph.umass.edu,,Andrea Foulkes,Associate Professor of Biostatistics,University of Massachusetts Amherst,715 North Pleasant Street,(413) 545-1881,,foulkes@schoolph.umass.edu,Mixture modeling for multi-locus genotype-trait association,1,Andrea,S,Foulkes,"Division of Biostatistics, University of Massachusetts Amherst",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Characterizing the underpinnings of complex diseases will inevitablyrequire consideration of multiple single nucleotide polymorphisms(SNPs) within and across genes, presenting several analytic challengesdue to the large number of potentially informative SNPs and thelargely uncharacterized relationships among them.  In the context ofpopulation-based investigations, an additional challenge arises due tothe unobservable nature of haplotypic phase.  We describe a mixturemodeling approach to this setting that offers a flexible statisticalframework for: (1) incorporating unknown models of association andgenetic models; (2) integrating known demographic and clinical riskfactors for disease that potentially modify or confound associations;(3) accommodating multiple genetic polymorphisms; and (4) accountingfor ambiguity in haplotypic phase.  Further extension involvingapplication of a recursive partitioning algorithm allows forcharacterization of gene-gene interactions.  The approach is evaluatedthrough extensive simulation studies.   Finally, an application todata arising from a pharmacogenomic study of cardiovascular outcomesin HIV-infected individuals is provided.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Statistical genetics,Machine learning,,,,,,,10-Nov-10,fox@stat.duke.edu,,Emily Fox,,Duke University,Department of Statistical Science,6177334935,,fox@stat.duke.edu,Bayesian Nonparametric Covariance Regression,1,Emily,B.,Fox,Duke University,David,B.,Dunson,Duke University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Although there is a rich literature on methods for allowing the variance in a univariate regression model to vary with predictors, time and other factors, very little has been done in the multivariate case. Our focus is on developing a class of nonparametric covariance regression models, which allow an unknown p x p covariance matrix to change flexibly with predictors. The proposed modeling framework induces a prior on a collection of covariance matrices indexed by predictors through priors for predictor-dependent loadings matrices in a factor model. In particular, the predictor-dependent loadings are characterized as a sparse combination of a collection of unknown dictionary functions (e.g, Gaussian process random functions). The induced covariance is then a (sparse) quadratic function of these dictionary elements. Our proposed framework leads to a highly-flexible, but computationally tractable formulation with simple conjugate posterior updates. Theoretical properties are discussed and the methods are illustrated through simulations studies and the Google Trends flu dataset.",TRUE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Bayesian methods,Functional data analysis,,,,,,,15-Nov-10,frank.v.mannino@gsk.com,,Frank Mannino,,GlaxoSmithKline,1250 South Collegeville Road,610-917-5644,,frank.v.mannino@gsk.com,Meta-optimization of different stages of clinical trials,1,Frank,,Mannino,GlaxoSmithKline,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"To aid in the design and planning of late stage clinical trials, Ideveloped methods and software tools to optimize multiple aspects ofthese trials.  Using statistical methodology and Monte Carlosimulations, I analyze design features such as patient recruitment,treatment randomization, choice of statistical model and drug supply. By combining these elements and quantifying uncertainties in inputparameters, I build a risk-benefit function to help analyze andcompare the efficiencies and costs of different designs.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Clinical trials,Computational methods,,,,,,,26-Oct-10,frederic.ferraty@math.univ-toulouse.fr,,Frederic FERRATY,,Insitute of Mathematics of Toulouse,118 route de Narbonne,+33(0)561556022,,frederic.ferraty@math.univ-toulouse.fr,Nonparametric sparse regression with functional data,1,Frederic,,Ferraty,"Institute of Mathematics of Toulouse, University of Paul Sabatier, France",Peter,G,Hall,"Department of Mathematics and Statistics, University of Melbourne, Australia",Philippe,,Vieu,"Institue of Mathematics of Toulouse, University of Paul Sabatier, France",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The high-tech evolution offers the opportunity to deal withhigh-dimensional data (i.e. large number of variables) andparsimonious models have been developed to give to practitionersimplementable and interpretable statistical tools. A useful way ofgetting parsimonious modelling consists in selecting few variablesamong a large set of candidates; this variable selection methodologyis often called 'sparse modelling'.When the observed data contain some continuous features (i.e.collection of curves, surfaces, etc), they are called functional datawhich are involved in numerous applications (chemometrics, medicalsciences, etc). This work combines functional data (which can be viewed as high-correlatedhigh-dimensional data), selection-variable-model and nonparametricmethods in order to propose nonlinear parsimonious (i.e. sparse)regression models with functional data.  Examples will illustrate thepractical good behaviour of such methodology whereas some theoreticalaspects will be given. This work suggests at least two ideas foranalyzing functional data. The  first is that functional datasets canreveal some pointwise and continuous structure. The second idea isthat the complementarity of linear and nonlinear regressions allowsthe extraction of additional relevant information contained infunctional data.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Functional data analysis,Variable subset selection/model selection,Nonparametric methods,,,,,,12-Nov-10,fridley.brooke@mayo.edu,,Brooke L. Fridley,Associate Professor,Mayo Clinic,200 First St SW,507-538-3646,,fridley.brooke@mayo.edu,A Bayesian Latent Model for Prioritization of SNPs for Follow-up Studies,1,Brooke,L.,Fridley,Mayo Clinic,Ed,,Iversen,Duke University,Ya-Yu,,Tsai,Moffitt Cancer Center,Gregory,D.,Jenkins,Mayo Clinic,Ellen,L.,Goode,Mayo Clinic,Thomas,A.,Sellers,Moffitt Cancer Center,,,,,,,,,,,,,,,,,"Numerous GWAS have identified general loci harboring phenotype-associated alleles. One difficult question facing researchers is how to prioritize SNPs for functional studies. Often, a list of the top M SNPs is determined based on the association p-value. However, complexities arise when multiple GWAS analyses are completed (e.g., for subgroups of subjects) and when biological knowledge is of interest. We propose a Bayesian latent variable model (BLVM) for incorporating observed 'features' about a SNP to estimate a latent 'quality score', with SNPs prioritize based on the posterior probability distribution of the quality score rankings. We illustrate the method using data from an ovarian cancer GWAS of 1815 cases (1070 serous subtype) and 1900 controls, using the following SNP features: p-value from analysis of all cases, p-value from analysis of serous subtype only, and minor allele frequency. On chromosome 20, the 1st-ranked SNP (ranked in top 5 markers 46.8%) from the BLVM ranked 2nd and 7th based on p-values from analyses of all cases and of serous subtype, respectively, and the 2nd (46.3%) ranked SNP from BLVM ranked 1st and 9th in analyses of all cases and serous subtype, respectively. As these results show, the BLVM is useful for integrating multiple SNP 'features' to prioritize loci for functional studies.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Statistical genetics,Latent variables,,,,,,,15-Nov-10,frp3@pitt.edu,,Francis,,University Of Pittsburgh,6399 Morrowfield Avenue,412-651-4591,412-651-4591,frp3@pitt.edu,Accounting for a doubly censored longitudinal covariate in survival analysis by joint modeling.,1,Francis,,Pike,"University Of PittsburghDepartment Of Biostatistics",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Censoring of a longitudinal outcome often occurs when biomarker data is collected in a biomedical study.  In the setting considered here, the data are doubly censored as the result of an investigator imposing restrictions on measurements from a kinetic model producing 'biologically implausible' values.  The goal of the analysis was to determine the importance of this longitudinal marker in predicting survival, pointing to the need for a joint modeling approach that incorporated doubly censored data.  The proposed joint model links a linear mixed effects Tobit model to an exponential survival model to construct a 'joint Tobit model'.  Through a simulation study, the performance of the proposed model is compared to a joint model where the censored values of the longitudinal component are replaced using 'fill-in' methods.  In this case, the upper and/or lower limits of censoring are replaced by the limit of detection, by half of the limit of detection, or by the limit of detection divided by the square root of 2.  The simulation study results show that the estimates obtained using the proposed method are subject to less bias and have better coverage than the 'fill-in' methods.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Joint models for longitudinal and survival data,Survival analysis,,,,,,,15-Nov-10,fthomas4@uthsc.edu,,Fridtjof Thomas,,University of Tennessee Health Science Center,"66 N. Pauline, Suite 633",9014486461,,fthomas4@uthsc.edu,Rapid Bayesian Segmentation of Next-Generation Sequencing Data for Genomic Copy Number Analysis of Tumors,1,Fridtjof,,Thomas,University of Tennessee Health Science Center,Stanley,,Pounds,St. Jude Children's Research Hospital,Jinghui,,Zhang,St. Jude Children's Research Hospital,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Next-generation sequencing (NGS) technology provides the opportunityto perform genomic copy number analysis of tumors at an unprecedentedresolution.  By so dramatically increasing the resolutionNGS technology also introduces computational and statisticalchallenges, most notably much larger data sets and potentiallynon-negligible autocorrelation in the data.  Here, we introduce rapidBayesian segmentation (RBS) as a computationally efficient procedurethat also addresses the statistical challenges of autocorrelated data. RBS uses a closed-form Bayesian AR(1) change-point model to accountfor autocorrelation in the analysis and performs the calculations inorder(n) time without resorting to MCMC sampling.  We evaluate theperformance of RBS and compare it to that of other segmentationmethods in a series of real-data examples and simulations.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Bayesian methods,Genomics,,,,,,,04-Nov-10,fuentes@stat.ncsu.edu,,Montse,Professor of Statistics,NCSU,"Statistics Department, NCSU",9195151921,,fuentes@stat.ncsu.edu,Air Pollution and preterm pregnancy: identifying critical windows of exposure,1,Montse,,Fuentes,NCSU,Josh,,Warren,NCSU,Amy,,Herring,UNC,Peter,,Langlois,Texas Department of State Health Service,,,,,,,,,,,,,,,,,,,,,,,,,"A major methodological challenge in the study of environmental exposures and birth outcomes is the identificationof a critical window of exposure. The developing organ systems of the fetus may be more vulnerable to exposuresto environmental toxicants during these critical windows because of a variety of factors, including higher ratesof cell proliferation or changes in metabolism. We introduceBayesian spatial shrinkage methods to control potential multicollinearity of exposure due to multi-pollutantsexposure and multiple lags. This framework facilitates the search for susceptible periods of exposure duringfetal development, and sheds additional light on exposures previously examined in isolation or under strictassumptions about the nature of the association. Gaininga better understanding of how different pollutants affect birth outcomes during various pregnancy time periodsshould help in providing the best advice and care in order to minimize the chances of harmful birth outcomes. We apply our methods to geo-coded birth outcome datafrom the state of Texas (1997-2004) to  identify the critical windows of the pregnancy where increased exposure  to fine  particulate matter and ozone  is particularly harmful. Our results indicate  the susceptible window for higher preterm probabilities is mid-first trimester for the fine PM and beginning of the first trimester for the ozone.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Spatial/temporal modeling,Latent variables,,,,,,,14-Nov-10,fuhaoda@gmail.com,,"Haoda Fu, Ph.D.",,Eli Lilly and Company,Drop Code 2232,3177557938,,fuhaoda@gmail.com,Bayesian Adaptive Dose-Finding Studies with Delayed Responses,1,Haoda,,Fu,Eli Lilly and Company,David,,Manner,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In recent years, Bayesian response-adaptive designs have been used toimprove the efficiency of learning in dose-finding studies.  In thispaper, we propose a new Bayesian predictionmodel to incorporate all the data (from patients who have completedthe study and those who have not completed) to make decisions aboutthe study at the interim analysis. Examples of decisions made at theinterim analysis include adaptive treatment allocation, droppingnonefficacious dose arms, stopping the study for positive efficacy,and stopping the study for futility. The model is able to handleincomplete longitudinal data including missing data considered missingat random (MAR). A utility-functionbaseddecision rule is also discussed. The benefit of our new method isdemonstrated through trial simulations. Three scenarios are examined,and the simulation results demonstrate that this new methodoutperforms traditional design with the same samplesize in each of these scenarios.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Adaptive design/adaptive randomization,Bayesian methods,,,,,,,23-Sep-10,fwei@westga.edu,,Fengrong Wei,,University of West Georgia,"1601 Maple Street, Department of Mathematics, University of West Georgia",678-839-5314,,fwei@westga.edu,Variable Selection in High-dimensional Logistic Regression,1,Fengrong,,Wei,University of West Georgia,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"A group minimax concave penalized  (gMCP) approach for variable selection and estimation in high-dimensional logistic regression models with grouped variables is considered. The gMCP uses a composite of the minimax concave penalty and the Euclidean norm of the regression coefficients in each group. It is related to the group Lasso in that it forms a continuum between the hard threshold and the group Lasso estimators as the regularization parameter in the gMCP varies from 1 to infinity. The gMCP is a nearly unbiased and accurate method for penalized variable selection. We propose an efficient group coordinate descent algorithm to compute the solution path of the gMCP estimate. Under appropriate conditions, we show that the gMCP has high probability of distinguishing the relevant and irrelevant groups, and thus correct selection, without assuming the strong irrepresentable condition required by the Lasso. This selection consistency applies to both the low-dimensional and high-dimensional cases. Moreover, we prove that the gMCP attains an optimal convergence rate in high probability.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,High dimensional data,Generalized linear models,,,,,,,15-Nov-10,fwright@bios.unc.edu,,Fred A. Wright,Professor,Univ North Carolina,4115B McGavran-Greenberg,9198433655,9199663804,fwright@bios.unc.edu,Small-sample differential expression analysis with RNA-seq data,1,Fred,A,Wright,University of North Carolina,Yihui,,Zhou,University of North Carolina,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"A number of investigators have described the overdispersion propertiesof data arising from RNA-seq digital gene expression analysis. Motivated by earlier work on the mean-variance relationship forsmall-sample microarray analysis, we describe similar modelsappropriate to RNA-seq datasets, with the goal of obtaining morepowerful tests of differential expression. Additional complicatingissues include the possible role of surrogate variables, andestimation of effective number of degrees of freedom in order toobtain valid statistical tests.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Genomics,Statistical genetics,,,,,,,13-Nov-10,gallen@rice.edu,,Genevera Allen,Assistant Professor,Rice University,6100 Main St.,9105458187,,gallen@rice.edu,Modeling High-dimensional Data with the Matrix-variate Normal,1,Genevera,I,Allen,Baylor College of Medicine & Rice University,Justin,S,Dyer,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"High-dimensional data common in the biomedical sciences, imaging and theInternet, often contains complicated dependencies between variables.When arranged in the form of a matrix, this data is transposablemeaning that neither the rows nor the columns can be consideredindependent instances.  Allen and Tibshirani (2010) proposed to model asingle high-dimensional data matrix with the matrix-variate normaldistribution.  In this paper, we explore further parametrizations ofthe model that are appropriate for working with a single matrix or asmall number of replicated matrices.  Parameters are estimated viamaximum likelihood and theoretical properties of theseestimates are given.  In addition, we discuss methods forregression andclassification with the matrix-variate normal in the context ofhigh-dimensional data.  Results and examples are presented using theNetflix movie rating data, microarrays, and functional MRIsdemonstrating several advantages of using the matrix-variate normal model.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,High dimensional data,Multivariate methods,,,,,,,15-Nov-10,gang.han@moffitt.org,,Gang Han,Biostatistician,H. Lee Moffitt Cancer Center & Research Institute,12902 Magnolia Drive,8137451313,8137456107,gang.han@moffitt.org,A Parametric Comparison for Survival data with Multiple Events and Failure Changes,1,Gang,,Han,H. Lee Moffitt Cancer Center & Research Institute,Ji-Hyun,,Lee,H. Lee Moffitt Cancer Center & Research Institute,Janelle,,Perkins,H. Lee Moffitt Cancer Center & Research Institute,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The log-rank test is widely used as a standard approach to compare survivorship. It assumes that the survival times are mutually independent. However, in some applications, the independence assumption may be invalid with multiple events per subject being possible. We propose a parametric test to compare the survivorship based on the exponential distribution. Specifically, using the memory-less property of the exponential distribution, we derive Gamma distributions of two total-time-on-tests (TTOTs), with the number of events as the shape parameter and the failure rate as the scale parameter. A uniformly most powerful unbiased (UMPU) test is used to compare the two failure rates. Multiple comparison adjustments are used if more than two groups are being compared. This method will be applied to comparing the survivorship of allogeneic hematopoietic cell transplant patients with hematologic malignancies at a low risk of relapse and death (acute leukemia in first complete remission or chronic myelogenous leukemia (CML) in first chronic phase) and the survivorship of patient group who are at a higher risk of relapse and death (acute leukemia beyond first remission, CML beyond chronic phase, or other malignancies) for both before and after the progression of the cancer.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Survival analysis,Cancer applications,,,,,,,04-Oct-10,gang-cheng@uiowa.edu,,Gang Cheng,PhD Student,University of Iowa,455 Hawkeye Drive,(319) 353-4243,,gang-cheng@uiowa.edu,Efficient Algorithms for Computing the Non- and Semi-Parametric Maximum Likelihood Estimates of Panel Count Data,1,Gang,,Cheng,"Department of Biostatistics, University of Iowa",Ying,,Zhang,"Department of Biostatistics, University of Iowa",Liqiang,,Lu,"School of Mathematics, Fudan University, P.R. China",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Non-parametric and semi-parametric analysis of panel count data haverecently been an active research topic in statistical literature.Maximum likelihood method based on non-homogeneousPoisson process has been proved an efficient inference procedure forsuch analysis. However, computing the non- and semi-parametric maximumlikelihood estimates (MLE) can be very intensive numerically. In thismanuscript, we develop an efficient numerical algorithm stemmed fromthe Newton-Raphson method to compute the non- and semi-parametric MLEfor panel count data. Simulation studies are carried out todemonstrate the numerical efficiency of the proposed algorithmcompared to the existing methods in the literature.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,TRUE,Longitudinal data,Computational methods,,,,,,,14-Nov-10,gao2@oakland.edu,,Xiaoli Gao,,Oakland University,Department of Mathematics and Statistics,2483703440,,gao2@oakland.edu,Asymptotic Properties of Fused Lasso Regularization Procedure in L1 regression,1,Xiaoli,,Gao,Oakland University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Fused-Lasso regularization procedure generates an estimator with bothsparsity and spatial dependence properties. In linear regression, L1loss is an alternative to L2 loss because of its robustness to someoutliers. In this manuscript, we investigate the asymptotic propertiesof a fused-lasso procedure under L1loss function (L1FL). We show thatthe L1FL estimator enjoys both estimation consistency and variableselection consistency properties in high-dimensional settings. Theresults are illustrated by some simulation studies.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,High dimensional data,Statistical genetics,,,,,,,14-Oct-10,gaohong.dong@novartis.com,,Gaohong Dong,Senior TA Statistician,Novartis Pharmaceuticals Corporation,One Health Plaza,513-225-2086,,gaohong.dong@novartis.com,A Bayesian-frequentist two-stage single-arm phase II clinical trial design,1,Gaohong,,Dong,"Novartis Pharmaceuticals Corporation,East Hanover, NJ 07936",Weichung,Joe,Shih,"Department of Biostatistics,School of Public Health,University of Medicine and Dentistry of New Jersey,Piscataway, NJ 08854",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"It is well-known that both frequentist and Bayesian clinical trial designs have their own advantages and disadvantages. To have better properties inherited from these two types of designs, we developed a Bayesian-frequentist two-stage single-arm phase II clinical trial design. This design allows both early acceptance and rejection of the null hypothesis (H0). The frequentist setting is very similar to Fleming (1982), Chang et al (1987) and Shusters design (2002). Under the Bayesian setting, the upper and lower boundaries are determined with predictive probability of trial success outcome. Given a beta prior and a sample size for stage I, based on the marginal distribution of the responses at stage I, we derived Bayesian Type I and Type II error rates. By controlling both frequentist and Bayesian error rates, our design has special features compared to other frequentist or Bayesian designs. A prior plays an important role in our design.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,TRUE,Adaptive design/adaptive randomization,Bayesian methods,,,,,,,14-Oct-10,gchen@bios.unc.edu,,Guanhua Chen,,"Biostatisitcs,UNC-CH",316 Summerwalk Circle,9194487302,,gchen@bios.unc.edu,Statistical methods for analyzing customized copy number variation array,1,Guanhua,,Chen,"Department of Biostatistics,University of North Carolina at Chapel Hill",Wei,,Sun,"Department of Biostatistics and Genetics,University of North Carolina at Chapel Hill",Patrick,F,Sullivan,"Department of  Genetics,University of North Carolina at Chapel Hill",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Schizophrenia is a mental disease that is found strongly influencedthe genetic factors, customized CGH array is designed to detect thecopy number variation(as a genetic factor) in the candidate regionthat associated with Schizophrenia. The article will introduce thenovel procedure of data normalization, copy number prediction andassociation analysis for the customized CGH array data from Nimblegenplatform. GC content correction by lowess regression is applied tonormalize the data, with which data quality is improved. Hidden MarkovModel based method is employed to detect the copy number variation.Then logistic regression method is used for association analysisbetween copy number variation and Schizophrenia probe by probe. Alsowe adapt the principal component analysis to control the potentialpopulation structure, which enhance the power of detection. Currentavailable data indicates that several regions such as regions containgenes C4B or TNXB are associated with Schizophrenia by using ourmethod, which is consistent with previous research finding.Additionally, some new regions associated with Schizophrenia are foundand needed to confirm by experiment.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Statistical genetics,Applied data analysis,,,,,,,12-Nov-10,gebregz@musc.edu,,Mulugeta Gebregziabher,Asst Professor,Medical University of South Carolina,"135 Cannon St, Suite 303",8438761112,8438761126,gebregz@musc.edu,Discovering Phenotye Subgroups of Autism,1,Mulugeta,,Gebregziabher,"Biostatistics and Epidemiology, MUSC",Mattew,,Shotwell,"Biostatistics and Epidemiology, MUSC",Jane,,Charles,"Pediatrics, MUSC",Joyce,,Nicholas,"Biostatistics and Epidemiology, MUSC",,,,,,,,,,,,,,,,,,,,,,,,,"We evaluate the performance of the Dirichlet process mixture (DPM) and the latent class model (LCM) in identifying autism phenotype subgroups based on categorical autism spectrum disorder (ASD) phenotypes from the Diagnostic and Statistical Manual of Mental Disorders, Fourth Edition Text Revision. A simulation study is designed to mimic the ASD phenotypes dataset in order to evaluate the LCM and DPM methods in this context. Likelihood based information criteria and Bayesian methods are used to identify the best fitting models and the Rand statistic is used to compare the performance of the two in recovering the true phenotype subgroups. Our results indicateexcellent recovery of the true subgroup structure in the simulated data for both methods. The LCM performs slightly better than DPM when the correct number of latent subgroups is selected a priori. Comparison of model fit indices in identifying the best fitting LCM showed that adjusted Bayesianinformation criteria (ABIC) picks the correct number of classes over 90% of the time. In contrast, DPM utilizes a maximum a posteriori (MAP) criterion to estimate the number of classes which also yielded promising results. Thus, when phenotypes are categorical, LCM in conjunction with ABIC could be used in modeling individual differences in which subjects are assumed to belong to one of a finite number of subgroups.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Applied data analysis,Variable subset selection/model selection,,,,,,,30-Oct-10,geert.molenberghs@uhasselt.be,,Geert Molenberghs,Professor,I-BioStat,Universiteit Hasselt,32476354512,3211268299,geert.molenberghs@uhasselt.be,A Model for Hierarchical Data With Combined Normal and Conjugate Random Effects,1,Geert,,Molenberghs,"I-BioStat, Universiteit Hasselt & Katholieke Universiteit Leuven",Geert,,Verbeke,"I-BioStat, Katholieke Universiteit Leuven & Universiteit Hasselt",Clarice,GB,Demetrio,"ESALQ, Universidade Sao Paulo, Brazil",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Non-Gaussian outcomes are often modeled using members of exponential family. Two of the main reasons for extending this family are (1) the occurrence of overdispersion, meaning that the variability in the data is not adequately described by the models, which often exhibit a prescribed mean-variance link, and (2) the accommodation of hierarchical structure in the data, stemming from clustering in the data which, in turn, may result from repeatedly measuring the outcome, for various members of the same family, etc. The first issue is dealt with through a variety of overdispersion models, such as, for example, the beta-binomial model for grouped binary data and the negative-binomial model for counts. Clustering is often accommodated random subject-specific effects. Though not always, one conventionally assumes such random effects to be normally distributed. While both of these phenomena may occur simultaneously, models combining them are uncommon. This paper proposes a broad class of generalized linear models accommodating overdispersion and clustering through two separate sets of random effects. emphasize on conjugate random effects at the level of the mean for the first aspect and normal random effects embedded within the linear predictor for the second aspect, even though our family is more general.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Longitudinal data,Multivariate methods,,,,,,,17-Sep-10,geert.verbeke@med.kuleuven.be,,Geert Verbeke,Prof.,I-BioStat,U.Z. Sint-Raphael,+3216336891,,geert.verbeke@med.kuleuven.be,A mixed model for high-dimensional multivariate longitudinal data,1,Geert,,Verbeke,"I-BioStat, K.U.Leuven",Steffen,,Fieuws,"I-BioStat, K.U.Leuven",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In many applications, multiple outcomes are gathered longitudinally for a sample of subjects, and the research questions of interest cannot be answered without jointly modeling all outcomes. A flexible model  that can easily handle unbalanced data, is a mixed model which assumes a random-effects model for each outcome separately and a joint distribution for all random effects in the multivariate mixed model. However, in cases where many outcomes are to be modeled simultaneously, the high dimension of the random-effects distribution poses specific numerical problems. We propose a pairwise model fitting approach in which all possible bivariate models are fitted, and where inference follows from pseudo-likelihood arguments. The approach is applicable for linear, generalized linear, and nonlinear mixed models, or for combinations of those. The methodology will be extensively illlustrated in the analysis of several real data sets.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Longitudinal data,Multivariate methods,,,,,,,15-Nov-10,gelfondjal@uthscsa.edu,,Jonathan Gelfond,Assistant Professor,UT Health Science Center San Antonio,Mail Code 7933,210 567 0851,,gelfondjal@uthscsa.edu,Fundamentals of Elements for Ethical Translational Data Analysis,1,Jonathan,A,Gelfond,UT Health Science Center San Antonio,Elizabeth,,Heitman,Vanderbilt University,Brad,H,Pollock,UT Health Science Center San Antonio,Craig,,Klugman,,,,,,,,,,,,,,,,,,,,,,,,,,"With the advent of the translational research concept and theinformation age, basic and clinical scientists rely on informatics andstatistics as never before to generate and test hypotheses and todiscover patterns of disease hidden within overwhelming amounts ofdata.  Too often, physicians and scientists are not adequatelyproficient in statistics to analyze data or interpret results, andstatistical expertise may not be properly incorporated within theresearch process. We argue for the ethical imperative of statisticalstandards, and we present ten nontechnical elements that form aconceptual framework for the ethical application of statistics intranslational research. These elements are drawn from the literatureon the ethics of data analysis and the American StatisticalAssociation ethical guidelines.  The elements are: 1) Awareness ofstatistical ethical guidelines, 2) Multidisciplinary Expertise, 3)Objectivity, 4) Openness & Transparency, 5) Verification ofAssumptions, 6) Accuracy of primary data & computation, 7) Appropriatedesign and sample size, 8)  Parsimony in Model Selection, 9)Interpretable Quantification of Evidence, and 10) Avoidance ofMisinterpretation. We illustrate these elements with examples fromcontemporary translational research.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Biostatistics Education,Statistical education,,,,,,,15-Nov-10,gene.pennello@fda.hhs.gov,,Gene Pennello,Team Leader and Mathematical Statistician,Food and Drug Adminstration,Division of Biostatistics,301-796-6038,301-847-8123,gene.pennello@fda.hhs.gov,Recent Developments in the Statistical Evaluation of Medical Devices under FDA Regulatory Review,1,Gene,A,Pennello,Food and Drug Administration,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"A medical device is a medical item that does not work through chemical action (as a drug) or biological action (as a biological product), including artificial hearts, pacemakers, lasers for eye surgery, artificial hips/knees, and diagnostic tests, from imaging systems to lab tests.  A premarket application contains data on reasonable assurance of safety and effectiveness of the device. A medical device of moderate risk can be cleared via the 510(k) process if it is shown to be substantial equivalent to a legally marketed predicate device.  Applicants may use the least burdensome means of evaluating device effectiveness, which, if necessary, may entail non-randomized comparisons, non-blinded treatment assignments, or an enrichment strategy. Recent developments in the statistical evaluation of medical devices will be surveyed, e.g., risk-benefit assessment, propensity scores for non-randomized comparisons, sensitivity analysis, missing data imputation, and Bayesian analysis for premarket evaluation and post-market signal detection. Emerging technologies may be discussed, including diagnostic imaging and biomarkers for identifying patients eligible for specific therapy.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Other,"Biologics, pharmaceuticals, medical devices",Regulatory and Legal Statistics,,,,,,14-Nov-10,genton@stat.tamu.edu,,Marc G. Genton,Professor,Texas A&M University,Department of Statistics,979 458 0889,,genton@stat.tamu.edu,Cross-covariance Functions for Multivariate Random Fields,1,Marc,G,Genton,Texas A&M University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Multivariate data indexed by spatial coordinates have becomeubiquitous in a large number of applications, for example inenvironmental and climate sciences to name but a few. Thishas prompted a renewed interest in multivariate random fieldsin recent years for modeling purpose. However, this approachrequires cross-covariance functions, the construction of whichis a challenging problem. We will review various approachesto the construction of valid parametric cross-covariancefunctions, ranging from separable models to more flexiblemodels based on the linear model of coregionalizationor based on latent dimensions. This review will serve asan introduction to the other talks in this topic-contributed session.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Spatial/temporal modeling,Multivariate methods,,,,,,,02-Nov-10,georgexzh@gmail.com,,John J. Chen,Associate Professor,Stony Brook University,Dept of Preventive Medicine,631-444-2191,,georgexzh@gmail.com,Specify Random-effects Covariance Structure for longitudinal studies,1,Guangxiang,,Zhang,"Department of Applied Math and Statistics, Stony Brook University.",John,J.,Chen,"Department of Preventive Medicine, Stony Brook University.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Mixed-effect models (MEMs) have been widely used in longitudinal dataanalysis as they allow for correlations among repeated measurementsfrom the same unit. In practice, the iterative maximum likelihoodfitting algorithms might fail to converge due to the estimatedcovariance matrix for random effects being near-singular. To improvesuch convergence on the boundary issues, we propose a simpledata-driven algorithm to adaptively fit the MEMs, aiming to reduce thesubsequent random effects correlation estimate down to zero in optimallinear transformed space.  We show that current available algorithmsare not fully optimal for actual computations because the conditionnumbers are unnecessarily increased when the correlation estimates arenot near-zero. In addition, the conditions where traditional meancentering technique will actually increase the correlation are alsodiscussed. Simulations show that the proposed algorithm near-perfectlyimproves the non-convergence rate, and the positive definite propertyand singularity of covariance matrix estimates.Two real data sets are used to illustrate the application of thisalgorithm, which is extremely straightforward applicable and easilyimplemented with current algorithms (e.g., R (nlme and lme4) and SAS).",FALSE,FALSE,,FALSE,TRUE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Random effects,Computational methods,,,,,,,09-Nov-10,gffu@psu.edu,,Guifang Fu,,"Penn state university,Dept of Statistics","411 waupelani Dr. ,",8505598406,,gffu@psu.edu,A statistical model for mapping biological shape,1,Guifang,,Fu,"Department of statistics, Penn state university",Rongling,,Wu,"Public health department, Penn state university",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Despite the fundamental importance of morphological shape, little isknown about the detailed genetic mechanisms of shape variation.  Inthis talk, I will present a statistical model for mapping quantitativetrait loci (QTL) that govern the differences in morphological shape.By incorporating image analysis, statistical model and marker-basedlinkage disequilibrium (LD) analysis, we are able to locate the genesthat control the static allometry of the leaf shape traits.Radius-contour-centroid (RCC) is used to quantitatively represent ashape, and dimension is reduced by PCA. Through incorporating theseprocedures into the LD based mapping framework, we can identifyindividual QTLs responsible for global and local shape variability,and simultaneously estimate QTL allele frequency and marker-QTLlinkage disequilibrium by the EM algorithm. The statistical behaviorof the model and its utilization were verified by a real data analysison the poplar genetics leaf data from Tibet of China.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Statistical genetics,Imaging,,,,,,,10-Nov-10,ghosh@purdue.edu,,Jayanta K Ghosh,,Professor,"Department of Statistics , Purdue University",765-494-6041,,ghosh@purdue.edu,Dirichlet Mixtures of Normals for Patient Based Drug Use - Tentative Suggestions,1,Jayanta,K,Ghosh,"Professor, Department of Statistics, Purdue University",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"There was a recent workshop at SAMSI on the topic mentioned in the title. I will lecture on my suggestions on how the Dirichlet mixture can be used, given some additional inputs from doctors and pharmaceutical scientists.If time permits, I may also make a few comments on how computation time may be saved using an algorithm due to Michael Newton with some theory and further improvements by Ryan Martin, Surya Tokdar and me. This is based on new joint work with Ryan.",TRUE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Bayesian methods,High dimensional data,Nonparametric Methods,,,,,,15-Nov-10,ghosha3@mail.nih.gov,,Arpita Ghosh,,National Cancer Institute,6120 Executive Blvd,301-247-9053,,ghosha3@mail.nih.gov,Unified Analysis of Secondary Phenotypes in Case-Control Association Studies,1,Arpita,,Ghosh,"Biostatistics Branch, National Cancer Institute",Fei,,Zou,"Department of Biostatistics, The University of North Carolina at Chapel Hill",Fred,A.,Wright,"Department of Biostatistics, The University of North Carolina at Chapel Hill",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In genome-wide association studies, the data are usually sampledretrospectively as in a case-control design. A host of other secondaryphenotypes, possibly correlated with the primary disease phenotype,are often collected and also analyzed for association with geneticvariants.  It has been repeatedly shown that analysis of secondaryphenotypes which ignores the sampling scheme can produce highly biasedassociation risk estimates.   Although a number of approaches havebeen proposed to properly analyze secondary phenotypes, theseapproaches often fail to reproduce the marginal logistic modeltypically assumed for the original case-control phenotype.  Inaddition, handling covariates in a flexible manner remainschallenging. We provide a general retrospective likelihood frameworkto perform association testing for both binary and continuoussecondary phenotypes while respecting desired marginal models. Wedemonstrate how the approach can incorporate covariates, andeasily allow for interaction between the genetic variant and thesecondary phenotype on primary disease risk. We describe extensivesimulations to evaluate the performance of our method in comparisonwith competing methods.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Statistical genetics,Epidemiologic methods,,,,,,,14-Nov-10,gina@wubios.wustl.edu,,Gina D'Angelo,Assistant Professor,"Washington University School of Medicine, Division","660 South Euclid Avenue, Box 8067",314-362-3758,,gina@wubios.wustl.edu,Missing data approaches for partial correlations of regional volumetric data,1,Gina,M,D'Angelo,"Washington University School of Medicine, Division of Biostatistics",Jingqin,,Luo,"Washington University School of Medicine, Division of Biostatistics",Chengjie,,Xiong,"Washington University School of Medicine, Division of Biostatistics",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In the dementia area it is often of interest to study relationshipsamong regional brain measures.  For many of these studies it is oftennecessary to adjust for covariates such as age.  Partial correlationis a statistical measure frequently used to correlate two variableswhile adjusting for other variables.  Complete case analysis istypically the analysis of choice for partial correlations with missingdata.  However, complete case analysis will lead to biased andinefficient results when the data are missing at random.  We haveextended the partial correlation coefficient in the presence ofmissing data using the EM algorithm, and compared it with a multipleimputation method and complete case analysis.  We have proposedvarious variance estimations for all proposed methods.  We havecompared the EM algorithm to the multiple imputation method andcomplete case analysis method using simulation studies.  These methodswill be illustrated with volumetric data from an Alzheimer's diseasestudy.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Imaging,Missing data,,,,,,,15-Nov-10,giurcanu@louisiana.edu,,Mihai C Giurcanu,Assistant Professor of Statistics,University of Louisiana at Lafayette,"Department of Mathematics, University of Louisiana at Lafayette, 406 Maxim Doucet Hall",3528700925,,giurcanu@louisiana.edu,Bootstrapping in Sparse Correlation Models,1,Mihai,C,Giurcanu,University of Louisiana at Lafayette,Brett,D,Presnell,University of Florida,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In this paper, we study the asymptotic behaviour of the standardbootstrap, m-out-of-n bootstrap, and oracle-bootstrap (Giurcanu,Presnell, 2009) estimators of the distributions of sparse estimatorsin correlation models. Our results show that, if the correlation modelis sparse, then the standard bootstrap estimators converge indistribution to some random distributions, and thus, they areinconsistent, and that the m-out-of-n and the oracle-bootstrapestimators are consistent. We also study the asymptotic properties ofthe bootstrap distribution estimators when some regressioncoefficients are small. Our results show that, if some small regression parameters are very small, then the standard bootstrapestimators are inconsistent and the m-out-of-n and theoracle-bootstrap estimators are consistent. Furthermore, when some small regression parameters are moderately small, none of thebootstrap estimators are consistent. Finally, when some small regression parameters are moderately large, then the standardbootstrap, some m-out-of-n bootstrap, and some oracle-bootstrapestimators are consistent. In an empirical study, we compare thefinite sample properties of the bootstrap methods for various samplesizes and model parameters.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Variable subset selection/model selection,Computational methods,,,,,,,14-Nov-10,gjh27@cornell.edu,,Giles Hooker,Professor,Cornell University,Dept. Bio. Stat. and Comp. Bio.,6072551638,6072554698,gjh27@cornell.edu,Functional Convolution Models and Smooth Time Series Analysis,1,Giles,,Hooker,Cornell University,Maria,,Acensio,Cornell University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"This talk presents an extension of distributed lag models in time series analysis to functional data. We assume the measurement of input and output functional objects and a model in which output depends on the recent past of the input through a functional linear regression. This is also a restriction of  the historical linear model studied in Malfait and Ramsay (2003). An ordinary  least squares approach to estimating this model is presented and novel bootstrap methods are developed to provide confidence intervals under the assumption of a smooth, stationary error process. Example applications in modeling vehicle emissions and ecological responses to climate change are demonstrated.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Functional data analysis,Nonparametric methods,,,,,,,15-Nov-10,gjm112@gmail.com,,Gregory Mattjews,,University of Connecticut,215 Glenbrook Road,413-335-3098,,gjm112@gmail.com,Assessing database privacy using the area under the receiver-operator characteristic curve,1,Gregory,J,Matthews,"Department of Statistics, University of Connecticut",Ofer,,Harel,"Department of Statistics, University of Connecticut",Robert,H,"Aseltine, Jr.","Division of Behavioral Sciences and Community Health, Institute for Public Health Research,University of Connecticut Health Center",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"One of the most pressing issues in the confidentiality literature isthe quantification of privacy. One proposal, epsilon-differentialprivacy, moves away from absolute guarantees of privacy to relativeguarantees. However, the selection of an appropriate epsilon isdifficult because its interpretation is unclear. Further, whencomparing different privacy preserving techniques to one another, adirect comparison cannot be made by simply comparing the respectivevalues of epsilon. The aim of this work is to provide a measure thatallows for direct comparison across different privacy schemes and ismore easily interpreted.  In turn, this will aid in policy debatepertaining to how much privacy is acceptable.  Our proposal sets theproblem in a hypothesis testing framework and uses the area under thereceiver-operator characteristic (ROC) curve as a measure of privacy.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Health services research,ROC analysis,,,,,,,01-Nov-10,gma@amgen.com,,Guoguang (Julie) Ma,Senior Manager,Amgen Inc.,1120 Veterans Blvd,650-244-8407,,gma@amgen.com,"Adverse Event Signal Detection: Overall comparisons, Future Projections and False Discoveries",1,Guoguang (Julie),,Ma,Amgen Inc.,Jitendra,,Ganju,Amgen Inc.,Jing,,Huang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"One challenge with detecting signals from unexpected adverse events (AEs) in randomized clinical trials is the high rate of false positive findings if the per comparison error rate is controlled, or the high rate of false negative findings if the family-wise error rate is controlled. A different challenge is evaluating, after the trial is completed, whether the assessment of risk changes if the trial period were to be increased (i.e. either exposure to treatment or the observation period is increased). We propose a method, intended for informal inference, to address the dual problems of high error rates and risk assessment under trial extension. The method is applied to two real data sets.  Limitations of the method are also discussed.   The following is proposed: (a) visualization of AE data to help decide whether or not to proceed with additional analyses. (b) If further analysis is suggested, then for each AE, make future projections of the number of subjects with that AE based on a weighting scheme using empirical Bayes methodology. (c) Flag AEs that are deemed significant based on overall incidence from the observed and projected portions of the trial after controlling the false discovery rate rather than a family-wise error rate. The new AEs flagged by extending the trial are additional AEs to pay attention to in making the overall risk assessment.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Biopharmaceutical research,Clinical trials,,,,,,,08-Nov-10,goulda@merck.com,,A. Lawrence Gould,,Merck Research Laboratories,"351 N. Sumneytown Pike, UGD1-88",267 305 6888,,goulda@merck.com,Statistical Properties of a Design with Multiple Analyses of Futility,1,A. Lawrence,,Gould,Merck Research Laboratories,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"This presentation describes an adaptive design that employs two or more interim futility analyses using predictive probability to determine whether a trial should continue or be terminated, usually for futility but possibly for efficacy.  The properties of the design depend on the the critical values for continuing and stopping, on the timing of the interim analyses, and on assumptions about the true event rates on the active and control treatments that account for uncertainty of their design stage values when they are based on previous trials.  Uncertainty about the true values that affects the statistical properties also is incorporated explicitly.  Alternative design strategies are evaluated using a utility analysis that accounts for overhead costs, lost opportunity costs, and benefits from correctly identifying an effective treatment.  Different futility stopping criteria are used at each interim evaluation, initially to avoid continuing a trial that early findings suggest is very unlikely to be definitive, and subsequently to avoid continuing a trial whose predictive probability of success is not high enough to justify completion.  All of the computations are analytic, and no normality assumptions are required.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Bayesian methods,Adaptive design/adaptive randomization,,,,,,,11-Oct-10,gray.simone@epa.gov,,Simone Gray,,Environmental Protection Agency,109 T.W. Alexander Dr,919-541-2021,,gray.simone@epa.gov,Process Modeling for Contingency Tables with Ordered Categories,2,Matthew,,Heaton,Duke University,Simone,,Gray,Environmental Protection Agency,Alan,,Gelfand,Duke University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We consider the setting of a multi-way contingency table with at leastone ordinal classification. The contribution of this presentation isto propose a joint probability model for the uncensored variables thatis apart from the imposed categorization. Specifically, we assume thatthe joint distribution of the expected cell counts is induced by alog-Gaussian process over m-dimensional space. In other words, arealization of a log-Gaussian process provides the intensity surfacethat drives the expected cells in the table. With such an approach weachieve full inference regarding the underlying distribution, inparticular, inference for familiar associations between the ordinalvariables in the absence of interval censoring. Additionally,inference can be provided for any newly created cells where suchcreation is achieved through redefinition of the ordinalclassifications. Rather than ad hoc reallocation, we achieve a fullymodel-based reallocation enabling quantification of uncertainty. Themethodology is detailed within a Bayesian hierarchical framework,showing associated computation and convenient dimension reductiontechniques to facilitate model fitting. We illustrate with bothsimulated data and a real census dataset.",FALSE,FALSE,,FALSE,FALSE,FALSE,,contributedposter,,,,FALSE,FALSE,FALSE,TRUE,Categorical data,Hierarchical models,,,,,,,05-Nov-10,gshan@buffalo.edu,,Guogen Shan,,clinical trials,246 Montrose Ave,7162180066,,gshan@buffalo.edu,Two-stage k-sample designs for the ordered alternative problem,1,Guogen,,Shan,"Department of Biostatistics,University at Buffalo",Gregory,E,Wilding,"Department of Biostatistics,University at Buffalo",Alan,D,Hutson,"Department of Biostatistics,University at Buffalo",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In pre-clinical studies and clinical dose-ranging trials, theJonckheere-Terpstra test is widely used in the assessment ofdose-response relationships. Hewett and Spurrier (1979) presented atwo-stage analogs of the test in the context of large sample sizes. Inthis paper, we propose an exact test based on Simon's minimax andoptimal design criteria originally used in the context of one-armphase II designs based on binary endpoints. The convergence rate ofthe joint distribution of first and second stage test statistics tothe limiting distribution is studied, and design parameters areprovided for a variety of assumed alternatives. The behavior of thetest is also examined in the presence of ties.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Clinical trials,Nonparametric methods,,,,,,,13-Oct-10,guerraw@mail.med.upenn.edu,,Matthew Guerra,,University of Pennsylvania School of Medicine,501 Blockley Hall,2155738950,,guerraw@mail.med.upenn.edu,The Analysis of Binary Longitudinal Data with Time-Dependent Covariates,1,Matthew,,Guerra,University of Pennsylvania School of Medicine,Justine,,Shults,University of Pennsylvania School of Medicine,Jay,,Amsterdam,University of Pennsylvania School of Medicine,Thomas,,Ten Have,University of Pennsylvania School of Medicine,,,,,,,,,,,,,,,,,,,,,,,,,"We consider longitudinal studies with binary outcomes that aremeasured repeatedly on subjects over time. Our analysis goal is to fita logistic model that relates the expected value of the outcomes withexplanatory variables that are measured on each subject.However, additional care must be taken to adjust for the associationbetween the repeated measurements on each subject. We propose a newapproach that extends the maximum likelihood method fortime-independent covariates of Zeger, Liang, and Self   (The analysisof binary longitudinal data with time-independent covariates. (1985).Biometrika 72, 31-38) to covariates that may be fixed or time-varying. We also implement and make comparisons with two other approaches:generalized estimating equations, which may be more robust tomisspecification of the true correlation structure, and alternatinglogistic regression, which models association via odds-ratios, thatare subject to less-restrictive constraints than are correlations. Theproposed estimation procedure will yield consistent and asymptoticallynormal estimates of the regression and correlation parameters, if thecorrelation on consecutive measurements on a subject is constant.Simulations demonstrate that our approach can yield improvedefficiency in estimation of the regression parameter. We present ananalysis to demonstrate application of the methods we consider.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Other,Longitudinal data,Binary Data,,,,,,14-Oct-10,guhan003@umn.edu,,RAJARSHI GUHANIYOGI,Ph.D,UNIVERSITY OF MINNESOTA,516 University Avenue S.E.,6512077569,,guhan003@umn.edu,Bias-adjusted hierarchical low rank spatial process  models for large datasets,1,RAJARSHI,,GUHANIYOGI,"Ph.D student, UNIVERSITY OF MINNESOTA, DIVISION OF BIOSTATISTICS",SUDIPTO,,BANERJEE,"ASSOCIATE PROFESSOR, UNIVERSITY OF MINNESOTA, DIVISION OF BIOSTATISTICS",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Continued advancements in Geographical Information Systems (GIS) andrelated software enable accurate geocoding of locations generatingscientic data in diverse disciplines. Statisticians today commonlyencounter spatial datasets collected over thousands of locations.Given the rich dependence structures often underlying such data,statisticians often develop hierarchical spatial models implementedthrough Markov chain Monte Carlo (MCMC) to fit models that would beinfeasible with classical methods within inappropriate asymptoticparadigms. However, estimating hierarchical spatial process modelsinvolve expensive matrix decompositions whose computational complexityincreases in cubic order with the number of spatial locations,rendering such models infeasible for large spatial data sets. Tocircumvent these computational bottlenecks, a suite of  'low-rank'methods, such as predictive process models, have recently beenproposed in the geostatistical literature. These methods usuallyoperate on lower-dimensional subspaces and induces biases in theresidual variance components as a result of over-smoothing or modelmisspecication. Hitherto little work has been devoted tounderstanding such biases and their inferential consequences. Ourcurrent work attempts to characterize these biases, demonstrates theirpresence as a systemic phenomena, and explores remedial models withoutincurring computational costs. We illustrate our work using syntheticexperiments as well as an application to forest sciences.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,TRUE,Spatial/temporal modeling,Forestry/agriculture applications,,,,,,,15-Nov-10,gunjang@mail.med.upenn.edu,,Gun Ho Jang,Dr.,University of Pennsylvania,"Blockley Hall 210, 423 Guardian Dr.",215-746-3433,,gunjang@mail.med.upenn.edu,A Hidden Markov Chain Model for Joint SNP and CNP Calling,1,Gun Ho,,Jang,University of Pennsylvania,Rui,,Feng,University of Pennsylvania,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Both a singular nucleotide polymorphism (SNP) and copy numbervariation (CNV) are widespread characteristics of human genome andhave been shown to be related to various human diseases. Limited bythe available statistical methods, current practice in associationstudies is separate calling or analysis of SNP genotypes and CNVs.Here, we developed a hidden markov model (HMM) for joint calling ofboth SNP and CNV using signal intensities derived from the commongenotyping platforms. In addition, we estimated a confidenceprobability for each of the CNV and normal interval calls. Oursimulations show that our model has a higher detection rate of CNV andmore accurate genotype calls in both shorter and longer CNV regionscompared with various existing CNV calling methods including PennCNV,a different HMM model, a method using a scan statistic, and a mixturemodel. Also, our estimated confidence can separate those calls thatare likely to be false, which combined with our HMM certainly canreduce type-I error and increase power for genetic associationstudies. Though applications to both HapMap data and a real GWAS ofacute lung injury, our method produced some useful populationparameters and showed the power of detecting disease-associated genes.",FALSE,FALSE,,FALSE,TRUE,TRUE,"TutorialsT1: Nearest Neighbors Techniques for Natural Resources Applications; Monda, March 21, 8:30-10:15amT3: Statistical Inference with Missing Data; Monday, March 21, 1:45  3:30 pm",oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Biomarkers/surrogate markers,Genomics,,,,,,,12-Nov-10,guoying.sun@gmail.com,,Guoying Sun,,FDA,1401 Rockville Pike,301-827-9333,,guoying.sun@gmail.com,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,FALSE,FALSE,,FALSE,FALSE,FALSE,,,,,,FALSE,FALSE,FALSE,FALSE,,,,,,,,,15-Nov-10,gyenokya@jhsph.edu,,Gayane Yenokyan,Assistant Scientist,Johns Hopkins Biostatistics Center,"615 N. Wolfe St, Rm E-3153",410 502 3828,,gyenokya@jhsph.edu,Covariate-adaptive randomization and estimation of treatment effect in a large phase III trial of hemorrhagic stroke,1,Gayane Yenokyan,,Yenokyan,"Johns Hopkins Biostatistics CenterDepartment of BiostatisticsJohns Hopkins School of Public Health",Jonathan,,Gellar,"Department of BiostatisticsJohns Hopkins School of Public Health",Michael,,Rosenblum,"Department of BiostatisticsJohns Hopkins School of Public Health",Richard,E.,Thompson,"Johns Hopkins Biostatistics CenterDepartment of BiostatisticsJohns Hopkins School of Public Health",Daniel,F.,Hanley,Johns Hopkins School of Medicine,,,,,,,,,,,,,,,,,,,,,"Randomization in clinical trials may result in a lack of balance in important prognostic factors between treatment arms. Achieving balance on the hemorrhage volume and clot location near the thalamus, both of which are predictive of poor outcomes, is considered important by the stroke clinical community. The covariate-adaptive stratification method has been proposed to minimize imbalances on such factors.We compared traditional and covariate-adaptive allocation methods to inform the randomization decision in a large, multi-center phase III hemorrhagic stroke trial. A modification to Pocock and Simon's adaptive allocation was proposed for the situations when the number of sites is large relative to the trial size. We assessed the accuracy of g-computation estimator of Robins (1986), which adjusts for the covariates, and the unadjusted estimator, defined as the difference between the sample means in the treatment and control groups. Our simulations show that the modified adaptive design is superior to the block randomization on the overall balance in prognostic factors and the balance of treatment within sites. Adaptive design offers better precision of treatment effect when using the unadjusted estimator. However, when the g-computation estimator is used, the adaptive design does not have a clear advantage over the block randomization.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Adaptive design/adaptive randomization,Clinical trials,,,,,,,04-Nov-10,zhengsr1993@gmail.com,,Shurong Zheng,,Northeast Normal University,Department of Mathematics,86-431-85099589,,zhengsr1993@gmail.com,Two-stage Dose Finding for Cytostatic Agents in Phase I Clinical Trials,1,Shurong,,Zheng,Department of Mathematics,Guosheng,,Yin,The University of Hong Kong,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Conventional dose-finding methods in oncology are mainly developed for cytotoxic agents with the aim of finding the maximum tolerated dose.  In phase I clinical trials with cytostatic agents (mostly targeted therapies), the designs with toxicity endpoints may not work well because cytostatic agents are typically less toxic and tolerable, and efficacy is more relevant. For cytostatic agents, we develop a two-stage dose-finding procedure by first identifying the toxicity upper bound of the searching range through dose escalation, and then determining the most efficacious dose by dose de-escalation while toxicity is continuously monitored. In oncology, efficacy often takes a relatively long period of time to observe compared with toxicity which may occur shortly after treatment. To facilitate a continual patient accrual and dose assignment, we model the time to efficacy by redistributing the mass of the censored efficacy event to the right and compute the fractional contribution of the censored data.  We evaluate the operating characteristics of the new dose-finding design through simulation studies and demonstrate its satisfactory performance with cytostatic agents.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Adaptive design/adaptive randomization,Clinical trials,,,,,,,11-Nov-10,haihong_li@vrtx.com,,Haihong,,Vertex Pharmaceuticals,130 Waverly St,6174447294,,haihong_li@vrtx.com,On optimal testing strategies when multiple hypotheses are grouped into two ordered families,1,Haihong,,Li,Vertex Pharmaceuticals,Abdul,J,Sankoh,Vertex Pharmaceuticals,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"One of the recent advancements in clinical trial design andstatistical methods that provide strong control of the family-wisetype I error rate for multiple testing of hypotheses is the adaptivealpha allocation approach proposed by Li & Mehrotra (Statistics inMedicine 2008; 27:5377-5391). In this approach, the hypotheses aregrouped into two families based on perceived trial power and thesignificance level for the second family is set adaptively based onthe largest observed p-value in the first family. In researchconducted recently, we introduced improvement to this procedure andshowed the improved test is substantially more powerful in the generalcase of two or more hypotheses in the first family. In thispresentation we further explore methods that are optimal and showthat though there is no uniformly most power test, reasonably powerfultests can be constructed within a certain class of testing proceduresand under specific alternative hypotheses.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Multiple testing,Biopharmaceutical research,,,,,,,15-Nov-10,haiqun.lin@yale.edu,,Haiqun Lin,,Yale University,60 College Street,1-203-785-4707,,haiqun.lin@yale.edu,Joint Analysis of Longitudinal Multi-State Transition and Time-to-Event,1,Haiqun,,Lin,Yale University School of Public Health,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We present a joint model with latent variables for longitudinal ordinal response and time-to-death in longitudinal aging study.  Longitudinal ordinal response can be regarded as multistate transitions over time. We use semiparametric model to describe the transitions jointly with time-to-death.  Two time frames are used in the joint model, gap-time is used in modeling the longitudinal transitions and elapse time is used in modeling time-to-death. We illustrate the method with the data from a longitudinal study on community dwelling older adults and with a simulation study.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Joint models for longitudinal and survival data,Latent variables,,,,,,,14-Oct-10,hakmook@stat.brown.edu,,Hakmook Kang,,Brown University,Box G-S121-7,401-863-6877,,hakmook@stat.brown.edu,Spatio-Spectral Mixed Effects Model for Functional Magnetic Resonance Imaging Data,1,Hakmook,,Kang,"Center for Statistical SciencesBrown UniversityProvidence, RI 02912",Hernando Ombao,,,"Center for Statistical SciencesBrown UniversityProvidence, RI 02912",Crystal Linkletter,,,"Center for Statistical SciencesBrown UniversityProvidence, RI 02912",Nicole Long,,,"Department of Cognitive, Linguistic and Psychological SciencesBrown UniversityProvidence, RI 02912",David Badre,,,"Department of Cognitive, Linguistic and Psychological SciencesBrown UniversityProvidence, RI 02912",,,,,,,,,,,,,,,,,,,,,"The goal of this paper is to model cognitive control relatedactivation and connectivity among pre-defined regions of interest(ROIs) of the human brain. Standard approaches to fMRI analysis do notsimultaneously take into account both the spatial and temporalcorrelations that are prevalent in fMRI data. To address theselimitations, we propose a spatio-spectral mixed effects model. Workingin the spectral domain simplifies the spatio-spectral covariancestructure. Additionally, by incorporating voxel-specific andROI-specific random effects the model is able to capture themulti-scale spatial covariance structure: local correlation (within anROI), and global correlation (between ROIs). Modeling the globalcorrelation structure properly provides insight into the functionalconnectivity structure. Building on existing theory on linear mixedeffects models to conduct estimation and inference, we applied ourmodel to fMRI data collected to estimate activation in pre-specifiedROIs in the prefontal cortex and estimate the correlation structure inthe network. Our analysis concluded the existence of functionalcoupling between two ROIs, namely, the anterior premotor cortex andthe lateral prefrontal cortex.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Spatial/temporal modeling,Imaging,,,,,,,23-Sep-10,halberst@mail.med.upenn.edu,,Steffanie M. Halberstadt,,"University of Pennsylvania, Department of Biostati",501 Blockley Hall,605-521-1053,,halberst@mail.med.upenn.edu,A Joint Latent Variable Model Approach to Item Reduction and Validation,1,Steffanie,M,Halberstadt,"University of Pennsylvania, Department of Biostatistics",Mary,D,Sammel,"University of Pennsylvania, Department of Biostatistics",Ellen,W,Freeman,"University of Pennsylvania, Department of Obstetrics and Gynecology",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Many applications of biomedical science involve unobservable constructs, from measurement of health states to severity of complex diseases.  From a statistical perspective, the goals of measurement are to combine pieces of information in a way that thoroughly describes a construct and then to validate the information.  Typically item reduction and validation are done separately.  This article proposes a Multiple Indicator Multiple Cause (MIMIC) latent variable model that combines these two steps.  A joint latent variable model eliminates the bias that occurs in the traditional two-stage process.  A modified Score test is developed to test the statistical significance of items in the MIMIC model under certain constraints.  The methods are motivated by an example from a premenstrual syndrome clinical trial in which the objective was to identify core symptoms of severe premenstrual syndrome from a symptom scale and to determine the relationship between the reduced symptom set and a gold standard diagnosis measure.  Simulations are presented that illustrate the performance of the test under various conditions.  Results show that three items from the symptom scale are candidates for elimination according to the Score test.  Further, simulations show that the Score test performs better than the conventional Wald test under certain conditions.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Latent variables,Multivariate methods,,,,,,,11-Nov-10,haleyhedlin@gmail.com,,Haley Hedlin,,JHSPH Department of Biostatistics,615 N. Wolfe St.,701-238-2705,,haleyhedlin@gmail.com,Estimating temporal associations in electrocorticographic (ECoG) time series using multiple subjects,1,Haley,,Hedlin,"Department of Biostatistics, Johns Hopkins School of Public Health",Dana,,Boatman,"Department of Neurology, Johns Hopkins Hospital",Brian,,Caffo,"Department of Biostatistics, Johns Hopkins School of Public Health",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Granger causality (GC) is a statistical technique used to estimatetemporal associations in multivariate time series.  Many applicationsand extensions of GC have been proposed since its formulation byGranger in 1969.  Here we propose an approach to extend GC to multiplesubjects in order to facilitate quantitative across-subjectcomparisons while simultaneously adjusting for potentially mediatingor confounding associations between time series. We present an examplein the context of event-related electrocorticographic (ECoG) time series",FALSE,FALSE,,FALSE,FALSE,FALSE,,contributedposter,,,,FALSE,FALSE,FALSE,TRUE,Other,High dimensional data,neurostatistics,,,,,,15-Nov-10,hanalee@email.unc.edu,,Hana Lee,,UNC,"1900 Baity Hill Dr., #317",919-951-8783,,hanalee@email.unc.edu,Detecting significance level of brain activity using self-calibrated method,1,Hana,,Lee,University of North Carolina at Chapel Hill,Young,,Truong,,Xuemei,,Huang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In many applications of modeling functional magnetic resonance imaging(fMRI) data for central nervous system (CNS) disordered studies, it isnecessary to identify regions of interest (ROI) and analyze aggregatedata from each region. This is often carried out by assuming (1) ahomogeneous hemodynamic response function (HRF), and (2) a homogeneityof the variance-covariance structure within and between subjects. Wepropose a method for assessing directly the level of heterogeneitywithin any given ROI along with a procedure for detecting activationby using non-ROIs to calibrate the significance level. This flexiblemethod can be applied to fMRI-based neural studies involving block orevent related designs. The effectiveness of the proposed procedureswill be illustrated by a simulated study along with fMRI data analysisbased on 5 normal subjects and one Parkinson's disease patient, whoseROIs are known to be quite heterogeneous.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Imaging,Computational methods,,,,,,,14-Nov-10,hansont@stat.sc.edu,,Timothy E. Hanson,Associate Professor,University of South Carolina,Department of Statistics,(803) 777-3859,(803)777-4048,hansont@stat.sc.edu,Identifiability of Models for Multiple Diagnostic Testing in the Absence of a Gold Standard,1,Timothy,,Hanson,University of South Carolina,Geoffrey,,Jones,Massey University,Wesley,,Johnson,"University of California, Irvine",Ronald,,Christensen,University of Mew Mexico,,,,,,,,,,,,,,,,,,,,,,,,,"Summary We discuss the issue of identifiability of models for multipledichotomous diagnostic tests in the absence of a gold standard (GS)test. Data arise as multinomial or product-multinomial countsdepending upon the number of populations sampled. Models are generallyposited in terms of population prevalences, test sensitivities andspecificities, and test dependence terms. It is commonly believed thatif the degrees of freedom in the data meet or exceed the number ofparameters in a fitted model then the model is identifiable. Goodman(1974,Biometrika 61, 215-231) established that this was not the case35 years ago. We discuss currently available models for multiple testsand argue in favor of an extension of a model that was developed byDendukuri and Joseph (2001,Biometrics 57, 158-167). Subsequently, wefurther develop Goodman's technique, and make geometric arguments togive further insight into the nature of models that lackidentifiability. We present illustrations using simulated and real data.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Diagnostic and screening tests,Categorical data,,,,,,,15-Nov-10,hao.wu@emory.edu,,Hao Wu,Assistant Professor,"Department of Biostatistics and Bioinformatics, Em","1518 Clifton Rd., NE",4047129576,4047271370,hao.wu@emory.edu,Joint analysis of multiple ChIP-seq experiments,1,Hao,,Wu,"Department of Biostatistics and Bioinformatics, Emory University",Hongkai,,Ji,"Department of Biostatistics, Johns Hopkins University",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"ChIP-seq is a powerful approach to study protein-DNA interactions. With the rapid growth of publicly available ChIP-seq data, it becomes more and more common that multiple datasets are related to similar transcription factor or biological pathways. Integrating such data and analyzing them jointly allows one to borrow information across datasets to improve peak detection. We will present a hierarchical mixture model to capture the correlation among datasets and perform the joint analysis. Simulation and real data results show the advantages of integrating data over analyzing each individual dataset alone.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Genomics,Hierarchical models,,,,,,,12-Nov-10,haol@bcm.edu,,Hao Liu,,Baylor College of Medicine,Division of Biostatistics,(832) 2126406,,haol@bcm.edu,Bayesian Analysis of Correlated Data in Limiting-Dilution Transplantation Experiments,1,Hao,,Liu,"Division of Biostatistics, Dan L. Duncan Cancer Center, Baylor College of Medicine, Houston, TX 77030",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Limiting-dilution transplantations are in vivo experiments that havebeen widely used by  cancer biologists to study the initiation ofbreast cancer from mammary stem cells. The quantitative purpose is toestimate the frequency of cells with regenerative abilities ortumor-initiating capacities. The data are the presence or absence ofmammary cell growth: these are usually correlated data when observedon two cleared mammary glands on the same mouse.  Current statisticalmethods for limiting dilution assay are not developed for thesituation; they are mainly for in vitro experiments with independentdata.  In this paper, we present a Bayesian method for analyzingcorrelated bivariate binomial data arisen from limiting-dilutiontransplantation experiments.  The correlation is introduced byunobserved random variables in  a Poisson single-hit model. Wedescribe a Bayesian estimation procedure with a tuned and efficientMarkov chain Monte Carlo algorithm. We further illustrate the methodby a real data analysis example.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Cancer applications,Categorical data,,,,,,,12-Nov-10,haoz@amgen.com,,Hao Zhang,,UC Davis,5000 Orchard Park Circle 5513,(530)220-2645,,haoz@amgen.com,Using linear model to assess individual biosimilarity for drug interchangeability of follow-on biologics,3,Eric,,Chi,Amgen,Shein-Chung,,Chow,Duke University,Hao,,Zhang,UC Davis,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"For assessment of biosimilarity of follow-on biologics, it is a safety concern whether approved follow-on biologics can be used interchangeably with the innovative product.  In this presentation, we will focus on the assessment of individual biosimilarity following the concept of individual bioequivalence for drug products. A linear model is used to assess individual biosimilarity for addressing drug interchangeability for pharmacokinetic responses.  Several designs including the 2x3 dual design recommended by the FDA, the commonly used replicated design, the extra-reference design proposed by Chow et. al. 2002, and a proposed design are compared both theoretically and through simulation studies. For each design, the Type I error and the power of the test are investigated under different combinations of parameters and various sample sizes. The comparison of the performances of the designs can be used as a reference for design selection.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Pharmacokinetic/pharmacodynamics (PK/PD) modeling,Biopharmaceutical research,,,,,,,15-Nov-10,harezlak@iupui.edu,,Jaroslaw Harezlak,Assistant Professor,Indiana University School of Medicine,"410 W 10th St., Suite 3000",317-274-2682,317-274-2678,harezlak@iupui.edu,Partially empirical eigenvectors for regression (PEER) for generalized functional linear models (GFLM),1,Jaroslaw,,Harezlak,"Indiana University School of MedicineDivision of Biostatistics410 W 10th St., Suite 3000Indianapolis, IN 46202",Timothy,W.,Randolph,"Fred Hutchinson Cancer Research Center Biostatistics and Biomathematics 1100 Fairview Ave. N., M2-B500 Seattle, WA 98109",Ziding,,Feng,"Fred Hutchinson Cancer Research Center Biostatistics and Biomathematics 1100 Fairview Ave. N., M2-B500 Seattle, WA 98109",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"GFLMs (generalized functional linear models) are often used toestimate the association between a predictor function and a response.Approaches used either reduce the functions by estimating theirprincipal components or project the functions onto the span of fixedbases.  A major challenge in GFLM estimation is to incorporate thestructural properties of the functions into the analysis. We providean extension of a recently proposed method - PEER (partially empiricaleigenvectors for regression) for functional linear models (FLM) toGLFM. The PEER approach to FLMs incorporates the structure of thefunctions via a joint spectral decomposition of the predictorfunctions and a penalty operator into the estimation process via ageneralized singular value decomposition. We extend this approach toGFLMs and compare the estimation performance with the more classicalmethods, including principal component regression and regularizationof the basis function expansion. Finally, we apply our methodology tothe data collected on HIV-infected patients quantifying theassociation between the brain metabolite concentrations measured bymagnetic resonance spectroscopy (MRS) and binary cognitive impairmentstatus.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Functional data analysis,High dimensional data,,,,,,,04-Oct-10,hatfield@umn.edu,,Laura Hatfield,,Division of Biostatistics,"Mayo A460, MMC 303",6122035893,,hatfield@umn.edu,Multilevel Bayesian models of zero-inflated longitudinal outcomes and survival times in mesothelioma,1,Laura,A,Hatfield,"Division of Biostatistics, University of Minnesota",Mark,E,Boye,"Global Health Outcomes, Eli Lilly and Company",Michelle,D,Hackshaw,"Global Health Outcomes - Oncology, Merck \& Co., Inc.",Bradley,P,Carlin,,,,,"Division of Biostatistics, University of Minnesota",,,,,,,,,,,,,,,,,,,,,"Malignant pleural mesothelioma (MPM) is a rapidly fatal form of pulmonary cancer usually associated with asbestos exposure. Previous studies have established pemetrexed (Alimta(R)) plus cisplatin, compared with cisplatin alone, as effective in prolonging progression-free survival (PFS) in the first-line setting. However, this finding has not been supported by corresponding published patient-reported trial results. We conducted this research to interpret the benefits to survival by jointly modeling it with longitudinal patient-reported outcomes (PROs). We build hierarchical Bayesian models that combine zero-inflated beta distributions for the PROs with proportional hazards Weibull models for the right-censored PFS values. Correlations among an individual's probability of a non-zero PRO, the non-zero PRO severity scores, and PFS are modeled using latent random variables. The results indicate significantly decreased lung symptom severity over time and increased PFS in the pemetrexed/cisplatin group. We observe both correlation between the individual probability of non-zero PRO and severity of non-zero PROs, and associations between the PRO latent variables and PFS. This paper supports the modest survival benefit of pemetrexed/cisplatin for first-line treatment of patients with MPM and couples it with significantly improved patient-reported outcomes.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Joint models for longitudinal and survival data,Bayesian methods,,,,,,,04-Nov-10,hbane001@ucr.edu,,Hiya Banerjee,Postdoctoral Fellow,Medical University of South Carolina,"40 Bee Street,",352-222-3600,,hbane001@ucr.edu,Methods of Finding the Initial Values of Parameters in the Maximum Likelihood Estimating Equations for a Logistic Regression Model and Comparison of Their Final Solutions,2,Dr. Subir,,Ghosh,"University of California, Riverside",Hiya,,Banerjee,Medical University of South Carolina.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We present two methods of finding the initial values of parameters ofthe maximum likelihood estimating equations (MLEE) for a logisticregression model using two criterion functions. We use the initialvalues and the corresponding criterion functions to obtain the finalsolutions of MLEE. Most experiments include more than two doses fordetermining a lethal dose like ED50. For two doses, we present anexact analytic expression for the solution of estimating equations.The iterative methods make use of the initial values of theparameters. We use the search algorithm for performing theoptimization to find the final solutions of MLEE. The numerical valuesof our estimates of ED50  are nearly equal to the value by thestandard method. The proposed methods are transparent in the selectionof the initial values of parameters. The methods are computerintensive like bootstrap and jackknife methods.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Categorical data,Generalized linear models,,,,,,,15-Nov-10,hbrandt2@uwo.ca,,Holger Brandt,,University of Western Ontario,Department of Psychology,519661211189299,,hbrandt2@uwo.ca,Sensitivity analysis for the identification of surrogate variables,1,Holger,,Brandt,University of Western Ontario,Andreas,G.,Klein,University of Western Ontario,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In clinical studies concerning treatment efficacy the interest insurrogate variables has been increasing. Nonetheless theidentification of surrogate variables poses several theoreticalproblems that have not yet been fully taken into account by themajority of the present-day approaches. These problems are discussedand a simulation study for a new approach that is based on thepotential outcomes framework is presented.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Biomarkers/surrogate markers,Markers and surrogate markers,,,,,,,12-Nov-10,hchakraborty@rti.org,,Hrishikesh Chakraborty,Group Leader and Senior Research Statistician,RTI International,300 Parish House Road,9194852623,,hchakraborty@rti.org,Comparison of Intraclass Correlation Estimators for Clustered Binary Data,1,Hrishikesh,,Chakraborty,"Statistics and Epidemiology, RTI International, Research Triangle Park, NC, USA.",Mark,,Kindem,"Statistics and Epidemiology, RTI International, Research Triangle Park, NC, USA.",Dhuly,,Chowdhury,"Statistics and Epidemiology, RTI International, Research Triangle Park, NC, USA.",Pranab,K,Sen,"Department of Biostatistics, University of North Carolina at Chapel Hill, NC, USA.",,,,,,,,,,,,,,,,,,,,,,,,,"Several methods have been proposed to estimate the intraclass correlation coefficient (ICC) for clustered binary data.  While some methods are very specific to the type of design and underlying distributional assumptions, others are based on more general methods such as pseudo-likelihood and extended quasi-likelihood estimation. We developed a new method to estimate ICC for clustered binary data that utilizes a multinomial approach, using re-sampling methods and U-statistics.  The main advantage of this new method is that it can be used for any type of categorical variable without making additional assumptions.  To compare the methods, we created simulated datasets using Monte Carlo simulation, varying numerous inputs such as outcome proportion, cluster size, and number of clusters, and calculated estimates of ICC using these data.  By doing this, we were able to compare the ICC estimates of our new method to the estimates of established calculation methods.  We found that the ANOVA and our newly created multinomial method estimates are the closest to the population ICC for varying proportions, proportion variations, cluster sizes, cluster size variations, and number of clusters.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Other,Clustered data methods,Cluster Randomized Trials,,,,,,15-Nov-10,hdai@cmh.edu,,Hongying (Daisy) Dai,,Children's Mercy Hospital,Department of Medical Research,816-7015233,,hdai@cmh.edu,Incorporating Global Tests of P-values in Multifactor Dimensionality Reduction Models for Genotyping Data,1,Hongying,,Dai,"Children's Mercy HospitalUniversity of Missouri Kansas City",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Multifactor Dimensionality Reduction (MDR) provides a series of emerging combinatorial models in conjunction with novel machine learning and data mining techniques to detect and characterize complex gene-to-gene (GxG) interactions associated with susceptibility to disorders. False positive discovery emerges as the number of interactions among multiple risk factors increases exponentially with the dimension of the risk factors. We propose to utilize the p-values of all tested interaction models to investigate whether there are interactions among genes. We speculate that multiple genes could be involved in numerous GxG interactions, causing a subset of p-values to be smaller than 0.05. Under the null hypothesis of no interaction, p-values follow a uniform (0, 1). Two omnibus tests, 1)modified likelihood ratio test and 2) L2 distance based D-test, as well as nine traditional tests, including 3)AIC and BIC, 4) Kolmogrov-Smirnov (K-S) test; 5) Kuiper Test; 6) Cramer-von Mises Test; 7) Anderson-Darling test; 8) Inverse Chi-square test; 9) Inverse Normal test; 10) Logit Test; and, 11) Mann-Whitney U Test are applied to control false discovery. We also perform simulation to compare global tests in MDR framework and illustrate our methodology with two case studies.",FALSE,FALSE,,FALSE,TRUE,TRUE,T5: Essentials for success in Research,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Statistical genetics,Epidemiologic methods,,,,,,,15-Nov-10,heidi.sucharew@cchmc.org,,Heidi Sucharew,,Cincinnati Children's Hospital,3829 Mt Vernon Ave,513-803-1920,,heidi.sucharew@cchmc.org,Using Latent Profile Analysis to Characterize Glycemic Control during Pregnancy,1,Heidi,,Sucharew,"Division of Biostatistics and Epidemiology, Cincinnati Children's Hospital Medical Center, Cincinnati, OH",Rhonda,,VanDyke,"Division of Biostatistics and Epidemiology, Cincinnati Children's Hospital Medical Center, Cincinnati, OH",Jane,,Khoury,"Division of Biostatistics and Epidemiology, Cincinnati Children's Hospital Medical Center, Cincinnati, OH",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Latent profile analysis (LPA) is a method for identifying clusters of individuals with similar response patterns by maximizing differences between profiles while minimizing differences within. The LPA model is expressed as a generalized finite mixture model, where each individual is a member of a discrete latent variable or profile. BIC and the Lo-Mendell-Rubin test are used to determine the optimal number of profiles. In clinical applications, validity of the resulting profiles may be assessed by association with subsequent outcomes or randomization of subjects into training and test datasets, with comparison of the resulting profiles. Additionally, we propose an algorithm for determining an individual's profile membership when they are not included in the initial model development. This algorithm uses approximate probabilities for the response pattern and Bayes' theorem to define profile membership. We illustrate the application and algorithm using data from a 17-year study of pregnant women with type 1 diabetes. Monthly glycohemoglobin A1, a measure of glycemic control, was collected throughout pregnancy and birth outcomes were obtained. We demonstrate this novel application of LPA to maternal glycemic control, and association of profile membership with pregnancy outcomes.  The algorithm for subject allocation outside of the estimation procedure will also be demonstrated.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Applied data analysis,Latent variables,,,,,,,15-Nov-10,heli@temple.edu,,Li He,,Temple University,1420 Locust St. #28I,2152009982,,heli@temple.edu,Adaptive Multiple Testing Procedures Incorporating Correlations,1,Li,,He,Temple University,Sanat,K,Sarkar,Temple University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"When there are correlations among test statistics, a multiple testing procedure can be made more powerful in detecting interesting nonnull cases by suitably incorporating these correlations into the procedure. In this paper, we propose adaptive versions of Bonferroni, Sidak and BH procedures with improved power by taking correlations into account, with proven control of the famiywise error rate (FWER) for the first two and the false discovery rate (FDR) for the third, under positive dependence. Typically, there are two stages involved in an adaptive version of a FWER or FDR controlling procedure obtained through estimating m0, the number of true nulls. The first stage forms this estimator based on the results of some multiple testing procedure, and the second stage is the actual procedure that is being adjusted using the estimator formed at the first stage. In our procedures, the correlation effect is taken into account while estimating m0. We construct an estimate of m0 at the first stage from a suitable multiple testing procedure based on the pairwise distributions of the null p-values. Simulations indicate that our proposed adaptive procedures have better power than the corresponding non-adaptive procedures as well as the adaptive procedures that do not take correlations into account in detecting high signals under mild dependence.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Multiple testing,High dimensional data,,,,,,,27-Sep-10,heqianch@email.unc.edu,,Qianchuan He,,UNC-Chapel hill,Department of Biostatistics,919-951-4067,,heqianch@email.unc.edu,A variable selection method for genome-wide association studies,1,Qianchuan,,He,"Department of BiostatisticsUNC-Chapel Hill",Dan-Yu,,Lin,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Genome-wide association studies (GWAS) involvinghalf a million or more single nucleotide polymorphisms (SNPs)allow genetic dissection of complex diseases in a holistic manner.The common practice of analyzing one SNP at a time does not fullyrealize the potential of GWAS to identify multiple causal variantsand to predict risk of disease. Existing methods for jointanalysis of GWAS data tend to miss causal SNPs that are marginallyuncorrelated with disease and have high false discovery rates(FDRs). We introduce GWASelect, a statistically powerful andcomputationally efficient method totackle the unique challenges of GWAS data. This method searchesiteratively over the potential SNPs conditional on previouslyselected SNPs and is thus capable of capturing causal SNPs thatare marginally correlated with disease as well as those that aremarginally uncorrelated with disease. A special resamplingmechanism is built into the method to reduce false-positivefindings. Simulation studies demonstrate that the GWASelectcan be substantially more powerful than existingmethods while having a lower FDR. Inaddition, the regression models based on the GWASelect tend toyield more accurate prediction of disease risk than existingmethods. The advantages of the GWASelect are illustrated with theWellcome Trust Case-Control Consortium (WTCCC) data.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,TRUE,Statistical genetics,Variable subset selection/model selection,,,,,,,14-Nov-10,hiparker@jhsph.edu,,Hilary Parker,Graduate Student,Johns Hopkins School of Public Health,615 N Wolfe St E3035,3314727537,,hiparker@jhsph.edu,The practical effect of batch on genomic prediction,1,Hilary,S,Parker,"Department of Biostatistics, Johns Hopkins School of Public Health",Rafael,A,Irizarry,"Department of Biostatistics, Johns Hopkins School of Public Health",Jeffrey,T,Leek,"Department of Biostatistics, Johns Hopkins School of Public Health",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Measurements from microarray and other high-throughput technologies are susceptible to a number of non-biological variables such as temperature, reagent lots, and even ozone. A commonly used surrogate for these non-biological variables is the date on which the experiment was performed.  It has been shown that these artefacts, collectively called batch effects, can severely alter the outcome of any differential expression analysis, resulting in misleading biological conclusions. Here we examine the impact of batch effects on predictors built from genomic technologies - specifically gene expression microarrays. We compare single microarray (fRMA) and multiple microarray (RMA, MASS5) preprocessing methods and both rank-based (top-scoring pairs) and continuous (PAM) predictors. We show that in general, prediction is made more difficult by batch effects. We also show that when there is perfect confounding of batch and the outcome being predicted, then accuracy is substantially reduced. In an effort to mitigate this effect, we determine which probes from commonly used Affymetrix arrays are most susceptible to batch and investigate their properties. Down-weighting these 'batch-affected' probes may lead to increased predictive accuracy when building gene expression based predictors.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,TRUE,Microarray analysis,Genomics,NA,,,,,,14-Nov-10,hji@jhsph.edu,,Hongkai Ji,Assistant Professor,"Department of Biostatistics, Johns Hopkins Univers","615 North Wolfe Street, RM E3638",410-955-3517,,hji@jhsph.edu,Functional Interpretation of ChIP-seq Using Publicly Available Gene Expression Data,1,Hongkai,,Ji,"Department of Biostatistics, Johns Hopkins University",George,,Wu,"Department of Biostatistics, Johns Hopkins University",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Chromatin immunoprecipitation coupled with massively parallel sequencing (ChIP-seq) is a powerful approach to map transcription factor binding sites. It is often combined with gene expression profiling to study gene regulation. Both ChIP-seq and gene expression data in public domains are rapidly growing. The entire data from diverse biological contexts contain enormous amounts of information that have not been fully utilized so far. We have developed a new approach that combines ChIP-seq with large amounts of publicly available gene expression data to do data mining. Our new approach allows one to discover novel functional contexts of transcription factors. We have tested our approach in a study involving the transcription factor c-Myc. Our analysis has led to a novel discovery that c-Myc plays a functional role in Ewings sarcoma.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Genomics,Data mining/massive data sets,,,,,,,10-Nov-10,hjkim@truman.edu,,Hyun-Joo Kim,Associate Professor of Statistics,Truman State University,100 normal,6607854693,,hjkim@truman.edu,MODEL AND VARIABLE SELECTION FOR COUNTING DATA BASED ON INFORMATION CRITERIA: STATISTICAL MODELLING ON TICK BURDEN AND THE HOST CHARACTERISTICS,1,Hyun-Joo,,Kim,"Department of Mathematics and Computer Science, Truman State University",Stephanie,,Fore,"Department of Biology, Truman State University",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In statistical modeling, selecting an optimal model from a class ofcandidates is a critical issue. A number of model selection criteriahave been introduced including the Akaike (1973, 1974) informationcriterion, AIC, the corrected Akaike information criterion (Hurvichand Tsai, 1989), AICc, Kullback information criterion, KIC, andcorrected Kullback information criterion, KICc (Cavanaugh, 1999,2003). In wildlife and ecology, a count data dealing withoverdispersion is common. For such case, Quasi Akaike informationcriteria and its corrected version, QAIC and QAICc (1992) have beensuggested. New criteria, QKIC and QKICc were proposed recently (Kimet. al., 2010) and arguably outperform the existing criteria. In thispaper, the model selection and variable selection performance of theseinformation criteria is discussed in simulation study and astatistical model is developed for the tick, Dermacentor variabilis,load on a white-footed mouse, Peromyscus leucopus in northern Missouri.",FALSE,FALSE,,FALSE,TRUE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Environmental and ecological applications,Variable subset selection/model selection,,,,,,,10-Nov-10,hongyu.zhao@yale.edu,,Hongyu Zhao,,Yale University,60 College Street,203-785-3613,,hongyu.zhao@yale.edu,Statistical issues in next generation sequencing data analysis,1,Hongyu,,Zhao,Yale University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Next generation sequencing data offer much more detailed and accurateinformation than microarray data on various aspects of generegulation. For example, ChIP-seq data have been widely adopted as amore effective alternative to ChIP-chip to study protein-DNAinteractions. RNA-seq allow researchers to study novel alternativesplicing events. It is desirable to integrate different types of data.In this presentation, we discuss how to jointly model distinct nextgeneration sequencing data to delineate the gene expression regulatoryprocess.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Genomics,Data mining/massive data sets,,,,,,,30-Oct-10,hongzhe@upenn.edu,,Hongzhe Li,Professor,University of Pennsylvania,Department of Biostatistics & Epideiology,215 573-5038,,hongzhe@upenn.edu,Joint Inference of Sparse Network and Genetic Association in Genetical Genomics  Studies,1,Hongzhe,,Li,University of Pennsylvania,,,,,Jianxin,,Shi,University of Pennsylvania,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Genetical genomics experiments have now been routinely conducted tomeasure both the genetic variants and gene expression data on thesame subjects. The gene expression levels are often treated asquantitative traits and are subject to standard genetic analysis inorder to identify the gene expression quantitative loci (eQTL).However, the genetic architectures for many gene expressions may becomplex, and poorly estimated genetic architectures may compromisethe inferences of the dependency structures of the genes at thetranscriptional levels. In this paper, we introduce a joint modelingapproach in the framework of sparse seemingly unrelated regression(SSUR)  models to simultaneously identify the genetic variantsassociated with gene expressions and construct the sparse Gaussiangraphical model based on the eQTL data. We present an efficientcoordinate descent algorithm to obtain the penalized estimation  forboth the regression coefficients and sparse concentration matrix.Simulation experiments and asymptotic theory are used to justify ourproposed methods. We present application of the methods to analysisof a yeast eQTL data set.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Genomics,Graphical models,,,,,,,17-Sep-10,hsamawi@georgiasouthern.edu,,Hani Samawi,Professor,Georgia Southern University,JPHCOPH,9124781345,9124785811,hsamawi@georgiasouthern.edu,STEADY STATE RANKED GIBBS SAMPLER,1,Hani,M,Samawi,"Georgia Southern UniversityKarl E. Peace Center for Biostatistics JPHCOPH",Martin,,Dunbar,"Georgia Southern UniversityKarl E. Peace Center for Biostatistics JPHCOPH",Ding-Geng (Din),,Chen,"Georgia Southern UniversityKarl E. Peace Center for Biostatistics JPHCOPH",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Gibbs sampler, as a computer intensive algorithm is an importantstatistical tools, both in application and in theoretical work. Thisalgorithm, in many cases, is time consuming; this paper extends theconcept of using the steady state ranked simulated sampling approach(SRSIS), utilized in  Monte Carlo methods by Samawi (2009), to improvethe well known Gibbs sampler algorithm. It is demonstrated that thisapproach provides unbiased estimators, in case of estimating the meansand the distribution function, and substantially improves theperformance of Gibbs sampler algorithm and convergence which  resultsin a significant reduction in costs and time required to attain acertain level of accuracy. Similar to Casella and George (1992), weprovide some analytical properties in simple cases and compare theperformance of our method using the same illustrations.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Computational methods,Bayesian methods,,,,,,,28-Oct-10,hsunk@mail.med.upenn.edu,,Hokeun Sun,,University of Pennsylvania,205 Blockley Hall,215-746-3517,,hsunk@mail.med.upenn.edu,Groupwise Thresholding of Covariance Matrices for Identifying Gene-Gene Interactions,1,Hokeun,,Sun,"Center for Clinical Epidemiology and BiostatisticsUniversity of Pennsylvania School of Medicine",Hongzhe,,Li,"Center for Clinical Epidemiology and BiostatisticsUniversity of Pennsylvania School of Medicine",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In the recent genome wide association studies, new statistical and computational models have been developed to identify gene-gene interactions. It is well known that  combinations of single nucleotide polymorphism (SNP) rather than an individual SNP play an important role in the development of complex diseases. A number of literatures have proposed the use of case-only designs as an alternative to case-control designsto study gene-gene or gene-environment interactions since its appearance. In this article we consider a block covariance matrix of case-only SNP data where a sequence of SNP ispartitioned into genes. Each block of the matrix represents groupwise SNP correlation between two genes. We propose groupwise thresholding procedure to estimate a high-dimensional block-sparse covariance matrix. The method is based on minimizing the penalized least square function to select nonzero blocks of the matrix which are corresponding to gene-gene interactions. The thresholding procedure requires essentially no computational burden, so the implementation of the method for high-dimensional SNP data is relatively easy.Simulation studies demonstrate that the proposed method performs well in terms of both estimation and selection. The method is applied to the analysis of High-density lipoprotein (HDL) cholesterol SNP data to identify gene-gene interactions.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Statistical genetics,Variable subset selection/model selection,,,,,,,05-Nov-10,hsuweiwe@msu.edu,,Wei-Wen Hsu,,Michigan State University,"2092 Lac Du Mont, Apt.B2",6626941514,,hsuweiwe@msu.edu,A Wald test for homogeneity in zero-inflated models for discrete data,1,Wei-Wen,,Hsu,"Department of Statistics and Probability, Michigan State University",David,,Todem,"Division of Biostatistics, Department of Epidemiology, Michigan State University",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Tests of homogeneity in zero-mixture models for discrete data  havebeen well discussed in the literature, but the existing methodologieshave relied primarily on  score statistics. An often citedjustification for the use of  these statistics  is that they do notrequire the model to be fitted under the alternative. But the adventof computer software with robust functions and procedures has madeeasy for these alternative models to be fitted routinely in practice.In this paper, we exploit this opportunity by using results generatedfrom these analyses to develop a Wald test statistic to evaluatehomogeneity in this class of models.  We show how the proposed testcan be performed with a minimal programming effort for the practisingstatistician. Technically, the test is based on a reparameterizationof the mixing weights that translates the homogeneity hypotheses intoa linear combination of parameters from the marginal model. Oneappealing feature of this reparameterization is that it naturallyincorporates covariates into the mixing weights, a characteristicoften ignored by existing testing procedures. A simulation study isconducted to evaluate the empirical performance of the proposed Waldtest statistic.Its real life applications are illustrated using the number ofepisodes of urinary tract infections among HIV patients and dentalcaries counts in young children.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Multiple testing,Generalized linear models,,,,,,,12-Nov-10,huangracer@gmail.com,,Lei Huang,,NYU Child Study Center,"424 west 110th street, apt 18B",9175455026,,huangracer@gmail.com,Nonparametric quantile regression for identification of developmental biomarkers,2,Philip,T,Reiss,"Department of Child and Adolescent Psychiatry, New York University",Lei,,Huang,"Department of Child and Adolescent Psychiatry, New York University",Eva,,Petkova,"Department of Child and Adolescent Psychiatry, New York University",Michael,P,Milham,"Department of Child and Adolescent Psychiatry, New York University",Fransicsco,X,Catellanos,"Department of Child and Adolescent Psychiatry, New York University",,,,,,,,,,,,,,,,,,,,,"Recent studies have linked psychological disorder with abnormaldevelopment of brain connectivity measures. Consequently it may soonbecome possible to screen for disorders on the basis of growth chartsof functional connectivity between certain regions of interest (ROIs)in the brain. This can be approached by spline-based nonparametricquantile regression.  However, unlike standard growth chart estimationproblems, this application entails estimating many growth charts inorder to pinpoint those that distinguish normal from abnormaldevelopment.  This necessitates using a fast automatic method foroptimal smoothing parameter selection.  We develop a penalized splinemethod to estimate quantiles of resting-state functional connectivitybetween ROIs as a function of age, using an improved approach tosmoothness selection. We apply our method to estimate extremeconditional quantiles of between-ROI connectivity from a sample oftypically developing controls, and to identify pairs of ROIs whoseconnectivity in individuals with attention deficity/hyoperactivitydisorder may tend to develop abnormally.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Nonparametric methods,Biomarkers/surrogate markers,,,,,,,13-Nov-10,hui.2.zhi@gsk.com,,Hui Zhi,Prin. Statistician,GlaxoSmithKline,17.2266G,9194839989,,hui.2.zhi@gsk.com,Improving efficacy of clinical pharmacokinetic studies using dependence,1,Hui,,Zhi,GlaxoSmithKline,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In typical clinical pharmacokinetic studies, primary endpoints of interest usually include area under the concentration-time curve (AUC), maximum concentration (Cmax), and average concentration (Cavg). Such parameters are commonly utilized for sample size calculation, study design and post clinical trial statistical analysis. However the standard practice is to consider these parameters individually, ignoring potential significant correlation among them. We illustrate that this approach can be too conservative, and propose to improve inference efficiency by properly incorporating dependence. Numerical studies will be reported.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Biopharmaceutical research,Clinical trials,,,,,,,28-Oct-10,hui.zhang@stjude.org,,"Hui Zhang, Ph.D",Assistant Member,St. Jude Children's Research Hospital,"262 Danny Thomas Pl., MS 768",9015956736,9015958843,hui.zhang@stjude.org,Distribution-free Models for Latent Population Mixtures,1,Hui,,Zhang,"Department of Biostatistics,St. Jude Children's Research Hospital",Xin,M,Tu,"Department of Biostatistics and Computational Biology,University of Rochester Medical Center",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Many studies in biomedical, psychosocial and related servicesresearch involve mixtures of populations. For example, when evaluatingthe effect of an HIV prevention intervention for a population ofadolescent girls, it is not only of significant importance to studywhether the intervention has an effect on those who are sexuallyactive (the at-risk subgroup), but also on abstinent girls (thenon-risk sub-group), since the intervention is likely to havedifferential effects between the two different populations. Since thesub-groups are generally unobservable, it is not possible to compareintervention effects across such sub-populations using existing methods.      In this thesis, we propose a novel approach to tackle the analyticproblems. We employ a Zero-inflated Poisson (ZIP) like model to helpidentify the two latent sub-groups and integrate this sub-model intothe context of a primary model of interest to enable estimation ofparameters of interest such as the intervention effect in the HIVprevention study. We develop this proposed system of models byutilizing a new class of functional response models (FRM). To provideinference for longitudinal data analysis, we integrate the inverseprobability weighted (IPW) estimate within the context of FRM anddevelop distribution-free inference about the parameters of the systemof models. As we have demonstrated in our prior research oninvestigating the differences in modeling longitudinal data betweenthe dueling parametric generalized linear mixed-effects model (GLMM)and distribution-free generalized estimating equations (GEE)paradigms, the proposed distribution-free approach seems to offer theonly sensible solution to this type of modeling problem involvingpopulation mixtures.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Nonparametric methods,Longitudinal data,,,,,,,08-Nov-10,huizh@umich.edu,,Hui Zhang,,"Department of Biostatistics, University of Michiga",3775 Green Brier Blvd Apt 252B,7342776934,,huizh@umich.edu,Semiparametric methods for the analysis of failure time data with outcome-dependent sampling and dependent censoring,1,Hui,,Zhang,"Department of Biostatistics, University of Michigan",Douglas,E,Schaubel,"Department of Biostatistics, University of Michigan",John,D,Kalbfleisch,"Department of Biostatistics, University of Michigan",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Outcome-dependent sampling (ODS) is an efficient and cost-savingsampling scheme, wherein subjects are selected into the study based onthe outcomes of interest (i.e., death, survival). Most methods foranalyzing ODS-based data have an underlying assumption that subjectsare censored in a manner independent of the failure rate. However,this assumption is often violated in public health studies. Forexample, wait-listed end-stage liver disease patients may receive aliver transplant and therefore not die on the waitlist, an issue whichcould produce substantial bias in the estimation of waitlist mortalityif treated as independent censoring. We propose methods, based onweighted estimating equation with a double-inverse-weighting schemewhich combines weights corresponding to the probability of remaininguncensored and the probability of being sampled. The proposedestimators of the regression parameter are shown to be consistent andasymptotically normal, and consistent estimators of the asymptoticcovariance matrices are derived. Finite sample properties of theproposed estimators are examined through simulation studies. Theproposed methods are applied to data from the Scientific Registry ofTransplant Recipients.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Survival analysis,Applied data analysis,,,,,,,15-Nov-10,hung-chia.chen@fda.hhs.gov,,Hung-Chia Chen,Dr.,"National Center for Toxicological Research, Food a",3900 NCTR ROAD HFT-020,8705437665,,hung-chia.chen@fda.hhs.gov,Biclustering to identify the relationship of drugs and adverse events,1,Hung-Chia,,Chen,"Division of Personalized Nutrition and Medicine, National Center for Toxicological Research, FDA",James J.,,Chen,"Division of Personalized Nutrition and Medicine, National Center for Toxicological Research, FDA",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Many approved drugs are removed from the market after thepost-marketing discovery of unexpected adverse events, such as liveror kidney toxicity, that were not detected in extensive pre-clinicaland clinical testing. The occurrence of drug-induced liver toxicity isthe single most common reason for the Food and Drug Administration'sregulatory actions concerning drugs. It may result in the drug's beingwithdrawn from market, even though the drug may benefit the vastmajority of those taking it, without increased risk. The Adverse EventReporting System (AERS) is the primary computerized informationdatabase designed to support the FDA's post-marketing safetysurveillance program for all approved drug and therapeutic biologicproducts. A two-way (drug by event) clustering will be applied todetermine which drugs are similar and which adverse events aresimilar, and to identify local patterns and global structure for thedrug and event relationships. According to the clustering, thedisproportional ratio scores will be recomputed to detect the set ofdrugs and strongly associated adverse effects in a large two-way table.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Data mining/massive data sets,Biopharmaceutical research,,,,,,,08-Oct-10,hutianle@umich.edu,,Tianle Hu,,"Dept of Biostatistics, Univ of Michigan",15578 Northville Forest Dr.,7342392203,,hutianle@umich.edu,Time-dependent cross-ratio estimation for bivariate failure times,1,Tianle,,Hu,"Department of Biostatistics, University of Michigan",Bin,,Nan,"Department of Biostatistics, University of Michigan",Xihong,,Lin,"Department of Biostatistics, Harvard School of Public Health",James,,Robins,"Departments of Biostatistics and Epidemiology, Harvard School of PublicHealth",,,,,,,,,,,,,,,,,,,,,,,,,"In the analysis of bivariate correlated failure time data, it is important to measure the strengthof association among the correlated failure times. One commonly used measure is the cross-ratio. Motivatedby Coxs partial likelihood idea, we propose a novel parametric estimator for the cross-ratio that is a flexiblecontinuous function of both components of the bivariate survival times. We show that the proposed estimatoris consistent and asymptotically normal. The performance of the proposed technique in finite samples is examinedusing simulation studies. In addition, the proposed method is applied to the Australian twin data for theestimation of dependence of the risk for appendicitis between monozygotic twin pairs as well as dizygotic twinpairs.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Multivariate survival,Survival analysis,,,,,,,11-Nov-10,hxia@amgen.com,,H. Amy Xia,Biostatistics Director,"Amgen, Inc.",One Amgen Ctr Dr,8054479846,,hxia@amgen.com,Continuously Monitoring of a Safety Event of Interest in an Ongoing Phase 2 Trial,1,Amy,,Xia,"Amgen, Inc.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The statistical issues posed by monitoring safety in clinical trials are considerably different from monitoring efficacy. In the presence of a safety concern, timely assessment of new data from an ongoing trial and establishment of a fast response system are important to protect patients participating in the trial. In this context, it is preferred to monitor an event of interest continuously; that is, to assess the risk whenever a new event occurs. In contrast, when focusing on efficacy, the number of interim analyses and the number of subjects or events per interim analysis are often predetermined under the framework of traditional group sequential methods. In this presentation, we propose a novel Bayesian approach for establishment of statistical guidelines in order to facilitate informed and objective decisions made by the monitoring committee. The approach allows incorporation of both internal and external information and offers flexibility and efficiency. The challenges from both statistical and operational perspectives will also be discussed.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Clinical trials,Bayesian methods,,,,,,,15-Nov-10,hxu@mcg.edu,,Hongyan Xu,,Medical College of Georgia,1120 15th St,7622335586,,hxu@mcg.edu,Genetic association test using next generation sequencing data,1,Hongyan,,Xu,Georgia Health Science University,Varghese,,George,Georgia Health Science University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Next generation sequencing can generate more sequence (NGS) data with considerably less cost then the conventional sequencing based on the Sanger method. Therefore, it holds much promise for unraveling the genetic basis of complex traits through large-scale genetic association studies. However, the NGS data are different from the Sanger sequencing data in that the genotypes for each individual cannot be observed directly, instead, they are represented by reads from a series of short fragments. The proportion of the two alleles in a heterozygote individual may be affected by multiple factors in sample preparation and amplification. In other words, the genotypes have to be inferred from the NGS data and there is quite some uncertainty associated with the inference. We model the number of allele reads as a binomial random variable and developed an genetic association test accounting for the uncertainty in the genotype inference. Simulations show that the new test retains correct type I error rate and has competing power compared to similar tests that are recently developed for NGS data.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Genomics,Statistical genetics,,,,,,,12-Oct-10,hyang13@student.gsu.edu,,Hanfang Yang,,Georgia State University,"30 Pryor street, suite 750",4047293668,,hyang13@student.gsu.edu,EMPIRICAL LIKELIHOOD CONFIDENCE INTERVALS FOR ROC CURVES WITH RIGHT CENSORING,1,Hanfang,,Yang,"Georgia state university, Math and statistics department",Yichuan,,Zhao,Georgia state university,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In this thesis, we apply smoothed empirical likelihood method to investigate confidence intervals for the receiver operating characteristic (ROC) curve with right censoring. As a particular application of comparison of distributions from two populations, the ROC curve is constructed by the combination of cumulative distribution function and quantile function. Under mild conditions, the smoothed empirical likelihood ratio converges to chi-square distribution, which is the well-known Wilks's theorem. Furthermore, the performances of the empirical likelihood method are also illustrated by simulation studies in terms of coverage probability and average length of confidence intervals. Finally, a primary biliary cirrhosis data is used to illustrate the proposed empirical likelihood procedure.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_poster,,,,FALSE,FALSE,FALSE,FALSE,ROC analysis,Survival analysis,,,,,,,12-Nov-10,hycao@uchicago.edu,,Hongyuan Cao,Assistant Professor,University of Chicago,5841 S. Maryland Avenue MC 2007,7738340750,,hycao@uchicago.edu,On multiple testing and the monotone likelihood ratio,1,Hongyuan,,Cao,University of Chicago,Wenguang,,Sun,North Carolina State University,Michael,R.,Kosorok,UNC-Chapel Hill,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"High-throughput screening has become an important mainstay forcontemporary biomedical research. A standard approach is to getp-values and adjust for multiple comparison in a manner that controlsfalse discovery rate (FDR). The concavity of $p$-value distributionunder the alternative has been a standard condition for developingmany FDR procedures: Storey (2003), Genovese and Wasserman (2004),Kosorok and Ma (2007). A more general concept is the monotonelikelihood ratio condition (MLRC) introduced in Sun and Cai (2007). Weshow in this paper that the concavity assumption can be violated for(i) a simpleheteroscedastic normal mixture model and (ii) dependent tests. Someinteresting implications, including different testing procedures(step-up vs step-down), the choice of test statistic and the powerdefinition in multiple testing are discussed.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Multiple testing,High dimensional data,,,,,,,15-Nov-10,hyeh@kumc.edu,,Hung-Wen Yeh,,University of Kansas Medical Center,"5028K Robinson, 3901 Rainbow Blvd.",913-588-0531,,hyeh@kumc.edu,On Statistical Methodology for Pile Sorting and its Use in Cancer Screening Research,1,Hung-Wen,,Yeh,University of Kansas Medical Center,Byron,,Gajewski,University of Kansas Medical Center,Baljit,,Kaur,University of Kansas Medical Center,Christine,,Daley,University of Kansas Medical Center,,,,,,,,,,,,,,,,,,,,,,,,,"Pile/card sorting, is a powerful methodology to understand systematically about what community members think and what concepts are attached to the barriers associated with cancer screening.  Its advantages over conventional approaches in identifying barriers include it allows community key informants freely listing all relevant barriers in their community, missing data are much less likely because performing card sorting is interesting and participants enjoy the task, and the results, with the aid of multidimensional scaling (MDS), are generalizable and provide taxonomy of barriers.  However, existing literature lacks the details on how card sorting data are prepared for MDS analysis and uncertainty of item coordinates in MDS results is omitted.  In this research, we articulate how to prepare card sorting data and address the uncertainty issue by incorporating bootstrapping with MDS.  An algorithm and a SAS macro are developed to compute distance matrices and to perform bootstrapping with MDS for other researchers to apply in their studies.  Examples are illustrated on data to help understand barriers of breast and colon cancer screening in American Indian communities.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Cancer applications,Multivariate methods,,,,,,,01-Nov-10,hzhang@sc.edu,,Hongmei Zhang,,University of South Carolina,800 Sumter Street,803-777-3823,,hzhang@sc.edu,Bayesian Adaptive Calibration and Variable Selection in Linear Models with Mismeasured Covariates,1,Hongmei,,Zhang,University of South Carolina,Xianzheng,,Huang,,Jianjun,,Gan,,Wilfried,,Karmaus,,Tara,,Sabo-Attwood,,,,,,,,,,,,,,,,,,,,,,"We propose a Bayesian variable selection method built upon an expanded Zellner's g-prior in linear measurement error models. Pseudo covariates are constructed and included in the model aiming to adaptively adjust a tuning parameter controlled by false-model selection rate, which in turn determines the components in the expanded Zellner's g-prior. Simulations demonstrate that models selected using the proposed method are generally more favorable and with smaller prediction loss compared to the models selected from other Bayesian variable selection methods based on the classical Zellner's-g prior. The method is applied to two real data examples, one is a food frequency questionnaire data from a nurse study, and the other is a gene expression data from a lung disease study.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Variable subset selection/model selection,Bayesian methods,,,,,,,15-Nov-10,hzhang@stat.ncsu.edu,,Hao Helen Zhang,Associate Professor,North Carolina State University,Campus Box 8203,919-4490565,,hzhang@stat.ncsu.edu,Multiclass Probability Estimation via Large-Margin Classifiers,1,Hao,,Zhang,North Carolina State University,Yichao,,Wu,North Carolina State University,Yufeng,,Liu,UNC at Chapel Hill,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Classical approaches for multiclass probability estimation aretypically based on regression techniques such as multiple logisticregression, or density estimation approaches such as LDA and QDA.These methods often make certain assumptions on the probabilityfunctions or on the underlying distributions of each subclasses. Wepropose a model-free procedure to estimate multiclass probabilitiesbased on large-margin classifiers. The new estimation scheme isemployed by solving a series of weighted large-margin classifiers andthen systematically extracting the probability information from thesemultiple classification rules. A main advantage of the proposedprobability estimation technique is that it does not impose any strongparametric assumption on the underlying distribution and can beapplied for a wide range of large-margin classification methods.  Ageneral computational algorithm is developed for class probabilityestimation. Furthermore, we establish asymptotic consistency of theprobability estimates. Both simulated and real data examples arepresented to illustrate performance of the new procedure.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Data mining/massive data sets,Machine learning,,,,,,,26-Oct-10,hzhu@bios.unc.edu,,hongtu zhu,,UNC-Biostatistics,"McGavran Greenberg Hall, CB#7420",919 9299010,919 9299010,hzhu@bios.unc.edu,Multiscale Adaptive Spatial-Temporal Models for Functional Images,1,Hongtu,,Zhu,UNC-Biostatistics and BRIC,Jianqing,,Fan,Princeton University,Japing,,Wang,UNC-Biostatistics and BRIC,Weili,,Lin,UNC-Radiology and BRIC,,,,,,,,,,,,,,,,,,,,,,,,,"The aim of this paper is to   develop a multiscale adaptive spatial-temporal estimation method (MAST) to denoise 2-dimensional (2D) or 3D noisy functional images.     Compared with most statistical methods for independently estimating unknown functions,     MAST, however, is a comprehensive   framework for  simultaneously estimating  unknown functions across all locations, specifically while accounting     for the complex spatial dependence and patterns in 2D or 3D functional images. MAST  has five features:  being spatial, being hierarchical,  being adaptive,being connected, and being aggregated. To   hierarchically and spatially denoise functional images,  MAST notonly creates adaptive ellipsoids at each location  to capture  spatial dependence amongimaging observations in neighboring voxels, but also cluster  voxels into possibly distant homogeneous groups to combine dependence among spatially  disconnected clusters.  Finally, MAST  combine sure independent screening and penalized likelihood methods to temporally smooth functional images.    Theoretically, we establish consistency of theadaptive estimates under some mild conditions. Two sets ofsimulation studies and a real data set  are used to demonstrate the methodology andexamine its finite sample performance in imaging  segmentation and classification.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Imaging,High dimensional data,,,,,,,13-Nov-10,hzhu@cph.osu.edu,,Hong Zhu,Assistant Professor,"Division of Biostatistics, College of Public Healt","320 W. 10th Ave., B-118 Starling Loving Hall",(614) 293-3713,(614) 293-3937,hzhu@cph.osu.edu,Network models for studying frailty as a dynamic system,1,Hong,,Zhu,"Division of Biostatistics,College of Public Health,The Ohio State University",Ravi,,Varadhan,"Division of Geriatrics & Gerontology,School of Medicine,Johns Hopkins University",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Frailty is a state of health signified by an increased vulnerabilityto adverse health outcomes in the face of stressors, leading to a lossof resilience. The research interest focuses on the dynamicinteractions within and across the complex adaptive system underlyingfrailty. The literature hypothesizes that frail and non-frail people woulddiffer in terms of the dynamics of physiological system in response tostimuli. It is challenging to formalize resilience,  acharacteristic of the dynamics displayed by the system in response tostimuli.  We propose network models for studying frailty as a dynamicsystem based on the stimulus-response experiment.  We demonstrate thatresilience of a complex system can be quantified and modeled indifferent ways. Through simulation studies, we explore therelationship between network topological properties and its dynamics.The properties of three network models are studied and compared interms of different measures of resilience. Our work should provide adeeper understanding of the role of multisystem interactions in theetiology of frailty.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Epidemiologic methods,Computational methods,,,,,,,29-Sep-10,hzhu2@ncsu.edu,,Hongjie Zhu,,North Carolina State University,"Bioinformatics Research Center,North Carolina State University, Campus Box 7566",9199955577,,hzhu2@ncsu.edu,Biological Pathway Selection through Nonlinear Dimension Reduction,1,Hongjie,,Zhu,Bioinformatics Research Center/North Carolina State University,Lexin,,Li,Department of Statistics/North Carolina State University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In the analysis of high-throughput biological data, it is often believed that the biological units such as genes behave interactively by groups, i.e., pathways in our context. It is conceivable that utilization of available pathway knowledge would greatly facilitate both interpretation and estimation in statistical analysis of such high-dimensional biological data. In this article, we propose a two-step procedure for the purpose of identifying pathways that are related to and influence the clinical phenotype. In the first step, a nonlinear dimension reduction method is proposed, which permits flexible within-pathway gene interactions as well as nonlinear pathway effects on the response. In the second step, a regularized model-based pathway ranking and selection procedure is developed that is built upon the summary features extracted from the first step. Simulations suggest that the new method performs favorably compared to the existing solutions. An analysis of a glioblastoma microarray data finds four pathways that have evidence of support from the biological literature.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,TRUE,Variable subset selection/model selection,High dimensional data,,,,,,,21-Sep-10,i.liddy@gmail.com,,Liddy Chen,,UNC Chapel Hill,4145 Piney Gap Dr.,919-810-6047,,i.liddy@gmail.com,Sample Size Determination in Shared Frailty Models for Multivariate Time-to-Event Data,1,Liddy,M,Chen,"1. Department of Biostatistics, UNC, Chapel Hill, NC (PhD student)2. Premier Research Group Limited, NC",Joseph,G,Ibrahim,"Department of Biostatistics, UNC, Chapel Hill, NC",Haitao,,Chu,"1. Department of Biostatistics, UNC, Chapel Hill, NC2. Division of Biostatistics, University of Minnesota, MN",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In many clinical or epidemiology studies, subjects may experience multiple related events or the event of interest more than once (recurrent events) during the course of the study.  The frailty model is increasingly popular for analyzing multivariate time-to-event data.  The most common model for a frailty is the shared frailty model, which is an extension of the proportional hazards regression model.  Although study design consideration is as important as analysis strategies, sample size determination methodology in studies with multivariate time-to-event data is greatly lacking in the literature.  In this paper, we develop a sample size determination method for the shared frailty model to investigate the treatment effect on multivariate event times, including recurrent events.  We first assume a common treatment effect on multiple event times, and the sample size determination is based on testing the common treatment effect.  We then consider sample size determination for testing the treatment effect on one time-to-event while treating the other event times as nuisance, and compare the power from a multivariate frailty model to that of a univariate parametric and semi-parametric survival model.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,TRUE,Power analysis/sample size,Multivariate survival,,,,,,,14-Nov-10,i_chervoneva@mail.jci.tju.edu,,Inna Chervoneva,Dr,Thomas Jefferson University,"1015 Chestnut St., Suite M100",2159554083,,i_chervoneva@mail.jci.tju.edu,Dynamic system modeling of blood glucose and insulin in type I diabetic subjects,1,Inna,,Chervoneva,Thomas Jefferson University,Boris,,Freydin,Thomas Jefferson University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We develop a model of physiological regulation of glycemia in response to meals and insulin infusion. The model combines the model for glucose dynamics adapted from models of response to an intravenous glucose tolerance test, a model for intravenous insulin delivery, and a model for glucose absorption from the mixed meals. The generalized profiling estimation proposed by Ramsay et al [2007] is used to estimate unknown parameters in differential equations for glucose and insulin dynamics. We investigate the choice of the smoothing parameter that controls the balance between data fitting criterion and fidelity to the model differential equations. Real data from type I diabetics as well as simulated data are used to compare alternative models.  Sorensen [1985] model was used to simulate realistic glucose-insulin profiles.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Functional data analysis,Applied data analysis,,,,,,,12-Nov-10,ibond@umich.edu,,Irina Bondarenko,,University of Michigan,"Department of Biostatistics, SPH",(734) 358-5017,,ibond@umich.edu,Combining Multiple Data Sources Using Calibrated Imputation,1,Irina,,Bondarenko,University of Michigan,Trivellore,,Raghunathan,University of Michigan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Measuring the effectiveness of medical care is a cornerstone of health policy. Recently, an effort was undertaken to design a framework to measure the efficacy of medical care via creation and use of national health accounts. This goal of this effort is to link spending with measures of population health.The broad objective of this paper is to combine information from nationally representative and administrative surveys to develop a rich set of indicators for various health conditions. We present a method for linking data from multiple sources containing claims and/or self-report. This approach allows us to create a set of indicators reflecting current and ever status for a number of diseases.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Missing data,Health policy applications,,,,,,,09-Nov-10,ibrahim@bios.unc.edu,,Joseph Ibrahim,,"Department of Biostatistics, UNC","Department of Biostatistics, UNC",919-843-2715,919-966-3804,ibrahim@bios.unc.edu,Bayesian Meta Experimental Design -- Evaluating Cardiovascular Risk in New Antidiabetic Therapies to Treat Type 2 Diabetes,1,Joseph Ibrahim,G,Ibrahim,UNC Biostatistics,Ming-Hui,,Chen,UCONN,Amy,,Xia,Amgen Inc.,Thomas,,Liu,Amgen Inc,,,,,,,,,,,,,,,,,,,,,,,,,"The recent guidance from the FDA for the evaluation of new therapies in the treatment of Type 2 diabetes,calls for a program-wide meta-analysis of cardiovascular outcomes. In this context,we develop a new Bayesian meta-analytic approach using survival models to assess whether the size of a clinical development program is adequate to evaluate a particular safety endpoint.We extend the fitting and sampling priors of Wang and Gelfand (2002) to Bayesian meta-analysis clinical trial design with a focus on controlling the type I error and power.The historical survival data are incorporated via the power priors of Ibrahim and Chen (2000). Various properties of the proposed methodologyare examined and an efficient Markov chain Monte Carlo sampling algorithm is developed to sample from the posterior distributions. In addition,we develop a novel simulation-based algorithm for computing various quantities,such as the power and the type I error, involved in the Bayesian meta-analysis trial design.The proposed methodology is applied to the design of a phase 2/3 development program including a non-inferiority clinical trial for CV risk assessment in T2DM studies.",FALSE,FALSE,,FALSE,TRUE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Bayesian methods,Experimental design,,,,,,,08-Nov-10,ibs104@psu.edu,,Ivan,,The Pennsylvania State University,326 Thomas Building,814-769-3845,,ibs104@psu.edu,Exploratory Spatial Analysis of in vitro RSV Co-infections,1,Ivan,B,Simeonov,"Department of Statistics, Pennsylvania State University",Xiaoyan,,Gong,"Department of Biology, Pennsylvania State University",Oekyung,,Kim,"Department of Biology, Pennsylvania State University",Mary,,Poss,"Department of Biology, Pennsylvania State University;Fogarty International Center, National Institutes of Health",Francesca,,Chiaromonte,"Department of Statistics, Pennsylvania State University",John,,Fricks,"Department of Statistics, Pennsylvania State University",,,,,,,,,,,,,,,,,"The cell response to virus infection is dynamic and is reflected bychanges in cell susceptibility to infection. The response of humanepithelial cells to sequential infections with human respiratorysyncytial virus strains A2 and B were evaluated to determine if aprimary infection with one strain will impact the ability of cells tobe infected with the second as a function of virus strain and timeelapsed between the two exposures. Infected cells were then visualizedwith fluorescent markers, and location of all cells in the tissueculture well were identified using imaging software. Tools fromspatial statistics were employed to investigate the likelihood of acell being infected given its proximity to a cell infected with eitherthe homologous or heterologous virus. Point processes, K-functions,and simulation procedures were used to account for specific featuresof our data when assessing spatial associations. Our results suggestthat intrinsic cell properties increase susceptibility of cells toinfection, with a stronger effect seen with RSV-B then RSV-A.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Spatial/temporal modeling,Infectious disease models,,,,,,,29-Oct-10,idattner@stat.haifa.ac.il,,Itai Dattner,,"Department of Statistics, Faculty of Social Scienc",Mount Carmel,972-504205056,,idattner@stat.haifa.ac.il,Adaptive deconvolution of distribution functions,1,Itai,,Dattner,"Department of Statistics, University of Haifa, Haifa, Israel",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Many practical problems are related to the estimation of distribution functions when data contains measurement errors. For example, consider the estimation of the prevalenceof a disease which is determined by some underlying biomarker, measured with error, having value greater than some known constant.We present a data-driven method for estimating distribution functions in measurement error models, illustrate its superiority with respect to other methods both through theoryand simulations, and apply it to a real example of estimating hypertension prevalence. In addition, we develop an estimator for the case where the error distribution is not known, but an external sample of measurement errors is available.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Measurement error,Nonparametric methods,,,,,,,08-Nov-10,ikuko.funatogawa@vanderbilt.edu,,Ikuko Funatogawa,,"Department of Biostatistics, Vanderbilt University",571 Preston Building,615-480-9723,,ikuko.funatogawa@vanderbilt.edu,Autoregressive Linear Mixed Effects Model for Analysis of Unequally Spaced Longitudinal Data with Dynamic Dose Modification,1,Ikuko,,Funatogawa,"Department of Biostatistics, Vanderbilt University School of Medicine",Takashi,,Funatogawa,"Department of Biostatistics, Vanderbilt University School of Medicine",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In this study, we focus on analysis of longitudinal data from  clinical studies in which drug is administered repeatedly and the doses are adjusted in each patient. Recently, we proposed an autoregressive linear mixed effects model for the analysis of longitudinal data in which the current response is regressed on the previous response, fixed effects, and random effects (Funatogawa et al. 2007 Stat Med). The model represents profiles approaching random equilibriums, and the current response depends on dosing history. By using this model, we can estimate each patients dose-response curve assuming that continuous responses are approaching to individual equilibriums by repeated administration of same doses. In such a trial, intermittent missing and unequally spaced time points are often seen. These are apparently inherent problems of the autoregressive model. Moreover, the number of measurements on a patient is often large, and then the calculation of likelihood is burden because the likelihood is expressed by matrices whose sizes depend on the number. In this study, to overcome these problems, we provide a state space form of the proposed model for calculating the marginal (unconditional) likelihood.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Longitudinal data,Clinical trials,,,,,,,15-Nov-10,imreyp@ccf.org,,Peter B. Imrey,Professor of Medicine,Cleveland Clinic Foundation,Dept. of Quantitative Health Sciences/JJN3,216-444-0923,216-444-8023,imreyp@ccf.org,"The National Research Council Report on Biometric Recognition, the Other Biometrics",1,Peter,B,Imrey,Cleveland Clinic Foundation and Case Western Reserve University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Applications of biometric recognition are increasing in both ordinarylife and national security settings, but remain controversial forlarge-scale population-based government implementations.  In September2010 the National Academy of Sciences published BiometricRecognition: Challenges and Opportunities, an assessment of thestatus and prospects of this Other Biometrics by a National ResearchCouncil committee.  The report stresses the probabilistic nature ofbiometric recognition, the paucity of data on underlying temporalstability and individual distinctiveness of biometric traits, and theneed to design and appraise the performance of biometric recognitionapplications in the context of the operational and cultural systems inwhich the biometric recognition technology is embedded.  Theseemphases have been criticized as overly negative by some industrygroups, and as self-evident by other commentators.  This talk willreview the report's major conclusions and discuss the sources ofvariation in biometric matching decisions, the strengths andlimitations of a diagnostic testing/signal detection theoryperspective for performance evaluations, and issues in designingresearch to assess individual distinctiveness of a biometric trait andits potential to yield highly accurate biometric recognition atnational and international scales.",FALSE,FALSE,,FALSE,TRUE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Other,Defense and national security applications,biometric recognition,,,,,,03-Nov-10,indranil.ghosh@email.ucr.edu,,Indranil Ghosh,Graduate Student,"University Of California,Riverside","1122 West Linden Street,Apt#205",9512754215,,indranil.ghosh@email.ucr.edu,Classical and Bayesian Inference For A Hidden Truncated Bivariate Pareto(type(II)) Distribution,1,Indranil,,Ghosh,"University Of California,Riverside",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The use of the Pareto distribution as a model for varioussocio-economic phenomena dates back to the late nineteenth century.Pareto's distributions and their close relations and generalizations provide a very flexible family of fat-tailed distributions which maybe used to model income distributions as well as a wide variety ofother social and economic distributions. However among the family ofPareto models(type(I)-type(IV)), Pareto(type(II)) modelneeds further investigation simply because of the fact that within ourhierarchy of generalized Pareto distributions, it is thePareto(type(II)) family which is most suited for residual life analysis.We consider both the classical and Bayesian method fo estimating theparameters of a hidden truncated bivariate Pareto(type(II)) model whenone of the covariable is truncated from above. Such type of models areuseful in analyzing specially income distributions in which usually wehave cases of unreported income.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Bayesian methods,Constrained estimation/order restricted inference,,,,,,,13-Nov-10,inyoungk@vt.edu,,Inyoung Kim,Assistant professor,Virginia Tech,410 A Hutcheson Hall,5402315366,,inyoungk@vt.edu,Generalized Semiparameric Single Index Model for High Dimension Variable Selection,1,Inyoung,,Kim,"Department of Statistics, Virginia Polytechnic Institute and State University",Chongrui,,Yu,"Department of Statistics, Virginia Polytechnic Institute and State University",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Generalized single index models are commonly used in many applicationswith many variables because single-index model avoids the curse ofdimensionality. However most of these applications usually have thenumber of samples is relatively larger than the number of variables.Generalized single index models are not developed yet when the numberof variables are larger than the number of samples. In this article,we propose a method for single index model in high dimensional casewhere the number of variables is larger than the number of samples.Our method is developed by using regression splines and double penaltyfunctions. One penalty is for smoothing parameter and the otherpenalty is for variable selection. Our penalty for variable selectionis different from traditional penalty functions which typically areused in variable selection. We study the advantage of our approachusing both simulation study and a high dimensional type II DiabetesMellitus microarray data.",TRUE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Generalized linear models,High dimensional data,,,,,,,15-Nov-10,ivanescua@ecu.edu,,Andrada Ivanescu,,East Carolina University,2435 Health Sciences Building,2527446042,,ivanescua@ecu.edu,Bivariate surface estimation for functional data,1,Andrada,E,Ivanescu,East Carolina University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"This work proposes an estimation method for the mean function of a bivariate stochastic process that is observed at discrete points, and is corrupted by additive noise. We can see this setting in applications where the samples of a functional dataset are recorded as functions of two separate variables. The estimation of the bivariate mean function is performed using a combination of orthonormal basis functions for each variable, and the selection of relevant features is performed via regularization and using data-adaptive threshold levels. The method is implemented in simulation studies and real data applications.",FALSE,FALSE,,FALSE,FALSE,TRUE,SC3,presentation_or_poster,,,,FALSE,FALSE,FALSE,TRUE,Functional data analysis,Variable subset selection/model selection,,,,,,,15-Nov-10,j.blume@vanderbilt.edu,,Jeffrey Blume,Associate Professor of Biostatistics,Vanderbilt University Medical Center,1161 21st Ave South,615-343-9267,,j.blume@vanderbilt.edu,The Likelihood paradigm in action: an application to fMRI data and evaluation of performance,1,Jeffrey,,Blume,Vanderbilt University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Likelihood ratios are reliable tools for measuring the strength of statistical evidence in the presence of multiple comparisons despite that fact that neither the Likelihood ratio, nor the probability of observing misleading evidence, is ever adjusted for the multiple comparisons. Moreover, Likelihood ratios are less likely to be misleading than, say, a hypothesis test even when the Type I error is controlled over all endpoints. One interesting result is that the average error rate is minimized when using likelihood ratios to measure of the strength of evidence, regardless of the number of comparisons or of any adjustments to the Type I error. We will discuss theoretical arguments and simulations to support this claim. In addition we demonstrate the applicability of likelihood methods in fMRI data where both the explicit formulation of an alternative hypothesis and the numerous multiple comparisons are challenges the likelihood approach deals with very well.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Imaging,Multiple testing,,,,,,,08-Nov-10,jacob-oleson@uiowa.edu,,Jacob Oleson,,Department of Biostatistics,College of Public Health,319-384-5017,,jacob-oleson@uiowa.edu,Predicting Infectious Disease Outbreak Carried by Migratory Waterfowl,1,Jacob,J,Oleson,University of Iowa,Christopher,K,Wikle,University of Missouri,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The spread of an emerging infectious disease is a major public healththreat. Given the uncertainties associated with vector-born diseases,in terms of vector dynamics and disease transmission, it is criticalto develop statistical models to address how and when such aninfectious disease could spread throughout a region such as the UnitedStates.   Modeling spatio-temporal data of this type is inherentlydifficult given the uncertainty associated with observations,complexity of the dynamics, high dimensionality of the underlyingprocess, and the presence of excessive zeros.  The spatio-temporaldynamics of the waterfowl migration are developed by way of a noveltwo-tiered functional temporal and spatial dimension reductionprocedure that captures spatial and seasonal trends, as well asregional dynamics.  Furthermore, the model relates the migration to apopulation of poultry farms that are known to be susceptible to suchdiseases, and is one of the possible avenues towards transmission todomestic poultry and humans.  The result is a predictive distributionof those counties containing poultry farms that are at the greatestrisk of having the infectious disease infiltrate their flocks assumingthat the migratory population was infected.  The model naturally fitsinto the hierarchical Bayesian framework.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Infectious disease models,Environmental and ecological applications,,,,,,,15-Oct-10,jadawson@wisc.edu,,John Alexander Dawson,Graduate Student,"Department of Statistics, University of Wisconsin-",1300 University Avenue,(608) 265-4382,(608) 265-7916,jadawson@wisc.edu,An Empirical Bayesian Model for Identifying Differentially Correlated Genes,1,John,A,Dawson,"Department of StatisticsUniversity of Wisconsin-Madison",Christina,,Kendziorski,"Departments of Statistics and of Biostatistics and Medical InformaticsUniversity of Wisconsin-Madison",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"A common goal of microarray and related high-throughput genomicexperiments is to identify genes that vary across biologicalcondition. Most often this is accomplished by identifying genes withchanges in mean expression level across conditions, so calleddifferentially expressed (DE) genes, and a number of effective methodsfor identifying DE genes have been developed. Although useful, theseapproaches do not accommodate other types of differential regulation.An important example concerns differential correlation (DC).Investigations of this class of genes are hampered by the largecardinality of the space to be interrogated as well as by influentialoutliers. As a result, existing DC approaches are often underpowered,exceedingly prone to false discoveries, and/or computationallyintractable for even a moderately large number of pairs. To addressthis, an empirical Bayesian approach for identifying DC gene pairs isdeveloped. The approach provides a false discovery rate (FDR)controlled list of significant DC gene pairs without sacrificing poweror computational tractability. The complexity in computation is easedby a modification to the EM algorithm. Simulations suggest that theproposed approach outperforms existing methods in far lesscomputational time; and case study results suggest that the approachwill likely prove to be a useful complement to current DE methods inhigh-throughput genomic studies.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Statistical genetics,High dimensional data,,,,,,,15-Nov-10,jak@biostat.ufl.edu,,John A. Kairalla,Assistant Professor,University of Florida,PO Box 103653,352-265-0111 x85845,,jak@biostat.ufl.edu,Internal Pilot with Interim Analysis for Multiple Degree of Freedom Hypothesis Tests,1,John,A,Kairalla,University of Florida,Keith,E,Muller,University of Florida,Christopher,S,Coffey,University of Iowa,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"An internal pilot with interim analysis (IPIA) design combines interimpower analysis with interim data analysis. Previous research hasprovided IPIA results and methods for single degree of freedomhypothesis within the Gaussian general linear model. We extend IPIAmethods for use in more complex univariate designs within the Gaussianlinear model framework such as multi-group comparisons (e.g., ANOVA)and other multiple degree of freedom tests. We introduce exact theorythat can be used in small sample situations to plan studies withmultiple degree of freedom hypotheses.  The new results allowcalculation of power, type I error rate, and expected sample size forany univariate linear model with fixed predictors and Gaussian errors. Examples will be presented.",FALSE,FALSE,,FALSE,FALSE,TRUE,"Not sure if current Local Arrangements Chair (Me) needs to go to RAB or planning meetings, so not sure if there is conflict there...",contributedposter,,,,FALSE,FALSE,FALSE,TRUE,Adaptive design/adaptive randomization,Experimental design,,,,,,,20-Oct-10,jan.luts@esat.kuleuven.be,,Jan Luts,PhD,Katholieke Universiteit Leuven,"Kasteelpark Arenberg 10, bus 2446",+32 16 321065,+32 16 321970,jan.luts@esat.kuleuven.be,A mixed effects least squares support vector machine model for classification of longitudinal data,1,Jan,,Luts,"Department of Electrical Engineering (ESAT), Research Division SCD, Katholieke Universiteit Leuven, Belgium",Geert,,Molenberghs,"I-BioStat, Universiteit Hasselt, Belgium;I-BioStat, Katholieke Universiteit Leuven, Belgium",Geert,,Verbeke,"I-BioStat, Katholieke Universiteit Leuven, Belgium",Sabine,,Van Huffel,"Department of Electrical Engineering (ESAT), Research Division SCD, Katholieke Universiteit Leuven, Belgium",Johan,A.K.,Suykens,"Department of Electrical Engineering (ESAT), Research Division SCD, Katholieke Universiteit Leuven, Belgium",,,,,,,,,,,,,,,,,,,,,"The classical approach to analyze longitudinal data is by means ofmixed effects models, thereby taking into account the relationshipbetween observations from the same subject. Estimation of the fixedand random effects is commonly based on the theory of best linearunbiased prediction (Verbeke G., Molenberghs G., Linear mixed modelsfor longitudinal data, Springer, 2000). Recently, connections betweenthis traditional approach and kernel machines have been described(Pearce N.D., Wand M., EJS 3 (2009) 797-823). Kernel machines (e.g.support vector machines) are typically used in the machine learningcommunity to deal with classification problems involving balanced(i.e. finite dimensional) non-longitudinal data. The present studyextends the least squares support vector machine (LS-SVM) classifier(Suykens J.A.K., Vandewalle J., Neural Process Lett 9 (3) (1999)293-300) to a mixed effects LS-SVM model for classification oflongitudinal profiles. This kernel method combines the regularizationaspects of support vector machines with mixed effects models.Furthermore, this semiparametric approach is able to deal withnonlinearity in the data and it addresses binary, as well asmulti-class problems. The technique is applied to several simulatedand real-life data sets, including a study to evaluate the robustnesswith respect to the choice of the regularization parameters.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Longitudinal data,Machine learning,,,,,,,14-Nov-10,janet@statcollab.com,,Janet Wittes,,Statistics Collaborative,"1625 Massachusetts Ave., NW",202-247-9700,202-247-9701,janet@statcollab.com,After the Party's Over: Post-trial Responsibilities of the DMC,1,Janet,T,Wittes,Statistics Collaborative,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The charter of a DMC describes the responsibilities of the DMC while the trial it is monitoring is ongoing. Depending on the trial, the DMC may monitor only safety; it may monitor both safety and efficacy; it may monitor safety but look at efficacy as efficacy relates to the judgment of whether the likely risks outweigh the likely benefit of the experimental intervention. Some DMCs are responsible for tracking the operations of the trial, for example, its accrual, the quality of its data, and the fidelity of adherence to the protocol. Many DMCs view that their responsibility is primarily to the participants in the trial and only secondarily to people who will or will not use the information from the trial after the results become public. But what should a DMC do if the paper describing the primary results overstate the benefit of the intervention or understate its harms? Such publications are relevant to future patients, not those in the trial. In this talk, I cautiously suggest that DMCs consider including in their charters a statement that the DMC remain intact until the final version of the paper describing the primary outcome is in galley proof.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Clinical trials,"Biologics, pharmaceuticals, medical devices",,,,,,,11-Nov-10,jaredcf@umich.edu,,Jared,,University of Michigan,1857 Shirley Lane,7346601167,,jaredcf@umich.edu,Variable selection in monotone single-index models via the lasso,1,Jared,C,Foster,University of Michigan,Jeremy,M.G.,Taylor,University of Michigan,Bin,,Nan,University of Michigan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We consider the problem of variable selection for the single-indexmodel when the link function is assumed to be monotone.  Such anassumption is reasonable in many settings, and allows for morestraightforward inference.  We present a lasso-penalized least squaresapproach to estimating regression parameters in such models forcontinuous Y.  To obtain initial regression parameter estimates, alinear model is fit, and variable selection is performed via thelasso, with the first estimated parameter (corresponding to the firstcolumn in the design matrix) being unpenalized.  These estimates arethen rescaled by the first, unpenalized estimate, so that the first ofthe rescaled initial estimates is equal to 1.  For purposes ofidentifiability, the first element of the final regression parameterestimates is forced to be 1.  Monotone link function estimates areachieved using the pooled adjacent violators algorithm (PAVA),followed by kernel regression.  In the estimation process, a linearapproximation to the link function is used, therefore reducing thesituation to that of linear regression, and allowing for the use ofstandard lasso algorithms, such as coordinate descent.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Variable subset selection/model selection,Machine learning,,,,,,,11-Nov-10,jason@berryconsultants.com,,Jason Connor,Statistical Scientist,Berry Consultants,9757 Cypress Pine St,317-877-1084,,jason@berryconsultants.com,:  Implementation and Lessons Learned from Bayesian Clinical Trials: from Theory to Practice,1,Jason,T,Connor,Berry Consultants,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The planning and execution of trials that are adaptive by design require extensive collaboration during the planning stages among statisticians, clinicians, the sponsor's business leaders and drug development team, regulators, DMCs and IRBs.  Adaptive-by-design means making planned, well-defined changes in key clinical trial design parameters during trial execution, based on data from that trial and predefined and agreed upon prior distributions, to achieve goals of validity, scientific efficiency, and safety.  This requires an iterative design process but the result is typically a more flexible trial that, in the execution stage, can prospectively adapt to changes in patient populations or properties of the compound or device under investigation, producing smaller or more appropriate sample size requirements or more efficient randomization.  This presentation focuses on our experiences serving in multiple roles (from designers to DMC members) in collaborations on more than 50 Bayesian adaptive designs and their implementation.  It includes eliciting the goals of the trial of the sponsor and balancing them with evolving regulatory requirements.  We also will describe using simulation in quantifying trial operating characteristics over a wide range of possible true scenarios and measuring how changing design parameters changes design properties.  Finally, we discuss implementing these designs in collaboration with IRBs, DMCs, and clinicians ingrained in the culture of standard, (i.e. fixed and group sequential) clinical trial designs.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Adaptive design/adaptive randomization,Clinical trials,,,,,,,25-Oct-10,jay.herson@earthlink.net,,Jay Herson,,Johns Hopkins University,"4450 South Park Ave., #1503",301 675-9275,,jay.herson@earthlink.net,Independence of Data Monitoring Committees and Sponsors,1,Jay,,Herson,Johns Hopkins University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"It is widely believed that DMCs should be independent of clinical trial sponsors. Several examples will be given where the question of independence of  DMCs and sponsor come into question. Suggestions will be given as to  how to deal with these issues so that even the appearance of  non-independence can be avoided.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Clinical trials,Consulting,,,,,,,15-Nov-10,jchar.jackson@gmail.com,,John Jackson,,NICHD,6607 east wakefield dr,703 6600837,703 6600837,jchar.jackson@gmail.com,Latent Variable Models for Longitudinal Count and Binary Data,1,John,C,Jackson,NICHD,Paul,S,Albert,NICHD,Zhiwei,,Zhang,NICHD,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Latent Variable Models for Longitudinal Count and Binary DataUnderstanding the association between risky driving and crash events helps yield insight to teenage driving behavior.  Further, prediction of crash events from previously observed kinematic behavior is important from a public health perspective.  The Naturalistic Teenage Driving Study (NTDS) is the first U.S. study to document continuous driving performance and crash/near crash experience of newly-licensed teenagers during their first 18 months of licensure.  Here we use counts of kinematic events (e.g. lateral positive accelerations over 0.5g) to describe risky driving behavior. We present binary and ordinal latent variable models for investigating these associations. Models are also developed where random effects are included to address heterogeneity among drivers propensity for risky driving; we discuss the estimation of these models using the EM algorithm for the models not including random effects, and the Monte Carlo EM algorithm for the random effects models.  Time permitting we will discuss joint models where the crash outcomes are linked to the kinematic measures with a hidden Markov model for the latent states.   Key Words: Latent Model, Driving Study, MCEM",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Latent variables,Longitudinal data,,,,,,,14-Nov-10,jdkalbfl@umich.edu,,John D Kalbfleisch,Professor,University of Michigan,Department of Biostatistics,7344742275,,jdkalbfl@umich.edu,Micro-Simulation Model for a Kidney Paired Donation Program,1,John,D,Kalbfleisch,University of Michigan,Peter,X,Song,University of Michigan,John,Y,Li,University of Michigan,Yan,,Zhou,University of Michigan,,,,,,,,,,,,,,,,,,,,,,,,,"This paper discusses development of a micro-simulation model for kidney paired donation (KPD) program.  Such a model is very important in planning and organizing KPD programs since, similar to the situation with early detection programs in cancer and other diseases, there is little opportunity to carry out experiments. The micro-simulation model envisaged will enable us to utilize excellent statistical information available from various data sources about the mechanisms that affect the success or failure of kidney transplants from living unrelated donors. Statistical approaches and strategies developed through simulation will be presented  It is expected that such a systematic approach to KPD allocation, if employed on a national basis, will generate many additional years of recipient and graft survival through the dual mechanisms of increased and better KPD matching.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Other,Health services research,simulation models,,,,,,12-Nov-10,jefmorris@mdanderson.org,,Jeffrey S. Morris,Professor,University of Texas MD Anderson Cancer Center,PO Box 301402,7132029822,,jefmorris@mdanderson.org,"Adaptive, Robust Functional and Image Regression in Functional Mixed Models",3,Hongxiao,,Zhu,SAMSI,Philipi,J,Brown,"The University of Kent, Canterbury",Jeffrey,S,Morris,"The University of Texas, MD Anderson Cancer Center",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"New methods have been developed in recent years for the analysis of functional and image data, which are increasingly encountered in many settings.  Many methods involve extensions of linear regression such as functional regression and functional mixed models.  Existing methods, however, tend to be sensitive to outliers, as no analogs to robust linear regression have been developed for the functional setting.  Here, we discuss a unified Bayesian method for robust functional regression, whereby a functional response of unspecified form is regressed on a set of linear predictors.  The method is developed within the general functional mixed model framework, which can simultaneously model multiple factors and accommodate between-function correlation induced by the experimental design.  We demonstrate outstanding robustness properties, doing an excellent job estimating functional regression coefficients even in the presence of Cauchy errors and random effects, and yet not trading off much efficiency when the true likelihood is Gaussian.  We also observed remarkable adaptive smoothing properties in our estimates of the fixed and random effect functions, which arise from an interaction of the robust likelihood and adaptive sparsity priors.",FALSE,FALSE,,FALSE,FALSE,TRUE,AOAS editorial board meeting,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Functional data analysis,High dimensional data,,,,,,,15-Nov-10,jenniema@virginia.edu,,Jennie Ma,,University of Virginia,PO Box 800717,434-243-5778,,jenniema@virginia.edu,Analysis of heterogeneous outcomes in a randomized clinical trial for the treatment of methamphetamine addiction with the latent variable approach,1,Jennie,Z,Ma,University of Virginia,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Multiple response measures are often recorded in order to fully capture the underlying treatment effect in randomized clinical trials. Due to complex nature of diseases and individual variation, patients may response to the treatment differently, and separate analysis of treatment effect on each type of these outcome measures may likely produce mixed results. In this study, we demonstrated the advantage of the latent variable approach in assessing the treatment effect of topiramate on methamphetamine addiction with heterogeneous responses in a randomized clinical trial. Our results showed that such method does not only evaluate treatment effect with respect to multivariate outcomes of methamphetamine dependence simultaneously but also accounts for potential heterogeneity.",FALSE,FALSE,,FALSE,TRUE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,TRUE,Latent variables,Applied data analysis,,,,,,,12-Nov-10,jennifer.nezzer@ppdi.com,,Jennifer Nezzer,"Team Leader, Biostatistics",PPD Inc,7551 Metro Center Drive,512-747-5363,,jennifer.nezzer@ppdi.com,Analysis and Sample Size Determination for Biosimilar Compounds,2,J,W,Adair,PPD Inc,Jennifer,,Nezzer,PPD Inc,Austin,,Combest,,Dirk,,Reitsma,,,,,,,,,,,,,,,,,,,,,,,,,,"There is currently no formal FDA or regulatory guidance fordetermining bioequivalence margins in terms of efficacy and safety forbiosimilar compounds. Two methods defining bioequivalence margins wereconsidered from both frequentist and Bayesian perspectives. First, thebioequivalence margin was defined as the lower bound of the 95%confidence interval of the difference in response rates between thereference biological product (RBP) and placebo/control from a previousphase III trial. This method guards against washing out the treatmenteffect with control (standard of care or baseline therapy). Secondly,the bioequivalence margin was defined as a fixed bioequivalence limitof 80% to 125% around the ratio of response rates of the biosimilarand the RBP. This is currently the standard for assessingpharmacokinetic bioequivalence in generic products. Both methods havedistinct drawbacks in the frequentist setting including large andinconsistent sample size requirements. We address these within theBayesian framework and investigate viable options for powering andanalyzing biosimilar trials. A Bayesian framework to a biosimilardevelopment strategy can help to both optimize clinical trial samplesize and leverage prior information pertaining to the RBP.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Bayesian methods,Power analysis/sample size,,,,,,,02-Nov-10,jeongjae@iupui.edu,,Jaesik Jeong,,IUPUI,"410 West 10th Street, Suite 3000",3172741510,,jeongjae@iupui.edu,An Empirical Bayes Model for Metabolite Identifications Using Mass Spectrometry,1,Jaesik,,Jeong,IUPUI,Xiang,,Zhang,University of Louisville,Changyu,,Shen,IUPUI,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Mass spectrometry (MS) based metabolite profiling has been increasingly popular for scientific and biomedical studies, primarily due to recent technology development such as two dimensional gas chromatography (GCxGC). Nevertheless, the identifications of up to thousands of metabolites based on the large amount of experimental spectra are still subject to errors. Therefore, statistical/computational approaches to improve the accuracy of the identifications and validity of false positive control/estimate are in great need. We propose a hierarchical statistical model in the empirical Bayes framework to tackle this problem. A unique feature of our approach is the construction of two score measures for each metabolite in the library that characterize the propensity of identifying the metabolite when it is present or absent in the sample, respectively. We demonstrate our method through application to a real data set generated from GCxGC-MS.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Metabolomics,Hierarchical models,,,,,,,07-Nov-10,jeongyoun@gmail.com,,Jeong Youn Lim,Student,University of Pittsburgh,4628 Bayard St #317,412 335 8834,,jeongyoun@gmail.com,Regression,1,Jeong Youn,,Lim,University of Pittsburgh,Jong-Hyeon,,Jeong,University of Pittsburgh,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Residual life analysis provides useful information when the effect ofprognostic factors on the distribution of remaining lifetimes isevaluated at several years after the initial diagnosis/therapy. Forinstance, in long-term breast cancer clinical trial where thesecondary therapy now being considered for patients who remainrecurrence free after the initial treatment, the residual lifeanalysis would provide a straightforward prediction of a patient'slifetime that could be prolonged by the new therapy. However, theresidual life regression has not been studied in the completing riskssetting commonly encountered in medical data. In this study we proposecompeting risks quantile residual life regression model based on theconditional cause-specific quantile residual life defined from thecause-specific residual cumulative incidence function. This modelprovides meaningful interpretations of covariate effects on anyquantile residual life at a specific time point. Simulation studiesare performed to assess the regression parameter estimator andassociated test statistics. The proposed method is illustrated with areal dataset from a clinical trial on breast cancer.",FALSE,FALSE,,FALSE,TRUE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Other,Survival analysis,Residual lifetime,,,,,,15-Nov-10,jessica999@hotmail.com,,Jessica,,The university of chicago,300 w main st,7738546952,,jessica999@hotmail.com,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,FALSE,FALSE,,FALSE,FALSE,FALSE,,,,,,FALSE,FALSE,FALSE,FALSE,,,,,,,,,13-Oct-10,jfeder@jhsph.edu,,Jennifer Bobb,,Johns Hopkins Bloomberg School of Public Health,Dept. of Biostatistics,412-600-6843,,jfeder@jhsph.edu,A Bayesian Model Averaging Approach for Estimating the Relative  Risk of Mortality Associated with Heat Waves in 105 U.S. Cities,1,Jennifer,F,Bobb,Johns Hopkins Bloomberg School of Public Health,Francesca,,Dominici,Harvard School of Public Health,Roger,D,Peng,Johns Hopkins Bloomberg School of Public Health,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Estimating the risks heat waves pose to human health is a critical part of assessing the future impact of climate change. In this paper we propose a flexible class of time series models to estimate the relative risk of mortality associated with heat waves and conduct Bayesian model averaging (BMA) to account for the multiplicity of potential models. Applying these methods to data from 105 U.S. cities for the period 1987-2005, we identify those cities having a high posterior probability of increased mortality risk during heat waves, examine the heterogeneity of the posterior distributions of mortality risk across cities, assess sensitivity of the results to the selection of prior distributions, and compare our BMA results to a model selection approach. Our results show that no single model best characterizes risk across the majority of cities, and that for some cities heat wave risk estimation is sensitive to model choice. While model averaging leads to posterior distributions with increased variance as compared to statistical inference conditional on a particular model, we find that heat wave mortality risk is robust to accounting for model uncertainty over a broad class of models.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Environmental and ecological applications,Applied data analysis,,,,,,,09-Nov-10,jgao@emory.edu,,Jingjing Gao,,Emory University,1784 N Decatur Rd,4047274842,,jgao@emory.edu,A Statistical Validation and Evaluation Framework For Accuracy of Automated Segmentation and Classification Algorithms in Pathology Image Analysis,1,Jingjing,,Gao,Emory University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"A major challenge in digital pathology is the high amount ofinter-observer variability amongst pathologists leading to greatdiscrepancy in human diagnosis, which results from the fact thatpathology has largely been a qualitative discipline. Motivated byimproving the accuracy and efficiency of pathology diagnosis,quantitative study of histology tissue samples with the help ofcomputer image analysis techniques has attracted intensive researchinterests in recent years. Consequently, numerous segmentation andclassification computer algorithms aiming at circulating nuclei andproviding grading have been developed. Nevertheless, the validation ofthe accuracy and precision of an algorithm are lack of statisticallytheoretical support. Researchers usually overlay the results on theraw images and make visual judgment.  We are motivated to design ageneralizable testing and evaluation framework for human-guidedvalidation workflow which is statistically defensible and reproducibleand will result in improvements on pathology diagnosis. We propose astatistical design pattern that requires pathology data and isrepresentative of use cases from biomedical and clinical research domains.",FALSE,FALSE,,FALSE,FALSE,FALSE,,contributedposter,,,,FALSE,FALSE,FALSE,FALSE,Imaging,Spatial/temporal modeling,,,,,,,04-Nov-10,jgold@uoguelph.ca,,Jourdan Gold,,University of Guelph,876 Edinburgh rd. South,519-400-8545,,jgold@uoguelph.ca,Effects of Timeline Uncertainty upon Infectious Disease Modeling,1,Jourdan,C,Gold,University of Guelph,Rob,,Deardon,University of Guelph,Zeny,,Feng,University of Guelph,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Infectious disease data is very often only partially observed; the exact time of infection for an individual may be missing, or it may be measured only approximately due to the effects of measurement error. Because of the complexity of the underlying disease system, one often makes simplifying assumptions in the modeling process. These assumptions, while computationally convenient, could lead to a poorly fitted model. We can account for data uncertainty but doing so may cause computational problems.A simulation study was performed in order to ascertain the effects of ignoring timeline uncertainty. We will detail results obtained, with respect to the trade-off between model inferential quality and computational-time, by using a particular family of discrete-time heterogeneous infectious disease model known as an individual-level model (ILM). Modeling approaches will vary from those under 'fixed data' assumptions to those under a 'full dataaugmentation approach'. Methods that may help to overcome the inferential (model quality) and / or computational issues involved in the use of such models will also be discussed.",FALSE,FALSE,,FALSE,TRUE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Infectious disease models,Epidemiologic methods,,,,,,,07-Oct-10,jgoldsmi@jhsph.edu,,Jeff Goldsmith,,"Johns Hopkins Bloomberg SPH, Department of Biostat",615 North Wolfe St,410 - 502 - 3365,,jgoldsmi@jhsph.edu,Longitudinal Penalized Functional Regression,1,Jeff,,Goldsmith,"Department of BiostatisticsJohns Hopkins Bloomberg SPH",Ciprian,,Crainiceanu,"Department of BiostatisticsJohns Hopkins Bloomberg SPH",Brian,,Caffo,"Department of BiostatisticsJohns Hopkins Bloomberg SPH",Daniel,,Reich,"Neuroimmunology BranchNational Institute of Neurological Disorders and Stroke",,,,,,,,,,,,,,,,,,,,,,,,,"We propose a new regression model and inferential tools for the case when both the outcome and the functional exposures are observed at multiple visits.  This data structure is new but increasingly present in applications where functions or images are recorded at multiple times. This raises new inferential challenges that cannot be addressed with current methods and software. Our proposed model generalizes the Generalized Linear Mixed Effects Model (GLMM) by adding functional predictors.  Smoothness of the functional coefficients is ensured using roughness penalties estimated by Restricted Maximum Likelihood (REML) in a corresponding mixed effects model. This method is computationally feasible and is applicable when the functional predictors are measured densely, sparsely or with error;  code implementing the proposed procedure is freely available.  Methods are applied to a longitudinal diffusion tensor imaging (DTI) study relating changes in the microstructure of intracranial white matter tracts to cognitive disability in multiple sclerosis patients,  but we note that the discussed data structure is increasingly common and our methods apply generally.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,TRUE,Functional data analysis,Longitudinal data,,,,,,,14-Nov-10,jgy2@pitt.edu,,Jonathan,,Yabes,4037 Ludwick Street,630-915-3394,,jgy2@pitt.edu,Competing Risks Analysis with Uncertain Causes,1,Jonathan,G.,Yabes,"Department of Biostatistics, University of Pittsburgh",Chung-Chou,H.,Chang,"Department of Medicine, University of Pittsburgh",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The cumulative incidence function (CIF) or subdistribution has been commonly reported in biomedical studies with competing risks data. Interest is typically focused on a primary event in relation to some covariates while accounting for the presence of competing events. A proportional subdistribution modeling approach (Fine and Gray, 1999) offers a convenient framework for this analysis. Just as in any standard competing risks analysis, it requires that the true cause of failure be known with certainty. However in some situations the true cause may be masked or cannot be determined exactly. For instance, in evaluating the risk of developing coronary heart disease (CHD) or of a CHD-related death, death from a cause unrelated to CHD is a competing event. For some individuals who died, accurate information about whether the death was CHD-related or not may be unavailable unless a second stage diagnosis is performed. In this paper, we propose the use of a weighted approach based on the risk factors associated with the event to adjust the estimates.  In a simulation study we demonstrate how improper handling of these cases can lead to misleading results and study the properties of the proposed method.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Survival analysis,Applied data analysis,,,,,,,15-Nov-10,jhe@kumc.edu,,Jianghua He,Dr.,University of Kansas Medical Center,"Department of Biostatistics,KUMC",913-588-2985,,jhe@kumc.edu,Time-Varying Coefficient Survival Model: An Application in Examing the Dynamic Associaiton of BMI and Mortality,1,Jianghua,,He,University of Kansas Medical Center,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The association of BMI and mortality in the Framingham Heart Study has been reported to be dynamic so that different or even opposite results could be obtained under different settings when traditional analysis methods such as logistic models or Cox models are used. As the proportional hazards assumptions are violated, time-dependent covariates Cox models have been used to model the dynamic association of BMI and mortality in previous studies.  However, this type of models is restricted as the functional forms of the time-varying coefficients have to be pre-specified. In this study, nonparametric time-varying coefficient survival models are used to show how the shape of the association of BMI and mortality evolves with the follow-up time.  The modeling results are compared with those obtained using other approaches. The inverse-causality issue widely discussed in the epidemiological research is also examined in this study.  Dropping deaths within the early years of follow-up has been a commonly used strategy in reducing the biases due to inverse-causality in traditional research. Based on the results of this study, dropping early deaths seems inadequate in alleviate the impact of inverse-causality.",FALSE,FALSE,,FALSE,TRUE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Survival analysis,Applied data analysis,,,,,,,15-Nov-10,jhogan@stat.brown.edu,,Joseph W Hogan,Professor of Biostatistics,Brown University,Box G-S121-7,401 863 9243,,jhogan@stat.brown.edu,Statistical Methods for Evaluating the Effect of Food Assistance as a Supplement to HIV Treatment in Kenya,1,Joseph,W,Hogan,Brown University,Catherine,N,Gichunge,"Moi University and AMPATH, Eldoret Kenya",Edwin,,Sang,"Moi University and AMPATH, Eldoret Kenya",F,,Komen,"Moi University and AMPATH, Eldoret Kenya",Abraham,,Siika,"Moi University and AMPATH, Eldoret Kenya",,,,,,,,,,,,,,,,,,,,,"Individuals being treated for HIV in Kenya and other countries in thedeveloping world frequently require food assistance.  The USAID-AMPATHProgram, headquartered in Eldoret, Kenya, provides care to over100,000 individuals with HIV, and provides food assistance to over20,000.  Despite the critical need, there is a shortage of evidencequantifying the effect of food assistance for those in treatment, andindeed there are questions about its efficacy.AMPATH is well positioned to contribute to the evidence base becauseof the sheer number of individuals in treatment and the existence of ahigh-quality electronic medical records system; however, data areobservational and appropriate statistical methods are required.  Weused matching to create a set of controls for each individualreceiving food assistance.  We then used conditional inference methodsto evaluate mortality, clinic adherence, longitudinal weight change,and longitudinal CD4 trajectories.  Analysis of each outcome presentsspecific challenges that must be addressed to obtain valid inferenceabout program effectiveness.  We provide details for analysis of eachoutcome.  Our analysis demonstrates a substantial positive effect offood aid; more broadly, we demonstrate the use of advanced statisticalmethods for program evaluations that will inform funders of HIVtreatment programs in the developing world.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Epidemiologic methods,Causal inference,,,,,,,14-Nov-10,jiangtao.luo@unmc.edu,,Jiangtao Luo,Assistant Professor,"Department of biostatistics, College of Public Hea",University of Nebraska Medical Cneter,(402)559-1976,(402)559-7259,jiangtao.luo@unmc.edu,Estimation and Algorithm for Joint Linkage and linkage Disequilibrium Analysis in family Data,1,Jiangtao,,Luo,"Department of Biostatistics, College of Public Health,University of Nebraska Medical Center, Omaha, NE 68198-4375",Zhong,,Wang,"Penn State Medical Center, Cancer Institute 500 University Drive,Hershey, PA  17033",Rongling,,Wu,"Penn State Medical Center, Cancer Institute 500 University Drive,Hershey, PA  17033",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The joint linkage and linkage disequilibrium for family data are studied in this paper. The algorithm for the estimates of the parameters is given here. We also show that convergence of the algorithm has some nice properties.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Statistical genetics,Genomics,,,,,,,15-Nov-10,jian-huang@uiowa.edu,,Jian Huang,Professor,University of Iowa,Department of Statistics and Actuarial Science,319-335-0823,,jian-huang@uiowa.edu,The Sparse Laplacian Shrinkage Estimator for High-Dimensional Regression,1,Jian,,Huang,"Department of Statistics and Actuarial Science,241 SH,University of Iowa,  Iowa City, Iowa 52242",Shuangge,,Ma,"Division of Biostatistics,School of Public Health,Yale University ,New Haven, CT 06520",Hongzhe,,Li,"Department of Biostatistics and Epidemiology,University of Pennsylvania School of Medicine,Philadelphia, PA 19104",Cun-Hui,,Zhang,"Department of Statistics and Biostatistics,Rutgers University,Piscataway, NJ 08854",,,,,,,,,,,,,,,,,,,,,,,,,"We propose a new penalized method for variable selection andestimation that explicitly incorporates the correlation patterns amongpredictors. This method is based on a combination of the minimaxconcave penalty and Laplacian quadratic associated with a graph as thepenalty function. We call it the sparse Laplacian shrinkage (SLS)method. The SLS uses the minimax concave penalty for encouragingsparsity and Laplacian quadratic penalty for promoting smoothnessamong coefficients associated with the correlated predictors. The SLShas a generalized grouping property with respect to the graphrepresented by the Laplacian quadratic. In a special case, it has asimilar grouping property as the elastic net method. We show that theSLS possesses an oracle property in the sense that it is selectionconsistent and equal to the oracle Laplacian shrinkage estimator withhigh probability. This result holds in sparse, high-dimensionalsettings with p  larger than  n  under reasonable conditions. Wederive a coordinate descent algorithm for computing the SLS estimates.Simulation studies are conducted to evaluate the performance of theSLS method and a data example is used to illustrate its application.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,High dimensional data,Graphical models,,,,,,,11-Nov-10,jiankang@umich.edu,,Jian Kang,,Department of Biostatistics University of Michigan,1420 Washington Heights,(734)936-4035,734-678-1267,jiankang@umich.edu,A Bayesian Spatial Point Process Classification Model with Application to Functional Neuroimaging Inverse Inference,1,Jian,,Kang,"Department of Biostatistics, University of Michigan",Timothy,D,Johnson,"Department of Biostatistics, University of Michigan",Thomas,E,Nichols,"Department of Statistics, University of Warwick",Lisa,,Feldman Barrett,"Department of Psychology, Northeastern University",Tor,D,Wager,"Department of Psychology and Neuroscience, University of Colorado",,,,,,,,,,,,,,,,,,,,,"Decoding of behavioral information or cognitive states from human brain activity is a primary goal in functional neuroimaging research. Many studies are designed to determine the distributed patterns of brain activation that result from different known brain functions.  In the meta analysis of these studies,  it is of great interest to perform inverse inference on cognitive states from peak activation locations that report from a new study. Motivated by this problem, we develop a Bayesian classification model for multiple types of point patterns via spatial point processes. With appropriate modeling of the intensity function for each type of point pattern, we construct a classifier based on the posterior probability of the type given a point pattern.  We show this posterior probability, for a new study, can be efficiently estimated via importance sampling. We also propose a statistical map as an exploratory tool to discover the impact of brain regions on distinguishing cognitive states. Our method is illustrated by the analysis of 437 emotion studies. Our model shows a higher correct classification rate compared with a naive Bayes classifier,  and the proposed statistical map provides valuable insights into the relationships between emotions and brain activity.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Imaging,Bayesian methods,,,,,,,10-Nov-10,jianrong.wu@stjude.org,,Jianrong Wu,Associate Member,St Jude Children's Research Hospital,868 winterfalls TRL,901-595-2850,,jianrong.wu@stjude.org,Censored tumor growth delay data analysis,1,Jianrong,,Wu,St Jude Children's Research Hospital,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In tumor xenograft experiments, tumor response to the anti-cancer agents is often assessed by tumor growth delay, the difference in median tumor quadrupling times between treatment and control. Tumor quadrupling time is often subjected to right censoring because death of the experimental mice or limitations of the follow-up period. In the literature, tumor growth delay is simply reported without a standard error or confidence interval being given, which ignores the noise in the experimental data. Here, we present several confidence intervals for the difference of medians in a general right-censored failure time framework.Simulation studies are conducted to compare the coverage probability of these intervals for small samples.The proposed intervals are applied to tumor growth delay data from an actual tumor xenograft experiment.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Survival analysis,Biopharmaceutical research,,,,,,,15-Nov-10,jianxin.shi@nih.gov,,Jianxin Shi,,"Biostatistics Branch, DCEG, NCI","6120 Executive Blvd, Room 8040",301-443-8222,,jianxin.shi@nih.gov,FamilyCNV: an efficient and accurate algorithm for calling germline copy number variants in family-based genome-wide association studies,1,Jianxin,,Shi,"Biostatistical Branch, DCEG/NCI",Peng,,Li,"Biostatistical Branch, DCEG/NCI",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Germline copy number variants (CNVs) have received increasingattention in large scale genome-wide association studies (GWAS) in thepast few years. The CNV calling algorithms for unrelated subjects havelow power for short CNVs and may create Mendelian inconsistencies ineach family. PennCNV, a state of art CNV algorithm, has an option tosimultaneously call CNVs in one family trio. However, PennCNV is veryslow to analyze trios and is not computationally feasible to extend toanalyze bigger families in GWAS. Here, we present a novel algorithm,FamilyCNV, for jointly calling CNVs in extended pedigrees. FamilyCNVgreatly improves the power of detecting short inheritable CNVs as wellas the inference of the CNV boundaries in each family. FamilyCNV canalso infer chromosome-specific CNVs, which allows examining theimprinting effect of the CNVs on the trait. FamilyCNV is computationalvery efficient and can be applied to large scale family-based GWAS. Asa comparison, FamilyCNV takes about three minutes to analyze one triowhile PennCNV takes several hours. The application of FamilyCNV to family-based GWAS of testicular germ cell tumors (TGCT) andSchizophrenia will be discussed.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Statistical genetics,Epidemiologic methods,,,,,,,14-Nov-10,jianzhu@umich.edu,,Jian Zhu,,University of Michigan,1415 Washington Heights,734-277-2723,,jianzhu@umich.edu,IRT Summarized Pattern Mixture Model For Data Not Missing At Random,1,Jian,,Zhu,"Department of BiostatisticsUniversity of Michigan",Trivellore,E,Raghunathan,"Department of BiostatisticsUniversity of Michigan",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Imputation for large scale study when data are missing not at randomis generally difficult, especially when there are a large number ofitems with general missing patterns. This paper is aimed toinvestigate several pattern mixture models for such data. The patternsare determined by summarized information from response indicatorsassuming item response models. Both Bayesian models and sequentialregression imputation methods were considered. Simulation studiesbased on such pattern mixture models were conducted for multivariatenormally distributed data with different missing mechanisms. Furtherbias reduction by imputation results from the pattern mixture modelscompared to results assuming data are missing at random, was examined.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Missing data,Latent variables,,,,,,,15-Nov-10,jiaxiuhe@usc.edu,,Jiaxiu,Mr.,University of Southern California,5124 Dartmouth Ave.,323-205-8652,,jiaxiuhe@usc.edu,Exploring the effects of non-specific filtering on gene expression data,1,Jiaxiu,,He,"Department of Preventive Medicine, University of Southern California",Kimberley,D,Siegmund,"Department of Preventive Medicine, University of Southern California",Xin,,Wang,"Department of Marketing, University of Cincinnati",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Bourgon et al. 2010 PNAS analyzed the effects of non-specificfiltering on gene expression data prior to statistical testing. Usingan ALL dataset, the paper showed that filtering by overall variancesincreased the number of total discoveries. However, when the sametechnique was applied to another publicly available dataset (Geoaccession # GSE10957), the number of discoveries decreased instead. Weare going to use simulated data to illustrate what might cause thesedifferent results.Gene expression data (on the log2 scale) will be simulated fromindependent normal distributions for two groups, using means andvariances we observe in real data. A proportion of genes will besimulated as truly differentially expressed, where the effect size issimulated from either a normal distribution or uniform. The remainingtruly null genes will be simulated from distributions with nodifference in means. We will then explore the effect of filtering byoverall variance, prior to conducting two-sample t-tests followed bythe Benjamini & Hochbergs step-up procedure to control thefalse-discovery rate. We will characterize features of the data thatcould explain the discrepant results when using these two publiclyavailable data sets.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,TRUE,High dimensional data,Multiple testing,,,,,,,07-Oct-10,jichun@mail.med.upenn.edu,,Jichun Xie,,"Department of Biostatistics and Epidemioloty, Univ","501 Blockley Hall, 423 Guardian Dr.",347-223-9909,,jichun@mail.med.upenn.edu,Sample Size and Power Analysis for Sparse Signal Recovery in Genome-Wide Association Studies,1,Jichun,,Xie,"Department of Biostatistics and EpidemiologyUniversity of Pennsylvania School of Medicine",T,Tony,Cai,"Department of StatisticsThe Wharton School University of Pennsylvania",Hongzhe,,Li,"Department of Biostatistics and EpidemiologyUniversity of Pennsylvania School of Medicine",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Genome-wide association studies (GWAS)  have successfullyidentified hundreds of novel genetic variants associated with manycomplex human diseases. However, there is a lack of  rigorous  workon evaluating the  statistical power for identifying thedisease-associated SNPs in GWAS. In this paper, we consider theproblem of sparse signal identification in GWAS and present twoanalytical  frameworks for detailed analysis of the statisticalpower for detecting and identifying the disease-associated SNPs. Wepresent an explicit sample size formula for achieving a given falsenon-discovery rate while controlling the false discovery rate basedon an optimal false discovery procedure. The problem of sparse SNPrecovery is also considered and boundary condition is established interm of sparsity and signal strength for almost full recovery ofboth disease-associated SNPs and nondisease-associated SNPs. Adata-adaptive procedure is proposed to achieve this bound. These results provide important tools forsample size calculation and power analysis for GWAS. The analyticalresults  are illustrated with a genome-wide association study ofneuroblastoma.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,TRUE,High dimensional data,Multiple testing,,,,,,,21-Oct-10,jie@wald.ucdavis.edu,,Jie Peng,Associate Professor in Statistics,"University of California, Davis",One Shields Ave.,530-754-2566,,jie@wald.ucdavis.edu,High-dimension network inference with re-sampling methods,3,Li,,Hsu,"Fred Hutchinson Cancer Research Center, Seattle, WA, USA",Shuang,,Li,"Fred Hutchinson Cancer Research Center, Seattle, WA, USA",Jie,,Peng,"University of California, Davis, USA",Pei,,Wang,"Fred Hutchinson Cancer Research Center, Seattle, WA, USA",,,,,,,,,,,,,,,,,,,,,,,,,"In this talk, we formulate network re-construction (here edgedetection) as a model selection problem under the regularized sparseregression framework. It is well known that, commonly used criteriasuch as BIC or cross-validation for model tuning tend to select manyfalse edges. We employ the idea of data perturbation and modelaggregation and propose a re-sampling based approach which allows usto estimate the false discovery rate. As a consequence, the resultingprocedure is able to control FDR at a pre-specified level and at thesame time, it is less conservative compared to some existing methods.This approach can be applied to a broad range of models wheneverstructure learning is of interest. The proposed method is illustratedby both simulated and real data sets.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,High dimensional data,Genomics,,,,,,,15-Nov-10,jim@ccbr.umn.edu,,James Neaton,,University of Minnesota,2221 University Ave SE,(612) 626-9040,,jim@ccbr.umn.edu,Adverse Event Summaries for the DMC:  How to See the Forest Through the Trees,1,James,D,Neaton,University of Minnesota,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"DMCs, usually comprised of a multi-disciplinary group of scientists,are responsible for monitoring accumulating safety data by treatmentgroup in clinical trials and making recommendations after each reviewwhether the interim data warrant modification of the protocol ortermination of the study.  To enable the DMC to see the forest forthe trees, the following questions should be considered in writingthe protocol and preparing the DMC reports: 1) should level ofseverity or perceived relationship to study treatment be considered inthe collection of safety data? 2) should data collection continuefollowing study treatment discontinuation? 3) should interim efficacyas well as safety data be reported to assess risk-benefit? 4) how canthe data be summarized to facilitate DMC reviews?  In this talk, eachof these questions will be discussed.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Other,Clinical trials,,,,,,,12-Nov-10,jimcrooks1975@gmail.com,,James L. Crooks,Postdoctoral Fellow,U.S. Environmental Protection Agency,109 T. W. Alexander Drive,919-541-3718,,jimcrooks1975@gmail.com,Simultaneous statistical bias correction of multiple PM2.5 species from a regional photochemical model,1,James,L,Crooks,U. S. Environmental Protection Agency,Haluk,,Ozkaynak,U. S. Environmental Protection Agency,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In recent years environmental epidemiologists have begun utilizing regional-scale air quality computer models to predict ambient air pollution concentrations in health studies instead of or in addition to central site monitoring data.  The advantages of such models include better spatial and temporal coverage and the capability to predict concentrations of multiple pollutants and species of particulate matter.  However, there are also drawbacks, chief among them the fact that these models can exhibit systematic spatial and temporal biases in certain pollutants.  In order to correct such biases prior to their application in epidemiological investigations it is very important to pre-adjust the model surfaces.  We present a novel statistical method of spatio-temporal bias correction of the Community Multi-scale Air Quality (CMAQ) model that allows simultaneous bias adjustement of PM$_{2.5}$ mass and its major constituent species using publically available speciated data from ambient monitors.  Furthermore, the technique also uses the widespread unspeciated PM$_{2.5}$ mass observations to constrain the sum of the PM$_{2.5}$ species' concentrations far from their monitors.  We develop the model in the context of epidemiological studies investigating the association between PM$_{2.5}$ species' ambient concentrations and birth outcomes in the state of New Jersey.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Spatial/temporal modeling,Bayesian methods,,,,,,,09-Nov-10,jinaelee@gmail.com,,Jinae Lee,,University of Georgia,259 Statistics Bldg.,706-340-7785,706-542-3391,jinaelee@gmail.com,Practice-related changes in neural circuitry supporting eye movements investigated via wavelet-based clustering analysis,1,Jinae,,Lee,University of Georgia,Cheolwoo,,Park,University of Georgia,Benjamin,,Austin,University of Wisconsin,Kara,,Dyckman,University of Georgia,Qingyang,,Li,University of Georgia,Jennifer,,McDowell,University of Georgia,Nicole,A.,Lazar,University of Georgia,,,,,,,,,,,,,"In functional Magnetic Resonance Imaging (fMRI) studies clustering methods are used to detect similarities in the activation time series among voxels. It is assumed that the temporal pattern of activation is organized in a spatially coherent fashion such that clustering will extract the main temporal patterns and partition the dataset by grouping similarly behaved functions together.  In this work we propose a clustering procedure built in the wavelet domain to take temporal correlation into account. We also construct a no trend test based on wavelets to significantly reduce the high dimension of the data prior to clustering. In an actual clustering step, Principal Component Analysis K-means is applied and produces clustered maps that show the apparent structure of the activation of a brain. First, we evaluate the performance of our clustering method using the simulated data and compare it to other approaches. Second, we analyze the fMRI data acquired on two occasions while the participants were engaged in saccade tasks. We attempt to aggregate voxel time series into a small number of clusters and compare the clustered maps for the three practice groups and also between the two scan time points. Furthermore, using ROIs, we identify regions that show the statistical differences between the groups and time points based on the Bootstrap method.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Imaging,Functional data analysis,,,,,,,12-Nov-10,jincaowu@umich.edu,,Jincao Wu,,University of Michigan,1952 Traver Road Apt 202,734 2729631,,jincaowu@umich.edu,Joint Modeling of MRI and Polychotomous Disease Status Using Wavelet with Application to Alzheimer's Disease,1,Jincao,,Wu,"Department of Biostatistics, University of Michigan",Timothy,D,Johnson,"Department of Biostatistics, University of Michigan",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Our study is motivated by the challenge of using MRI to diagnose Alzheimer's disease. In an MRI study of Alzheimers patients, white matter changes are highly heterogenous and  differ in size and location making it difficult to use MRI as an accurate diagnostic tool. In our study, we propose to jointly model MRI data and polychotomous disease status (normal, mild cognitive impairment or Alzheimers disease) using wavelets, which can mitigate these problems. In stage I, we apply a 3-D discrete wavelet transformation on the MRI data and shrink the small wavelet coefficients to zero by Bayesian Lasso. In this way, the signal in the data can be represented by a small number of large wavelet coefficients. In stage II, a cumulative probit regression model is used to predict disease status and to select covariates via the reversible jump Markov chain Monte Carlo (RJMCMC) algorithm.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Imaging,Bayesian methods,,,,,,,14-Nov-10,jing.su@uth.tmc.edu,,Jing Su,School of Public Health,"School of Public Health, University of Texas Healt",7900 Cambridge ST,806-283-2743,,jing.su@uth.tmc.edu,A population based simulation of lung cancer prevention among high-risk individuals defined by genetic factors,1,Jing,,Su,"Department of Epidemiology, University of Texas MD Anderson Cancer Center, Houston, TX 77030;Department of Biostatistics, School of Public Health, University of Texas Health Science Center at Houston, Houston, TX 77030.",Bo,,Peng,"Department of Epidemiology, University of Texas MD Anderson Cancer Center, Houston, TX 77030",Millennia,,Foy,"Brown Foundation Institute of Molecular Medicine, University of Texas Health Science Center at Houston, Houston, TX 77030",Olga,,Gorlova,"Department of Epidemiology, University of Texas MD Anderson Cancer Center, Houston, TX 77030",Christopher,,Amos,"Department of Epidemiology, University of Texas MD Anderson Cancer Center, Houston, TX 77030",,,,,,,,,,,,,,,,,,,,,"Periodical screening, thought chest x-ray or helical CT, is currentlynot recommended as a therapy of the prevention of lung cancer, becauseresearchers worry about that radiation exposure may raise thepotential risk of carcinogenesis. However, it is reasonable andachievable to identify certain high-risk individuals by theirbiometric information, such as family history associated with lungcancer, some specific genes/biomarkers, and heavy smoking history. Thecoming question would be presented: may early detection be beneficialin such a subpopulation? We set up a microsimulation model to evaluatethe effects and costs of this idea under a forward-time populationwith realistic individual, familial, and population level properties. TSCE (Two-Stage Clonal Expansion) model has been applied to estimatethe individual risk of lung cancer, and hypothetical genetic riskfactors within different disease models are utilized to simulate theheritability of lung cancer. Different cancer screening strategies areused to verify whether it is cost-effective to screen high-riskpopulation defined by individual genetic factors.",FALSE,FALSE,,FALSE,FALSE,FALSE,,contributedposter,,,,FALSE,FALSE,FALSE,FALSE,Statistical genetics,Survival analysis,,,,,,,15-Nov-10,jing.wang@nyumc.org,,JING WANG,Senior Data Analyst,New York University,"215 Lexington Avenue, 16th floor",212-263-2783,,jing.wang@nyumc.org,Characterizing heterogeneity: an application of principal point classification to Autism data,1,JING,,WANG,New York University,Eva,,Petkova,New York University,Thaddeus,,Tarpey,Wright State University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"An important goal in medical research is to identify groups of subjects characterized with a particular trait or quality and to distinguish them from other subjects in a clinically relevant way. Measures of biological phenomena, in general, and of psychiatric conditions, in particular, often exhibit symmetric shapes resembling a normal distribution; yet, the statistical approaches predominantly applied have been based on an assumption of underlying categories, whether observed or latent.  It is well known that members of homogeneous populations with symmetric (multivariate) unimodal distributions can exhibit very distinct characteristics and partitioning of such homogeneous distributions is of importance even if distinct underlying categories are not assumed to underlie the measured phenomenon. Tarpey (2007) and Tarpey and Petkova,  (2010) introduced a statistical method for studying variation within homogeneous distributions without the assumption of existing mixtures. The method is based on principal points characterization.  We show how the method can be used to describe a multivariate distribution and to characterize heterogeneity in a population.  This is illustrated with clinical phenotype data on a large sample of children with Autism.",FALSE,FALSE,,FALSE,FALSE,FALSE,,contributedposter,,,,FALSE,FALSE,FALSE,FALSE,Multivariate methods,Computational methods,,,,,,,15-Nov-10,jing_zhang@brown.edu,,jing zhang,,brown university,"121 south main st., 7th floor",4015270653,,jing_zhang@brown.edu,Causal Inference about Mediation when there are Several Mediators,1,jing,,zhang,"Center for Statistical Sciences, Brown University",Joseph,,Hogan,"Center for Statistical Sciences, Brown University",Michael,,Daniels,"Department of Statistics, University of Florida",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In the context of randomized intervention trials of behavior science,the typical objective is to understand how the effect of anintervention operates on a primary outcome through potential mediatingvariables. Often there is more than one mediation path, and therelations between potential mediating variables suggest that themultiple mediator model is more of interest than the single mediatormodel.  We develop a model to infer separately the mediation effectsfor individual variables when there are several potential mediators.  A causal model, parameterized in terms of natural direct and indirecteffects (Pearl, 2001), is used to encode mediation.  To identify thenatural indirect effects, we require information about the jointpotential outcomes distribution of each mediator.  Our modelidentifies this joint distribution baseline covariates and targetedrestrictions the correlation structure of the potential mediators. Unobserved potential mediators and associated potential outcomes cantherefore be imputed under the model, and causal contrasts of interestcan be computed in a straightforward manner. We illustrate our methodsin both simulation studies and an analysis of a recent interventiontrial designed to increase physical activity.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Causal inference,Missing data,,,,,,,12-Oct-10,jingyang-zhang@uiowa.edu,,Jingyang Zhang,,"Department of Biostatistics, The University of Iow",200 Hawkins Drive,319-541-7248,,jingyang-zhang@uiowa.edu,A Sequential Diagnostic Method Based on Multiple Diagnostic Tests without a Gold Standard,1,Jingyang,,Zhang,"Department of Biostatistics, The University of Iowa",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The receiver operating characteristic (ROC) methodology is simple andwidely used in diagnostic testing. Having multiple diagnostic tests onone subject is common in medical practice, and there have been avariety of methods proposed to combine the tests to obtain moreaccuracy. But almost all of the methods require a reference test, or agold standard on the disease, which is not usually available. In thispaper, motivated by a lab data set of two diagnostic tests for acertain antibody, we propose a new method to classify subjects basedon multiple diagnostic tests without a gold standard. This method usesa mixture of two multivariate normal distributions to fit theunclassified data and we develop a new sequential classification ruleto make the diagnosis. The method is exemplified with the motivatingdata and simulation studies are carried out to assess the performanceof our method. We also discuss some possible extensions and somelimitations of the method.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,TRUE,Diagnostic and screening tests,ROC analysis,,,,,,,15-Nov-10,jingyuan@amgen.com,,Jingyuan Yang,,Amgen,1 Amgen Center Dr. Mail Stop 24-2-C,614-313-0425,,jingyuan@amgen.com,"Modeling asymmetry, high kurtosis and heavy tails in longitudinal endpoints using multivariate skew Laplace distribution",1,Jingyuan,,Yang,Amgen,Grace,,Park,Amgen,Huei,,Wang,Amgen,Lifen,,Zhou,Amgen,,,,,,,,,,,,,,,,,,,,,,,,,"For longitudinal endpoints with asymmetric, highly kurtotic, and heavy tailed empirical marginal distribution, conventional analyses using non-parametric methods or mixed-effects models may not be ideal. We propose to model asymmetry, high kurtosis and heavy tails in such endpoints using multivariate skew Laplace distribution, which fits the empirical marginal distribution well and also accounts for the intra-subject correlation among repeated measures. Parameters in this model can be estimated using the Expectation-Maximization (EM) algorithm and differences between treatment arms can be tested using likelihood ratio tests. The proposed model is applied to disease progression rates from a clinical trial to demonstrate the model fit.  A simulation study based on this trial is conducted to compare type I error rate and power of the proposed method with conventional non-parametric tests and mixed-effects models.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,"Biologics, pharmaceuticals, medical devices",Longitudinal data,,,,,,,13-Oct-10,jinha@umich.edu,,Jinkyung Ha,,"Biostatistics, School of Public Health, University",1420 Washington Heights,248-953-0171,,jinha@umich.edu,Adjusted Prostate Cancer Mortality Rates under Misattributed Cause of Death,1,Jinkyung,,Ha,"Biostatistics, School of Public Health, University of Michigan",Alexander,,Tsodikov,"Biostatistics, School of Public Health, University of Michigan",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"One of possible explanations for the recent trend in prostate cancer mortality rates is that a certain number of men who die of other causes may be mislabeled as dying from prostate cancer. To assess this hypothesis, we consider the problem of estimating mortality rates where other cause of death can be misattributed to prostate cancer. We first propose a mortality model which is a convolution of cause-specific survival and distributions for variables measured at diagnosis. Under proportional hazards assumption, we propose survival estimates adjusted for attribution bias, which are used to correct inflated mortality rates. With a variety of misattribution models, a sensitivity analysis is performed to assess the effect of attribution bias on the recent trend in mortality rates. Data used in this article is obtained from the Surveillance, Epidemiology, and End Results Program.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Survival analysis,Cancer applications,,,,,,,12-Nov-10,jinheeyu@buffalo.edu,,Jihnhee Yu,,University at Buffalo,3435 Main St. Farner Hall,716-829-6029,,jinheeyu@buffalo.edu,Two-sample Empirical Likelihood Ratio Tests for Medians in Application to Biomarker Evaluations,1,Jihnhee,,Yu,"Univeristy at Buffalo, SUNY",Albert,,Vexler,"Univeristy at Buffalo, SUNY",Seong-Eun,,Kim,"Univeristy at Buffalo, SUNY",Alan,,Hutson,"Univeristy at Buffalo, SUNY",,,,,,,,,,,,,,,,,,,,,,,,,"The median is a commonly used parameter to characterize biomarker data. In particular, with two vastly different underlying distributions, comparing medians provides ostensibly different information than comparing means; however, very few tests for medians are available in such a circumstance. We propose a series of two-sample median-specific tests using empirical likelihood methodology and investigate their properties. We present the technical details of incorporating the relevant constraints into the empirical likelihood function for median testing in depth. An extensive Monte Carlo study shows that the proposed tests have excellent operating characteristics even under unfavorable occasions such as non-exchangeability under the null hypothesis. We apply the proposed methods to analyze biomarker data from Western Blot analysis to compare normal cells with bronchial epithelial cells from a case-control study.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Nonparametric methods,Applied data analysis,,,,,,,04-Nov-10,jin-liu@uiowa.edu,,Jin Liu,,University of Iowa,Schaffer Hall,319-471-5954,,jin-liu@uiowa.edu,Accounting for linkage disequilibrium in genome-wide association studies: A penalized regression method,1,Jin,,Liu,"Department of Statistics & Actuarial Science, University of Iowa",Kai,,Wang,"Department of Biostatistics, University of Iowa",Shuangge,,Ma,"Division of Biostatistics, School of Public Health, Yale University",Jian,,Huang,"Department of Statistics & Actuarial Science, University of Iowa",,,,,,,,,,,,,,,,,,,,,,,,,"Penalized regression methods are becoming increasingly popular ingenome-wide association studies (GWAS) for selecting genetic markersassociated with disease. However, standard penalized variableselection methods such as the LASSO do not make efficient use of theinformation contained in genetic marker data from GWAS, since they donot take into account the linkage disequilibrium information betweenadjacent markers along the chromosome. We propose a novel penalizedmethod for GWAS using a dense set of single nucleotide polymorphisms(SNPs). The proposed method adaptively incorporates linkagedisequilibrium (LD) information by penalizing the difference of thegenetic effects at adjacent SNPs with high correlation. It uses theminimax concave penalty (MCP) for marker selection. The MCP has beenshown to possess oracle selection properties under reasonableconditions in high-dimensional settings. A coordinate descent algorithmis derived to implement the proposed method. This algorithm isefficient and stable in dealing with a large number of SNPs. Amulti-split method is used to calculate the p-values of selected SNPsfor assessing their significance. We refer to the proposed penaltyfunction as the smoothed MCP and the proposed approach as the SMCPmethod. Performance of the proposed SMCP method and its comparisonwith a LASSO approach are evaluated through simulation studies, whichdemonstrate that the proposed method is more accurate in selectingassociated SNPs. Its applicability to real data is illustrated usingdata from a study on rheumatoid arthritis.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Microarray analysis,High dimensional data,no,,,,,,19-Oct-10,jinmei@gwu.edu,,Mei Jin,,The George Washington University,350 South Van Dorn Street,202-531-4949,,jinmei@gwu.edu,Group Sequential Designs for Reliability Studies,1,Mei,,Jin,George Washington University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,FALSE,FALSE,,FALSE,FALSE,FALSE,,,,,,FALSE,FALSE,FALSE,FALSE,,,,,,,,,03-Nov-10,jinmei324@gmail.com,,Mei Jin,,The George Washington University,2140 Pennsylvania Ave NW,202-531-4949,,jinmei324@gmail.com,Optimal Two-Stage Design for Evaluation of Measurement Errors in Reliability Studies,1,Mei,,Jin,"Department of Statistics,The George Washington University,Washington, DC",Aiyi,,Liu,"Biostatistics and Bioinformatics Branch,National Institute of Child Health and Human Development,National Institutes of Health ,Rockville, MD",Zhaohai,,Li,"Department of Statistics,The George Washington University,Washington, DC",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The intraclass correlation coefficient (ICC) has a lengthy history of application in several different fields of research. It is a widely recognized index of reliability among measurements. In studies involving human samples, the measuring cost can be often high and the resource is limited. Two-stage designs are proposed to lead to savings in sample size, time and cost when compared with standard fixed sample procedures. We present two-stage test that is optimal in the sense that the average sample number (ASN) is minimized when the measurements have low reliability subject to constraints upon the size of the type I and type II errors. The performance of the proposed technique is examined using simulation studies for a range of design parameters. As an example of applications, the method is used to assess the genotypic correlation. In addition, the proposed method is extended to the design for two-stage tests of the ICC derived from a two-way ANOVA model.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Measurement error,Power analysis/sample size,,,,,,,15-Nov-10,jizhu@umich.edu,,Ji Zhu,,University of Michigan,439 West Hall,7349362577,,jizhu@umich.edu,Joint estimation of multiple graphical models,4,Jian,,Guo,University of Michigan,Liza,,Levina,University of Michigan,George,,Michailidis,University of Michigan,Ji,,Zhu,University of Michigan,,,,,,,,,,,,,,,,,,,,,,,,,"Gaussian graphical models explore dependence relationships betweenrandom variables, through estimation of the corresponding inversecovariance matrices. In this paper we develop an estimator for suchmodels appropriate for data from several graphical models that sharethe same variables and some of the dependence structure. In thissetting, estimating a single graphical model would mask the underlyingheterogeneity, while estimating separate models for each category doesnot take advantage of the common structure. We propose a method whichjointly estimates the graphical models corresponding to the differentcategories present in the data, aiming to preserve the commonstructure, while allowing for differences between the categories. Thisis achieved through a hierarchical penalty that targets the removal ofcommon zeros in the inverse covariance matrices across categories. Weestablish the asymptotic consistency and sparsity of the proposedestimator in the high-dimensional case, and illustrate its superiorperformance on a number of simulated networks. An application tolearning semantic connections between terms from webpages collectedfrom computer science departments is also included.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,High dimensional data,Graphical models,,,,,,,12-Nov-10,jjclark@email.unc.edu,,Jennifer Clark,Graduate Student,"University of North Carolina, Chapel Hill",439 Summerwalk Circle,615-828-1908,,jjclark@email.unc.edu,Visualizations of the Interactive Effects of Alcohol and Tobacco on Pharyngeal Cancer using Bivariate Splines,1,Jennifer,,Clark,"Department of Biostatistics, University of North Carolina, Chapel Hill",Andrew,,Olshan,"Department of Epidemiology, University of North Carolina, Chapel Hill",Amy,,Herring,"Department of Biostatistics, University of North Carolina, Chapel Hill",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We analyzed large population-based data of squamous cell carcinoma ofthe head and neck (SCCHN) across 46 North Carolina counties.  Anunconditional logistic regression was run first to get ORs forassociation between cancer and exposure; we then ran comparablebivariate spline models to further explore and provide visual aid foralcohol/tobacco interactions as well as to examine the assumption ofhomogenous risk within various alcohol and tobacco categories used inthe logistic regression.  Plots of bivariate splines confirmed aninteractive effect of some alcoholic beverages and tobacco on SCCHN. There were slight differences in risk when displaying the spline plotsby their categorical versions.  Furthermore, the bivariate splinemodel tended to be the model of best fit when examining theinteractive effects on pharyngeal cancer.",FALSE,FALSE,,FALSE,TRUE,TRUE,T5:  Essentials for Success in Research:  Everything you wanted to know about NIH Grants and Publishing (Tuesday 1:45-3:30),contributedposter,,,,FALSE,FALSE,FALSE,FALSE,Epidemiologic methods,Graphical models,,,,,,,04-Nov-10,jjlee@mdanderson.org,,J. Jack Lee,Professor,University of Texas M. D. Anderson Cancer Center,"1400 Pressler Street, Unit 1411",713-794-4158,,jjlee@mdanderson.org,Bayesian Adaptive Designs for Targeted Agent Development in Cancer Clinical Trials,1,J. Jack,,Lee,University of Texas M. D. Anderson Cancer Center,Xuemin,,Gu,University of Texas M. D. Anderson Cancer Center,Suyu,,Liu,University of Texas M. D. Anderson Cancer Center,Nan,,Chen,University of Texas M. D. Anderson Cancer Center,,,,,,,,,,,,,,,,,,,,,,,,,"Advances in biomedicine have revolutionized cancer therapy by the development of targeted agents. Targeted therapies have shown to be more efficacious and less toxic than the conventional broad-based chemotherapies.  Targeted therapies, however, do not work for all patients.  The major challenge is to identify markers to predict treatment efficacy.  Biomarker based adaptive designs are applied to (1) identify prognostic and predictive markers for targeted agents, (2) test treatment efficacy, and (3) provide better treatments for patients enrolled in the trial.  In contrast to the frequentist equal randomization designs, Bayesian adaptive randomization designs allow treating more patients with effective treatments, monitoring the trial more frequently to stop ineffective treatments early, and increasing efficiency while controlling type I and type II errors. Bayesian logistic regression, hierarchical model, and Cox regression are applied for binary and time-to-event endpoints. Putative markers are chosen via variable selection methods. Bayesian adaptive design can be more efficient, more ethical, and more flexible in the study conduct than standard designs. Examples and experiences learned from real studies will be given.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Adaptive design/adaptive randomization,Bayesian methods,,,,,,,12-Nov-10,jkrall@jhsph.edu,,Jenna Krall,,Johns Hopkins Department of Biostatistics,3022 North Calvert St. Apt 1,412-965-2012,,jkrall@jhsph.edu,Accounting for spatial misalignment in a national study of particulate matter constituents and mortality,1,Jenna,R,Krall,"Department of Biostatistics, Johns Hopkins Bloomberg School of Public Health",Michelle,L,Bell,"School of Forestry and Environmental Studies, YaleUniversity",Roger,D,Peng,"Department of Biostatistics, Johns Hopkins Bloomberg School of Public Health",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"While total mass particulate matter smaller than 2.5 micrometers(PM2.5) has been linked to adverse health outcomes, the constituentsdriving its toxicity have not yet been identified.  Spatial-temporalmodels have been previously applied to pollution data to account forpotential spatial misalignment between aggregated health outcomemeasures and point measures of pollution.  Since PM2.5 constituentsare highly spatially variable, yet temporally and spatially sparse, wepropose adding a categorical region component to a stationaryspatial-temporal model to account for nonstationarity.  Previous workconcerning the toxicity of PM2.5 constituents is limited to localstudies of mortality and national studies of other health outcomes. Thus, we conduct the first ever study of PM2.5 constituents andmortality nationally.  Our results illustrate significant differencesin the spatial-temporal correlation of PM2.5 constituents across theUnited States, demonstrating the importance of accounting for spatialmisalignment.  The addition of a nonstationary term tospatial-temporal models analyzing PM2.5 constituents provides evidence forsubstantial spatial heterogeneity and its use could helpilluminate the relationship between constituents of PM2.5 and mortality.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Environmental and ecological applications,Spatial/temporal modeling,,,,,,,04-Nov-10,jlgast@gwu.edu,,Joseph L Gastwirth,Professor,George Washington Universtiy,2140 Pennsylvania Ave NW,2029946548,2029946917,jlgast@gwu.edu,The Use of Survival Analysis to Estimate Compensation in Equal Employment Litigation,2,Joseph,L,Gastwirth,"Department of StatisticsGeorge Washington University",Qing,,Pan,"Department of StatisticsGeorge Washington University",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"A number of legal decisions have accepted survival analyses demonstrating that members of a protected group have received less favorable employment opportunities than similarly qualified majority members. After plaintiffs prevail, courts need to calculate the expected earnings they would have earned had they not been discriminated against. An essential component of this calculation is the estimation of their length of employment.  Survival methods are appropriate in hiring, promotion or termination cases; however, the appropriate model depends on the type of case.  For example, in a promotion case, the censoring or leaving process may be correlated with the promotion process.  Data from actual cases will be reanalyzed to illustrate the usefulness of survival techniques in this area.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Other,Survival analysis,Legal Applications,,,,,,12-Nov-10,jlin@bios.unc.edu,,Ja-An Lin,,"Department of Biostatistics, The University of Nor","3101 McGavran-Greenberg Hall, CB #7420",919-966-7250,,jlin@bios.unc.edu,Projection Regression Models for Multivariate Measure: Theory and Applications,1,Ja-An,,Lin,"Department of Biostatistics, The University of North Carolina at Chapel Hill",Hongtu,,Zhu,"Department of Biostatistics, The University of North Carolina at Chapel Hill",Joseph,G.,Ibrahim,"Department of Biostatistics, The University of North Carolina at Chapel Hill",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"This paper presents projection regression model (PRM) to delineate theassociation between a multivariate response with a set of explanatoryvariables, such as diagnostic, age and gender. In the neuroimagingliterature, a standard statistical approach to this problem is to fita multivariate linear model and then use the Hotelling's T-square totest hypotheses of interest. An alternative approach is to fit asimple linear model and test hypothesis for each component ofmultivariate measures and then correct for multiplicity. However, eventhe dimension of multivariate measures is relatively small, say 5,such standard approaches can suffer from the issue of low statisticalpower in detecting the association between multivariate measures andexplanatory variables. PRM generalizes a statistical method based onthe principal component of heritability for association analysis inthe genetic study of complex traits. The key idea of PRM is to extracta principal feature of multivariate measures relative to explanatoryvariables and then use a shrinkage method as well as a Wald-typestatistic to test for an association between the principal feature andexplanatory variables. Simulation studies are used to examine thefinite sample performance of PRM.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Imaging,High dimensional data,,,,,,,26-Oct-10,jlin@stat.fsu.edu,,Jianchang,,"Department of Statistics, Florida State University",214 OSB 117 N. Woodward Ave.,8502287421,,jlin@stat.fsu.edu,Semiparametric Bayesian survival analysis via transform-both-sides model,1,Jianchang,,Lin,"Department of Statistics, Florida State University",Debajyoti,,Sinha,"Department of Statistics, Florida State University",Stuart,,Lipsitz,"Division of General Medicine, Brigham and Women's Hospital",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We propose a semiparametric survival model with a log-linear medianregression function as an useful alternative to popular proportionalhazards (Cox, 1972) and linear transformation models (Cheng et al.,1995). Compared to existing semiparametric models and quantileregression methods, our models have many practical advantagesregarding the interpretation of regression parameters via median, theease of prior elicitation and computation, and the performance ofBayesian estimators. Our Bayesian estimation method is extended to asemiparametric multivariate survival model with symmetric randomeffects distribution. We illustrate the implementation of ourapproaches and model diagnostics via reanalysis of a small-cell lungcancer study and a retinopathy study.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Bayesian methods,Survival analysis,,,,,,,11-Nov-10,jlin9@emory.edu,,Ji Lin,,Emory University,1231 Clairmont Rd,678-559-5154,,jlin9@emory.edu,Sensitivity analysis for non-ignorable missing data in logistic regression via weighting,1,Ji,,Lin,Emory University,Robert,,Lyles,Emory University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Missing values in exposure data are a widespread obstacle in statistical applications in epidemiology. Commonly, the missing at random (MAR) assumption is made to ease the analysis. However,  it is often the case that data are not missing at random (NMAR), and the MAR assumption is difficult to verify. To handle a questionable MAR assumption, results under a series of plausible alternative NMAR assumptions are sometimes compared with those under MAR, such that the sensitivity to violations of the MAR assumption can be assessed. Here, a framework to specify alternative mechanisms via the missingness probability, the missingness risk ratio, or the missingness odds ratio is proposed to facilitate such a sensitivity analysis. The proposed framework provides an intuitive and straightforward approach by assigning proper weights to the records in an appropriately constructed expanded data set. The expanded data set can then be supplied to any standard statistical software package that accommodates an option to apply the weights to the log-likelihood contributions of each record. Closed forms for the weights are provided, and we recommend a standard jackknife procedure for estimating standard errors. Examples are given to illustrate the accessibility of the proposed approach for the practicing epidemiologist.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Missing data,Generalized linear models,,,,,,,06-Oct-10,jlwarre2@unity.ncsu.edu,,Joshua Warren,,NCSU Dept. of Statistics,2311 Stinson Dr.,919 418 4999,,jlwarre2@unity.ncsu.edu,Air Pollution and Preterm Birth:  Identifying Critical Windows of Exposure,1,Joshua,L,Warren,NCSU Dept. of Statistics,Montserrat,,Fuentes,,Amy,,Herring,,Peter,,Langlois,,,,,,,,,,,,,,,,,,,,,,,,,,"Exposure to high levels of air pollution has many known adverse healtheffects including heart and lung disease.  Associations betweenexposure and increased mortality have also been estimated.  The linkbetween exposures to pollutants, such as particulate matter 2.5micrometers and smaller (PM2.5 ) and ozone, and birth outcomes is notas well established because of the lack of quality data.  We develop amodel for examining the relationship between exposure to PM2.5 andozone and the probability of preterm birth.  Our focus is onidentifying the critical windows of the pregnancy in which increasedexposure to these pollutants is particularly harmful.  We introduce acontinuous exposure model in the Bayesian setting that will help toidentify these critical times during pregnancy using geo-coded birthoutcome data from Harris County, Texas (2000-2004) along with twosources of daily pollution data.  Our model indicates that higherexposure to the PM2.5 pollutant during the middle of the firsttrimester through the beginning of the second trimester significantlyincreases the probability of a preterm delivery.  Elevated exposureduring the first few weeks of pregnancy and early in the secondtrimester to ozone is also associated with a significant increase inthe probability of a preterm delivery.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Other,Bayesian methods,Environmental Health,,,,,,15-Nov-10,jmathia@ncsu.edu,,Jamila Mathias,Graduate Student (Ph.D),North Carolina State University,1005 Kavkaz St.,4049318121,,jmathia@ncsu.edu,Constructing bivariate contours for censored data,1,Jamila,,Mathias,North Carolina State University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Reference regions are often used to determine whether some measures of interest lie within a 'normal' range. If the outcomes are multivariate in nature the reference region becomes a multidimensional monitoring tool. In biomedical studies, some markers may be subject to censoring due to detection limits, and this complicates the construction of reference regions. In this study, we develop a projection-based bivariate contour construction method for data with one left censored response variable via regression of censored quantiles. Nonparametric extrapolation methods are introduced aiming to provide finite sample improvement in situations where some lower quantiles of the censored variable are not identifiable. The performance of several proposed methods are assessed through a simulation study and the analysis of data measuring thyroid function.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Environmental and ecological applications,Latent variables,,,,,,,27-Oct-10,jmcgread@jhsph.edu,,John McGready,,Johns Hopkins Bloomberg School,615 N. Wolfe Street,410 614 9405,,jmcgread@jhsph.edu,Demystifying Hypothesis Testing,1,John,,McGready,"Johns Hopkins University Bloomberg School of Public HealthDepartment of Biostatistics",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"While many concepts in statistics, including first principles, areindeed complicated, we as statisticians like to add another layer ofcomplications via our approaches to teaching the subjects.  Flipthrough any introductory (io)statistics  text, and one is likely findpage after page with what I like to call the money making sections. These are the portions of the text that describe basic, potentiallyeasy to comprehend concepts, with an excess of formulae, notation andtechnical verbiage.  The adjective money making is a reference tothe need to hire a statistician to decipher these concepts.  Onenotable example of this is the ways in which texts describe hypothesistesting.  For instance, the protocol for performing a two-samplet-test usually involves formulaic representations of a  teststatistic and a rejection rule. The notation and formulae getincreasingly complex as the complexity of the tests increases(chi-squared, F-tests etc.)   In this talk, we present a unifiedconceptual paradigm for developing an understanding about hypothesistest, and the connection to confidence intervals.  The approach wetake fundamentally equates hypothesis testing to measuringstandardized distances, and making a decision about whether the resultis close or far to the null value.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Statistical education,Biostatistics Education,,,,,,,14-Oct-10,jminnier@hsph.harvard.edu,,Jessica Minnier,,Harvard University,655 Huntington Ave,5035488531,,jminnier@hsph.harvard.edu,Risk Classification with an Adaptive Naive Bayes Kernel Machine Model,1,Jessica,,Minnier,"Department of Biostatistics, Harvard School of Public Health",Jun,,Liu,"Department of Statistics, Harvard University",Tianxi,,Cai,"Department of Biostatistics, Harvard School of Public Health",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The complex genetic architecture of disease makes it difficult to identify genomic markers associated with disease risk. Standard risk prediction models often rely on additive or marginal relationships of markers and the phenotype of interest. These models perform poorly when associations involve interactions and non-linear effects. We propose a multi-stage method relating markers to disease risk by first forming gene-sets based on biological criteria. With a naive bayes kernel machine model, we estimate gene-set specific risk models that relate each gene-set to the outcome. Second, we aggregate across gene-sets by adaptively estimating weights for each set. The KM framework models the potentially non-linear effects of predictors without specifying a particular functional form. Estimation and predictive accuracy are improved with kernel PCA in the first stage and adaptive regularization in the second stage to remove non-informative regions from the final model. Prediction accuracy is assessed with bias-corrected ROC curves and AUC statistics. Numerical studies suggest that the model performs well in the presence of non-informative regions and both linear and non-linear effects.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Machine learning,Variable subset selection/model selection,,,,,,,12-Nov-10,joan.buenconsejo@fda.hhs.gov,,Joan Buenconsejo,Mathematical Statistician,FDA,10903 New Hampshire Avenue,301-796-1181,,joan.buenconsejo@fda.hhs.gov,Leadership in Goverment,1,Joan,,Buenconsejo,FDA,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Opportunities for statisticians to become leaders in government agencies are many and varied.  In my presentation, I will describe my experience as an Excellence in Government Fellow, as a statistical team leader supporting the Division of Pulmonary, Allergy and Rheumatology Products, and as the President of the FDA Statistical Association. I will share what I have learned from those experiences as a statistician who has assumed a variety of leadership roles.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Other,Statistical education,Leadership,,,,,,15-Nov-10,john.yap@fda.hhs.gov,,John Stephen Yap,,FDA,"White Oak Building 21, Room 4657",301-796-4202,,john.yap@fda.hhs.gov,Mapping High-Order Epistasis for Complex Traits in Experimental Crosses Using the Score Test,1,John Stephen,,Yap,FDA,Chenguang,,Wang,FDA,Song,,Wu,St. Jude Children's Hospital,Yao,,Li,West Virginia University,Myron,,Chang,University of Florida,Rongling,,Wu,Pennsylvania State University,,,,,,,,,,,,,,,,,"Genetic interactions have been thought to play a pivotal role inshaping the formation, development and evolution of life.  However,when modeling two or more genes or quantitative trait loci (QTLs), thelikelihood ratio test (LRT), which is used to detect the existence ofQTLs, becomes computationally more complex.  Chang et al. (2009)proposed to use the score test as an alternative to the LRT for asingle QTL in a backcross population.  The authors showed that thescore test is computationally simpler than the LRT and that thecritical threshold for the score test can also be used for the LRT. Here, we propose to extend the use of the score test in mapping oneQTL to mapping two or three QTLs in a backcross population.  We deriveclosed form solutions for the score test statistics and show throughsimulations the computational advantage of the score test over theLRT.  We also illustrate the use of the score test by analyzing a realrice data set.  Our model will provide a computationally efficientroutine procedure for identifying high-order QTL interaction forquantitative traits.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Statistical genetics,Genomics,,,,,,,10-Oct-10,joseph.c.cappelleri@pfizer.com,,Joseph C Cappelleri,Senior Director,Pfizer Inc,50 Pequot Avenue,860 732 8668,,joseph.c.cappelleri@pfizer.com,Statistical Considerations on Patient-Reported Outcomes for Labeling Claims,1,Joseph,C,Cappelleri,Pfizer Inc,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In December 2009, the Food and Drug Administration released its final guidance on patient-reported outcomes (PROs) for use in medical product development to support labeling claims. This presentation covers several areas of statistical import (design issues, missing data, multiplicity, composite endpoints, interpretation of results, and responder analysis for consideration in the design, analysis, and interpretation of PROs) for a regulatory label claim.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Other,,Regulatory and Legal Statistics,,,,,,15-Nov-10,joshua.sampson@nih.gov,,Joshua Sampson,Investigator,National Cancer Institute,6120 Executive Blvd,301-443-8207,,joshua.sampson@nih.gov,Efficient Study Design for Next Generation Sequencing,1,Joshua,N,Sampson,"DCEG, National Cancer Institute",Nilanjan,,Chatterjee,"DCEG, National Cancer Institute",Meredith,,Yeager,"Core Genotyping Facility, DCEG, National Cancer Institute",Kevin,,Jacobs,"Core Genotyping Facility, DCEG, National Cancer Institute",Stephen,,Chanock,"Core Genotyping Facility, DCEG, National Cancer Institute",,,,,,,,,,,,,,,,,,,,,"Background: Next Generation Sequencing represents a powerful tool for detecting genetic variation associated with human disease. Because of the high cost of this technology, it is critical that we develop efficient study designs that consider the trade-off between the number of subjects, n, and the coverage depth, c. How we divide our resources between the two can greatly impact study success, particularly in pilot studies.Results: We propose a strategy for selecting the optimal combination of n and c for studies aimed at detecting rare variants and for studies aimed at detecting associations between rare or uncommon variants and disease. For detecting rare variants, we find the optimal coverage depth to be between 5 and 12 reads. For association studies, we observed that the strategy of sequencing all available subjects to be preferable. In deriving these combinations, we provide a detailed analysis describing the distribution of coverage of depth across a genome, the depth needed to identify a minor allele in an individual, and the spectrum of tests available.Conclusions: The optimal coverage depth depends on the aims of the study, and the chosen depth can have a large impact on study success.",FALSE,FALSE,,FALSE,FALSE,FALSE,,contributedposter,,,,FALSE,FALSE,FALSE,TRUE,Statistical genetics,Genomics,,,,,,,10-Nov-10,jpinhei1@its.jnj.com,,Jose Pinheiro,Senior Director,Johnson & Johnson PRD,920 Rt 202 South,908 927 5204,,jpinhei1@its.jnj.com,Accounting for Model Uncertainty via Multiple Comparisons Tests,1,Jose,C,Pinheiro,Johnson & Johnson PRD,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Model uncertainty is often ignored when selecting empirical models to describe observed data. This will generally result in overfitting problems, which may have important inferential consequences in some areas of application. This talk will discuss the problem of model uncertainty in the context of clinical drug development, more specifically, in clinical trials used to test the presence of dose response and to select a dose, or doses, to be brought into confirmatory trials. Multiple candidate models are often considered at the time of planning the study, and accounting for the underlying multiplicity issue when selecting a model to fit the observed data at the end of the trial is critical for ensuring the validity of the conclusions and decisions. A hybrid approach combining multiple contrast tests and modeling approaches will be described and illustrated with real dose finding studies. Extensions of the approach to general types of response data and models, including time-to-event, will also be discussed.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Clinical trials,Multiple testing,,,,,,,15-Nov-10,jqian@hsph.harvard.edu,,Jing Qian,,Harvard University,655 Huntington Ave,617-432-4916,,jqian@hsph.harvard.edu,Variable Selection and Prediction With High-dimensional Matched Case-Control Neuroimaging Data,1,Jing,,Qian,"Department of Biostatistics,Harvard School of Public Health",Rebecca,A,Betensky,"Department of Biostatistics,Harvard School of Public Health",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"With rapid technology advance, matched case-control studies which arefrequently used in medical studies to increase efficiency usuallyinvolve high-dimensional covariates. For example, a matchedcase-control study was conducted recently in acute ischemic strokepatients admitted to Mass General Hospital, to identify brain regionsof acute infarction linked to pneumonia in stroke patients. The 138imaging variables along with nearly 10000 two-way interactionschallenge statistical analysis. Although many high-dimensionalvariable selection methods have been developed, few approaches areavailable for matched case-control design. Building on the recentlydeveloped Lasso type variable selection methods, we propose penalizedlikelihood based variable selection methods accommodating matcheddesign. In addition to select relevant variables, it is also importantto construct a prediction method for early risk evaluation. Therefore,we also construct prediction score based on selected variables usingthe same matched case-control sample as in variable selection. Theproposed methods are evaluated via extensive simulation studies andillustrated by the imaging data for stroke patients.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Variable subset selection/model selection,High dimensional data,,,,,,,15-Nov-10,jqshen@stanford.edu,,Jeremy J. Shen,,Stanford University,344 Olmsted Rd Apt 108,5103871235,,jqshen@stanford.edu,Copy Number Profiling Using Next-Generation DNA Sequencing with Change-Point Methods,1,Jeremy,J,Shen,Stanford University,Nancy,R,Zhang,Stanford University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"As DNA sequencing capacity continues to grow at an exciting pace,there is increasing interest to use sequencing to study genomestructural changes including copy number variation/aberration(CNV/CNA).  We present a change-point model for CNV detection usingthe read depth information from next-generation sequencing of matchedcase-control DNA samples. We model the mapped read positions asnon-homogeneous Poisson Processes and formulate the problem as thecalling of change points in the ratio of their rate functions. Wederived the score and generalized likelihood ratio statistics underthis model, and adapted the Circular Binary Segmentation (CBS)algorithm for calling change-points in this new framework.  Proceduresfor inference, such as model selection and confidence assessment, willalso be discussed.  We demonstrate the performance of the new method on simulation andexisting cancer genome sequencing data.  Poisson process models forincorporating paired-end and mapping quality information will beconsidered as well.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,,,,,,,,,12-Oct-10,jrgonzalez@creal.cat,,Juan R,Associate Research Professor,"Center for Research in Environmental Epidemiology,","Av. Dr Aiguader, 88",+34 932 147 327,,jrgonzalez@creal.cat,A novel statistical method to detect mosaic rearrangements using SNP array data,1,Juan,R,Gonzalez,"Center for Research in Environmental Epidemiology, Barcelona, Spain",Benjamin,,Rodriguez-Santiago,"Dpt Ciencies Experimentals i de la Salut, University Pompeu Fabra, Barcelona, Spain",C‡ceres,,Alejandro,"Center for Research in Environmental Epidemiology, Barcelona, Spain",Roger,,Pique-Regi,"Department of Human Genetics, University of Chicago, IL, USA",Lluis,,Armengol,"Quantitative Genomic Medicine Laboratories, Barcelona, Spain",Luis,A,PŽrez-Jurado,"Dpt Ciencies Experimentals i de la Salut, University Pompeu Fabra, Barcelona, Spain",,,,,,,,,,,,,,,,,"Mosaicism for copy number and copy neutral chromosomal rearrangementshas been recently identified as a relatively common source of geneticvariation in normal population. Mosaic alterations can be found usingSNP array data, but methods lack sensitivity to identify smallvariants and low mosaic degree. Therefore, there is the need for toolsthat help to establish the prevalence and importance of mosaicvariation in DNA structural variation. Here, we propose a novelmethodology, Mosaic Alteration Detection-MAD, and offer a softwaretool to find mosaic variants controlling for false positives whilemaintaining high sensitivity. Simulation studies as well as reanalysisof existing data confirmed the good performance of the proposedmethod. By analyzing real data we found the existence of new eventsthat are smaller and with low percentage of affected cells.  Themethods are implemented in as part of the package R-GADA that can beobtained in http://groups.google.com/group/gadaproject",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Genomics,Statistical genetics,,,,,,,11-Oct-10,jschen24@hotmail.com,,Jinsong Chen,,"Division of Biostatistics and Epidemiology, Depart","2401 Peyton Drive, Apt 102",5408181866,,jschen24@hotmail.com,Generalized Single-Index Mixed Model for Repeated Measures Data,1,Jinsong,,Chen,"Division of Biostatistics and Epidemiology, Department of Public Health Sciences, School of Medicine,University of Virginia, Charlottesville, VA 22908, U.S.A.",Inyoung,,Kim,"Department of Statistics, Virginia Polytechnic Institute and State University, Blacksburg, VA 24061, U.S.A.",George,R,Terrell,"Department of Statistics, Virginia Polytechnic Institute and State University, Blacksburg, VA 24061, U.S.A.",Lei,,Liu,"Division of Biostatistics and Epidemiology, Department of Public Health Sciences, School of Medicine,University of Virginia, Charlottesville, VA 22908, U.S.A.",,,,,,,,,,,,,,,,,,,,,,,,,"In this paper, we propose a generalized single-index mixed model for analyzing repeated measures data. A double penalized quasi-likelihood approach (DPQL) is proposed to estimate nonparametric function and parameters including single-index coefficients. We use the sandwich formula for joint inference. A bias correction procedure is developed to improve the asymptotic performance of the DPQL estimates of single-index coefficients with canonical link function and a single source of variation. A simulation example, the study of health effects of air pollution in North Carolina, and the analysis of the Adolescent Alcohol Prevention Trial data, illustrate the effectiveness of our approach.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Nonparametric methods,Longitudinal data,,,,,,,15-Nov-10,jsharp@clemson.edu,,Julia Sharp,,Clemson University,237 Barre Hall,864-656-3252,,jsharp@clemson.edu,Regression Parameter Estimate Adjustments With the Addition of Correlated and/or Interacting Variables,1,Julia,L.,Sharp,Clemson University,William,C.,Bridges,Clemson University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The addition of predictors to an existing regression model can change the parameter estimates of existing predictors in the model and/or the estimated error standard deviation of the model.  Literature has documented the impact of adding correlated predictors on the parameter estimates; and some literature has addressed the impact on the parameter estimates of adding predictors that interact with existing predictors.  However, research that attempts to compare and quantify the changes in both the estimated parameters and the estimated error standard deviation in response to additional predictors is limited.  In this study, a series of regression models was simulated in which predictors that correlated and interacted with existing model predictors were added.  The changes in parameter estimates of existing predictors and error standard deviation were measured.  As would be expected, the results vary based on the parameter estimates, correlation, amount of interaction with the existing predictor, and size of the error standard deviation. The impact of correlated and interacting predictors seems larger than simply adding these terms individually.  Correlated variables seem to have a larger impact on parameter estimates while interacting variables seem to have a larger impact on error standard deviation.",FALSE,FALSE,,FALSE,FALSE,FALSE,,contributedposter,,,,FALSE,FALSE,FALSE,TRUE,Applied data analysis,Consulting,,,,,,,15-Nov-10,jshults@mail.med.upenn.edu,,Justine Shults,Associate Professor,University of Pennsylvania School of Medicine,Room 610 Blockley Hall,215-573-6526,215-573-4865,jshults@mail.med.upenn.edu,Recent Issues Regarding the Prentice Constraints for Correlated Binary Data,2,Matthew,,Guerra,University of Pennsylvania School of Medicine,Justine,,Shults,University of Pennsylvania School of Medicine,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"It is well known that in the analysis of clustered or longitudinalbinary data, that the correlations are subject to constraints that arein addition to those required to achieve a positive definitecorrelation matrix. We critique these suggestions and describe analternate approach, which is to consider implementation of our MARK1MLapproach for analysis of longitudinal binary data.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Clustered data methods,Longitudinal data,,,,,,,11-Nov-10,jsinnott@hsph.harvard.edu,,Jennifer Sinnott,,Harvard School of Public Health,655 Huntington Ave,614 2086118,,jsinnott@hsph.harvard.edu,Prediction of Survival with Accelerated Failure Time Kernel Machine Model,1,Jennifer,A,Sinnott,Harvard School of Public Health,Tianxi,,Cai,Harvard School of Public Health,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"When using high-dimensional genomic data to predict a complex phenotype, it is wise to leverage prior biological information such as pathways or linkage disequilibrium to increase reproducibility and predictive accuracy. To predict censored survival outcomes with a large number of genetic markers, we propose a two-stage approach. We group markers into gene-sets based on biological knowledge. In stage 1, we test the effect of each gene-set on survival via an Accelerated Failure Time (AFT) kernel machine (KM) framework. By capturing the potential non-linear and interactive effects, the KM modeling is likely to gain power and predictive accuracy. At this stage, we select important gene-sets based on an FDR control and estimate their effects on the outcome. In stage 2, we use those estimated gene-set effects as covariates, and fit a regularized AFT model to estimate the optimal weights for combining the selected gene-sets. This regularization using the adaptive LASSO penalty allows us to remove false positives that passed through stage 1. The AFT framework is well-suited to this approach because if two gene-sets are independent, their joint effects are equal to their marginal effects. This property does not hold in the Cox PH model. We demonstrate our approach using simulation studies, and show an application to the Framingham Heart Study.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,High dimensional data,Survival analysis,,,,,,,11-Nov-10,juheelee2@gmail.com,,Juhee Lee,Postdoc fellow,MD Anderson Cancer Center,3720 W. Alabama St #7206,6142097214,,juheelee2@gmail.com,On Differential Gene Expression Using RNA-Seq Data,1,Juhee,,Lee,"Department of Biostatistics, M.D. Anderson Cancer Ctr.",Yuan,,Ji,"Department of Biostatistics, M.D. Anderson Cancer Ctr.",Shoudan,,Liang,"Dpt. of Bioinformatics and Computational Biology, M.D. AndersonCancer Ctr.",Guoshuai,,Cai,"Dpt. of Bioinformatics and Computational Biology, M.D. Anderson Cancer Ctr.",Peter,,Mueller,"Department of Biostatistics, M.D. Anderson Cancer Ctr.",,,,,,,,,,,,,,,,,,,,,"We introduce model-based Bayesian inference for RNA-Seq data. RNA-Seqis a high-throughput next-generation sequencing experimental platformthat can be used tomeasure the messenger  RNA expression of samples. RNA-Seq experimentsmitigate some of thelimitations that are inherent to microarray data. But inference alsogives rise to some new challenges. We propose a Bayesian hierarchicalmodel to implement coherent, fast and robust inference for RNA-Seqdata. We focus on differential gene expression experiments, i.e.,experiments carried out to learn about differential gene expressionunder two biologic conditions.  The proposed model exploits availableposition-specific counts, minimizing required data pre-processing and more importantly, eliminating the need forbiological replicates. Moreover, it includes mechanisms to automaticallydiscount outliers at the level of positions within genes, and reportscoherent posterior probabilities of differential expression at thegene level.  An implementation as a public domain R package isavailable.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Bayesian methods,Hierarchical models,,,,,,,31-Oct-10,jul221@psu.edu,,Jingyuan Liu,PhD student,Penn State University,325 Thomas Bldg,814-321-7556,,jul221@psu.edu,A robust model for multilocus population genetics,1,Jingyuan,,Liu,"Dept. of Statistics, Penn State University",Xiyang,,Zhao,"Beijing Forestry University, Beijing, China",Fang,,Fu,"Beijing Forestry University, Beijing, China",Runze,,Li,"Dept. of Statistics, Penn State University",Rongling,,Wu,"Center for Statistical Genetics, Penn State University",,,,,,,,,,,,,,,,,,,,,"A multilocus analysis has emerged as a vital ingredient of populationgenetics and evolutionary biology. A fundamental assumption used forcurrent multilocus analysis approaches is Hardy-Weinberg equilibrium(HWE) at which maternally- and paternally-derived gametes combinerandomly during fertilization. Given the fact that natural populationsare rarely panmictic, these approaches will have a significantlimitation for practical use. We present a robust model for multilocuslinkage disequilibrium analysis which does not rely on the assumptionof random mating. The new model capitalizes on Weir's definitions ofzygotic disequilibria and is based on an open-pollinated design inwhich multiple maternal individuals and their half-sib families aresampled from a natural population. This design captures two levels ofassociations: one is at the upper level that describes the pattern ofco-segregation between different loci in the parental population andthe other is at the lower level that species the extent ofco-transmission of homologous alleles at different loci from parentsto their ospring. An MCMC method was implemented to estimate geneticparameters that define these associations. Simulation studies wereused to validate the statisticalbehavior of the new model.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Statistical genetics,Genomics,,,,,,,13-Nov-10,jungboklee@korea.ac.kr,,JungBok Lee,Research Professor,Korea University,"Inst. of Human Genomic Study, Korea Univ. Hospital",82-10-8287-7175,,jungboklee@korea.ac.kr,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,FALSE,FALSE,,FALSE,FALSE,FALSE,,,,,,FALSE,FALSE,FALSE,FALSE,,,,,,,,,10-Nov-10,jungyeon.lee@nyumc.org,,Jung Yeon Lee,,Research Scientist,"215 Lexington Ave, 15th Fl",631-456-1883,,jungyeon.lee@nyumc.org,Course of comorbidity of tobacco and marijuana use: Psychosocial risk factors,2,Judith,S,Brook,"Department of Psychiatry, New York University School of Medicine, New York, NY",Jung Yeon,,Lee,"Department of Psychiatry, New York University School of Medicine, New York, NY",Elaine,N,Brown,"Department of Psychiatry, New York University School of Medicine, New York, NY",Stephen,J,Finch,"D epartment of Applied Mathematics & Statistics, Stony Brook University, Stony Brook, NY",,,,,,,,,,,,,,,,,,,,,,,,,"This longitudinal study examined the psychosocialfactors associated with the comorbidity of pairs of tobaccoand marijuana use trajectories from adolescence extending into adulthood in two ethnic groups, Blacks and Puerto Ricans. Data on psychosocial functioning and tobacco andmarijuana use at four points in time were obtained. The association between the trajectories of tobaccoand marijuana use was quite high. Pairs of comorbid trajectories of tobacco and marijuana use may share at least three kinds of infl uence: (a) a constellation of externalizing personality risk factors, (b) Depressive Mood and low Ego Integration, and (c) identification with certain group values. Knowledge of the risk and protective factors forpairs of comorbid trajectories of use may strengthen thefoundation for individual and group targets for prevention andtreatment programs.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Longitudinal data,Health services research,,,,,,,07-Nov-10,Junlong.Li@mizzou.edu,,Junlong Li,,University of Missouri,105 W Broadway Apt 1,573-999-1009,,Junlong.Li@mizzou.edu,Regression analysis of Clustered Interval-censored Failure Time Data,1,Junlong,,Li,University of Missouri,Jianguo,,Sun,University of Missouri,Xingwei,,Tong,Beijing Normal University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Clustered interval-censored data occur when the failure times ofinterest are clustered into small groups and known only to lie incertain intervals. Methods have been proposed for their regressionanalysis, but most of them apply only to clustered right-censoreddata. In this paper, we discuss a Cox frailty model for the analysisof clustered interval-censored failure time data.  For inference, thesieve maximum likelihood estimation approach will be applied and atwo-step EM algorithm is developed. The asymptotic properties of theresulting sieve maximum likelihood estimates are established and theirfinite sample properties are investigated through a simulation study. The proposed method is illustrated by the data arising from alymphatic filariasis study.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Survival analysis,Multivariate survival,,,,,,,09-Oct-10,jwang8@ncsu.edu,,Jiangdian Wang,,"Department of Statistics, NC State University","Department of Statistics, NC State University",919-257-0959,,jwang8@ncsu.edu,Modeling Infant Mortality Data using Shape Restricted Multivariate Bernstein Polynomials,1,Jiangdian,,Wang,"Department of Statistics, NC State University",Sujit,K,Ghosh,"Department of Statistics, NC State University",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The estimation of shape-restricted regression curves is challengingfor multivariate predictors, especially for functions with compactsupport. Most of the currently available statistical estimationmethods for shape restricted regression functions are generallycomputationally very intensive. Some of the existing methods areapplicable to only nonparametric additive models ignoring theinteraction terms. This article considers a suitable class ofmultivariate polynomials with unknown order and proposes a sievedestimator obtained from a nested sequence of shape-restrictedmultivariate Bernstein polynomials. Our proposed method is shown to becomputationally attractive and universally consistent under some mildregularity conditions. Our method is also flexible in the sense thatit can be easily adapted to accommodate many popular multivariateshape restrictions, such as nonnegativity, isotonicity, convexity andconcavity. The proposed estimator is evaluated by Monte Carlosimulation studies and is applied to a real data that investigates theunderlying decreasing trend of the regression function relating thelevel of Expenditure Per Capita and Adult Literacy Rate to theresponse variable Infant Mortality Rate.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Constrained estimation/order restricted inference,Nonparametric methods,,,,,,,05-Nov-10,jwick@kumc.edu,,Jo Adrianne Wick,Assistant Professor,University of Kansas Medical Center,3901 Rainbow Boulevard,913588-4790,,jwick@kumc.edu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,FALSE,FALSE,,FALSE,FALSE,FALSE,,,,,,FALSE,FALSE,FALSE,FALSE,,,,,,,,,10-Nov-10,jwu@ms.soph.uab.edu,,Jihua Wu,Post-doc Scholar,University of Alabama at Birmingham,1301 33rd St. South,205-975-9298,,jwu@ms.soph.uab.edu,A hidden Markov model for haplotype inference using previously identified haplotype and haplotype patterns,1,Jihua,,Wu,"Section on Statistical Genetics, Department of Biostatistics, University of Alabama at Birmingham",Guo-bo,,Chen,"Section on Statistical Genetics, Department of Biostatistics,University of Alabama at Birmingham",Degui,,Zhi,"Section on Statistical Genetics, Department of Biostatistics,University of Alabama at Birmingham",Kui,,Zhang,"Section on Statistical Genetics, Department of Biostatistics,University of Alabama at Birmingham",,,,,,,,,,,,,,,,,,,,,,,,,,FALSE,FALSE,,FALSE,FALSE,FALSE,,,,,,FALSE,FALSE,FALSE,FALSE,,,,,,,,,11-Nov-10,jyahn@uga.edu,,Jeongyoun Ahn,,University of Georgia,101 Cedar St.,706-542-3433,,jyahn@uga.edu,"Clustering High Dimension, Low Sample Size Data Using the Maximal Data Piling Distance",1,Jeongyoun,,Ahn,University of Georgia,Myung Hee,,Lee,Colorado State University,Young Joo,,Yoon,"Konkuk University, South Korea",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We propose a new hierarchical clustering method for high dimension, low sample size (HDLSS) data. The method utilizes the fact that each individual data vector accounts for exactly one dimension in the subspace generated by HDLSS data. The linkage that is used for measuring the distance between clusters is the orthogonal distance between affine subspaces generated by each cluster. The ideal implementation would be to consider all possible binary splits of the data and choose the one that maximizes the distance in between. Since this is not computationally feasible in general, we use the singular value decomposition for its approximation. We provide theoretical justification of the method by studying high dimensional asymptotics. Also we obtain the probability distribution of the  distance measure under the null hypothesis of no split, which we use to propose a criterion for determining the number of clusters. Simulation and real data analysis with microarray data show competitive clustering performance of the proposed method.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,High dimensional data,Microarray analysis,.,,,,,,08-Nov-10,jyan@stat.uconn.edu,,Jun Yan,Associate Professor,University of Connecticut,215 Glenbrook Rd.,860-486-3416,,jyan@stat.uconn.edu,Augmented Estimating Equations for Semiparametric Panel Count Regression with Informative Observation Times and Censoring Time,3,Xiaojing,,Wang,University of Connecticut,Shuangge,,Ma,Yale University,Jun,,Yan,University of Connecticut,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We propose an augmented estimating equation (AEE) approach for asemiparametric mean regression model with panel count data underpossibly informative observation schemes and censoring. On a grid of time points, counts in all the subintervals of each observation window are treated as missing values, and are imputed with a robust working model given the observed count in the window. The observation scheme and the event process are allowed to bedependent through covariates and an unobserved frailty, which enters the mean function multiplicatively. Conditional on covariates, the censoring time and the event process can be dependent through frailty.Regression coefficients and unspecified baseline meanfunction are estimated with an Expectation-Solving (ES) algorithm,which solves the conditionally expected version of the complete-data estimating equations given the observed data.Simulation studies demonstrate that the estimator performs well formoderate sample sizes and appears to be competitive in comparison withexisting estimators under a wide range of practical settings. Theutility of the proposed methods is illustrated with a bladder tumor study.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Estimating equations,Spatial/temporal modeling,,,,,,,31-Oct-10,jz9p@virginia.edu,,Jianhui Zhou,,University of Virginia,"Department of Statistics, Halsey Hall",434-924-3355,,jz9p@virginia.edu,Consistent Model Selection for Marginal Generalized Additive Model for Correlated Data,3,Lan,,Xue,Oregon State University,Annie,,Qu,University of Illinois at Urbana-Champaign,Jianhui,,Zhou,University of Virginia,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We consider the generalized additive model when responses from thesame cluster are correlated. Incorporating correlation in theestimation of nonparametric components for the generalized additivemodel is important since it improves estimation efficiency andincreases statistical power for model selection. In our setting, thereis no specified likelihood function for the generalized additive modelsince the outcomes could be non-normal and discrete, which makesestimation and model selection very challenging problems. We proposeconsistent estimation and model selection whichincorporate the correlation structure. We establish an asymptoticproperty with $L_{2}$-norm consistency for the nonparametriccomponents, which achieves the optimal rate of convergence. Inaddition, the proposed model selection strategy is able to select thecorrect generalized additive model consistently. That is, withprobability approaching to 1, the estimators for the zero functioncomponents converge to 0 almost surely. We will illustrate our methodusing numerical studies with both continuous and binary responses, anda real data application of binary periodontal data.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Clustered data methods,Generalized linear models,,,,,,,10-Nov-10,jzhang@mailbox.sc.edu,,Jiajia Zhang,,"Department of epidemiology and biostatistics, Univ",800 Sumter Street,803-777-4474,,jzhang@mailbox.sc.edu,An Alternative Estimation Method for the Semiparametric Accelerated Failure Time Mixture Cure Model,2,Linzhi,,Xu,"Albert Einstein College of Medicine, Yeshiva University, 1300 Morris Park Ave, Bronx, NY 10461, United States",Jiajia,,Zhang,"Department of Epidemiology and Biostatistics, University of South Carolina, Columbia, SC 29208, United States",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We propose an alternative estimation method for the semiparametric accelerated failure time mixture cure model by incorporating the profile likelihood into the M-step of the EM algorithm. The proposed method performs as well as the existing methods when the censoring is light and better than the existing methods when the censoring is moderate from the simulation studies. Regarding to the computational time, the proposed method runs faster than the existing methods. For illustration, we apply the proposed method to a data set of failure times from the bone marrow transplantation.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Survival analysis,Computational methods,,,,,,,14-Nov-10,katarina.kosmelj@bf.uni-lj.si,,Katarina Kosmelj,prof,"Biotechnical faculty, University of Ljubljana",Jamnikarjeva 101,+38640245987,,katarina.kosmelj@bf.uni-lj.si,Clustering of Population Pyramids,1,Katarina,,Kosmelj,"Biotechnical Faculty, University of LjubljanaJamnikarjeva 1011000 LjubljanaSlovenia, Europe",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In many real situations, data are collected/presented as histograms.Such an example are population pyramids, which present the agedistribution of a population by sex. Countries described by populationpyramids can be regarded as symbolic data objects with two randomvariables, one presenting age for male and one for female; eachage-variable is presented in a form of a histogram.The objective of our study is to partition the countries intohomogeneous clusters according to similarity of their populationpyramids in a particular year. We shall use the distance which isderived from the Wasserstein metric. It can be considered as theexpected value of the squared Euclidean distance between homologouspoints of the support of the two distributions. Irpino and Verde(2006) showed that for two frequency distributions this distance isexpressed in a simple way. It has a very useful property for theclassification: total inertia can be decomposed into the within andbetween cluster inertia, according to Huygens theorem.A case study on several countries will be presented; hierarchicalclustering with Wards's method and dynamic clustering will be used.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Clustered data methods,Multivariate methods,,,,,,,15-Nov-10,kaushik.ghosh@unlv.edu,,Kaushik Ghosh,Assistant Professor,University of Nevada Las Vegas,4505 Maryland Parkway,702-895-0392,,kaushik.ghosh@unlv.edu,Joint Modeling of Longitudinal Data with Informative Dropout in the Presence of Changepoints,2,Pulak,,Ghosh,"Indian Institute of Management, Bangalaore, India",Kaushik,,Ghosh,"University of Nevada, Las Vegas",Ram,C,Tiwari,Food and Drug Administration,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In longitudinal studies of patients with the human immunodeficiency virus (HIV), objectives of interest often include modeling of individual-level trajectories of HIV ribonucleic acid (RNA) as a function of time. Empirical evidence, however,suggests that individual trajectories often possess multiple points of rapid change, which may vary from subject to subject.Additionally, some individuals may end up dropping out of the study and the tendency to drop out may be related to thelevel of the biomarker. In this article, we propose a new joint model, where a multiple-changepoint model is proposed for the longitudinal viral RNA response and proportional hazards model for the time of dropout process. Dirichlet process (DP) priors are used to modelthe distribution of the individual random effects and error distribution. A fully Bayesian approach for model fitting and prediction is implemented using MCMC procedures on the ACTG 398 clinical trial data. The proposed model is seen to give rise to improved estimates of individual trajectories when compared with a parametric approach.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Joint models for longitudinal and survival data,Bayesian methods,,,,,,,28-Sep-10,kcgchan@u.washington.edu,,Kwun Chuen Gary Chan,Assistant Professor,University of Washington,"Box 357232, 1959 NE Pacific Streeet",2066859177,,kcgchan@u.washington.edu,Beyond double robustness: multiple working models for missing data problems,1,Kwun Chuen Gary,,Chan,University of Washington,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Double robustness is an attractive feature in missing data analysisbecause consistency of estimation is achieved when either a missingdata model or a outcome regression model is correctly specified.  Inpractice, both models are difficult to specify because the missingdata model often involves high dimensional covariates and the outcomeregression model involves extrapolation.  When both models aremisspecified, certain doubly robust estimators can perform verypoorly.  In this talk we will introduce extensions to surveycalibration methodologies which admit multiple non-nested workingmodeling assumptions for both missing data and outcome regressionmodels and consistency of estimation is achieved when any one of theworking models are correct.  The method presents a great flexibilityin analyzing missing data with complicated missing data structure.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Missing data,Causal inference,,,,,,,15-Nov-10,kendzior@biostat.wisc.edu,,Christina Kendziorski,Associate Professor,UW-Madison,1300 University Avenue,608-262-3146,,kendzior@biostat.wisc.edu,An empirical Bayes hierarchical model for inference in RNA-seq experiments,1,Ning,,Leng,"Department of Statistics, UW-Madison",Christina,,Kendziorski,"Department of Biostatistics and Medical Informatics, UW-Madison",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"RNA-sequencing is a powerful approach providing estimates ofboth isoform and gene expression with unprecedenteddynamic range and accuracy.  A fundamental goal of RNA-seqexperiments measuring expression in two or more biological conditionsis the identification of differentially expressed isoforms and genes.Most of the statistical methods developed to identifydifferentially expressed genes measured using microarrays do not directly apply,and the methods that have been developed specifically for RNA-seq measurementsdo not directly accommodate isoform level expression, dependence acrossisoforms, or coding region information.  We have developed an empiricalBayesian modeling approach that accounts for and capitalizes on these features.Advantages of the approach are illustrated in simulations and in anRNA-seq study of mammary carcinoma in rat. This is joint work with Michael Gould's lab at UW-Madison.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Statistical genetics,High dimensional data,,,,,,,14-Oct-10,kevinhe@umich.edu,,Kevin He,Ph.D. Candidate,University of Michigan,2015 Medford Road,7347096355,,kevinhe@umich.edu,Modifications of and Alternatives to the Standardized Mortality Ratio in Evaluating Center-Specific Mortality,1,Kevin,,He,"Department of BiostatisticsSchool of Public HealthUniversity of Michigan",Douglas,E,Schaubel,"Department of BiostatisticsSchool of Public HealthUniversity of Michigan",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The standardized mortality ratio (SMR) based on a Cox regression modelis often used to evaluate center-specific mortality. However, theasymptotic properties and finite-sample behavior of the Cox SMR arenot well-studied. We describe some strong limitations of the Cox SMRthat relate to its underlying assumptions. We then developmodifications to the Cox SMR based on a stratified Cox model, whichremedy the limitations of the usual version. In addition, since centereffects computed through indirect standardization are not comparable,we propose a semiparametric generalization of direct standardization.The measures we consider are process-based and, therefore, allow us tonot only identify if a center's mortality is outlying, but also whenduring the follow-up the excess mortality tends to occur. Kernel-smoothing method is performed for the proposed measure.Hypothesis testing procedure is developed to identify outlying centersand to evaluate whether a particular center has an effect that isconstant over time. Asymptotic properties of proposed estimators arederived.  Finite-sample properties are examined through an extensivesimulation study. The methods considered and developed are applied tonational kidney transplant data.",FALSE,FALSE,,FALSE,FALSE,TRUE,"Short Course Sc7, 1pm-5pm on Sunday March 20, 2011.",studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Survival analysis,Epidemiologic methods,,,,,,,11-Oct-10,khlxq3@mail.missouri.edu,,Kyu Ha Lee,,University of Missouri Columbia,1025 Ashland Road 103,573-442-0552,,khlxq3@mail.missouri.edu,Bayesian Variable Selection in Semiparametric Proportional Hazards Model for High Dimensional Survival Data,1,Kyu Ha,,Lee,University of Missouri Columbia,Sounak,,Chakraborty,University of Missouri Columbia,Jianguo,,Sun,University of Missouri Columbia,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In this paper, we propose a Bayesian variableselection scheme for a Bayesian semiparametric survival model for right censored survival datasets. A special shrinkage prior on the coefficients corresponding to the predictor variables is usedto handle cases when the explanatory variables are of very high-dimension. The shrinkage prioris obtained through a scale mixture representation of Normal and Gamma distributions. Our proposedvariable selection prior corresponds to the well known lasso penalty. The likelihood functionis based on the Cox proportional hazards model framework, where the cumulative baseline hazardfunction is estimated using a discrete gamma process. We assign a prior on the tuning parameterof the shrinkage prior and adaptively control the sparsity of our model. The primary use of the proposedmodel is to identify the important covariates relating to the survival curves. To implementour methodology, we have developed a fast Markov chain Monte Carlo algorithm with adaptivejumping rule. We have successfully applied our method on simulated data sets under two differentsettings and real microarray data sets which contain right censored survival time. The performanceof our Bayesian variable selection model compared with other standard competing methods arealso provided to demonstrate the superiority of our method.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,TRUE,Microarray analysis,Variable subset selection/model selection,Bayesian Variable Selection,,,,,,12-Nov-10,kims2@mail.nih.gov,,Sung Duk Kim,Staff Scientist,NICHD/NIH,6100 Executive Blvd,301-435-6930,,kims2@mail.nih.gov,Bayesian Hierarchical Models for Massive Count Data: An Application to a Driving Study with Kinematic Events,1,Sungduk,,Kim,"Biostatistics and Bioinformatics Branch, Division of Epidemiology, Statistics and Prevention Research, Eunice Kennedy Shriver National Institute of Child Health and Human Development, NIH, Rockville, MD 20852",Zhen,,Chen,"Biostatistics and Bioinformatics Branch, Division of Epidemiology, Statistics and Prevention Research, Eunice Kennedy Shriver National Institute of Child Health and Human Development, NIH, Rockville, MD 20852",Zhiwei,,Zhang,"Biostatistics and Bioinformatics Branch, Division of Epidemiology, Statistics and Prevention Research, Eunice Kennedy Shriver National Institute of Child Health and Human Development, Rockville, MD 20852",Paul,S,Albert,"Biostatistics and Bioinformatics Branch, Division of Epidemiology, Statistics and Prevention Research, Eunice Kennedy Shriver National Institute of Child Health and Human Development, NIH, Rockville, MD 20852",,,,,,,,,,,,,,,,,,,,,,,,,"The highly elevated crash risk among newly-licensed teenagers declines rapidly over the first year or so of licensure, suggesting that performance among novices improves over time. The Naturalistic Teenage Driving Study (NTDS) is the first U.S. study to document continuous driving performance and crash/near crash experience of newly-licensed teenagers during their first 18 months of licensure. Counts of kinematic events(e.g., number of lateral accelerations over 0.5g) are available for each trip, and their incidence rates represent different aspects of driving behavior. We propose a hierarchical Poisson regression model with over-dispersion, heterogeneity, and serial correlation.  However, the unique structure of the NTDS dataset (thousands of trips for most drivers) poses challenges to standard Markov chain Monte Carlo methods for longitudinal count data. A sequential Markov chain Monte Carlo sampling algorithm is developed for implementing the Bayesian computations. The proposed methodology is motivated and illustrated by the NTDS data.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Hierarchical models,Bayesian methods,,,,,,,20-Sep-10,kimx1606@umn.edu,,sunkyung kim,,University of Minnesota,100 3rd Ave S #1506,2173771232,,kimx1606@umn.edu,Do kids in diet have friends in diet? Comparison study of exponential random graph and autologistic regression model via simulation,1,Sunkyung,,Kim,University of Minnesota,Melanie,M,Wall,Columbia University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Recent studies have found that adolescents' health is associated withpeer group's health. To investigate this network eect on ego'shealth, regression analysis has been applied by taking ego's healthoutcome as a response and adding friends' health summary statistics asa covariate. However, these models without considering complex networkstructure; friend of a friend is a friend, might be unreasonable inreal world, especially in adolescents' dense network environment. Tobe more realistic, recent studies also applied Exponential RandomGraph Model (ERGM) which considers both dyad dependence structure andavoids model degeneracy issue, via Geometrically Weighted EdgewiseShared partner(GWESP) statistic.In this paper, for seeking the answer of the simple question; `Dofriends in diet have friends in diet?', which investigates theassociation between ego and friends' binary health outcome (Yes forbeing in diet, No for not), we both apply ERGM and autologisticregression and then compare the performance of the two models via simulation under several scenarios. Since we don't know the truemechanism of the data in real world, we generate 500 data both fromERGM and autologistic and t them in all 6 models. Finally,we apply all models to the one high school data, `FOLWELL', fromProject EAT and conclusions to the same question are compared.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Other,Spatial/temporal modeling,Network data analysis,,,,,,11-Oct-10,kiranmoy.das@gmail.com,,Kiranmoy Das,Graduate Student,The Pennsylvania State University,445 Waupelani Drive (E14),352 871 3997,,kiranmoy.das@gmail.com,Dynamic Semiparametric Bayesian Model for Functional Mapping,1,Kiranmoy,,Das,The Pennsylvania State University,Rongling,,Wu,The Pennsylvania State University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Many phenomena of fundamental importance to agriculture, biology, andbiomedicine arise as a dynamic curve. Despite difficulty, thesedynamic traits can now be mapped and dissected by a new statisticalmodel, called functional mapping, through efficient modeling ofmean-covariance structures. In practice, the use of functional mappingis challenged by longitudinal variables measured at irregular andpossibly subject-specific time points, in which case nonnegativedefiniteness of the covariance matrix will prevent the computation oflongitudinal data. We present a semiparametric approach for functionalmapping within the mixture-model setting by jointly modeling mean andcovariance structures for irregular longitudinal data. Penalizedspline is used to model the mean functions of individual QTL genotypesas latent variables while an extended generalized linear model used toapproximate the covariance matrix. The parameters for modeling themean-covariances are estimated by MCMC, using Gibbs sampler andMetropolis Hastings algorithm. We derive the full conditionaldistributions for the mean and covariance parameters and compute Bayesfactors to test the hypothesis about the existence of significant QTLs.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,TRUE,Bayesian methods,"Biologics, pharmaceuticals, medical devices",,,,,,,04-Oct-10,kjarcher@vcu.edu,,Kellie J. Archer,Associate Professor,Virginia Commonwealth University,730 East Broad Street,804-827-2039,804-828-8900,kjarcher@vcu.edu,A comparison of frequentist and Bayesian penalized continuation ratio models for predicting an ordinal response in high-dimensional datasets,1,Kellie,J.,Archer,Virginia Commonwealth University,Andre,A.A.,Williams,Virginia Commonwealth University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"For high-throughput genomic datasets where the number of covariates(p) exceeds the sample size (n), the common approach to predicting anordinal response given the gene expression data has been to break theproblem into one or more dichotomous response analyses. Thisdichotomous response approach does not make use of all available dataand therefore leads to loss of power and increases the number of TypeI errors. Herein we describe an innovative frequentist approach thatcombines two statistical techniques, penalization and continuationratio models, for modeling an ordinal response for high-dimensionaldatasets. We present the results of our simulation study whichassessed the performance of the frequentist penalized continuationratio models in comparison to a previously described Bayesianapproach. Moreover, the frequentist and Bayesian approaches wereempirically compared using three application datasets, each of whichseeks to classify an ordinal class using microarray gene expressiondata as the predictor variables. We conclude that the frequentistpenalized continuation ratio approach is a competitive alternative tothe Bayesian approach when modeling an ordinal response given ahigh-dimensional covariate space.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,High dimensional data,Machine learning,,,,,,,12-Nov-10,kliang@stat.wisc.edu,,Kun Liang,,University of Wisconsin-Madison,5002 Sheboygan Ave Apt 129,6082654383,,kliang@stat.wisc.edu,Statistical Analysis of ChIP-seq: from Diversity to Consensus,1,Kun,,Liang,"Department of Biostatistics and Medical InformaticsUniversity of Wisconsin-Madison",Sunduz,,Keles,"Department of Statistics andDepartment of Biostatistics and Medical InformaticsUniversity of Wisconsin-Madison",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Statistical Analysis of ChIP-seq: from Diversity to ConsensusChromatin immunoprecipitation-sequencing (ChIP-seq) has become the preferred tool over ChIP-chip for detecting DNA-protein interactions. Despite the availability of large number of ChIP-seq analyzing programs, the proper statistical analysis of ChIP-seq data remains a huge challenge. We will give a brief overview of the ChIP-seq data analysis pipeline and try to bring consensus to some fundamental issues.",TRUE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Statistical genetics,Genomics,,,,,,,05-Nov-10,klokejd@upmc.edu,,John Kloke,,University of Pittsburgh,"200 Meyran Ave, Suite 300",412-864-3020,,klokejd@upmc.edu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,FALSE,FALSE,,FALSE,FALSE,FALSE,,,,,,FALSE,FALSE,FALSE,FALSE,,,,,,,,,14-Oct-10,klopiano@ufl.edu,,Kenneth K. Lopiano,,University of Florida,1710 NW 2nd Avenue,9045684759,,klopiano@ufl.edu,Unbiased Estimates of Uncertainty in General Linear Regression Models with Spatially Misaligned Data,1,Kenneth,K,Lopiano,University of Florida,Linda,J,Young,University of Florida,Carol,A,Gotway,Centers for Disease Control and Prevention,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Researchers in the fields of climate change, environmental risk assessment, and public health often augment their data collection with existing data or work entirely with existing data from multiple sources. When the datasets have a spatial component, the datasets are often {\it spatially misaligned}. Spatial misalignment occurs when two or more variables are observed at different locations or aggregated over different geographical units. When the datasets are spatially misaligned, the data must be combined using a common set of geographical units before relationships can be assessed. When smoothing techniques, such as kriging, are used to align the disparate datasets, Berkson-type measurement error is induced. As a result, although regression estimates are unbiased, estimates of their uncertainty are biased. In this work, an iteratively reweighted generalized least squares approach is proposed that produces unbiased estimates of the regression parameter and its standard error when kriging is used to align datasets in point-to-point and point-to-areal misalignment problems. The statistical properties of the approach are presented and simulation studies  are used to illustrate the performance of the proposed methodology. For concreteness, the association between MI and ozone in Florida is assessed, and the effect of properly accounting for the uncertainty in ozone illustrated.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Spatial/temporal modeling,Measurement error,,,,,,,15-Nov-10,klum@jhsph.edu,,Kirsten J. Lum,,Johns Hopkins University,615 North Wolfe Street,410-502-3357,,klum@jhsph.edu,Joint Modeling of Menstrual Cycle Length and Fecundity,2,Alexander,C,McLain,"Eunice Kennedy Shriver National Institute of Child Health and Human Development, National Institutes of Health, Department of Health and Human Services",Kirsten,J,Lum,Johns Hopkins University,Rajeshwari,,Sundaram,"Eunice Kennedy Shriver National Institute of Child Health and Human Development, National Institutes of Health, Department of Health and Human Services",Germaine,M,Buck Louis,"Eunice Kennedy Shriver National Institute of Child Health and Human Development, National Institutes of Health, Department of Health and Human Services",,,,,,,,,,,,,,,,,,,,,,,,,"Menstrual cycle length patterns have been used as indicators ofendocrine functions in environmental and occupational studies. Aquestion of considerable interest is assessing the association betweenmenstrual cycle length and fertility. Prospective pregnancy studies,which typically capture women of reproductive age until they getpregnant or until the end of study, are a rich source of menstrualcycle information.  However, methodological challenges exist inascertaining menstrual cycle characteristics based on daily diaryinformation collected in such studies.  These challenges include thelongitudinal data being highly skewed and also informatively censoredby pregnancy.  Previous literature has proposed a mixture of Weibullwith Normal distribution to model the menstrual cycles with emphasison identifying the cut-off for standard versus non-standard cycles.Here, we propose a mixture with Gumbel distribution to account forlong cycle lengths but also to account for shorter than average cyclelengths. Furthermore, we develop a joint model approach to assess thepatterns of menstrual cycle length within and between women, as wellas to assess the effect of lengths on fecundity.  We demonstrate thisapproach on menstrual cycle length and time-to-pregnancy data usingthe New York State Angler Cohort Prospective Pregnancy Study.",FALSE,FALSE,,FALSE,TRUE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Epidemiologic methods,Joint models for longitudinal and survival data,,,,,,,14-Nov-10,kohinoor@umich.edu,,Kohinoor Dasgupta,,"University of Michigan, Department of Statistics",439 West Hall,7345450591,,kohinoor@umich.edu,Modeling and Analysis of Multi-neuronal Spike Train Data,1,Kohinoor,,Dasgupta,"University of MichiganDepartment of Statistics",XuanLong,,Nguyen,,Stilian,,Stoev,,Vijay,,Nair,,,,,,,,,,,,,,,,,,,,,,,,,,"The time sequence of spikes generated by a set of neurons is referred to as multi-neuronal spike train data. Recent technical advances have allowed neuroscientists to collect and analyze huge amount of electrophysiological data at finer time scales. We propose some methods for modeling and estimating the connectivities among neurons and show how they can be used to identify the network structure. Our results allow estimation of the strengths of functional connections between neurons and reconstruct the graphical structure of the network that produced the spike data. We validate our methods on simulated data and present an analysis of data from cultures of cortical neurons.",FALSE,FALSE,,FALSE,FALSE,FALSE,,contributedposter,,,,FALSE,FALSE,FALSE,FALSE,Graphical models,Generalized linear models,,,,,,,03-Nov-10,koopm007@umn.edu,,Joseph S. Koopmeiners,Assistant Professor,"Division of Biostatistics, University of Minnesota","A460 Mayo Building, MMC 303",612-624-7486,,koopm007@umn.edu,A Simulation Study to Evaluate the Operating Characteristics of a Two-stage Study to Develop and Validate a Panel of Biomarkers for Predicting Prostate Cancer Recurrence,1,Joseph,S,Koopmeiners,"Division of Biostatistics, School of Public Health, University of MInnesota",Rachel,,Isaksson Vogel,"Biostatistics Core, University of Minnesota Masonic Cancer Center",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We consider study design for a two-stage study to develop and validatea panel of biomarkers for predicting prostate cancer recurrence. Instage one, a predictive model for prostate cancer recurrence isdeveloped using a set of candidate biomarkers. The study will beallowed to terminate for futility after stage one if initial estimatesof prognostic accuracy are unacceptable. If initial estimates ofprognostic accuracy are promising, the prognostic accuracy of thepredictive model is evaluated using a set of independent samples instage two. We present results from a simulation study to evaluate theeffect of design parameters (the proportion of samples used in stageone and the cutoff for early termination) and marker parameters(number of markers truly associated with prostate cancer recurrence,correlation between markers, etc.) on the type-I error rate, power andexpected sample size.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Diagnostic and screening tests,Power analysis/sample size,,,,,,,02-Nov-10,kosorok@unc.edu,,Michael R. Kosorok,Professor and Chair,University of North Carolina at Chapel Hill,"3101 McGavran-Greenberg Hall, CB 7420",9199668107,9199663804,kosorok@unc.edu,Personalized Medicine and Clinical Trials,1,Michael,R.,Kosorok,University of North Carolina at Chapel Hill,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In this talk, we discuss a number of issues in discovering and evaluating personalized medicine using clinical trials. Specifically, we propose using reinforcement learning to discover optimal dynamic treatment regimes for treating cancer and other life-threatening diseases. The approach we propose is to use a specially designed sequence of two randomized clinical trials that enables discovery and validation of these optimal regimens. Because these regimens are optimized over patient characteristics, including biomarkers, they are a form of personalized medicine. We discuss applications in non-small cell lung cancer, colorectal cancer and cystic fibrosis. We will also discuss briefly several open technical questions.",FALSE,FALSE,,FALSE,FALSE,TRUE,I also will be teaching a short course (SC7),invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Clinical trials,Machine learning,,,,,,,14-Nov-10,kristianlum@gmail.com,,Kristian Lum,postdoc,UFRJ,212 N. Duke Street,8572724701,,kristianlum@gmail.com,Spatial Population Estimation,1,Kristian,,Lum,UFRJ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"From ecology to epidemiology to human rights, many different fieldsare interested in ways to estimate the size of a population fromseveral incomplete lists. The traditional models employed for thispurpose typically assume that, although the probabilities of any givenlist recording a member of the population may vary,  all of themembers of the population are recorded by each list with the sameprobability. If this requirement cannot be met, the standard remedystratification to smaller sub-units. The degree to which the data canbe stratified is limited, however, if each stratum is treatedindependently. We propose instead a  model that accounts for spatialdependence in the parameters such that the total number of uncountedmembers within each stratum can be estimated simultaneously. Wepresent this first in terms of a simulation example and then applythis method to estimate the number of deaths and forced disappearancesin Casanare, Colombia from several administrative lists that recordedsuch human rights violations.",FALSE,FALSE,,FALSE,FALSE,FALSE,,contributedposter,,,,FALSE,FALSE,FALSE,FALSE,Demography and population studies,Bayesian methods,,,,,,,04-Nov-10,ktsakiri@ufl.edu,,KATERINA TSAKIRI,,Postdoctoral Student,"5400 NW 39th Avenue, K86 Apt",518-334-3033,,ktsakiri@ufl.edu,Separating and explaining different scales in water use time series,1,Katerina,,Tsakiri,"Postdoc StudentDepartment of Environmental Engineering Sciences University of FloridaP.O. Box 116450Gainesville, FL 32611",Igor,G.,Zurbenko,"ProfessorDepartment of Biometry and StatisticsState University of New York at AlbanyOne University PlaceRensselaer, NY 12144",James,P.,Heaney,"ProfessorDepartment of Environmental Engineering SciencesUniversity of FloridaP.O. Box 116450Gainesville, FL 32611",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We present techniques for studying the influence of the climatic andother variables for the explanation of the water use time series. Amethodology is described for separating the different time scalecomponents in time series of water use, namely, long term component,seasonal component, and short term component. We show thattemperature, precipitation, soil temperature, and relative humidityare the main climatic factors for the explanation of the long term,seasonal and short term component of the water use time series. Partof the residuals of the linear regression for the long term componentof water use can be explained by the unemployment rate.",FALSE,FALSE,,FALSE,FALSE,FALSE,,contributedposter,,,,FALSE,FALSE,FALSE,FALSE,Environmental and ecological applications,Time series,,,,,,,12-Oct-10,kun-chen@uiowa.edu,,Kun Chen,PhD Candidate,"Department of Statistics and Actuarial Science, Un",Department of Statistics and Actuarial Science,319-512-9234,319-335-3017,kun-chen@uiowa.edu,Reduced-rank Stochastic Regression with Sparse Singular Value Decomposition,1,Kun,,Chen,"Department of Statistics and Actuarial Science, University of Iowa",Kung-Sik,,Chan,"Department of Statistics and Actuarial Science, University of Iowa",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"For a reduced-rank multivariate stochastic regression model of, say, rank r, the regression coefficient matrix can be expressed as a sum of r unit-rank matrices each of which is proportional to the outer-product of the left and right singular vectors. For improving predictive accuracy and facilitating interpretation, it is often desirable that these left and right singular vectors be sparse or enjoy some smoothness property. We propose a regularized reduced-rank regression approach for solving the afore-mentioned problem. Computation algorithms and regularization parameter selection methods are developed, and the properties of the new method are explored both theoretically and by simulation. In particular, the proposed regularized estimator is shown to be asymptotically normal, selection consistent and enjoys the oracle property. We apply the proposed model to solving the biclustering problem with microarray gene expression data.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,TRUE,Multivariate methods,Variable subset selection/model selection,,,,,,,06-Oct-10,Kvasquez@salford-systems.com,,Katrina Vasquez,,Salford Systems,9685 Via Excelencia,6195438888,,kvasquez@salford-systems.com,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,FALSE,FALSE,,FALSE,FALSE,FALSE,,,,,,FALSE,FALSE,FALSE,FALSE,,,,,,,,,15-Nov-10,kwonde@mail.nih.gov,,Deukwoo Kwon,Research Fellow,National Cancer Institute,"6120 Executive Blvd.,",301-451-4348,,kwonde@mail.nih.gov,BAYESIAN VARIABLE SELECTION WITH BIOLOGICAL PRIOR INFORMATION,1,Deukwoo,,Kwon,National Cancer Institute,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Complex diseases are functionally caused by a combination ofenvironmental and genetic factors. Epidemiologists are posed with the problem of determining the specific causes and combinations of risk factors. With inexpensive genotyping technology available, in genetic association studies we analyze several thousands single nucleotide polymorphisms for each individual. Due to the large numbers of predictors available in genetic studies, we need to use variable selection techniques to decide which effects to include in a model that relates risk factors to phenotypic outcomes. Therefore, we present a hierarchical Bayesian variable selection method, which is an extension of the stochastic search variable selection. We introduce two latent binary vectors in a hierarchical manner to model the relationship between genes and SNPs and use generalized linear models to relate them to a phenotype. Whenbiological pathways information is available we need to incorporate this prior information into variable selection method.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Hierarchical models,High dimensional data,,,,,,,15-Nov-10,kzhang@ms.soph.uab.edu,,KUI ZHANG,,"Department of Biostatistics, University of Alabama",1665 University Blvd.,205-996-4094,,kzhang@ms.soph.uab.edu,A Hidden Markov Model for Haplotype Inference for Presentabsent Genotype data Using Previously Identified Haplotype and Haplotype Patterns,5,Jihua,,Wu,"Section on Statistical Genetics, Department of Biostatistics, University of Alabama at Birmingham, Birmingham, AL",Guo-bo,,Chen,"Section on Statistical Genetics, Department of Biostatistics, University of Alabama at Birmingham, Birmingham, AL",Degui,,Zhi,"Section on Statistical Genetics, Department of Biostatistics, University of Alabama at Birmingham, Birmingham, AL",Nianjun,,Liu,"Section on Statistical Genetics, Department of Biostatistics, University of Alabama at Birmingham, Birmingham, AL",Kui,,Zhang,"Section on Statistical Genetics, Department of Biostatistics, University of Alabama at Birmingham, Birmingham, AL",,,,,,,,,,,,,,,,,,,,,"Killer immunoglobulin-like receptor (KIR) genes vary considerably in their presence or absence on a specific regional haplotype. Because presence or absence of these genes is largely detected using locus-specific genotyping technology, the distinction between homozygosity and hemizygosity is often ambiguous. The performance of methods for haplotype inference for KIR genes may be compromised due to the large portion of ambiguous data. At the same time, many haplotypes or partial haplotype patterns have been previously identified and can be incorporated to facilitate haplotype inference for unphased genotype data. To accommodate the increased ambiguity of present-absent genotyping of KIR genes, we developed a hidden Markov model, which incorporated information about identified haplotypes or partial haplotype patterns and compared several measures on simulated KIR genotype in order to evaluate the reliability of haplotype assignments and the accuracy in estimating haplotype frequency. The simulation study shows that our method outperformed the two existing techniques (HAPLO-IHP and PHASE) by all five measures when either 60% or 25% of previously identified haplotypes were incorporated into the analyses. We also used our model to analyze the KIR genes and obtained some interesting results.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Statistical genetics,Computational methods,,,,,,,06-Nov-10,l.endrenyi@utoronto.ca,,Laszlo Endrenyi,Professor Emeritus,University of Toronto,Department of Pharmacology,416-925-3779,416-978-6395,l.endrenyi@utoronto.ca,Determination of the similarity of follow-on biologics,1,Laszlo,,Endrenyi,University of Toronto,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Different study designs and differing procedures of calculations are usually required for determining the similarity of two follow-on biologics and for evaluating the bioequivalence of two drug products with small molecules. The similarity of drug disposition and not of absorption is studied.  Also, due to the typically long half-lives, parallel group rather than crossover designs are usually applied.  Furthermore, total variation, both between and within subjects, is relevant and not just intraindividual variation.  Consequently, the prescribability of drugs, and not the switchability of products, is important.  Nevertheless, an approach evaluating the bioequivalence of highly-variable small molecules could be applied also for assessing the similarity of follow-on biologic products.    Standardized comparisons of metrics have valuable clinical interpretations.  Moreover, they yield acceptances which are much higher than comparisons without standardization.  The resulting producer risks are independent of the variability.  Application of the approach to the quantitative comparison of follow-on biologics is discussed.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Biopharmaceutical research,Pharmacokinetic/pharmacodynamics (PK/PD) modeling,,,,,,,15-Nov-10,l.zhang@emory.edu,,Lijun Zhang,,Emory Univ,"1518 Clifton Rd, NE",404-727-9169,,l.zhang@emory.edu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,FALSE,FALSE,,FALSE,FALSE,FALSE,,,,,,FALSE,FALSE,FALSE,FALSE,,,,,,,,,08-Nov-10,laan@berkeley.edu,,Mark van der Laan,Professor,UC Berkeley,"108 Haviland Hall, Division of Biostatistics",510-643-9866,510-643-5163,laan@berkeley.edu,Targeted MLE of Causal Effect in Case-Control Studies,1,Mark,J,van der Laan,UC Berkeley,Sherri,,Rose,UC Berkeley,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Case-control sampling is an extremely common design used to generatedata to estimate effects of exposures or treatments on a binaryoutcome of interest when the proportion of cases (i.e., binary outcomeequal to 1) in the population of interest is low. We present a general proposed methodology, involving a simpleweighting scheme of cases and controls, that maps any estimationmethod for a parameter developed for prospective sampling from thepopulation of interest into an estimation method based on case-controlsampling from this population. For regular case-control designs theweighting only relies on knowing the true population proportion ofcases or, equivalently, the true probability of being a case, and formatched case-control sampling it also relies on knowing thisproportion of cases within each population strata of the matchingvariable.We show that this case-control weighting of an efficient estimator fora prospective sample from the target population of interest maps intoan efficient estimator for matched and unmatched case-control sampling. We show how application of this generic methodology provides us withdouble robust locally efficient targeted maximum likelihood estimatorsof the causal relative risk and causal odds ratio for regular casecontrol sampling and matched case control sampling.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Causal inference,Epidemiologic methods,,,,,,,21-Oct-10,laber@umich.edu,,Eric B Laber,,University of Michigan,1085 S University,7343309675,,laber@umich.edu,Statistical Inference in Dynamic Treatment Regimes,1,Eric,B,Laber,University of Michigan,Min,,Qian,Columbia University,Susan,A,Murphy,University of Michigan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Clinical researchers wanting to make principled (evidence based) rulesfor tailoring treatment have run multi-stage randomized clinical trials in order toevaluate and compare different long-term treatment strategies.Q-learning and other extensions of regression to multi-stage data canbe usedeffectively to construct decision rules that lead to a favorableclinical outcome.  However, in order for these methods to be more widely adopted, one must be ableto conductstatistical inference.  In particular, one must be able to able toanswer the following types of questions: Do two treatment strategies result in significantlydifferent clinical outcomes?Which patient variables are relevant for tailoring treatment? The need to address these questions has led us to develop newstatistical methodology that allowsfor the construction of valid confidence intervals for parameters inthe regression modelsused in Q-learning.  The focus of this talk will be on the use of this new methodology to construct meaningful and interpretable regression models via Q-learning and the application of confidenceintervals to glean relevant scientific knowledge.  We illustrate these ideas by means ofa case study of the {\it Study of the Adaptive Interventions for Children with ADHD Trial}.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Other,Adaptive design/adaptive randomization,Dynamic Treatment Regimes,,,,,,15-Nov-10,lan.huang@fda.hhs.gov,,lan huang,mathematical statistician,FDA,"10903 New Hampshire Ave,  Bldg 21, Room 3629",3017965121,,lan.huang@fda.hhs.gov,Investigation of methods for identifying a predictive biomarker for the occurrence of disease with application to an imaging data for cardiac events,1,lan,,huang,FDA,Jyoti,,Zalkikar,FDA,Ram,,Tiwari,FDA,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"It is important and a challenge to identify new risk factors for specific disease in medical research. Sometimes, it is easy to show an association between a possible risk factor and a disease in epidemiologic studies, but the existence of an association does not always indicates the existence of a good prognostic marker for early diagnosis or predicting the occurrence of disease for individuals. There are two possible approaches for evaluating the ability of a factor to distinguish two groups of subjects with disease progression over time: time-to-event analysis approach (such as Kaplan Meier (KM) method and log-rank test for comparing two survival curves), and sensitivity and specificity analysis approach (such as traditional sensitivity and specificity evaluation, constructing ROC curves and AUC comparison, and time-dependent ROC analysis).  Through a simulation study, we compare some of these methods and develop a new method for time dependent sensitivity and specificity analysis using time-dependent logistic model and ROC analysis. We apply all discussed methods to a real imaging data for predicting the progression of some specific cardiac events in patients with NYHA (New York Hear Association) class II or class III heart failure and left ventricular dysfunction.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Biomarkers/surrogate markers,ROC analysis,,,,,,,11-Nov-10,lan-yan.yang@duke.edu,,Lan-Yan Yang,,Duke University School of Medicine,"2424 Erwin Rd, Hock Suite 1102, Room 11069",919-668-8004,,lan-yan.yang@duke.edu,Bayesian approach for assessment of biosimilarity based on reproducibility probability,1,Lan-Yan,,Yang,"Duke University School of Medicine, Durham, North Carolina, USA",Shein-Chung,,Chow,"Duke University School of Medicine, Durham, North Carolina, USA",Tsung-Cheng,,Hsieh,"Institute of Medical Sciences, Buddhist Tzu-Chi University, Hualien, Taiwan",Eric,,Chi,"Amgen, Inc., Thousand Oaks, California, USA",,,,,,,,,,,,,,,,,,,,,,,,,"In recent years, bioavailability/bioequivalence studies are of particular interest for approval of generic copies of drugs products. As indicated in the United States Food and Drug Administration guidance for assessment of average bioequivalence, the adopted criterion for bioequivalence is moment-based using log-transformed primary pharmacokinetic responses based on the bioequivalence limit of (80%, 125%). Unlike small molecule drug products, however, the development of biologic products is very different. For example, biologic product manufacturing process is very sensitive to small variations that commonly occur in the manufacturing process. In this study, we propose a Bayesian approach for the reproducibility probability for assessing the bioequivalence or biosimilarity. A simulation study for comparing the proposed approach and the traditional two on-sided test procedure is discussed. The criterion of the reproducibility probability for bioequivalence/biosimilarity study could be obtained based on the comparison of a reference product to the reference product study. The approach for evaluating this criterion is also discussed.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Biopharmaceutical research,Bayesian methods,,,,,,,08-Nov-10,laurence.detorrente@epfl.ch,,Laurence de TorrentŽ,,Ecole Polytechnique FŽdŽrale de Lausanne (EPFL),MA B1 443,+4176 5168210,,laurence.detorrente@epfl.ch,Weakness of Cross-Validation,1,Laurence,,de TorrentŽ,Ecole Polytechnique FŽdŽrale de Lausanne (EPFL),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Cross-validation is often used to select a model with a single dataset. It mimicks the situation, where a fresh dataset is available to validate a model. This old and simple methods splits the dataset into two parts, one for fitting and the other for validating. K-Fold (KFCV) and Leave-One-Out (LOOCV) Cross-Validation are the best-known versions.The main goal of this work is to show that cross-validation can be fooled.We consider a case-control study with binary predictors in which the cases and the controls (the class membership) are to be classified by simple functions of the predictors. In a null case, where the predictors are independent Bernoulli variables not linked to the class membership, any cross-validation will be fooled if a predictor variable agrees with the class membership in all but a few positions. We show that cross-validation has difficulties if we add two-factor and three-factor interactions.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Variable subset selection/model selection,Categorical data,,,,,,,28-Oct-10,laurence.detorrente@gmail.com,,Laurence de TorrentŽ,,EPFL,MA B1 443,+4176 5168210,,laurence.detorrente@gmail.com,Cross-Validation weaknesses,1,Laurence,,de TorrentŽ,Ecole Polytechnique FŽdŽrale de Lausanne (EPFL),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Cross-Validation is often used to select a model with a single dataset. It mimicks the situation, where a fresh dataset is available to validate a model. This old and simple method splits the dataset into two parts, one for fitting and the other for validating. K-Fold (KFCV) and Leave-One-Out (LOOCV) Cross-Validation are the best-known versions.The main goal of this work is to show that cross-validation can be fooled.We consider a case-control study with binary predictors in which the cases and the controls (the class membership) are to be classified by simple functions of the predictors. In a null case, where the predictors are independent Bernoulli variables not linked to the class membership, any cross-validation will be fooled if a predictor variable agrees with the class membership in all but a few positions. We show that cross-validation has difficulties if we add two-factor and three-factor interactions.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,,,,,,,,,17-Sep-10,lchen11@uchicago.edu,,Lin Chen,Assistant Professor,The University of Chicago,5841 S Maryland Ave MC2007,773-702-1626,,lchen11@uchicago.edu,A regularized Hotelling's T2 test for pathway analysis in proteomic studies,1,Lin,S,Chen,"Department of Health Studies, The University of Chicago, IL.",Debashis,,Paul,"Department of Statistics, University of California, Davis, CA.",Ross,L,Prentice,"Division of Public Health Sciences, Fred Hutchinson CancerResearch Center, WA.",Pei,,Wang,"Division of Public Health Sciences, Fred Hutchinson CancerResearch Center, WA.",,,,,,,,,,,,,,,,,,,,,,,,,"Recent proteomic studies have identified proteins related to specificphenotypes. In addition to marginal association analysis forindividual proteins, analyzing pathways may yield additional valuableinsights. Identifying pathways that differ between phenotypes can beconceptualized as a multivariate hypothesis testing problem: whetherthe mean vector u of a p-dimensional random vector X is u0. Proteinswithin the same biological pathway may correlate with one another in acomplicated way, and type I error rates can be inflated if suchcorrelations are incorrectly assumed to be absent. The inflation tendsto be more pronounced when the sample size is very small or there is alarge amount of missingness in the data, as is frequently the case inproteomic discovery studies. To tackle these challenges, we propose aregularized Hotelling's T2 (RHT) statistic together with anon-parametric testing procedure, which effectively controls the typeI error rate and maintains good power in the presence of complexcorrelation structures and missing data patterns. We investigateasymptotic properties of the RHT statistic under pertinent assumptionsand compare the test performance with four existing methods throughsimulation examples. We apply the RHT test to a hormone therapyproteomics data set, and identify several interesting biological pathways.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Multivariate methods,Proteomics,,,,,,,15-Nov-10,ldeng6@its.jnj.com,,Ling,Biostatistician,Johnson & Johnson Pharma R&D,57 York Drive,908-927-4351,,ldeng6@its.jnj.com,A More Powerful Test Based on Ratio Distribution for Retention Non-inferiority Hypothesis,1,Ling,,Deng,"Clinical Biostatistics, Johnson & Johnson Pharmaceutical R&D",Gang,,Chen,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Rothmann et al. (2003) proposed a method for the statistical inference of fraction retention non-inferiority (NI) hypothesis. One of the major concerns using this method in the design of a NI trial is that with limited sample size the study power is usually very low.  This makes a NI trial not applicable particularly when using time to event endpoint. To improve power, Wang et al. (2006) proposed a ratio test based on asymptotic normality theory. However a strong assumption of equal variance for the NI test statistics under null and under alternative hypotheses, which is generally not practical for a NI trial, is used in the sample size calculation.  With this assumption the sample size requirement is much lower in the design of a NI trial comparing to using Rathmanns method. In this paper, this strong assumption is removed in our proposed ratio test method, which is derived directly from Cauchy-like ratio distribution.  In addition, using this method, the fundamental assumption used in Rothmanns method that the observed control effect is always positive is no longer necessary. With the same assumption as used in Rothmanns method, the sample size based on the proposed distribution ratio test for a fraction retention NI hypothesis is significantly decreased. In addition, the proposed test statistics is more robust since exact ratio distribution rather than asymptotic theory is applied.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,TRUE,Power analysis/sample size,"Biologics, pharmaceuticals, medical devices",,,,,,,03-Nov-10,leem5@mail.nih.gov,,Minjung Lee,Statistician,National Cancer Institute,6116 Executive Blvd.,301-496-9272,301-480-2046,leem5@mail.nih.gov,Predicting the absolute risk of dying from colorectal cancer and from other causes using population based cancer registry data,1,Minjung,,Lee,National Cancer Institute,Kathleen,A,Cronin,National Cancer Institute,Mitchell,H,Gail,National Cancer Institute,Eric,J,Feuer,National Cancer Institute,,,,,,,,,,,,,,,,,,,,,,,,,"In this talk, we describe how population cancer registry data from theSurveillance, Epidemiology, and End Results (SEER) program of theNational Cancer Institute (NCI) can be used to develop a prognosticmodel to predict the absolute risk of mortality from cancer and fromother causes for an individual with specific covariates. Itincorporates previously developed methods for competing risk modelingalong with an imputation method to address missing cause of deathinformation. We illustrate these approaches with colorectal cancer andevaluate the model discriminatory and calibration accuracy by the areaunder the receiver operating characteristic curve and calibration plot.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Survival analysis,Cancer applications,,,,,,,08-Nov-10,leena.choi@vanderbilt.edu,,Leena Choi,Assistant Professor of Biostatistics,Vanderbilt University,"1161 21st Ave. South, S-2323 MCN",615-343-3497,615-343-4924,leena.choi@vanderbilt.edu,A Bayesian hierarchical nonlinear mixture model in the presence of artifactual outliers in a population pharmacokinetic study,1,Leena,,Choi,Vanderbilt University,Brian,S,Caffo,Johns Hopkins University,Utkarsh,,Kohli,Vanderbilt University,C. Michael,,Stein,Vanderbilt University,,,,,,,,,,,,,,,,,,,,,,,,,"The purpose of this study is to develop statistical methodology toestimate pharmacokinetic (PK) parameters in the presence of a largeproportion of artifactual outliers. The motivating PK data wereobtained from a population PK study to examine associations between PKparameters such as clearance of dexmedetomidine and cytochrome P4502A6 variants. The blood samples were sparsely sampled from patients inintensive care units (ICUs) while different doses of dexmedetomidinewere continuously infused. Conventional population PK analysis ofthese data revealed several challenges and intricacies. Especially,there was strong evidence that some plasma drug concentrations wereartifactually high and likely contaminated with the infused drug dueto blood sampling processes that are sometimes unavoidable in an ICUsetting. If not addressed, or if arbitrarily excluded, these outlyingvalues could lead to biased estimates of PK parameters. We propose anovel population PK model, a Bayesian hierarchical nonlinear mixturemodel, to accommodate the artifactual outliers using a finite mixtureas the residual error model. Our results showed that the proposedmodel handles the outliers well. We also conducted simulation studieswith a varying proportion of the outliers. These simulation resultsshowed that the proposed model can accommodate the outliers well.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Pharmacokinetic/pharmacodynamics (PK/PD) modeling,Hierarchical models,,,,,,,06-Nov-10,leex2919@umn.edu,,Sang Mee Lee,,University of Minnesota,601 Ontario St. S.E. #1,612-709-2394,,leex2919@umn.edu,Likelihood based approach to identify gene sets with either up- or down-regulated genes,1,Sang Mee,,Lee,University of Minnesota,Baolin,,Wu,University of Minnesota,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We study statistical methods for identifying gene sets which are significantly enriched with either up- or down-regulated genes. Most existing enrichment testing methods are based commonly on the overall magnitude of gene expressions and do not distinguish specific types of regulation. We describe a flexible two-component mixture model that takes account of potential dependence among genes and propose a likelihood ratio testing approach for assessing significance of one-sided enrichment. Through simulation studies and application to leukemia gene expression data, we illustrate the competitive performance of the proposed method.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Computational methods,Statistical genetics,,,,,,,02-Nov-10,lekang@buffalo.edu,,LE KANG,,University at Buffalo,Department of Biostatistics,7165755898,,lekang@buffalo.edu,A Monte Carlo EM algorithm for the estimation in latent class model analysis: application for assessing accuracy of diagnostic tests of cervical neoplasia in women with AGC,1,Le,,Kang,"Department of Biostatistics, University at Buffalo",Randy,,Carter,"Department of Biostatistics, University at Buffalo;GOG Statistical and Data Center, Roswell Park Cancer Institute",Kathleen,,Darcy,"GOG Statistical and Data Center, Roswell Park Cancer Institute",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In this article we use a latent class model to assess diagnostic test accuracy in situations where the true disease status is not observed, but observations on three or more diagnostic tests are available. We consider the simple case where the observed tests are assumed to be conditionally independent. A Monte Carlo EM algorithm is implemented to get parameter estimates of interest; namely, sensitivity and specificity of diagnostic tests and prevalence of the disease as a byproduct. To calculate the confidence intervals of estimated parameters, the missing information principle to the observed information matrix is applied. We compare the adjusted information matrix estimates with the estimates from bootstrap approach throught a simulation study and conclude the diagnostic accuracy among the reference diagnostic tests of cervical neoplasia in women with AGC with that of an imperfect 'gold standard' histological diagnosis.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,TRUE,Diagnostic and screening tests,Latent variables,,,,,,,15-Nov-10,lenarcic@post.harvard.edu,,Alan Lenarcic,Postdoctoral researcher,University of North Carolina,5 Howell Street #7,908-463-1382,,lenarcic@post.harvard.edu,Multiple Latent Trait Interaction Graphical Model,1,Alan,B,Lenarcic,University of North Carolina,William,,Valdar,University of North Carolina,Edo,,Airoldi,Harvard,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We posit a probabilistic generating model for interaction networks forboth the biological pathway and social epidemiology settings. Converting the Bagarow et al. 2009 insight, that individual nodes,whether they represent people or molecules, might not be classifiableonly as members of particular categories, but that their interactionswith different actors can be based upon multiple propertiesdetermining the connection, we model a connection then as coming froma successful interaction between two nodes based upon sharedaffinities.  An EM model allows affinities to be learned unsupervisedfrom the graphical structure.  Applied to Facebook data, we establishwhether a technique could discover particular properties of nodes thatdrive a contagion.  Applied to functional genomic screening, we hopeto understand whether a multi-trait model can provide insight anddescription into cascades, identifying agents to target.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Graphical models,Latent variables,,,,,,,08-Nov-10,lfan@umich.edu,,Ludi Fan,,University of Michigan,Department of Biostatistics,734 604 3346,,lfan@umich.edu,Comparing Cumulative Incidence Functions between Non-Randomized Groups in the Presence of Competing Risks,1,Ludi,,Fan,University of Michigan,Douglas,E,Schaubel,University of Michigan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In the presence of competing risks, it is often of interest to comparecumulative incidence functions (CIFs) among groups of subjects. Whengroup membership is not randomized, meaningful group-specificcontrasts require correction for imbalances in group-specificcovariate distributions. The application which motivated our workinvolves evaluating organ procurement organizations (OPOs) withrespect to the probability that a patient wait-listed for kidneytransplantation receives a transplant, in the presence of death as acompeting risk.  We propose two methods for comparing group-specificCIFs to an overall average. Both methods involve comparing the CIF ofeach OPO to that of a hypothetical average OPO. The CIFs are estimatedby averaging over fitted values from stratified Cox models of thecause-specific hazards. Both methods yield an observed minusexpected measure. The second method replaces the observed term fromthe first method with a weighted count, meaning that results of theCox models will only be used in aggregate form in the expected term.The proposed measures have interpretations from a causal inferenceperspective. Large-sample properties are derived using martingale andempirical process theory, with finite-sample properties evaluatedthrough simulation. We apply the methods to data from a national organtransplant registry.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Survival analysis,Causal inference,,,,,,,04-Nov-10,lhua@sdac.harvard.edu,,Lei Hua,Research Associate,Center for Biostatistics in AIDS Research,"651 Huntington Ave. HSPH, FXB 514",(617)432-2526,(617)432-3163,lhua@sdac.harvard.edu,Semiparametric Estimating Method for Over-dispersed Panel Count Data,1,Lei,,Hua,"Center for Biostatistics in AIDS Research (CBAR), Harvard School of Public Health",Ying,,Zhang,"Department of Biostatistics, University of Iowa",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Over-dispersed panel count data are often seen in real data,especially in medical applications. Neglecting over-dispersion leadsto a loss of efficiency. We propose to analyze over-dispersed panelcount data using a Gamma-Frailty nonhomogeneous Poisson model.Conditioning on a Gamma distributed frailty term, the cumulativecounts are assumed to follow a nonhomogeneous Poisson process.Variance of the frailty term helps to capture both the over-dispersionand correlation between counts within non-overlapping intervals.Parameters in the mean structure are estimated by maximizing a pseudolikelihood where the nuisance over-dispersion parameter is replaced byits consistent estimate. The asymptotic properties of the proposedpseudo maximum likelihood estimator are proved using modern empiricalprocess theory. Simulation studies show the proposed estimator is more efficient interms of a smaller standard error when over-dispersion is present.When using a spline-based standard error estimation method, accountingfor the over-dispersion based on Gamma-Frailty nonhomogeneous Poissonmodel also produces a smaller bias. The proposed method is applied tothe data from a bladder tumor clinical trial.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Longitudinal data,Nonparametric methods,,,,,,,12-Oct-10,lhund@hsph.harvard.edu,,Lauren Hund,,Harvard University,655 Huntington Avenue,8067894450,,lhund@hsph.harvard.edu,A Geostatistical Approach to Large-Scale Disease Mapping with Temporal Misalignment,1,Lauren,,Hund,Harvard University,Jarvis,T,Chen,Harvard School of Public Health,Nancy,,Krieger,Harvard School of Public Health,Brent,A,Coull,Harvard School of Public Health,,,,,,,,,,,,,,,,,,,,,,,,,"Breast cancer incidence is historically higher in women with moresocioeconomic resources, though researchers predict that this gradientin breast cancer incidence is decreasing with time.  We aim to addressthis hypothesis by examining data associations in cancer registry andcensus data from Los Angeles County, CA.  However, U.S. census tractboundaries change over time, and standard spatiotemporal diseasemapping techniques are difficult to apply in this setting.  Toovercome the temporal boundary misalignment issues in our data, weconstruct a geostatistical model for aggregate count data within theframework of a GLMM using radial splines.  By assuming that anunderlying continuous risk surface induces spatial correlation betweenareas, boundary misalignment becomes a non-issue.  Additionally, thisdisease mapping framework facilitates fast, easy model fitting byusing a PQL approximation to maximum likelihood estimation.  Weanticipate that the method will also be useful for large diseasemapping datasets for which fully-Bayesian approaches are infeasible. We apply our method to quantify changes in the socioeconomic gradientin breast cancer incidence in Los Angeles between the periods1988-1992 and 1998-2002.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Spatial/temporal modeling,Computational methods,,,,,,,29-Oct-10,li.698@buckeyemail.osu.edu,,Chih-Lin Li,,The Ohio State University,1811 Kenny Road Apt C,614-7720308,,li.698@buckeyemail.osu.edu,Causal Inference in Repeated Cross-Sectional Observational Studies,2,Bo,,Lu,The Ohio State University,Chih-Lin,,Li,The Ohio State University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In health studies, many intervention programs are observationalstudies and successful programs may be repeated over time withdifferent participants. Estimating causal effects in repeatedcross-sectional observational studies is more challenging than asingle-time cross-sectional study due to (1) lack of randomizations,(2) other health-related policy changes interfering with theintervention of interest, and (3) the effect changing over time.Following Rubin's potential outcomes frame work, we propose apropensity score matching based method to estimate causal parametersfor various effects. In the post-matching analysis, a robust rankbased difference-in-difference analysis is performed to estimateeffects. For repeated cross-sectional studies, the hidden bias mayarise from unmeasured confounders, time-dependent effect modifiers, orboth. We consider a sensitivity analysis using adifference-in-difference-in-difference estimator to assess thetemporal stability assumption. The proposed method will be illustratedby an Italian smoking cessation study.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Causal inference,Epidemiologic methods,,,,,,,08-Nov-10,liang.zhu@stjude.org,,Liang Zhu,Assistant Member,St.Jude Children's Research Hospital,"MS 768, Room R6037",901-6266857,,liang.zhu@stjude.org,Semiparametric Transformation Models for Joint Analysis of Multivariate Recurrent and Terminal Events,1,Liang,,Zhu,St. Jude Children's Research Hospital,Jianguo,,Sun,"University of Missouri, Columbia",Xingwei,,Tong,Beijing Normal University,Deo,Kumar,Srivastava,St. Jude Children's Research Hospital,,,,,,,,,,,,,,,,,,,,,,,,,"Recurrent event data occur in many clinical and observational studies, and in these situations, there may exist a terminal event such as death that is related to the recurrent event of interest. In addition, sometimes more than one type of recurrent event may occur, that is, one may encounter multivariate recurrent event data with some dependent terminal event. For the analysis of such data, one must take into account the dependence among different types of recurrent events and that between the recurrent events and terminal event. In this paper, we propose a joint-modeling approach for regression analysis of the data and establish the finite and asymptotic properties of the resulting estimates of unknown parameters. The method is applied to a set of bivariate recurrent event data arising from a long-term follow-up study of childhood cancer survivors.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Longitudinal data,Survival analysis,,,,,,,15-Nov-10,lichenuky@uky.edu,,Li Chen,,University of Kentucky,"800 Rose St., CC453                                                                     800 Rose St., CC453       800 Rose St., CC453",9199237536,,lichenuky@uky.edu,Predictive Accuracy of Covariates for Event Times,1,Li,,Chen,University of Kentucky,Danyu,,Lin,University of North Carolina at Chapel Hill,Donglin,,Zeng,University of North Carolina at Chapel Hill,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We propose a graphical measure, the generalized negative predictive value function, to quantify the predictive accuracy of covariates for survival time or recurrent event times. This new measure characterizes the event-free probabilities over time conditional on a thresholded linear combination of covariates and has direct clinical utility. We show that this function is maximized at the set of covariates truly related to event times and thus can be used to compare the predictive accuracy of different sets of covariates. We construct nonparametric estimators for this function under right censoring and prove that the proposed estimators, upon proper normalization, converge weakly to zero-mean Gaussian processes. We develop simple Monte-Carlo inference procedures to bypass the estimation of complex density functions involved in the asymptotic distributions. Simulation studies demonstrate that the proposed methods perform well in practical situations. Two clinical studies are presented.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Survival analysis,Biomarkers/surrogate markers,,,,,,,11-Nov-10,lil@email.sc.edu,,LI LI,,University of South Carolina,Department of Statistics,8033972920,,lil@email.sc.edu,Testing Homogeneity of Survival/Reliability Distributions Stemming from Different Maintenance Decisions,1,LI,,LI,University of South Carolina Department of Statistics,Tim,,Hanson,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We consider a recurrent events setting that is relevant to a reliability situation where components in a system wear out and need to be repeatedly repaired (with differing, possibly unknown amounts of success) over time, and (b) the clinical setting where a patient undergoes one of several possible treatments at each event time.  It is of interest to test whether the survival/reliability distribution changes with different maintenance (or treatment) decisions, while adjusting for other covariates, and further quantify how the failure time distribution changes.  In the reliability literature it has been shown that incorrectly assuming the distribution does not change with the maintenance decisions can lead to a ``spiral down' effect (Cooper, de Mello, & Kleywegt, 2006) where decisions get progressively worse because the estimation process ignores the fact that future observations might be influenced by decisions.  We consider a generalization of the dependent linear tail free process (Jara & Hanson, 2011) as a means to test the decision-dependence hypothesis and offer a ready modeling strategy under the alternative.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Bayesian methods,Nonparametric methods,,,,,,,11-Nov-10,lili.ding@cchmc.org,,Lili Ding,Research Associate,Cincinnati Children's Hospital Medical Center,3333 Burnet Ave. MLC 5041,(513) 803-0931,,lili.ding@cchmc.org,A semiparametric Bayesian approach to population pharmacokinetic modeling,1,Lili,,Ding,Cincinnati Children's Hospital Medical Center,Bin,,Huang,Cincinnati Children's Hospital Medical Center,Siva,,Sivaganesan,University of Cincinnati,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Population pharmacokinetics (PK) uses nonlinear mixed effects models to study the concentration profile of a given drug during the process of its absorption, distribution, metabolism and excretion. The major objectives of population PK studies include the estimation of PK parameters and the evaluation of the sources of between and within individual variability. Parametric population PK models assume a specific parametric distribution for PK parameters, most often the normal or log-normal distribution. However, the parametric distribution assumption may not always hold. We study a semiparametric Bayesian approach to population PK modeling where we use a Dirichlet process prior for the distribution of the PK parameters. Using both simulation studies and real data examples, we illustrate the advantages of the semiparametric model over the parametric model in the estimation of PK parameters, the estimation of the distribution of the PK parameters, and the prediction of observed concentration data.",FALSE,FALSE,,FALSE,TRUE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Pharmacokinetic/pharmacodynamics (PK/PD) modeling,Nonparametric methods,,,,,,,15-Nov-10,limc2@niehs.nih.gov,,Changwon Lim,,NIEHS,111 TW Alexander Dr,9195419956,,limc2@niehs.nih.gov,Preliminary Test Estimation Procedures in High Throughput Screening Assays,1,Changwon,,Lim,"Biostatistics Branch, NIEHS, NIH, 111 T. W. Alexander Dr, RTP, NC 27709",Pranab,K,Sen,"Department of Biostatistics, University of North Carolina at Chapel Hill, 3101 McGavran-Greenberg, CB#7420, Chapel Hill, NC 27599",Shyamal,D,Peddada,"Biostatistics Branch, NIEHS, NIH, 111 T. W. Alexander Dr, RTP, NC 27709",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Quantitative high throughput screening (qHTS) assays use cells or tissues to screen thousands of compounds in a short period of time. Data generated from qHTS assays are then fitted using a nonlinear regression model and decisions regarding toxicity of a chemical are made using the estimates of the parameters of the model. For such data sets, the error variance may be homoscedastic or heteroscedastic. Because thousands of compounds are evaluated in qHTS assays based on the estimates of the parameters of nonlinear models, it is important to apply an estimation procedure which is robust to the error variance structure. Additionally, it is desirable for the procedure to be robust to outliers and influential observations. In this talk we describe a preliminary test estimation (PTE) based methodology for drawing inferences regarding the parameters of a Hill model with application to qHTS assays. Performance of the PTE based methodology, in terms of false discovery rate (FDR) and power, is evaluated using a simulation study mimicking a real qHTS data. Results indicate that the proposed methodology achieves substantial reduction in FDR while not losing much power. Using a data set obtained from the National Toxicology Program (NTP), we illustrate the proposed methodology.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Nonlinear models,Biopharmaceutical research,,,,,,,14-Oct-10,lin.huo@uth.tmc.edu,,Lin Huo,,"Biostatistics, The University of Texas","1400 Pressler Street, Unit 1411, FCT4.6089",713-401-4003,,lin.huo@uth.tmc.edu,Bayesian Dose Finding in Combinations with Discrete-Dose and Continuous-Dose Drugs,1,Lin,,Huo,The University of Texas M.D. Anderson Cancer Center,Ying,,Yuan,The University of Texas M.D. Anderson Cancer Center,Guosheng,,Yin,The University of Hong Kong,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Treating patients with combined agents is a growing trend in cancerclinical trials. Evaluating the synergism of multiple drugs is oftenthe primary motivation for such drug-combination studies. To enhancethe patient outcome, a new cancer therapeutic agent is ofteninvestigated together with an existing standard of care (SOC) agent. Acertain fixed dosage of the SOC is often administered in order tomaintain some therapeutic effects in patients. Motivated by a recentdrug-combination trial with a continuous-dose SOC and adiscrete-dose investigational agent, we propose a two-stage Bayesianadaptive dose-finding design. The first stage takes a continualreassessment method to locate the appropriatedose for the discrete-dose investigational agent while fixing thecontinuous-dose SOC at the minimal therapeutic dose. In the secondstage, we make a fine dose adjustment by calibrating the continuousdose to achieve the target toxicity rate as closely as possible basedon the posterior estimates for the joint toxicity probabilities of thecombined doses. Based on the accumulating data, we adaptively assigneach new cohort of patients to themost appropriate dose combination. We conduct extensive simulationstudies to examine the operating characteristics of the design anddemonstrate the design's good performancewith practical scenarios.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,TRUE,Adaptive design/adaptive randomization,Bayesian methods,,,,,,,15-Nov-10,lin@bios.unc.edu,,Danyu Lin,Professor,University of North Carolina,"Dept of Biostatistics, Box 7420",919-843-5134,,lin@bios.unc.edu,Predictive accuracy of covariates for event times,2,Li,,Chen,University of Kentucky,D.,Y.,Lin,University of North Carolina,Donglin,,Zeng,University of North Carolina,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We propose a graphical measure, the generalized negative predictivevalue function, to quantify the predictive accuracy of covariates forsurvival time or recurrent event times.  This new measurecharacterizes the event-free probabilities over time conditional on athresholded linear combination of covariates and has direct clinicalutility.  We show that this function is maximized at the set ofcovariates truly related to event times and thus can be used tocompare the predictive accuracy of different sets of covariates. Weconstruct nonparametric estimators for this function under rightcensoring and prove that the proposed estimators, upon propernormalization, converge weakly to zero-mean Gaussian processes.  Wedevelop simple Monte-Carlo inference procedures to bypass theestimation of  complex density functions involved in the asymptoticdistributions. Simulation studies demonstrate that the proposedmethods perform well in practical situations. Two clinical studies arepresented.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Survival analysis,Clinical trials,,,,,,,15-Oct-10,lindsay_renfro@baylor.edu,,Lindsay A. Renfro,M.S.,Baylor University,3711 Holland Avenue,979 525 1810,979 247 4062,lindsay_renfro@baylor.edu,Bayesian Adaptive Trial Design for a Newly Validated Surrogate Endpoint,1,Lindsay,A,Renfro,"Baylor University,Department of Statistical Science",Bradley,P,Carlin,"University of Minnesota,Division of Biostatistics",Daniel,J,Sargent,"Mayo Clinic,Division of Biomedical Statistics and Informatics",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The evaluation and validation of surrogate endpoints for primary use in future clinical trials are increasingly important research areas, due to demands for more efficient trials coupled with recent acceptance of some surrogates as valid. However, little consideration has been given to appropriate design of trials utilizing newly-validated surrogates as primary endpoints. We propose a novel trial design that allows the new surrogate endpoint to play a dominant role in assessing treatment effect, while remaining realistically cautious about its use. By incorporating multi-trial historical information on the relationship between the surrogate and clinical endpoints, and checking accumulating data against this relationship during the new trial, we guard against continuing a trial that would lead to an erroneous treatment assessment based on a poor surrogate. However, if joint outcomes seem plausible given similar historical trials, we proceed with trusting the surrogate, and do so adaptivelyperhaps stopping the trial for early success or inferiority of the treatment, or for futility. We use simulation to test the operating characteristics of this design, as well as its ability to discriminate trustworthy from untrustworthy surrogates. We illustrate the design for colon cancer trials, where disease-free survival is a newly-validated surrogate for overall survival.",FALSE,FALSE,,FALSE,TRUE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,TRUE,Adaptive design/adaptive randomization,Biomarkers/surrogate markers,,,,,,,02-Nov-10,linglu@gwmail.gwu.edu,,Linglu Wang,,The George Washington University,522 21st ST NW Apt 503,202-494-8094,,linglu@gwmail.gwu.edu,Bayes factors in the presence of population stratiffication,1,Linglu,,Wang,"Department of Statistics, George Washington University, Washington DC, USA",Qizhai,,Li,"Academy of Mathematics and Systems Science, Chinese Academy of Sciences, Beijing, China",Zhaohai,,Li,"Department of Statistics, George Washington University, Washington DC, USA",Gang,,Zheng,"Office of Biostatistics Research, National Heart, Lung and Blood Institute, Bethesda, Maryland, USA",,,,,,,,,,,,,,,,,,,,,,,,,"Population stratiffication (PS) is a main concern of using the case-control design to detect genetic association. All methods to correct for PS have been studied in classical hypothesis testing. It is not clear, however, how the PS would affect Bayesian hypothesis testing and how to correct for it in Bayesian analysis. In this paper, we start with the investigation on how the PS would affect the asymptotic distribution of the estimate of odds ratio and its confidence interval. Using a large panel of null markers scanned in a genome-wide association studies, we apply a principle clustering analysis method to adjust for the effect of PS on the estimate of odds ratio and its asymptotic variance. Then we apply these corrected estimate and asymptotic variance in Bayesianhypothesis testing. It has been shown through simulations that the proposed method yields an appropriate correction for the PS in Bayesian analysis. Applications to HapMap data are used for illustration.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Bayesian methods,Genomics,,,,,,,15-Nov-10,linli@hsph.harvard.edu,,Lin Li,,Harvard School of Public Health,655 Huntington Ave,4046937884,,linli@hsph.harvard.edu,Regularized mixed models to account for population stratification,1,Lin,,Li,Harvard University School of Public Health Department of Biostatistics,Keyan,,Zhao,Stanford University School of Medicine Department of Genetics,Carlos,D,Bustamante,Stanford University School of Medicine Department of Genetics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Population stratification and high dimensionality are two big challenges often found in the analysis of genome-wide association studies (GWAS). On the one hand, mixed models have recently unleashed their powers in accounting for population structure, family structure and cryptic relatedness. On the other hand, regularized regressions, such as lasso, adaptive lasso, and elastic nets, have been applied to analyze the high dimensional data in GWAS. Although re-sequencing based dense genotyping and large pooled multi-population GWAS are becoming more and more popular, limited efforts have been taken to solve the two problems together. In this paper, we propose a new method using mixed models with convex penalties to analyze GWAS data. The method models phenotypes using a mixture of fixed effects and random effects. For estimation, it uses cyclical coordinate descent, computed along a regularization path. We show via simulations that the method is effective in modeling multiple genetic effects simultaneously while being able to accounting for population stratification, and is computationally efficient for the large-scale problems as found in GWAS. An application to real data is also illustrated.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Statistical genetics,Genomics,,,,,,,12-Nov-10,linlin.chen@rit.edu,,Linlin Chen,,Rochester Institute of Technology,85 Lomb Memorial Drive,5852608182,,linlin.chen@rit.edu,Multilayer Correlation Structure of Microarray Gene Expression Data,1,Linlin,,Chen,Rochester Institute of Technology,Lev,,Klebanov,Charles University in Prague,Anthony,,Almudevar,University of Rochester,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We show that there are at least two noise-type reasons for highcorrelations between gene expression levels. First is of technicalchar- acter, and is connected to a random character of the number ofcells used to prepare microarray. Another reason is the heterogeneityof cells in a tissue. Both reasons allow one to make some predictions,which are verified on real data.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,TRUE,Microarray analysis,High dimensional data,none,,,,,,15-Nov-10,lishaoyu@stt.msu.edu,,Yuehua Cui,Professor,Michigan State University,A432 Wells Hall Department of Statistics and Probability,517-432-7098,517-432-1405,lishaoyu@stt.msu.edu,Gene-Centric Gene Gene Interaction: A Model Based Kernel Machine Method,2,Yuehua,,Cui,Michigan State University,Shaoyu,,Li,Michigan State University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"AbstractMuch of the natural variation for a complex trait can be explained by the structural variation in DNA sequences. As part of the sequence variation, gene_gene interaction or epistasis has been ubiquitously observed in nature where its role in shaping an organisms development has been broadly recognized. Driven by its importance, the identification of genetic epistasis has been progressively pursued. A large body of currently adopted methods, either parametrically or non-parametrically, predominantly focus on pairwise single marker interaction. As genes are the functional units in living organisms, analysis by focusing gene as a unit could potentially yield more biologically meaningful results. In this work, we conceptually propose a gene-centric gene_gene interaction framework for genome-wide epistasis detection. In addition to the biological advantage, our method is statistically appealing by reducing the genome-wide multiple testing burdens. Simulation studies and application to a real data set are conducted to evaluate the performance and utility of the method. The approach provides a conceptual platform for epistasis identification.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Statistical genetics,Machine learning,,,,,,,04-Nov-10,liulei@virginia.edu,,Lei Liu,Associate Professor,University of Virginia,3181 Hospital West,434-982-3364,434-243-5787,liulei@virginia.edu,New estimation method for generalized mixed models with nonparametric functions,2,Jinsong,,Chen,"Division of Biostatistics and EpidemiologyDepartment of Public Health SciencesUniversity of Virginia",Lei,,Liu,"Division of Biostatistics and EpidemiologyDepartment of Public Health SciencesUniversity of Virginia",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In this article, we implement a new estimation method for generalizedmixed effects models, with nonparametric functions characterized bypenalized regression splines. The integration of the penalizedlikelihood with random effects is approximated by adaptive Gaussianquadrature, which can be conveniently implemented in SAS Proc NLMIXED.The selection of smoothing parameter is done through approximatedgeneralized cross-validation scores. Our method has two advantages:(1) the estimation is more accurate than the current availablequasi-likelihood method; (2) it can be used in fitting morecomplicated models, e.g., two-part random effects model withnonparametric functions. The performance of our approach is shown in asimulation study. We also apply our method to repeated measures of thesemi-continuous daily drinking records in a randomized controlledtrial of topiramate.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Nonparametric methods,Random effects,,,,,,,15-Nov-10,lixx0525@umn.edu,,Pei Li,,University of Minnesota,6259 Queensland Lane N,6122294230,,lixx0525@umn.edu,Bayesian Areal Wombling Using False Discovery Rates,1,Pei,,Li,Medtronic,Sudipto,,Banerjee,University of Minnesota,Alexander,,McBean,University of Minnesota,Bradley,,Carlin,University of Minnesota,,,,,,,,,,,,,,,,,,,,,,,,,"Boundaries on areally referenced spatial maps can be regarded as a subset of geographical boundaries that separate adjacent regions with substantially diffrent outcomes or even residual effects after reckoning with explanatory variables. This problem of detecting such boundaries is known as 'wombling', more specifically 'areal wombling', and can play a prominent role in spatial analysis and policy making. When using statistical model output to provide final set of boundaries as 'wombling boundaries', one needs to reckon with underlying multiplicities that may lead to biased  conclusions. Essentially, we are testing a significant number of hypthesis, one for each geographical boundary, and a reasonable decision rule must account for the effect of using a large number of marginal regional estimates. One such tool is the use of False Discovery Rates (FDR). This article proposes a computationally feasible framework to estimate hierarchical spatial models accounting for dependence between adjacent adjacent regions while being amenable to testing for equality of spatial effcts over adjacent regions and adjusting for multiplicities using FDR. A simulation study is conducted to illustrate the new approaches. 'Boundaries' on pneumonia and in¡uenza hospitalization maps from the SEER-Medicare program in Minnesota are detected using the proposed approaches.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Spatial/temporal modeling,Bayesian methods,,,,,,,10-Nov-10,lixxx311@umn.edu,,Ran Li,,University of Minnesota,1354 Paterson Plank Road Apt B,6098652904,,lixxx311@umn.edu,Gene set based clustering analysis of microarrays with L1 penalty,1,Ran,,Li,Univerisity of Minnesota,Baolin,,Wu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In this paper, we propose a penalized finite multivariate normal mixture model to explicitly incorporatethe gene dependence and simultaneously select important genes for microarray data.We apply the probabilistic principal component analysis (PPCA) model to dynamtically estimate the covariance matrix for genes within the same gene set during the EM algorithm. Our model outperform the traditional EM algothrim with independent covariance structure significantly in simulation and real data application.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Microarray analysis,Clustered data methods,penalized likelihood,,,,,,14-Oct-10,lixxx466@umn.edu,,Shuzhen Li,,Division of Biostatistics/ School of Public Health,1039 29th AVE SE APT F,612-876-0833,,lixxx466@umn.edu,Enhanced regional control of global false discovery rate for fMRI data,1,Shuzhen,,Li,"Division of Biostatistics,School of Public Health,University of Minnesota",Lynn,E.,Eberly,"Division of Biostatistics,School of Public Health,University of Minnesota",Brian,,Caffo,"Department of Biostatistics ,Johns Hopkins Bloomberg School of Public Health,Johns Hopkins University",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The effect of multiple hypothesis testing on error rates needs to beaccounted for in the analysis of Statistical Parametric Maps (SPM) ofneuroimaging data to identify brain regions activated by theexperimental stimuli. Whole brain (global) control of False DiscoveryRate (FDR) (Benjamini and Hochberg, 1995) has become the most widelyused method to do the thresholding in large scale analyses. Langers etal. (2007) proposed a regional method of global FDR control by takinginto consideration the spatial nature of neural correlation in brainactivation. In this work, we made two modifications to this regionalapproach and improved the power while still controlling global FDR.The modifications involve introducing a spatial weighting system intoa regional FDR estimation step and modifying the Langers et al. (2007)definition of neighborhood (corel) size. And the results indicate thatour proposed method is an improvement over the BH method (Benjaminiand Hochberg, 1995) and also performed uniformly better than thethresholding method in Langers et al. (2007).",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Imaging,Multiple testing,,,,,,,12-Oct-10,liy3@email.chop.edu,,Yimei Li,Instructor of Biostatistics,The Children's Hospital of Philadelphia & Universi,"CTRB 10207, 3501 Civic Center Boulevard",2678253817,,liy3@email.chop.edu,Prediction of Individual Long-term Outcomes in Smoking Cessation Trials Using Frailty Models,1,Yimei,,Li,"Division of Pediatric Oncology, The Children's Hospital of Philadelphia & University of Pennsylvania",E,Paul,Wileyto,"Department of Psychiatry, University of Pennsylvania",Daniel,F,Heitjan,"Department of Biostatistics & Epidemiology, University of Pennsylvania",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In smoking cessation clinical trials, subjects commonly receive treatment and report daily cigarette consumption over a period of several weeks. Although the outcome at the end of this period is an important indicator of treatment success, substantial uncertainty remains on how an individual's smoking behavior will evolve over time. Therefore it is of interest to predict long-term smoking cessation success based on short-term clinical observations. We develop a Bayesian method for prediction, based on a cure-mixture frailty model we proposed earlier, that describes the process of transition between abstinence and smoking. Specifically we propose a two-stage prediction algorithm that first uses importance sampling to generate subject-specific frailties from their posterior distributions conditional on the observed data, then samples predicted future smoking behavior trajectories from the estimated model parameters and sampled frailties. We apply the method to data from two randomized smoking cessation trials comparing bupropion to placebo. Comparisons of actual smoking status at one year with predictions from our model and from a variety of empirical methods suggest that our method gives excellent predictions.",FALSE,FALSE,,FALSE,TRUE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,TRUE,Cancer applications,Clinical trials,,,,,,,28-Oct-10,ljiang2@ncsu.edu,,Liewen,,North Carolina State University,2703 Broadwell Dr.,9199955588,,ljiang2@ncsu.edu,Penalized Joint Quantile Regression,1,Liewen,,Jiang,"Dept. of Statistics, North Carolina State University",Huixia,,Wang,"Dept. of Statistics, North Carolina State University",Howard,,Bondell,"Dept. of Statistics, North Carolina State University",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Conventional researches on quantile regression often focus on fitting the regression model at different quantiles separately. However, in situations where the quantile coefficients share some commonfeature, joint modeling of multiple quantiles to accommodate the common feature may improve the estimation efficiency. In practice, it is possible that for the same predictor, the quantile coefficient may be constant in some regions of the quantile level, but vary at other regions, it is also possible that some predictors may have constant impacts on the response variable at different locations of the response distributions, but the other predictors may exhibit different impacts at different quantile levels. According to these two scenarios, we develop two penalization methods, one is based on adaptive fused lasso penalty, and the other is based on adaptive sup-norm penalty. When the slopes indeed do not change with quantiles, the proposed methods will shrink them towards constants and thus improve the estimation efficiency. We show that the two methods share the oracle properties, and they lead toestimations with competitive or higher efficiency than the standard quantile regression estimation in finite samples.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Other,Variable subset selection/model selection,,,,,,,15-Oct-10,lli22@emory.edu,,Li Li,,Emory University,1518 Clifton Rd,4046945277,,lli22@emory.edu,Evaluating the Effect of Early Versus Late ARV Regimen Change After Failing on an Initial Regimen,1,Li,,Li,"Department of Biostatistics and Bioinformatics, Emory University",Joseph,J.,Eron,"Department of Medicine, University of North Carolina",Heather,,Ribaudo,"Department of Biostatistics, Harvard University",Roy,,Gulick,"Department of Medicine, Weill Medical College, Cornell University",Brent,A.,Johnson,"Department of Biostatistics and Bioinformatics, Emory University",,,,,,,,,,,,,,,,,,,,,"The current goal of initial antiretroviral (ARV) therapyis suppression of plasma HIV-1 RNA levels to below the detection limits of currently available assays. A substantial proportion HIV-infected patients who initiate therapy in clinical practice or clinical trials either fail to suppress HIV RNAor have HIV RNA levels rebound. In some clinical trials, such as the AIDS Clinical Trials Group (ACTG) StudyA5095, patients randomized to initial treatment but fail to suppress HIV RNA or have a rebound of HIV RNA on therapy are allowed to switch to second-line regimen subject to patient-specific information. The optimal timing of switching ARV therapy to ensure  sustained virologic suppression and prolonged clinical stability is not known.  Randomized trialsto compare early versus delayed switching have been difficult todesign and even more difficult to enroll.  Here, we provide a statistical framework to compare early versus late regimen change using observed data from the ACTG A5095 study.  Using efficient and doubly-robust estimators for the average causal effect, we conclude that patients who follow treatment strategies that switch within eight weeks of confirmedvirologic failure have significantly better health outcomes, on average, than patients following strategiesthat do not switch within eight weeks.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Clinical trials,Applied data analysis,,,,,,,28-Oct-10,lobaci01@nyumc.org,,Iryna Lobach,Assistant Professor,New York University,"650 First Ave, 540",212-263-6256,,lobaci01@nyumc.org,Genotype-Based Association Mapping of Complex Diseases: Gene-Environment Interactions with Multiple Genetic Markers and Measurement Errors in Environmental Exposures,1,Iryna,,Lobach,New York University,Ruzong,,Fan,Texas A&M University,Raymond,J,Carroll,Texas A&M University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"With the advent of dense single nucleotide polymorphism genotyping, population-based association studies have become the major tools for identifying human disease genes and for fine gene mapping of complex traits. We develop a genotype-based approach for association analysis of case-control studies of gene-environment interactions in the case when environmental factors are measured with error and genotype data are available on multiple genetic markers. The proposed risk functions can directly incorporate the observed genotype data while modeling the linkage disequilibrium information in the regression coefficients, thus eliminating the need to infer haplotype phase. Compared with the haplotype-based approach, an estimating procedure based on the proposed methods can be much simpler and significantly faster. In addition, there is no potential risk due to haplotype phase estimation. To model measurement error, we adopt the pseudo-likelihood method by Lobach et al. (2008). Performance of the proposed method is examined using simulation experiments. An application of our method is illustrated using a population-based case-control study of association between calcium intake with the risk of colorectal adenoma development.",FALSE,FALSE,,FALSE,FALSE,TRUE,Roundtable R8,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Statistical genetics,Epidemiologic methods,,,,,,,15-Nov-10,loh@research.att.com,,Ji Meng Loh,,AT&T Labs-Research,180 Park Ave,973-236-6230,,loh@research.att.com,Burgers and Fried Chicken - characterizing spatial patterns of fast food in New York City,1,Ji Meng,,Loh,AT&T Labs-Research,Naa Oyo,,Kwate,Rutgers University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In recent years, there has been a marked increase in U.S. obesityrates, especially among children and the disadvantaged. Fast food hasreceived attention as a factor in obesity both in adults and childrenand various research studies have suggested links between obesity andfast food consumption. Furthermore, there is evidence suggesting that food environments in residential neighborhoods andaround schools can play an important role in terms of the diversity ofdining options available. We will describe our ongoing efforts atunderstanding the spatial patterns of fast food restaurant locationsin New York City, in relation to demographic data from the census,school location data and market potential data.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Spatial/temporal modeling,Health policy applications,,,,,,,15-Nov-10,lpalmer@mdanderson.org,,J. Lynn Palmer,Associate Professor,U Texas MD Anderson Cancer Ctr,"Department Biostatistics, Unit 1411",713 792 7570,,lpalmer@mdanderson.org,Effects of estimation of missing data by stage and time,1,J. Lynn,,Palmer,The University of Texas M.D. Anderson Cancer Center,Janice,,Cormier,The University of Texas M.D. Anderson Cancer Center,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Missing data is common in longitudinal studies, especially for cancerpatients with later stage disease. Our goal is to summarize by examplehow four frequently-used methods of estimating missing data affectresults by stage and over time. 273 patients diagnosed with stage I-IVmelanoma were asked to provide FACT-M assessments at baseline, 1 week,3 and 6 months. Missing data occurred more often at later time pointsand for later stages.  We examined results of using the followingmethods of estimating missing data: 1) ignore missing observations, 2)enter the group mean by stage and time, 3) carry forward the lastknown observation, and 4) use linear estimation. Either carryingforward the last observation or using linear estimation was consideredthe preferred method. The choice would depend on the amount and timingof missing data because, for example, larger amounts of missing datawould make linear estimation not worth the extra effort. Using groupmeans as estimates of missing data was the least preferred method.Ignoring the missing observations may become a problem when estimatingresults for patients at a later stage of disease as sicker patientsmay drop out early, thereby raising the overall mean at later timepoints.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,TRUE,Missing data,Longitudinal data,,,,,,,11-Oct-10,lpang@ncsu.edu,,Lei Pang,,"NCSU, Department of Statistics",2806-22 Brigadoon Drive,8572774413,,lpang@ncsu.edu,Variance Estimation in Censored Quantile Regression via Induced Smoothing,1,Lei,,Pang,"North Carolina State University, Department of Statistics",Wenbin,,Lu,"North Carolina State University, Department of Statistics",Judy,H,Wang,"North Carolina State University, Department of Statistics",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Statistical inference in censored quantile regression is challenging,partly due to the unsmoothness of the quantile score function. A newprocedure is developed to estimate the variance of Bang and Tsiatis'sinverse-censoring-probability weighted estimator for censored quantileregression by employing the idea of induced smoothing. The proposedvariance estimator is shown to be asymptotically consistent. Inaddition, numerical study suggests that the proposed procedureperforms well in finite samples, and it is computationally moreefficient than the commonly used bootstrap method.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Survival analysis,Missing data,,,,,,,01-Oct-10,lparast@fas.harvard.edu,,Layla Parast,,Harvard University,Department of Biostatistics,5127319919,,lparast@fas.harvard.edu,Incorporating short-term outcome information to predict long-term survival with discrete markers,1,Layla,,Parast,Harvard University,Su-Chun,,Cheng,Dana Farber Cancer Institute,Tianxi,,Cai,Harvard University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In disease screening and prognosis studies, an important task is to determine useful markers for identifying high risk subgroups. Once such markers are established, they can be incorporated into public health practice to  provide appropriate strategies for treatment or disease monitoring based on each individual's predicted risk. In recent years, genetic and biological markers have been examined extensively for their potential to signal progression or risk of disease. In addition to these markers, it has often been argued that short-term outcomes may be helpful in making a better prediction of disease outcomes in clinical practice. In this paper we propose model-free non-parametric procedures to incorporate short-term event information to improve the prediction of a long-term terminal event. We include the optional availability of a single discrete marker measurement and assess the additional information gained by including the short-term outcome. We focus on the semi-competing risk setting where the short-term event is an intermediate event that may be censored by the terminal event while the terminal event is only subject to administrative censoring. Simulation studies suggest that the proposed procedures perform well in finite samples. Our procedures are illustrated using a dataset of post-dialysis patients with end-stage renal disease.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Survival analysis,Epidemiologic methods,,,,,,,10-Nov-10,lpeng@sph.emory.edu,,Limin Peng,,"Department of Biostatistics and Bioinformatics, Em","1518 Clifton Rd. NE, 3rd floor",404-727-7701,,lpeng@sph.emory.edu,Broad Sense Agreement between Continuous Measurements,1,Limin,,Peng,"Department of Biostatistics and Bioinformatics, Emory University",Ruosha,,Li,"Department of Biostatistics and Bioinformatics, Emory University",Ying,,Guo,"Department of Biostatistics and Bioinformatics, Emory University",Amita,,Manatunga,"Department of Biostatistics and Bioinformatics, Emory University",,,,,,,,,,,,,,,,,,,,,,,,,"The conventional concept of agreement has been confined to assess the exchangeability of different instruments, and thus is only applicable to compare measurements from the same scale. However, in practice, questions often arise regarding the feasibility of replacing one instrument by another while the two instruments under study are not in the same scale and may not follow a linear relationship. Focusing on the case where both instruments produce continuous measurements, we develop a significant expansion of the traditional framework of agreement, called broad sense agreement, which more generally targets at the replaceability of instruments. We propose a sensible broad sense agreement measure, which enables us to assess to what extent one continuous instrument can be replaced by another continuous instrument on a different scale. We present a nonparametric estimator of the proposed measure and study its asymptotic properties.  Extensive simulation studies are also conducted to evaluate the finite-sample performance of the proposed estimation. Finally, we apply the new method to a psychiatry study which involves two depression instruments: time-consuming HAM-D method and self administered less-expensive Caroll-D method.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Agreement,Nonparametric methods,,,,,,,15-Nov-10,lpoisso1@hfhs.org,,Laila Poisson,,Henry Ford Health Systems,Department of Public Health Sciences,313-874-5999,313-874-6730,lpoisso1@hfhs.org,Integrative set enrichment testing for multiple omics platforms,1,Laila,M,Poisson,"Department of Public Health Sciences, Division of Biostatistics, Henry Ford Health Systems, Detroit, Michigan, USA",Jeremy,MG,Taylor,"Department of Biostatistics, University of Michigan, Ann Arbor, Michigan, USA",Debashis,,Ghosh,"Departments of Statistics and Public Health Sciences, Penn State University, University Park, Pennsylvania, USA",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"To interpret the list of differential elements resulting from a between group analysis of high though-put data, we often look to see if it contains elements related by pre-defined sets. Enrichment testing assesses the overall evidence of differential behavior for elements within a defined set. When we have measured many molecular aspects, e.g. gene expression, metabolites, proteins, it is desirable to assess their differential tendencies jointly across platforms using an integrated set enrichment test. In this work we explore the properties of several methods for performing a combined enrichment test using gene expression and metabolomics as the motivating platforms. Using simulation models we explored the properties of several enrichment methods including two novel methods: a logistic regression 2-df Wald test and a 2D permutation p-value for the sum-of-squared statistics test. In relation to their univariate counterparts we find that the joint tests can improve our ability to detect results that are marginal univariately. We also find that joint tests improve the ranking of associated pathways compared to their univariate counterparts. However, there is a risk of Type I error inflation with some methods and others lose specificity when the sets are not representative of the true association patterns.",FALSE,FALSE,,FALSE,FALSE,FALSE,,contributedposter,,,,FALSE,FALSE,FALSE,TRUE,Other,High dimensional data,Integrative Analysis Methods,,,,,,30-Sep-10,Lqian@fau.edu,,Lianfen Qian,Professor,Florida Atlantic University,Department of Mathematical Sciences,5612972486,,Lqian@fau.edu,Generalized empirical likelihood methods for analyzing longitudinal data,2,Suojin,,Wang,"Department of Statistics, Texas A&M University, College Station, Texas 77843, U.S.A.",Lianfen,,Qian,"Department of Mathematical Sciences, Florida Atlantic University, Boca Raton, Florida33431, U.S.A.",Raymond,J.,Carroll,"Department of Statistics, Texas A&M University, College Station, Texas 77843, U.S.A.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Efficient estimation of parameters is a major objective in analyzinglongitudinal data. We propose two generalized empirical likelihoodbased methods that take into consideration within-subjectcorrelations. A nonparametric version of the Wilks theorem for thelimiting distributions of the empirical likelihood ratios is derived.It is shown that one of the proposed methods is locally efficientamong a class of within-subject variance-covariance matrices. Asimulation studyis conducted to investigate the finite sample properties of theproposed methods and compare them with the block empirical likelihoodmethod by You et al. (2006) and the normal approximation with acorrectly estimated variance-covariance. The results suggest that theproposed methods are generally more efficient than existing methodswhich ignore the correlation structure, and better in coveragecompared to the normal approximation with correctly specifiedwithin-subject correlation. An application illustrating our methodsand supporting the simulation study results is also presented.",FALSE,FALSE,,FALSE,FALSE,FALSE,"Please schedule my talk later than 9:30AM. Thanks.",oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Longitudinal data,Empirical likelihood,,,,,,,15-Nov-10,lqin.scharp@gmail.com,,Li Qin,,Fred Hutchinson Cancer Research Center,1100 Fairview Avenue North,2066674926,,lqin.scharp@gmail.com,Threshold Methods for Immunological Correlates of Protection,4,Andrew,,Dunning,Sanofi Pasteur,Fabrice,,Bailleux,Sanofi Pasteur,Kamal,,Desai,Sanofi Pasteur,Li,,Qin,Fred Hutchinson Cancer Research Center,Xuan,,Chen,Sanofi Pasteur,,,,,,,,,,,,,,,,,,,,,"Immunological correlates of protection, here we refer to theimmunological responses which are associated with protection fromdisease, play a central role in vaccines research.  Although inreality the relationship is likely continuous: increasing assay valuescorresponding to increased protection from disease, in practice theuse of threshold protective levels is ubiquitous.  The situation maybe likened to generalclinical medicine, where threshold reference levels have beenestablished for many common laboratory tests, such as in adults<200mg/dL for cholesterol, 0.7-1.5mg/dL for serum creatinine, and4-10.8_103/uL for white blood cell count. Yet limited quantitativemethods exist for inferring protective thresholds from data onimmunological assay values and subsequent disease occurrence. Standard methods are often inappropriate, since in many designs alarge number of unprotected subjects do not develop disease, inaddition to those protected.  This research examines nine thresholdmodels and methods in terms of their applicability to estimatingthreshold immunological correlates of protection, and develops testsand measures of discrimination and goodness-of-fit for evaluating thethresholds so found.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Biomarkers/surrogate markers,Clinical trials,,,,,,,05-Nov-10,ltang1@gmu.edu,,Liansheng Larry Tang,,George Mason Unviersity,"4400 University Dr, MS 4A7",7039939110,,ltang1@gmu.edu,Comparing Accuracy among  Clustered Diagnostic Markers with Applications to the BioCycle Study,1,Liansheng,,Tang,George Mason University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The accuracy of diagnostic markers plays an   important role in manyareas of medical research. Although multiple markers are frequently  compared  in cancer diagnostics and  imaging modality assessment,  the homogeneity test among markers has received less attention. Thisarticle presents two simultaneous procedures for testing accuracyamong clustered diagnostic markers. The first procedure is a test ofhomogeneity among  continuous markers  based on a a global hypothesisof the same   accuracy. The result derived  under the alternative provides the power analysis.   The second procedure is   asimultaneous pairwise comparison test based on  weighted areas underthe receiver operating characteristic curves.      This test isparticularly useful  if global difference among markers  is found bythe homogeneity test.       We apply our procedures to the BioCyclestudy, a cohort study  designed to assess and compare the accuracy ofhormone and  oxidative stress markers  in distinguishing from womenwith  ovulatory and  anovulatory menstrual cycles.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,ROC analysis,Diagnostic and screening tests,,,,,,,11-Nov-10,ltang3@emory.edu,,Li Tang,,"Department of Biostatistics and Bioinformatics, Em",1518 Clifton Rd. N.E.,4049893384,,ltang3@emory.edu,Regression analysis for differentially misclassified binary covariates in longitudinal studies,1,Li,,Tang,"Department of Biostatistics and Bioinformatics, Emory University, 1518 Clifton Rd. N.E., Atlanta, GA 30322",Robert,H,Lyles,"Department of Biostatistics and Bioinformatics, Emory University, 1518 Clifton Rd. N.E., Atlanta, GA 30322",Caroline,C,King,"Centers for Disease Control and Prevention, Atlanta, GA",David,,Celantano,"Johns Hopkins University School of Medicine, Baltimore, MD",Yungtai,,Lo,"Montefiore Medical Center and Albert Einstein College of Medicine, Bronx, NY",Jack,,Sobel,"Wayne State University School of Medicine, Detroit, MI",,,,,,,,,,,,,,,,,"Covariate mismeasurement is a long-standing problem, and is a knownsource of possibly severe bias when estimating regressioncoefficients. In our work, we focus on the case when a binarycovariate is misclassified in a longitudinal study. We aim to providean accessible method for practitioners whose goal is to restorevalidity through misclassification-corrected analyses that make use ofexternal or internal validation data. We develop a likelihood-basedapproach based on a generalized linear mixed model (GLMM) that canefficiently incorporate internal validation data, and covariates arealso permitted to impact sensitivity and specificity parameters. Wediscuss the use of the approach both in the case when a baselinepredictor is misclassified and when a time-dependent predictor ismisclassified. Simulation studies demonstrate the effectiveness of theproposed validation data-based analyses. Using main study and internalvalidation data from the HIV Epidemiology Research Study (HERS), wedemonstrate the value of this method in an analysis that adjusts formisclassification of bacterial vaginosis status.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Measurement error,Epidemiologic methods,,,,,,,15-Nov-10,luolola@mail.med.upenn.edu,,Lola Luo,,University of Pennsylvania,"200 N.Wynnewood Ave, B205",610-209-7124,,luolola@mail.med.upenn.edu,Comparison of non-linear vs. linear models in detecting disease modification effects in Alzheimer's trials,1,Lola,,Luo,University of Pennsylvania,Anthony,R,Entsuah,Merck Research Laboratory,Daniel,F,Heitjan,University of Pennsylvania,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Alzheimer's is a brain disease that causes problems with memory, thinking and behavior.  Currently, drugs that available on the markets for people who suffer from Alzheimer's disease only approved explicitly to treat the symptoms of the disease but not the underlying disease progression.  This presentation will compare non-linear vs. linear constraint Longitudinal Data Analysis (cLDA), Liang and Zeger,(3), methodologies in detecting the disease modification (DM) from symptomatic effect in Alzheimer's trials.  A nonlinear model which is adopted from Ploeger B. and Holford N.(1) is used to generate the data.  Non-linear models are from Ploeger B. and Holford N. (1) and Bhattaram V. et al (2).  cLDA model is from Liang and Zeger,(3).  A delayed-start trial design is used and three types of dropout rates are implemented: high (30-40%), mid (20-30%), and low (10%).  Simulations have found that only the correct nonlinear model showed better results in terms of power than the cLDA model.  However, it is not stable due to convergence issues.  Even though data from Alzheimer's trial are most likely nonlinear, the cLDA model performs just as well as the proposed non-linear models in the detection of the DM effect.  The stability of the cLDA model makes it a preferable choice to use.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Clinical trials,Consulting,,,,,,,11-Oct-10,luwang@umich.edu,,Lu Wang,,"University of Michigan, Ann Arbor",1415 Washington Heights,617-792-5085,,luwang@umich.edu,Detecting Critical Windows for Functional Curves,1,Lu,,Wang,"University of Michigan, Ann Arbor",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We consider inference for a semiparametric mixed effect model and functional linear model for longitudinal data. This work is motivated by collaboration with Columbia Center for Children's Environmental Health and Harvard Department of Environmental Health. The study goal is to evaluate individual profiles of prenatal exposure to airborne Polycyclic Aromatic Hydrocarbons (PAH) during pregnancy and to identify the critical gestational window of heightened vulnerability to airborne PAH on Fetal Growth. In the semiparametric mixed effect model, parametric fixed effects represent the covariate effects, an arbitrary smooth function accounts for the nonlinear periodic time effect, and the random effects are used to take care of the correlations arising from multiple observations of the same subject. We developed estimation and inference methods of the regression coefficients and the nonparametric function, and used functional linear model to link the birth outcomes with the predicted trajectory of individual exposure to PAH. Simulations are performed to evaluate the finite sample performance of the proposed estimators. We also apply the methods to the above PAH study.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Functional data analysis,Longitudinal data,,,,,,,29-Oct-10,lwelty@northwestern.edu,,Leah J. Welty,Assistant Professor,Northwestern University Department of Preventive M,680 N. Lake Shore Drive,312-503-4710,,lwelty@northwestern.edu,Double Sampling in Psychiatry: An Example that Keeps on Giving,1,Leah,J,Welty,Northwestern University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"One way to help students learn that statistics requires creativeproblem solving, rather than just plug-and-chug automation, is topresent them with a single problem that may be approached usingmultiple and distinct methods of escalating sophistication.  Whiletextbooks and other resources provide rich data sets that may have avariety of methods applied to them, it is less common to find a singleexample that keeps on giving -- especially ones that are accessibleto a student with no more than intermediate biostatistics knowledge. In this talk, we will discuss the problem of estimating prevalencerates from so-called double sampling designs in psychiatry, whichprovide just the type of example we seek.  Possible solutions rangefrom using basic conditional probability, to methods from surveysampling, to methods for missing data.  We will present example dataand background, and walk through these distinct approaches.  Thoughparticularly relevant for anyone teaching current or future healthprofessionals, this talk is designed to appeal more broadly tostatisticians interested in developing rich teaching examples thatexpose students to a variety of methods while helping them learn thatoften there is no single right answer.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Statistical education,Survey research data,,,,,,,14-Nov-10,lxzhang@gmail.com,,Lixun Zhang,,Yale University,132 Edwards St. Apt. 2B,(203)848-5057,,lxzhang@gmail.com,Spatio-Temporal Modeling of $NO_2$ Based on Data with Different Resolutions,1,Lixun,,Zhang,Yale University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"This paper presents a longitudinal model with a spatial component toestimate daily nitrogen dioxide ($NO_2$) levels based on two datasetswith different temporal resolution. The dataset from the STAR studycontains $NO_2$ measurements at a relatively large number of sites (avast majority of which are in the state of Connecticut,USA) but forjust a few monthly observations at each site. The dataset from EPAcontains measurements at an hourly level but only at a limited numberof sites (four sites in Connecticut). The goal is to estimate thedaily $NO_2$ level at the STAR study sites. The model performed welland two important implications could follow. First, the model makes itpossible to study the relationship between pollution and dailypollution-related symptoms (e.g. childhood asthma severity) in a moremeaningful way. Second, the model offers significant cost reduction onstudies of pollution levels related to $NO_2$ and other pollutants:the readily available pollutants observations at EPA monitoring sitesand the observations at some random sites could be used to makepredictions at more sites. The model is implemented under the Bayesframework with Gibbs sampler.",FALSE,FALSE,,FALSE,TRUE,TRUE,"Roundtables (Monday, Mar 21, 12:15-1:30)",oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Spatial/temporal modeling,Environmental and ecological applications,,,,,,,01-Nov-10,l-yao@northwestern.edu,,Lili Yao,,Northwestern University,l-yao@northwestern.edu,224-361-6163,,l-yao@northwestern.edu,Estimation of AUC with censored data,2,Qihua,,Wang,Chinese Academy of Sciences,Lili,,Yao,Northwestern University,Peng,,Lai,Chinese Academy of Sciences,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The area under the receiver operating characteristic curve(AUC) is themost commonly used summary measure of diagnostic accuracy for acontinuous-scale diagnostic test.  Our research work is to study theROC curve when the measurement have some censored data points. Weproposed two estimates for the AUC with censored data based on 'plugin' method. The asymptotic normality of these two estimators has beendeveloped based on counting process and martingale techniques.Correspondingly, the asymptotic confidence intervals for these twoestimates have been achieved. A simulation study is conducted toevaluate the performances of these proposed estimators.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,ROC analysis,Survival analysis,,,,,,,13-Nov-10,lynne@stat.uga.edu,,Lynne,University Professor,University of Georgia,Department of Statistics,1-706-542-3281,1-706-542-3391,lynne@stat.uga.edu,A Symbolic Analysis of Survival Times for Cardiac Patients,1,L.,,Billard,University of Georgia,C.,,Quantin,Hospitalier Universitaire de Dijon,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Information on acute myocardial infarction (AMI) was collected for 1095 hospitalized patients over an 18 month period. The construction of pathways followed by patients produced symbolic-valued observations requiring a symbolic regression tree analysis. This analysis was compared with the standard regression tree analysis (CART), using patients as statistical units, which selected Thrombolysis in Myocardial Infarction (TIMI) score as the primary predictor variable. In a symbolic regression tree analysis using hospital pathways as statistical units, the type of pathway followed was the key predictor variable, showing that pathways involving early admission to cardiology units produced high one-year survival rates.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Survival analysis,Clustered data methods,,,,,,,06-Oct-10,lzxue@stat.umn.edu,,Lingzhou Xue,Research Assistant,"School of Statistics, University of Minnesota","313 Ford Hall, 224 Church Street SE",6128683346,,lzxue@stat.umn.edu,Non-concave Penalized Composite Likelihood Estimation of Sparse Ising Models,1,Lingzhou,,Xue,"School of Statistics, University of Minnesota",Hui,,Zou,"School of Statistics, University of Minnesota",Tianxi,,Cai,"Department of Biostatistics, Harvard School of Public Health",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The Ising model is a useful tool for studying complex interactionswithin a system. The estimation of such a model, however, is ratherchallenging especially in the presence of high dimensional parameters.In this work, we propose efficient procedures for learning a sparseIsing model based on a penalized composite likelihood with non-concavepenalties. Non-concave penalized likelihood estimation has received alot of attention in recent years. However, such an approach iscomputationally prohibitive under high dimensional Ising models. Toovercome such difficulties, we extend the methodology and theory ofnon-concave penalized likelihood to penalized composite likelihoodestimation. An efficient solution path algorithm is devised by using anew coordinate-minorization-ascent algorithm. Asymptotic oracleproperties of the proposed estimator are established withNP-dimensionality. We demonstrate its finite sample performance viasimulation studies and further illustrate our proposal by studying theHuman Immunodeficiency Virus type 1 (HIV-1) protease structure basedon data from the Stanford HIV Drug Resistance Database.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,TRUE,High dimensional data,Machine learning,,,,,,,12-Oct-10,m_x_bar@hotmail.com,,Martin Dunbar,,Georgia Southern University,2000 Stambuk Lane Apt. 233,(478) 952-3150,,m_x_bar@hotmail.com,A More Efficient Steady State Independent Gibbs Sampler with its Application to Diabetes Data,1,Martin,,Dunbar,Georgia Southern University,Hani,,Samawi,,Ding-Geng,,Chen,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Markov Chain Monte Carlo methods, in particular, the Gibbs sampler, are widely used algorithms both in application and theoretical work in the classical and Bayesian paradigms.   However, these algorithms are often computer intensive.  This paper extends the Steady State Gibbs Sampling approach proposed by Samawi, et al. (2010) to improve the well known Gibbs sampler in multidimensional problems with the Steady State Independent Gibbs Sampler.  It is demonstrated that this newly developed sampler provides unbiased estimation and substantially improves the performance and convergence of the Gibbs sampler.  These result in a significant reduction in computing time that is required to attain a certain level of accuracy in parameter estimation. This newly developed sampler is used to estimate the regression model parameters of the diabetics and obesity data.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Computational methods,Bayesian methods,,,,,,,15-Nov-10,ma@stat.tamu.edu,,Yanyuan Ma,,Texas A&M University,Department of Staistics,979-862-7584,,ma@stat.tamu.edu,A Semiparametric Approach to  Dimension Reduction,1,Yanyuan,,Ma,Texas A&M University,Liping,,Zhu,East China Normal university,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We cast the dimension reduction problem in a semiparametricestimation framework. Viewing this problem from the new angle allowsus to derive a rich class of estimators, and obtain the classicaldimension reduction techniques as special cases in this class. Thesemiparametric approach also reveals that the common assumption oflinearity and/or constant variance on the covariates  can be removedat the cost of performing additional nonparametric regression. Thesemiparametric estimators without these common assumptions areillustrated through simulation studies and a data example.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,High dimensional data,Nonparametric methods,,,,,,,20-Sep-10,maggie.darrow@envisionpharma.com,,Maggie Darrow,,Envision Pharma,3530 Post Rd,203 480 0108,,maggie.darrow@envisionpharma.com,Title,1,Maggie,,Darrow,Envision Pharma,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,FALSE,FALSE,,FALSE,FALSE,FALSE,,,,,,FALSE,FALSE,FALSE,FALSE,,,,,,,,,15-Oct-10,mahn@ncsu.edu,,Mihye Ahn,,North Carolina State University,Department of Statistics,9192748801,,mahn@ncsu.edu,Variance component selection in linear mixed models,1,Mihye,,Ahn,North carolina state university,Hao Helen,,Zhang,North carolina state university,Wenbin,,Lu,North carolina state university,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The selection of random effects in linear mixed models is an important yet challenging problem in practice. We propose a robust and unified framework for automatically selecting random effects and estimating the covariance components in linear mixed models. A moment-based loss function is constructed for the covariance parameters of random effects and then a sandwich nonnegative garrote penalty is imposed for the selection of random effects. Large-sample theories show that the resulting estimator is consistent for both random effects selection and variance components estimation. Due to the nature of variance-covariance matrix of random effects, our procedure involves two challenging computation problems: nonlinear semidefinite programming and nonlinear programming with a linear inequality constraint. Furthermore, we propose a natural way to incorporate the selection of fixed effects after choosing random effects. Simulation studies reveal that a better selection of random effects can yield efficiency gain for the estimation of fixed effects. We use numerous examples to illustrate the behaviors of the proposed approach and compare it with existing ones, and finally apply the approach to a data set from the Amsterdam Growth and Health study.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Variable subset selection/model selection,Random effects,,,,,,,11-Nov-10,maiti@msu.edu,,Tapabrata Maiti,,Michigan State University,A424 Wells Hall,5173558677,,maiti@msu.edu,Spatial Ordinal Data Analysis of SEER Breast Cancer Data,1,Tapabrata,,Maiti,Michigan State University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Breast cancer is the most prevalent cancer among women and affects approximately one million women worldwide. The tumor stages are usually assigned into an ordered categorical  variable. In this study the patients are stratified by age, race, sex and their geographical locations. Our objective is to study the exposure effects while the spatial location effect taking into consideration. Due to spatial dependent structure of the response variable, a new estimation technique has been developed and applied to SEER data.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Spatial/temporal modeling,High dimensional data,,,,,,,08-Nov-10,makowsky@uab.edu,,Robert Makowsky,,The University of Alabama at Birmingham,327 Ryals Public Health Building,205-975-9122,,makowsky@uab.edu,Beyond missing heritability: Prediction of complex traits,1,Robert,,Makowsky,The University of Alabama at Birmingham,Nicholas,M.,Pajewski,The University of Alabama at Birmingham,Yann,C.,Klimentidis,The University of Alabama at Birmingham,Ana,I.,Vazquez,The University of Alabama at Birmingham,Christine,W.,Duarte,The University of Alabama at Birmingham,David,B.,Allison,The University of Alabama at Birmingham,Gustavo,,de los Campos,The University of Alabama at Birmingham,,,,,,,,,,,,,"Despite rapid advances in genomic technology, our ability to account for phenotypic variation using genetic information remains limited for many traits. Recently, a large proportion of the 'missing heritability' was statistically accounted for by modeling thousands of Single Nucleotide Polymorphims (SNPs) concurrently. However, an unanswered question is how these higher estimates of heritability translate into accurate predictions of yet-to-be observed phenotypes? Here we approach this issue by exploring the extent to which genetic models can account for phenotypic variation in training and validation samples as a function of the statistical approach used, the density of SNPs included and the number of subjects used to train the model. We use data from the Framingham Heart Study and are able to explain a large proportion of the genetic variation in height (heritability estimates up to 0.83, with R2 up to 0.96). However, the proportion of variance accounted for in validation samples is much smaller (R2 up to 0.25). Some factors affecting predictive ability (number of SNPs, model and size of the training sample) are examined. These findings begin to pave the way towards the potential application of genomic information for prediction of disease-related outcomes.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Statistical genetics,Applied data analysis,,,,,,,15-Nov-10,mandrekar.jay@mayo.edu,,Jay Mandrekar,Associate Professor of Biostatistics,Mayo Clinic,200 First Street SW,507 266 0573,507 284 9542,mandrekar.jay@mayo.edu,Factor Analysis as a tool for Assessments of Clinical Teaching Evaluations.,1,Jay,,Mandrekar,Mayo Clinic,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Factor analysis is a generic term for a family of statistical techniques concerned with the reduction of a set of observable variables in terms of a small number of latent factors. It has been developed primarily for analyzing relationships among a number of measurable entities (such as survey items or test scores). The underlying assumption of factor analysis is that there exists a number of unobserved latent variables (or 'factors') that account for the correlations among observed variables, such that if the latent variables are partialled out or held constant, the partial correlations among observed variables all become zero. In other words, the latent factors determine the values of the observed variables. Factor analysis has been widely used, especially in behavioral sciences, to assess the construct validity of a test or a scale. The focus of this talk is to provide an introduction to factor analysis in the context of research projects from Medical Education that involve clinical teaching evaluations, for example,  resident-teacher evaluations, resident's reflection on quality improvement etc.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Biostatistics Education,Statistical education,,,,,,,14-Oct-10,marcosop@yahoo.com,,Marcos Prates,Student,University of Connecticut,348C Foster Dr,860-336-6474,,marcosop@yahoo.com,A New Class of Link Function for Generalized Linear Mixed Models,1,Marcos,O,Prates,"Statistics Departament, University of ConnecticutInstitute for Public Health Research, University of Connecticut",Dipak,K,Dey,"Statistics Departament, University of ConnecticutInstitute for Public Health Research, University of ConnecticutCenter for Environmental Sciences and Engineering, University of Connecticut",Jun,,Yan,"Statistics Departament, University of ConnecticutInstitute for Public Health Research, University of ConnecticutCenter for Environmental Sciences and Engineering, University of Connecticut",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The link function plays an essential role in the generalizedlinear model and generalized linear mixed model (GLMM).Different choices of link function provide differentfit and prediction power for a specific data set.Although a considerable body of literature exists forlinks for binary data regression, only a very limited number of choices are available for other types of models such as Poisson regression and gamma regression. In a GLMM framework, we introduce a class of link functions that are implied from a new way to incorporate random effect. The new class covers the all existing link functions as special cases and offers a new avenue to construct links for various discrete and continuous response variables. As examples, we describe how ow our link function covers existing links and add a variety of alternative link function in the context of binary regression, Poisson regression, and gamma regression. The methodology can be naturally implemented in a Bayesian framework. Through three real data analyses, members of the proposed links are shown to improve fit over the the common used link functions.",FALSE,FALSE,,FALSE,FALSE,TRUE,1st Conference on Spatial Statistics,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Other,Bayesian methods,Generalized linear mixed models,,,,,,24-Oct-10,marina@rice.edu,,Marina Vannucci,,Rice University,6100 Main Street,713-348-6132,,marina@rice.edu,Bayesian Models for Variable Selection Incorporating Biological Information,1,Marina,,Vannucci,Rice University,Francesco,,Stingo,Rice University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"This talk will start with a brief review of Bayesian methods for variable selection in linear models that use mixture priors. Models and inferential algorithms are quite flexible and allow to incorporate additional information, such as data substructure and/or knowledge on relationships among the variables. Specific interest will be towards high-dimensional genomic data, and in particular DNA microarrays. The vast amount of biological knowledge accumulated over the years has allowed researchers to identify various biochemical interactions and define different families of pathways. There is an increased interest in identifying pathways and pathway elements involvedin particular biological processes. Drug discovery efforts, for example, are focused on identifying biomarkers as well as pathways related to a disease. We propose Bayesian models that address this question by incorporating information on pathways and gene networks in the analysis of genomic data.Our approach makes use of Markov Random Field priors, i.e., undirected graphical models, that incorporate biological information into the models. In addition to identifying markers that would have been missed otherwise and improving prediction accuracy, the integration of existing biologicalknowledge into the analysis provides a better understanding of underlying molecular processes.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Bayesian methods,Genomics,,,,,,,15-Nov-10,Mark.Levenson@fda.hhs.gov,,Mark Levenson,,FDA/CDER,10903 New Hampshire Ave,301-796-2097,301-796-9733,Mark.Levenson@fda.hhs.gov,Safety decision-making with multiple sources and different types of studies -- recent examples from FDA Advisory Committees,1,Mark,S,Levenson,FDA/CDER,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Randomized controlled trials including superiority and noninferiority trials, meta-analyses, re-analysis of controlled trials, and various types of observational studies may each contribute information to the knowledge of the safety of a drug. FDA and FDA Advisory Committees have had to weigh the evidence from such studies and either reach a regulatory decision or advise on one. Each of the types of studies has advantages and disadvantages, including size, unbiasness, generalizability, and feasibility. Some common principles of study quality such as the use of prospective analysis plans and rigorous validated endpoints apply to each of the types of studies. This talk presents recent examples from FDA Advisory Committees of the setting of multiple and diverse studies of a drug safety issue. In particular, this talk discusses the 2010 rosiglitazone FDA Advisory Committee meeting, at which the committee was presented with a range of studies of differing types.",FALSE,FALSE,,FALSE,FALSE,FALSE,Roundtable lunch,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Health policy applications,Epidemiologic methods,,,,,,,05-Nov-10,martin@stat.columbia.edu,,Martin Lindquist,,Columbia University,1255 Amsterdam Ave,(212) 851-2148,,martin@stat.columbia.edu,Brain Connectivity and Causal Inference,1,Martin,A,Lindquist,"Department of Statistics,Columbia University",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Human brain mapping has primarily been used to construct mapsindicating regions of the brain that are activated by certain tasks.Recently, there has been an increased interest in augmenting this typeof analysis with connectivity studies that seek to describe how brainregions interact and how these interactions depend on experimentalconditions and behavioral measures. Often researchers discriminate between functional connectivity, theundirected association between two or more fMRI time series, andeffective connectivity, the directed influence of one brain region onthe physiological activity recorded in other brain regions. We arguethat this distinction is not entirely clear or relevant. Instead, thevalidity of the conclusions made from any connectivity method willdepend strongly on certain key assumptions which are often poorlyspecified and difficult to check. We conclude by showing how ideasfrom causal inference provide a mathematical framework for determiningthese assumptions.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Imaging,Applied data analysis,,,,,,,15-Nov-10,matjxl@langate.gsu.edu,,Jiawei Liu,assistant professor,Georgia State University,725 COE Building,4044884589,,matjxl@langate.gsu.edu,Analyzing Gene Expression Data with Self-Contained Hypothesis,1,Jiawei,,Liu,Georgia State University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"DNA microarray allows the simultaneous measurement of theexpression levels of tens of thousands of genes for a singlebiological sample. An important and common problem in microarrayexperiments is the detection of genes that are differentiallyexpressed in a given number of classes. It needs to be carried outwithin the framework of multiple hypothesis testing. Many statisticaltests have been proposed in recent years for analyzing gene expressiondata in terms of gene sets. These methods are based on widelydifferent model assumptions and sampling approach, such as GSEA(Mootha, et al, 2003) and FCS (Pavlidis et al, 2004). This talk willreview the model hypotheses and sampling approaches behind thesemethods, and propose two ways to improve the GSEA and FCS methods. Onemethod treats subjects as the sampling unit under the self-containedmodel assumption. Another method treats genes as sampling unit byconsidering the gene correlation.  Simulation and real data analysisare performed based on the GSEA method.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Multiple testing,Genomics,,,,,,,12-Nov-10,matt@stat.duke.edu,,Matthew Heaton,,Duke University,5012 Stardust Drive,801-372-7268,801-372-7268,matt@stat.duke.edu,Kernel Averaged Predictors for Spatio-Temporal Processes,1,Matthew,J,Heaton,Duke University,Alan,E,Gelfand,Duke University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"For spatio-temporal processes, predictors from multiple spatio-temporal locations affect responses at a separate location.  For example, predictors such as precipitation, temperature, pollution emissions, etc. are often used to explain ozone production.  However, due to weather and other factors, the relationship between these predictors and ozone is not confined to a single spatial location or time period as is often assumed.  Again, the effect of pollution on mortality is spatially and temporally lagged because mortality does not, typically, occur at time of exposure.  Here, kernels are proposed as a tool to properly weight predictor surfaces in spatio-temporal regression models.  The kernels are assumed to be parametric with parameters that are estimable from the data.   Distributional results are provided for the case of a univariate predictor and response in the Gaussian process setting.  Additionally, relations to previously proposed models and computational details are discussed.  The methodology is demonstrated on simulated data as well as in an application to ozone levels as explained by temperature.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Spatial/temporal modeling,Hierarchical models,,,,,,,12-Nov-10,mattjschipper@gmail.com,,Matthew Schipper,,University of Michigan,8D18,269 270 1334,,mattjschipper@gmail.com,Dose finding trials in 2 dimensions: Sequential tite-CRM,1,Matthew,J,Schipper,University of Michigan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Oncology treatments are increasingly comprised of 2 or more agents.  In response, several 2D dose finding trial designs have been proposed in recent years.  We discuss a new Pancreas cancer trial which utilizes the sequential tite-CRM design.  In this design the 2D problem is converted into several sequentially run 1D subtrials.  This design is intuitive and easy to explain to clinicians. Simulation results are presented.  One drawback to this design is that the estimated toxicity probabilities may not be monotonic with one of the agents dose level.  A second drawback is possible reduced efficiency relative to 2D model based designs.  We thus propose and discuss an extension in which a simple logistic regression model is utilized to parameterize the probability of toxicity in the 2D dose space. Importantly, this model contains just 3 parameters and is thus estimable in the context of typically small PhI trials. For the first subtrial, this design operates like the tite-CRM.  Subsequent sub-trials jointly model all the trial data to estimate toxicity probabilities and thus assign dose levels.  With appropriate constraints on the parameters, the estimated probability of toxicity is guaranteed to be monotonic in dose.",FALSE,FALSE,,FALSE,FALSE,TRUE,I cannot present on Sunday.,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Adaptive design/adaptive randomization,Clinical trials,,,,,,,14-Oct-10,mcarone@jhsph.edu,,Marco Marco,,Johns Hopkins University,"615 N. Wolfe St., Office E3033",4105023363,,mcarone@jhsph.edu,Missing the target? A critical re-examination of the analysis of prevalent cohort survival data,1,Marco,,Carone,Johns Hopkins University,Daniel,O,Scharfstein,Johns Hopkins University,Masoud,,Asgharian,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We consider inference about the bivariate distribution of age-at-onset and total disease duration in a target population. While the birth cohort design is optimal for addressing this aim, it is often impractical to implement. The prevalent cohort design, whereby diseased individuals are recruited and followed forward in time, represents an efficient alternative. To adjust for the inherent sampling bias, these data have typically been analyzed assuming independence between disease duration at recruitment and total disease duration. We argue that this assumption is inadequate and may result in biased inference. We relax this assumption and derive novel nonparametric estimators of the distribution of interest. Using data from the Canadian Study of Health and Aging, we utilize our methodology to investigate age-at-onset and disease duration for dementia in the Canadian elderly population.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Survival analysis,Epidemiologic methods,,,,,,,11-Oct-10,mccallm@gmail.com,,Matthew N. McCall,,University of Rochester,112 Arvine Heights,202-222-5880,,mccallm@gmail.com,Estimation of the Human and Murine Transcriptomes,1,Matthew,N,McCall,"University of RochesterDepartment of Biostatistics and Computational Biology",Karan,,Uppal,Emory University School of Medicine,Harris,A,Jaffee,"Johns Hopkins UniversityDepartment of Biostatistics",Michael,J,Zilliox,"Emory University School of MedicineDepartment of Microbiology and Immunology",Rafael,A,Irizarry,"Johns Hopkins UniversityDepartment of Biostatistics",,,,,,,,,,,,,,,,,,,,,"Various databases have harnessed the wealth of publicly availablemicroarray data to address biological questions ranging fromacross-tissue differential expression to homologous geneexpression. Despite their practical value, these databases rely onrelative measures of expression and are unable to address the mostfundamental question -- which genes are expressed in a given celltype. Here we present an estimated transcriptome that providesreliable absolute measures of expression for most annotated genes for131 human and 89 mouse tissue types, including diseased tissue. Thisis made possible by an algorithm that transforms data from a singlemicroarray into expressed/unexpressed calls for each gene -- a geneexpression bar code. We evaluate our approach by comparisons toRNAseq, SAGE, and spike-in data and demonstrate its utility withexamples in cross-species comparisons and cancer diagnosis. Geneexpression transcriptomes and related resources are available fromhttp://rafalab.jhsph.edu/barcode.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,TRUE,Genomics,Microarray analysis,Transcriptome Estimation,,,,,,28-Sep-10,mcmahanc@mailbox.sc.edu,,Christopher McMahan,Graduate Research Assistant,University of South Carolina/Department of Statist,1929 Bluff Rd.,(931)980-2388,(803)777-4048,mcmahanc@mailbox.sc.edu,Informative Dorfman Screening,1,Christopher,S,McMahan,"Department of Statistics, University of South Carolina",Joshua,M.,Tebbs,"Department of Statistics, University of South Carolina",Christopher,R,Bilder,"Department of Statistics, University of Nebraska",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Since the early 1940s, group testing (pooled testing) has been used to reduce costs in a variety of applications, including infectious disease screening, drug discovery, and genetics. In such applications, the goal is often to classify individuals as positive or negative using initial group testing results and the subsequent process of decoding positive pools. Many decoding algorithms have been proposed, but most fail to acknowledge, and to further exploit, the heterogeneous nature of the individuals being screened. In this paper, we use individuals' risk probabilities to formulate informative decoding algorithms which implement Dorfman retesting in a heterogeneous population. We introduce the concept of thresholding to classify individuals as high risk or low risk, so that separate, risk-specific decoding algorithms may be used, while simultaneously identifying pool sizes that minimize the expected number of tests. When compared to competing algorithms which treat the population as homogeneous, we show that significant gains in testing efficiency can be realized with virtually no loss in screening accuracy. An important additional benefit is that our new procedures are easy to implement. We apply our methods to chlamydia and gonorrhea data collected recently in Nebraska as part of the Infertility Prevention Project.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,TRUE,Categorical data,Epidemiologic methods,,,,,,,06-Oct-10,mcwang@jhsph.edu,,Mei-Cheng Wang,,"Department of Biostatistics, Johns Hopkins Bloombe","Department of Biostatistics Johns Hopkins Bloomberg School of Public Health 615 N. Wolfe Street, E3546 Baltimore, MD 21205",410-955-7775,410-955-0958,mcwang@jhsph.edu,ROC Analysis for Recurrent Events Data,1,Mei-Cheng,,Wang,"Department of Biostatistics, Johns Hopkins University",Chin-Tsang,,Chiang,"Department of Mathematics, National Taiwan University",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Receiver Operating Characteristic (ROC) curve is  a common tool forsummarizing sensitivity and specificity of a diagnostic test  orbiomarker with continuous marker measurement. In statisticalliterature, extensions of time-dependent ROC curve have been developedby treating univariate survival time as a time-varying binary outcome.In this talk, we consider further extension of time-dependent TP (truepositive rate), FP (false positive rate), and time-dependent ROC function from univariate survival data to recurrent events data.Statistical methods and inferential results are developed forestimation of the ROC function and the time-dependent distribution ofmarkers for diseased and non-diseased groups. Model-based optimalityof marker combinations is also studies.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,ROC analysis,Survival analysis,,,,,,,08-Nov-10,mdaniels@stat.ufl.edu,,Michael Daniels,Professor and Chair,Department of Statistics,102C Griffin Floyd Hall,352 273 1845,,mdaniels@stat.ufl.edu,Analysis of Longitudinal Quality of Life Data Using Principal Stratification and a New Multivariate Longitudinal Ordinal Model,2,Keunbaik,,Lee,"Biostatistics ProgramLSU-Health Sciences Center",Michael,,Daniels,"Department of StatisticsUniversity of Florida",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Random effects models are commonly used to analyze longitudinalcategorical data. Marginalized random effects models (MREMs) are aclass of models that permit direct estimation of marginal mean parameters and characterize serial dependence forlongitudinal categorical data via random effects (Heagerty, 1999; Lee and Daniels, 2008). Inthis paper, we propose a model that extends previous models to multivariate longitudinalordinal data. A maximum marginal likelihood estimation method is proposed utilizing aQuasi-Newton algorithm with Quasi-Monte Carlo integration of the random effects. We analyzequality of life data from a colorectal cancer clinical trial using our methods. Dropout occurs ata high rate and is often due to tumor progression or death. To deal with progression/death, wewill show how principal stratification can be used to draw causal inferences about two ordinalquality of life measures using our new multivariate longitudinal model to deal with missingnessunrelated to death.",FALSE,FALSE,,FALSE,FALSE,FALSE,"i think RAB, RECOM and planning meeting since treasurer",invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Longitudinal data,Causal inference,,,,,,,15-Nov-10,mehmet.kocak@stjude.org,,Mehmet Kocak,Senior Biostatistician,St. Jude Children's Research Hospital,62 Danny Thomas Place,(901) 595-2947,(901) 595-4585,mehmet.kocak@stjude.org,A Bayesian Approach in Testing for periodicity in Cell-Cycle Gene Expression Profiles,1,Mehmet,,Kocak,"St. Jude Children's Research HospitalUniversity of Memphis",E. Olusegun,,George,"Department of Mathematical Sciences, University of Memphis, Memphis",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Investigating the cyclic behavior of genes during cell cycle has been of interest for a long time. The permutation test described by Lichtenberg et al. (2005) and Fishers G-test are among the most commonly used methods to test whether or not a given gene has significantly cyclic pattern. Fishers G-test doesnt utilize the exact timing of the time-course gene expression profile of a given gene as it only utilizes the rank of the exact time points. On the other hand, the permutation test may be inefficient when one wants to perform a large number of permutations. More importantly, both of these tests are testing for periodicity against noise. However, a given time-course data may have a behavior that is neither cyclic, nor just pure noise. Therefore, in this study, we propose a bayesian approach to test whether or not a gene has periodic behavior against various alternatives including noise. We compare the sensitivity and specificity of our novel approach with the permutation test and Fishers G-test using extensive simulations. We, then, apply the Bayesian approach to real gene expression time-course data on Schizosaccharomyces pombe (Rustici et. al. 2004; Oliva et. al. 2005; Peng et. al. 2005).",FALSE,FALSE,,FALSE,TRUE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Microarray analysis,Bayesian methods,Cell Cycle Gene-Expression Analysis,,,,,,14-Oct-10,meihuawu@umich.edu,,Meihua Wu,Graduate Student,"University of Michigan, Biostatistics Dept","1420 Washington Heights, 4th Fl",7346048424,,meihuawu@umich.edu,Designing Longitudinal Studies with Repeated Measures: the Case of Salivary Cortisol in the Multi-Ethnic Study of Atherosclerosis,1,Meihua,,Wu,"University of Michigan, Biostatistics Dept",Brisa,N,S‡nchez,"University of Michigan, Biostatistics Dept",Trivellore,E,Raghunathan,"University of Michigan, Biostatistics Dept",Ana,V,Diez-Roux,"University of Michigan, Epidemiology Dept",,,,,,,,,,,,,,,,,,,,,,,,,"Defining the times at which samples are collected is an important aspect of longitu- dinal study design. Unfortunately, simpling times are often determined based on convenience and their optimality is seldom established statistically. Such convenient sampling strategy is likely to undermine the statistical efficiency of the study, especially in those cases where the response profile over time is nonlinear. Using the example of salivary cortisol, which exhibits a the nonlinear shape across the days, we discuss an approach for identifying efficient sampling protocols for studies where longitudinal measurements are collected. We model the response curves using conditionally linear mixed models, which allow some parameters to be nonlinear and accommodate flexible shapes of the longitudinal process. Our approach incorporates multi level random effects to account for between- subject and between-day variability commonly seen in epidemiological studies of the stress response. Furthermore, we propose a framework to include overall study costs when choosing the best sampling protocol.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,TRUE,Longitudinal data,Experimental design,,,,,,,25-Oct-10,melissa.fazzari@einstein.yu.edu,,MELISSA J. FAZZARI,ASSISTANT PROFESSOR,ALBERT EINSTEIN COLLEGE OF MEDICINE,1300 MORRIS PARK AVE,718-678-1038,,melissa.fazzari@einstein.yu.edu,Sample Size Determination for Three-level Randomized Clinical Trials with Treatment Randomized at the Second or First level,1,MELISSA,J,FAZZARI,"DEPT. OF EPIDEMIOLOGY AND POPULATION HEALTH,ALBERT EINSTEIN COLLEGE OF MEDICINE",MIMI,Y,KIM,"DEPT. OF EPIDEMIOLOGY AND POPULATION HEALTH,ALBERT EINSTEIN COLLEGE OF MEDICINE",MOONSEONG,,HEO,"DEPT. OF EPIDEMIOLOGY AND POPULATION HEALTH,ALBERT EINSTEIN COLLEGE OF MEDICINE",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Randomized clinical trials typically yield data with a hierarchicalstructure.  For example, study patients (level 1) may be nested withinphysicians (level 2) who in turn are nested within hospitals (level3).  While the typical cluster randomized trial specifies hospital orclinical as the unit of randomization, in many cases, randomizationoccurs at the second or first level.  Sample size approaches for thelatter types of study designs are lacking, however.   We proposeclosed-form power functions and sample size formulae for detecting atreatment effect at the patient level in a 3-level hierarchicalsetting when randomization occurs at the first or second level. Themethods were derived using a test statistic based on maximumlikelihood estimates from a mixed-effects linear regression model forthree level data. A simulation study verifies that theoretical powerestimates using the derived formulae are nearly identical to empiricalestimates based on simulated data. The impact of the estimatedintra-class correlation at each level of the hierarchy on the requiredsample sizes is also discussed.",FALSE,FALSE,,FALSE,TRUE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Clustered data methods,Clinical trials,,,,,,,15-Nov-10,menghui_chen@merck.com,,Menghui Chen,Statistician,"Merck & Co., Inc.",126 East Lincoln Avenue,732-594-3824,,menghui_chen@merck.com,Predictive Modeling of Weight Loss Curves,1,Menghui,,Chen,Merck,Shailaja,,Suryawanshi,Merck,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Obesity is a significant worldwide health problem associated with increased risk of cardio-metabolic problems.  Lifestyle and pharmacological interventions often have limited success in preventing the regain after these interventions or after weight loss nadir is reached. Patients typically regain up to 40% of their lost weight in the year following treatment. In this presentation, change or percent change in body weight from baseline over time, controlled for factors such as baseline body weight, will be modeled using non-linear models.  Specifically polynomial or spline models will be assessed, recognizing that these could be specific to the time course of treatment, for example a flatter curve after weight loss nadir is reached. The parametric models will be built from a set of studies and evaluated using an independent set of studies.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Biopharmaceutical research,Nonlinear models,,,,,,,12-Nov-10,mengyuantracy@hotmail.com,,Mengyuan Xu,research fellow,NIEHS,1938 Owl Town Rd,2144584373,,mengyuantracy@hotmail.com,Identifying Transcription Co-regulator Binding Sites in ChIP-seq Data,1,Mengyuan,,Xu,the National Institute of Environmental Health Sciences,Clarice,,Weinberg,the National Institute of Environmental Health Sciences,David,,Umbach,the National Institute of Environmental Health Sciences,Leping,,Li,the National Institute of Environmental Health Sciences,,,,,,,,,,,,,,,,,,,,,,,,,"It is known that multiple transcription factors may work together toregulate gene expression. Most existing methods for motif discoveryconsider only one motif at a time. Here, we present a three-componentmixture framework to model the joint distribution of two motifs aswell as the situation where the two motifs may or may not coexist onthe same sequence. In order to estimate the position weight matrices(PWM) of each motif and the sequence proportions of containing none(pure noise), one of, and both binding sites at the same time, theexpectation-maximization (EM) algorithm is used to numericallymaximize the observed data likelihood with respect to the PWMs of thetwo motifs and sequence proportions.) Our method uses theexpectation-maximization (EM) algorithm to numerically maximize theobserved data likelihood with respect to the proportions and positionweight matrices of the two motifs. Based on the estimates of theparameters from the EM procedure, we compute the posteriorprobabilities of any given sequence and classify it as containingeither motif, both motifs, or pure statistical noise.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Missing data,Applied data analysis,,,,,,,06-Oct-10,mengzhao.gsu@gmail.com,,Meng Zhao,,Georgia State University,1322 Briarwood Rd NE,678-735-2805,,mengzhao.gsu@gmail.com,Empirical likelihood confidence intervals for the contrast of hazard functions with right censoring,1,Meng,,Zhao,Georgia State University,Yichuan,,Zhao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,FALSE,FALSE,,FALSE,FALSE,FALSE,,,,,,FALSE,FALSE,FALSE,FALSE,,,,,,,,,12-Nov-10,mez25@pitt.edu,,Mengyuan,Postdoctoral Fellow,"Department of Statistics, University of Pittsburgh","Department of Statistics, University of Pittsburgh",4126805284,,mez25@pitt.edu,An L1-regularized Logistic Model for Detecting Short-term Neuronal Interactions,1,Mengyuan,,Zhao,"Department of Statistics, University of Pittsburgh",Aaron,,Batista,"Department of Bioengineering, University of Pittsburgh",John,P.,Cunningham,"Department of Electrical Engineering, Stanford University",Cindy,,Chestek,"Department of Electrical Engineering, Stanford University",Zuley,R.,Alvidrez,"Department of Electrical Engineering, Stanford University",Rachel,,Kalmar,"Department of Electrical Engineering, Stanford University",Stephen,,Ryu,"Department of Neurosurgery, Stanford University Medical Center",Krishna,,Shenoy,"Department of Electrical Engineering & Department of Bioengineering, Stanford University",Satish,,Iyengar,"Department of Statistics, University of Pittsburgh",,,,,"Interactions among neurons are a key component of neural signal processing, but existing analysis methods are often not sufficiently sensitive and specific to reveal them. Generalized linear models offer a platform for analyzing multi-electrode recordings of neuronal spike train data. Here we suggest an L1-regularized logistic regression model (L1L method) to detect short-term (order of 3 ms) neuronal interactions.  We estimate the parameters in this model using a coordinate descent algorithm, and determine the optimal tuning parameter using the Bayesian Information Criterion. Simulation studies show that the L1L method in general has better sensitivities and specificities than the traditional shuffle-corrected cross-correlogram (covariogram) method does. The L1L method is able to detect excitatory interactions with both high sensitivity and specificity with reasonably large recordings, even when the magnitude of the interactions is small; similar results hold for inhibition given sufficiently high baseline firing rates. The false positives can be further removed by thresholding, because their magnitudes are typically smaller than true interactions. We then apply the method to data collected from a monkey dorsal premotor cortex (PMd) during a reaching task.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Variable subset selection/model selection,Applied data analysis,,,,,,,11-Nov-10,mfiecas@stat.brown.edu,,Mark Fiecas,,Brown University,121 South Main Street,281-639-2061,,mfiecas@stat.brown.edu,Spatio-temporal Models for Resting-state Functional Connectivity in fMRI,1,Mark,,Fiecas,Brown University,Hakmook,,Kang,Brown University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We investigate the default mode network in resting-state fMRI.  Thisdefault mode network has shown potential as a biomarker forvarious types of disease.  One popular approach for resting-statefunctional connectivity is a seed-based correlation analysis, whereone would select a time course from a voxel or from aregion-of-interest and cross-correlate it with the time courses fromother voxels or region-of-interests.  This popular approach, however,ignores the spatial correlation in the data, tending to inflatet-statistics. In this study, we extend the current seed-based approachby taking into account both the spatial and the temporal correlationin the data.  By adding voxel-level random effects, we are able tomodel the local spatial correlation within an ROI.  Our approach forestimating the mean structure of the model uses the iterativelyreweighted least squares procedure, and to estimate the variancestructure, we borrow ideas from the spatial statistics literature byusing a predictive process approach.  Our model allows us toinvestigate both the local within-ROI correlations and, for functionalconnectivity, the between-ROI correlations.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Imaging,Spatial/temporal modeling,,,,,,,13-Oct-10,mfinucan@hsph.harvard.edu,,Mariel Finucane,,"Harvard School of Public Health, Department of Bio","445 Ashbury St, Apt 7",4437451480,,mfinucan@hsph.harvard.edu,Estimating population-level trends in cardiometabolic risk factors using disparate data sources,1,Mariel,M,Finucane,"Department of Biostatistics, Harvard School of Public Health",Christopher,J,Paciorek,"Department of Biostatistics, Harvard School of Public Health and Department of Statistics, University of California Berkeley",Goodarz,,Danaei,"Department of Epidemiology, Harvard School of Public Health",Majid,,Ezzati,"Department of Global Health and Population and Department of Environmental Health, Harvard School of Public Health",,,,,,,,,,,,,,,,,,,,,,,,,"We present a flexible Bayesian model that combines data from disparate sources to estimate population-level trends in cardiometabolic risk factors for 199 analysis countries from 1980 to 2008. The model allows for time and age nonlinearity, and it borrows strength in time, age, covariates, and within and across regional country clusters to make estimates where data are sparse. Uncertainty propagates naturally through the model, allowing inference to reflect fully all sources of variability. Our cross-validated model has good out-of-sample predictive validity, globally as well as by region, age group, levels of covariates, and extent of data missingness, hence substantiating our predictions for country-years without data. This analysis represents the largest-ever analysis of high blood pressure, serum cholesterol, and body mass index, and the first global analysis of trends. In this paper, we use blood pressure as an illustrative example of model development and validation.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,TRUE,Hierarchical models,Applied data analysis,,,,,,,09-Nov-10,mgezmu@niaid.nih.gov,,Misrak Gezmu,Mathematical Statistician,National Institute of Allergy and Infectious Disea,6700B Rockledge Dr.,301-435-3722,301-480-0912,mgezmu@niaid.nih.gov,Collaborative research in low income countries and the need for in country biostatisticians.,1,Misrak,,Gezmu,"National Institute of Allergy and Infectious Diseases,National Institute of Health",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In the past decade, the biomedical sciences community has witnessed an increase in biomedical research in low income countries. An increase in global spending on health has boosted funds available to conduct biomedical research in low income countries to fight diseases such as HIV/AIDS, malaria, tuberculosis and other emerging and reemerging infectious diseases. The expansion of biomedical research requires the participation of interdisciplinary research teams from the research collaborators. Biostatisticians are critical members of the research teams and play an important role in the research. Sustaining and expanding a biostatistics workforce is a serious challenge even in the US. The challenge is much greater in low income countries where biostatistics is not well established as an academic discipline. Examples of collaborative researches between sub-Saharan Africa (SSA) and U.S. researchers will be presented; the need for SSA biostatisticians to participate in the research teams as equal partners with their U.S. counterparts will be discussed.  The examples discussed are taken from a workshop conducted at the National Institute of Allergy and Infectious Diseases, National Institute of Health in September 2009 on strengthening biostatistics resources in SSA.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Other,Biostatistics Education,Capacity building,,,,,,12-Nov-10,mgt26@georgetown.edu,,Mahlet G. Tadesse,Associate Professor,Georgetown University,Department of Mathematics & Statistics,202-687-1871,202-687-6067,mgt26@georgetown.edu,Integrating biological knowledge into the evaluation of genomic data,3,Francesco,S.,Stingo,Rice University,Yian,A.,Chen,Moffit Cancer Center,Mahlet,G.,Tadesse,Georgetown University,Marina,,Vannucci,Rice University,,,,,,,,,,,,,,,,,,,,,,,,,"Several databases have been built to structure and store biologicalknowledge into functionally and biochemically related groups. Evaluating genomic data in the context of these information may helpidentify relevant biomarkers and gain a better understanding ofmolecular processes underlying various phenotypes.  We propose aBayesian method that uses existing biological knowledge to modelassociations between response variables and pathways, and to identifyrelevant genes and pathways.  The information from the databases isused to formulate the model, as well as to specify a Markov randomfield prior on the genes, and to design MCMC transition moves for themodel fitting. We illustrate the method with an application to DNAmicroarray data with censored survival outcomes using the KEGG pathway database.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Genomics,Bayesian methods,,,,,,,12-Nov-10,mhbert@alumni.cmu.edu,,Marnie Bertolet,Assistant Professor,"University of Pittsburgh, Dept. of Epidemiology",130 Desoto St. / 127 Parran Hall,4126487098,,mhbert@alumni.cmu.edu,Tree-Based Identification of Subgroups for Time-Varying Covariate Survival Data,1,Marnie,,Bertolet,"University of Pittsburgh, Department of Epidemiology",Maria,M,Brooks,"University of Pittsburgh, Department of Epidemiology and Biostatistics",Vera,,Bittner,University of Alabama at Birmingham,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Classification and regression trees (CART) identify subsets of the population who are at varying degrees of risk for an outcome based on select risk factors.  Discrimination of subsets is performed using recursive binary splitting, allowing for combinations of risk factors that are not captured in standard model building techniques.  CART variations for time-varying covariates in survival data are intensive computationally and not widely available. We propose a technique to identify subsets of time-varying covariate risk factors based on the Cox model, utilizing recursive binary splitting and a greedy forward-stepwise selection to determine the split of a node.  This can be implemented in any statistical software package.  The technique is demonstrated on data from the Bypass Angioplasty Revascularization Investigation 2 Diabetes clinical trial to find combinations of time-varying modifiable cardiac risk factors (e.g. smoking status, blood pressure, lipid levels, and HbA1c level) to determine prognostic subgroups associated with time-to-event clinical outcomes.  If causality can be assumed, these groups should be used to prioritize treatment in a given patient.",FALSE,FALSE,,FALSE,FALSE,FALSE,,contributedposter,,,,FALSE,FALSE,FALSE,TRUE,Epidemiologic methods,Survival analysis,,,,,,,22-Oct-10,mhchen@stat.uconn.edu,,Ming-Hui Chen,Professor,University of Connecticut,"Department of Statistics, Univ of Connecticut",860-486-6984,,mhchen@stat.uconn.edu,Bayesian Design of Non-Inferiority Trials using Historical Data via Power Priors,1,Ming-Hui,,Chen,University of Connecticut,Joseph,G.,Ibrahim,University of North Carolina,Peter,,Lam,Boston Scientific Corporation,Alan,,Yu,Independent Consultant,Yuanye,,Zhang,University of Connecticut,,,,,,,,,,,,,,,,,,,,,"We develop a new Bayesian approach of sample size determination (SSD) for the design of non-inferiority clinical trials.  We extend the fitting and sampling priors of Wang and Gelfand (2002) to Bayesian SSD with a focus on controlling the type I error and power. Historical data are incorporated via  the power prior approach of Ibrahim and Chen (2000). Various properties of the proposed Bayesian SSD methodology are examined and a simulation-based computational algorithm is developed. The proposed methodology is applied to the design of a non-inferiority medical device clinical trial with historical data from previous trials.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Bayesian methods,Clinical trials,,,,,,,21-Oct-10,miaomiao.ge@uconn.edu,,Miaomiao Ge,,University of Connecticut,"80 Cisar Road, APT 27",860-208-0799,,miaomiao.ge@uconn.edu,A New Bayesian Joint Model via Subdistribution for Survival Data with Competing Risks,1,Miaomiao,,Ge,"Department of Statistics, University of Connecticut",Ming-Hui,,Chen,"Department of Statistics, University of Connecticut",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Competing risks data are routinely encountered in various medical applications due to the fact that patients may die from different causes. Recently, several models have been proposed for fitting such survival data. In this paper, we extend the model for the subdistribution of Fine and Gray (1999) to develop a new joint model for the subdistribution of primary cause and the conditional distribution of other causes. Various properties of the proposed model have been examined. An efficient Markov chain Monte Carlo sampling algorithm via latent variables is developed to carry out posterior computations. The deviance information criterion and logarithm of the pseudomarginal likelihood measures are used for model comparison. A real data is used to further illustrate the proposed methodology. Simulations are conducted to examine the performance of the proposed model as well as the two model comparison measures.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Survival analysis,Bayesian methods,,,,,,,21-Oct-10,michael.d.swartz@uth.tmc.edu,,Michael Swartz,,University of Texas School of Public Health,"1200 Herman Pressler, Suite W920",713-500-9570,,michael.d.swartz@uth.tmc.edu,Using Ascertainment for Targeted Resequencing to Increase Power to Identify Causal Variants,1,Michael,D.,Swartz,"Division of Biostatistics, UT Health, University of Texas School of Public Health",Bo,,Peng,"Department of Epidemiology, University of Texas M. D. Anderson Cancer Center",Cielito,C.,Reyes-Gibby,"Department of Epidemiology, University of Texas M. D. Anderson Cancer Center",Sanjay,,Shete,"Department of Epidemiology, University of Texas M. D. Anderson Cancer Center",,,,,,,,,,,,,,,,,,,,,,,,,"Researchers continue to use genome-wide association studies (GWAS) to find the genetic markers associated with disease.  Recent studies have added to the typical two-stage analysis a third stage that uses targeted resequencing on a randomly selected subset of the cases to detect the causal single-nucleotide polymorphism (SNP).  We propose a design for targeted resequencing that increases the power to detect the causal variant.  The design features an ascertainment scheme wherein only those cases with the presence of a risk allele are selected for targeted resequencing.   We simulated a disease with a single causal SNP to evaluate our method versus a targeted resequencing design using randomly selected individuals.  The simulation studies showed that ascertaining individuals for the targeted resequencing can substantially increase the power to detect a causal SNP, without increasing the false-positive rate.",FALSE,FALSE,,FALSE,TRUE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Statistical genetics,Epidemiologic methods,,,,,,,04-Nov-10,mijin-jang@uiowa.edu,,Mijin Jang,,The University of Iowa,1001 Oakcrest street Apt7E,3195417403,,mijin-jang@uiowa.edu,Working Correlation Selection in GEE,1,Mijin,,Jang,University of Iowa,Jane,F,Pendergast,University of Iowa,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"GEE is a widely used estimation method for marginal models in a longitudinal data setting.  If the marginal model for the mean is correctly specified and the correlation parameters are estimated consistently, the resulting solution to the estimating equations is asymptotically as efficient as if alpha were known, even when the working correlation is misspecified.  However, in small sample sizes, efficiency is increased when the selected working structure is close to the true underlying structure.  Several GEE working correlation selection criteria have been proposed, such as the QIC,CIC ,RJ, and SC measures.  The performances of these criteria in selecting the true correlation have been evaluated in limited settings, and generally have not included overspecified structures.  In this talk, several new working correlation structure selection criteria, based on functions of generalized eigenvalues of the estimated variance-covariance matrices, are proposed and compared.   In addition, penalization terms for overspecified structures are proposed.  The new selection criteria are shown to improve detection of the true covariance structure and reduce selection of an overparameterized structure.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Longitudinal data,Clustered data methods,,,,,,,15-Nov-10,mil21@pitt.edu,,MinJae Lee,,University of Pittsburgh,18600 South Park View Drive,412-361-0513,,mil21@pitt.edu,Censored Quantile Regression For Longitudinal Data with Dropouts,1,MinJae,,Lee,University of Pittsburgh,Lan,,Kong,University of Pittsburgh,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Quantile regression is increasingly used in longitudinal analysis of biomarker data due to its robustness to non-normality and heteroscedasticity. However, in some biomedical studies, the biomarker measurements can be censored at the detection limits of the bioassay used or missing when the subjects drop out from the study. Inappropriate handling of these two issues leads to biased estimation results. We consider the censored quantile regression approach to account for the censoring data and apply the inverse weighting technique to adjust for dropouts. In particular, we develop a weighted estimating equation for censored quantile regression, where an individual's contribution is weighted by the inverse probability of dropout at the given occasion. We conduct simulation studies to evaluate the properties of the proposed estimators and demonstrate our method with a real data set from Genetic and Inflammatory Marker of Sepsis (GenIMS) study.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Biomarkers/surrogate markers,Missing data,,,,,,,05-Nov-10,Min.Chen@UTSouthwestern.edu,,Min Chen,Assistant Professor,UT Southwestern Medical Center,Department of Clinical Sciences,2146480359,,Min.Chen@UTSouthwestern.edu,Detecting epistatic SNPs associated with complex diseases via a Bayesian classification tree search method,1,Min,,Chen,"Department of Clinical Sciences, University of Texas Southwestern Medical Center at Dallas",Judy,,Cho,"Internal Medicine, Yale University",Hongyu,,Zhao,"Department of Epidemiology and Public Health, Yale University.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Complex phenotypes are known to be associated with interactions among genetic factors. A growing body of evidence suggests that gene-gene interactions contribute to many common human diseases. Identifying potential interactions of multiple polymorphisms thus may be important to understand the biology and biochemical processes of the disease etiology. However, despite the great success of genome-wide association studies that mostly focus on single locus analysis, it is challenging to detect these interactions, especially when the marginal effects of the susceptible loci are weak and/or they involve several genetic factors. Here we describe a Bayesian classification tree model to detect such interactions in case-control association studies. We show that this method has the potential to uncover interactions involving polymorphisms showing weak to moderate marginal effects as well as multi factorial interactions involving more than two loci.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Genomics,Statistical genetics,,,,,,,07-Oct-10,min.yi@uth.tmc.edu,,Min Yi,,University of Texas M.D. Anderson Cancer Center,"Department of Surgical Oncology - Unit 444,University of Texas M.D. Anderson Cancer Center",832-598-6686,713-792-4689,min.yi@uth.tmc.edu,A Bayesian Model for Misclassified Binary Outcomes and Correlated Survival Data,1,Min,,Yi,"Department of Surgical OncologyUniversity of Texas M.D. Anderson Cancer Center",Sheng,,Luo,"Division of BiostatisticsSchool of Public HealthThe University of Texas Health Science Center at Houston",Xuelin,,Huang,"Department of BiostatisticsThe University of Texas MD Anderson Cancer Center",Kelly,K.,Hunt,"Department of Surgical oncologyThe University of Texas MD Anderson Cancer Center",,,,,,,,,,,,,,,,,,,,,,,,,"After breast conservation therapy, patients with breast cancer mayexperience breast tumor relapse (IBTR). IBTR is classified into twodistinct types: true local recurrence (TR) and new ipsilateral primarytumor (NP). However, the methods used to diagnose IBTR are imperfectand are prone to misclassification. In addition, some observedsurvival data (time to relapse and time from relapse to death) arestrongly correlated with IBTR status. Our goal was to present aBayesian approach to 1) model the potentially misclassified IBTRstatus and the correlated survival information, 2) estimate thesensitivity and specificity of the diagnostic methods, and 3) quantifythe covariate effects on event probabilities. The inference wasconducted using a Bayesian framework via Markov Chain Monte Carlosimulation implemented in WinBUGS. Simulation was used to validate ourBayesian method and assess its frequentist properties. Our methodswere motivated by, and applied to, a data set of 397 patients withbreast carcinoma. Our model has two important innovations in ourmodel: 1) it utilizes the additional survival times correlated withthe relapse status to improve the parameter estimation, and 2) itprovides tools to address the correlation between the two diagnosticmethods conditional to the true relapse status.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Bayesian methods,Cancer applications,,,,,,,10-Nov-10,minggenl@unr.edu,,Minggen Lu,,"University of Nevada, Reno","Lombardi Building, 203, MS 0274",(775) 682-7102,,minggenl@unr.edu,Sieve Likelihood Estimation of Partial Poisson Regression with Single-Index Model,1,Minggen,,Lu,"University of Nevada, Reno",Dana,,Loomis,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We study a spline-based semiparametric likelihood method for partial Poisson single-index model. We use B-splines to approximate the unknown nonparametric function and apply a modified Fisher scoring method to compute the estimators of the linear coefficients and the unknown function jointly. We show that the proposed spline-based likelihood estimator of nonparametric component is consistent with a possibly better than n1/3 convergence rate if the function is sufficiently smooth and that the estimators of the regression parameters are asymptotically normal and efficient. Also an expected information method to consistently estimate the standard error of the spline estimators of the regression parameters is proposed. A Monte Carlo study is conducted to evaluate the finite sample performance of the proposed spline method. The method is illustrated by North Carolina asbestos textile workers study.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Nonparametric methods,Environmental and ecological applications,,,,,,,10-Nov-10,minjae0404@gmail.com,,MinJae Lee,PhD,Faculty,18600 South Park View Drive,412-361-0513,,minjae0404@gmail.com,Censored Quantile Regression For Longitudinal Data with Dropouts,1,MinJae,,Lee,"Dept. of OB/GYN, University of Pittsburgh",Lan,,Kong,"Dept. of Biostatistics, University of Pittsburgh",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Missing data often arise in longitudinal studies. We specied a exible and robust quantile regression model for the repeatedly measured left-censoring response variable which incorporatesmissingness due to dropouts. We considered inverse weighting technique to the censoredQR model and we applied a bootstrap method for variance estimation. We conducted simulationstudies to evaluate the properties of the proposed estimators and demonstrated ourmethod with a real data set from Genetic and Inammatory Marker of Sepsis (GenIMS)study.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Biomarkers/surrogate markers,Missing data,,,,,,,15-Nov-10,mjoffe@mail.med.upenn.edu,,Marshall M. Joffe,,University of Pennsylvania,602 Blockley Hall,2155737395,,mjoffe@mail.med.upenn.edu,Selective and future ignorability in causal inference,1,Marshall,M,Joffe,University of Pennsylvania,Wei,P,Yang,University of Pennsylvania,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Most attempts at causal inference in observational studies are basedon assumptions that treatment assignment is ignorable (Rosenbaum andRubin 1983); ignorability involves conditional independence oftreatment and the potential outcomes. Such assumptions are usuallymade casually, largely because they justify the use of availablestatistical methods and not because they are truly believed. It willoften be the case that it is plausible that conditional independenceholds at least approximately for a subset but not all of theexperience giving rise to one's data, or conditional on some subset offuture potential outcomes. Such selective and future ignorabilityassumptions may be used to derive valid causal inferences inconjunction with structural nested models, whereas methods based onassuming full ignorability are biased in this setting.  We outlineselective and future ignorability assumptions mathematically andsketch how they may be used along with modifications of G-estimationmethods to obtain inference on structural nested models. We motivateand illustrate our development by considering an analysis of anobservational database to estimate the effect of erythropoetin use onmortality among hemodialysis patients.",FALSE,FALSE,,FALSE,FALSE,TRUE,cannot present until Monday afternoon,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Causal inference,Longitudinal data,,,,,,,02-Nov-10,mjun@stat.tamu.edu,,Mikyoung Jun,,Texas A&M University,3143 TAMU,9798453141,,mjun@stat.tamu.edu,A test for stationarity of spatio-temporal random fields on planar and spherical domains,1,Mikyoung,,Jun,Texas A&M University,Marc,G.,Genton,Texas A&M University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"A formal test for weak stationarity of spatial and spatio-temporalrandom eldsis proposed. We consider the cases where the spatial domain is at oron a sphere and we do not require distributional assumption for therandom elds. The method can be applied to univariate or tomultivariate random elds. Our test is based on the asymptoticnormality of certain statistics that are functions of estimators ofcovariances at certain spatial and temporal lags under weakstationarity. Simulation results for spatial as well asspatio-temporal cases on the two types of spatial domains arereported. We describe the results of two applications of the proposedmethod. One is to test stationarity of Pacic wind data. The other isto test axial symmetry of climate model errors for surface temperatureusing the NOAA GFDL model outputs and the observations from theClimate Research Unit in East Anglia and the Hadley Centre.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Spatial/temporal modeling,Environmental and ecological applications,,,,,,,08-Nov-10,mli@celgene.com,,Mingyu Li,,Celgene,"BR 2-13, 106 Allen Road,",9088607584,,mli@celgene.com,R Functions for Sample Size and Power Calculations for Assessing Consistency of Treatment Effects in Multi-Regional Clinical Trials,1,Mingyu,,Li,Celgene,Hui,,Quan,Sanofi-Aventis,Joshua,,Chen,Merck,Yoko,,Tanaka,Eli Lilly,Peter,,Ouyang,Celgene,Xiaolong,,Luo,Celgene,Gang,,Li,Johnson & Johnson,,,,,,,,,,,,,"Multiregional clinical trials (MRCTs) present great opportunities butalso challenges to the trial community. Due to potential heterogeneityof patient populations, it is critical to evaluate consistency oftreatment effects across different regions in a multiregional trial inorder to determine the applicability of the overall treatment effectto the patients in individual regions. As the main objective of aresearch stream within the PhRMA MRCT working group, this researchexplores a number of definitions for consistency assessments. Weaddress the issues primarily for superiority trials with continuousendpoints, then extend the ideas briefly to noninferiority trials,random effect models, binary endpoints, and survival endpoints.Computations and simulations are used to study the properties of theproposed definitions. To facilitate the application of the ideas todesign multiregional trials, we provide the corresponding R functionsfor calculating the unconditional and conditional power fordemonstrating consistency in relationship with overall/regional samplesizes and the anticipated treatments effects. Detailed step by stepinstructions and trial examples are also provided to illustrate theapplications of these R functions.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Clinical trials,Power analysis/sample size,,,,,,,15-Nov-10,mmarino@hsph.harvard.edu,,Miguel Marino,,Harvard Biostatistics,655 Huntington Avenue,714-928-2277,,mmarino@hsph.harvard.edu,Variable Selection for Multilevel Models in the Presence of Missing Data,1,Miguel,,Marino,"Harvard UniversityDepartment of Biostatistics",Yi,,Li,"Harvard UniversityDepartment of Biostatistics",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Multilevel models are commonly used to describe the relationship ofpredictors on mean response while accounting for clustering in thedata. When performing multilevel models with high number ofpredictors, variable selection is unavoidable. In addition to thecomplexity of clustering, multilevel data is often encountered withmissing data. Unfortunately, a majority of variable selectionmethodology has been developed for settings where thecomplete data is observed. In statistical practice, the need toadequately handle missing data is an important process withimplications for main analyses and sensitivity analyses.We develop a procedure that is able to perform variable selection formultilevel models with missing data. We address the missing data issuewith a multiple imputation approach that preserves the clustering ofthe data. The presence of multiple data sets creates additionalchallenges of combining variable selection results across multipledata sets. We propose a novel approach that stacks themultiply-imputed data sets which can allow the use of group variableselection via the group lasso to assess the overall significance ofeach predictor across the imputed data sets. We illustrate ourmethodology with a cancer prevention study.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Hierarchical models,Variable subset selection/model selection,,,,,,,15-Nov-10,Mohamed.Alosh@fda.hhs.gov,,Mohamed,,FDA,10903 New Hampshire Ave,301-796-0844,,Mohamed.Alosh@fda.hhs.gov,A consistencyadjusted strategy for testing alternative endpoints in a clinical trial,1,Mohamed,,Alosh,FDA,Mohammad,,Huque,FDA,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"A clinical trial might involve more than one clinically important endpoint (subgroup) each of which can characterize the treatment effect of the experimental drug under investigation.  For prespecifeid alternative endpoints (subgroups) there are several approaches which can be used for testing for efficacy for the alternative endpoints or the subgroup and total study population.  Traditional multiplicity approaches use constant significance levels for these alternative endpoints.  However, some recent multiplicity strategies allow the alpha-level allocated to testing subsequent endpoint to be dependent on the results of previous endpoint. In this presentation we discuss the need for establishing a minimum level of efficacy for the previous endpoint before proceeding to test for the subsequent alternative endpoint (subgroup) so that potential problems in interpreting study findings can be avoided. We consider implementing such requirements, which we call consistency criteria, along with adaptation of the significance level for subsequent endpoints at the study design stage and investigate its impact on study power. In addition, we consider its application to actual clinical trial data.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Biopharmaceutical research,Clinical trials,,,,,,,15-Nov-10,monica_bennett@baylor.edu,,Monica Bennett,,Baylor University,8591 Southwestern Blvd,5049826382,,monica_bennett@baylor.edu,Multilevel Bayesian Modeling of Follow-up Studies with Missing Data,1,Monica,M,Bennett,Baylor University,James,,Stamey,Baylor University,John,,"Seaman, Jr.",Baylor University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In this presentation we consider the problem of missing data in follow-up studies. These studies are commonly used to assess the rates of incidence of a particular event, such as death or injury, among different groups. In these studies it is most often assumed that the observed counts follow a Poisson distribution. Thus they are often analyzing using a Poisson regression model.  However, the analysis is complicated when some of the records indicating the cause of the incident have been destroyed or lost. Ignoring the missing data can lead to incorrect parameter estimates. To help overcome this problem, we develop a Bayesian multilevel Poisson model to account for the missing data. The model is developed so that it estimates the rates of incidence, as well as the probability of missing information.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Bayesian methods,Hierarchical models,,,,,,,04-Nov-10,moonseong.heo@einstein.yu.edu,,Moonseong Heo,,Albert Einstein College of Medicine,1300 Morris Park Avenue,718.920.6274,,moonseong.heo@einstein.yu.edu,Sample size requirements to detect an intervention by time interaction in longitudinal cluster randomized clinical trials with random slopes,1,Moonseong,,Heo,"Division of Biostatistics,Department of Epidemiology and Population Health, Albert Einstein College of Medicine",Xiaonan,,Xue,"Division of Biostatistics,Department of Epidemiology and Population Health, Albert Einstein College of Medicine",Mimi,Y,Kim,"Division of Biostatistics,Department of Epidemiology and Population Health, Albert Einstein College of Medicine",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In longitudinal cluster randomized clinical trials (cluster-RCT), subjects are nested within a higher level unit such as clinics and are evaluated for outcome repeatedly over the study period.  This study design results in a three level hierarchical data structure.  When the primary goal is to test the hypothesis that an intervention has an effect on the rate of change in the outcome over time and the between-subject variation in slopes is substantial, the subject-specific slopes are often modeled as random coefficients in a mixed-effects linear model.  In this paper, we propose samples size approaches based on ordinary least squares (OLS) estimates for detecting a difference in mean slopes between two intervention groups when the slopes are modeled as random.   Notably, the sample size is not a function of the variances of either the second or the third level random intercepts and depends on the number of second and third level data units only through their product.   Simulation results indicate that the OLS-based power and sample sizes are virtually identical to the empirical maximum likelihood based estimates. Sample sizes for random versus fixed slope models are also compared.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Clinical trials,Clustered data methods,,,,,,,20-Oct-10,mothus@fhcrc.org,,Megan Othus,,Fred Hutchinson Cancer Research Center,PO Box 19024,206-667-5749,,mothus@fhcrc.org,Cure Survival Models with Change-point Covariates,1,Megan,,Othus,Fred Hutchinson Cancer Research Center,Yi,,Li,Dana Farber Cancer Institute and Harvard University,Ram,,Tiwari,Food and Drug Administration,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Previous research on prostate cancer survival trends in the United States National Cancer Institute's Surveillance Epidemiology and End Results database has indicated a potential change-point in the age of diagnosis of prostate cancer around age 50.  Identifying a change-point value in prostate cancer survival and cure could have important policy and health care management implications.  Statistical analysis of this data has to address two complicating features: (1) change-point models are not smooth functions and so present computational and theoretical difficulties; and (2) models for prostate cancer survival need to account for the fact that many men diagnosed with prostate cancer can be effectively cured of their disease with early treatment. We develop a cure survival model that allows for change-point effects in covariates to investigate a potential change-point in the age of diagnosis of prostate cancer.  Our results do not indicate that age under 50 is associated with increased hazard of death from prostate cancer.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Survival analysis,Cancer applications,,,,,,,10-Nov-10,mpathak@huskers.unl.edu,,Manoj Pathak,Graduate Research Assistant/ Statistical Analyst,"Department of Biostatistics, College of Public Hea",4300 Holdrege Street # D102,402 730 9121,,mpathak@huskers.unl.edu,Effect of Modeling Expected Counts on Small Area Disease Mortality Maps,1,Manoj,,Pathak,"Graduate Research Assistant/ Statistical AnalystDepartment of Biostatistics, College of Public Health, University of Nebraska Medical Center, Omaha, NE",Jane,L.,Meza,"Professor and Chair, Department of BiostatisticsDirector, Center for Collaboration on Research, Design and AnalysisCollege of Public HealthUniversity of Nebraska Medical Center, Omaha, NE",Kent,M.,Eskridge,"Professor and Graduate Committee ChairDepartment of Statistics, University of Nebraska-Lincoln, Lincoln NE",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Medical practitioners, epidemiologists and biostatisticians use disease maps for estimating and presenting the geographic variation of a disease. A common approach in epidemiological studies is to map standardized mortality ratios (SMR) at various levels of geographic units or socio-demographic subpopulations level. Often, SMRs are calculated based on internally or externally standardized reference rates. However, reference rates do not take into account spatial correlation induced from the geographic proximities of nearby units. As a result, raw SMRs deviate more from the true relative risks in the presence of hot spots on the disease risk surface. In this study, we examine the effect of the expected counts of disease in estimating the true relative risk. We propose model-based estimates of expected cases instead of methods based on reference rates for producing improved disease maps.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Bayesian methods,Hierarchical models,,,,,,,12-Nov-10,mpennell@cph.osu.edu,,Michael Pennell,,The Ohio State University,B115 Starling-Loving Hall,614-293-9139,,mpennell@cph.osu.edu,Improving the Efficiency of Existing Group Randomized Trials using Bayesian Joint Modeling and Informative Priors,2,Xinyi,,Xu,The Ohio State University,Michael,L,Pennell,The Ohio State University,Bo,,Lu,The Ohio State University,David,,Murray,The Ohio State University,,,,,,,,,,,,,,,,,,,,,,,,,"The Group Randomized Trial (GRT) is regarded as the gold-standard for evaluating interventions applied to groups of people.  The design presents some analysis challenges in that subjects within each group are correlated and that there are often limited degrees of freedom for testing for an intervention effect because group is the experimental unit and few groups are usually enrolled.  In this paper, we propose a Bayesian methodology for addressing the small degrees of freedom problem in GRTs.  We jointly model continuous and binary outcomes using underlying normal random variables whose means are modeled as a linear function of fixed treatment, time, and covariate effects and random group and subject effects, the latter of which is shared across the two outcomes.  We also develop an informative prior for the ICC of each outcome which allows one to use ICC estimates collected in previous studies in the analysis.  The method is applied to body composition data collected in the Trial of Activity in Adolescent Girls (TAAG) study.  We find that our method provides greater efficiency (lower posterior standard deviations of the treatment effects) than univariate models for each outcome and models which place non-informative priors on the ICC.",FALSE,FALSE,,FALSE,TRUE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Clustered data methods,Bayesian methods,,,,,,,11-Nov-10,mquinlan22@yahoo.com,,Michelle Quinlan,Sr. Biostatistician,Novartis Oncology,180 Park Ave.,862-778-9506,,mquinlan22@yahoo.com,Estimating Shelf Life Using Mixed Model Quantile Regression,1,Michelle,,Quinlan,Novartis Oncology,Walt,,Stroup,University of Nebraska-Lincoln,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The goal of shelf life estimation is to determine the storage time during which the entire product meets specification with an acceptably high probability. In addition, the estimated shelf life should be applicable to all future batches (ICH Q1E). The ICH guidelines suggest treating batch effects as fixed; addressing batch-to-batch variability via tests for poolability; and, using a confidence interval for the mean to estimate shelf life. However, a fixed effects model does not allow inference to be made to future batches, and a confidence interval indirectly estimates a target quantile of the distribution.  Mixed model quantile regression (MMQR) combines the mixed model with quantile regression to model a quantile directly. The focus of shelf life estimation should be on a quantile of the distribution of batch shelf lives, where a batch shelf life is the time the batch mean intersects the acceptance limit. Exploiting the relationship between quantiles of the distribution of batch shelf lives and batch means over time, MMQR can be used to estimate a target quantile of the distribution of batch shelf lives. The MMQR estimated shelf life addresses the ICH objective of estimating the minimum batch shelf life and is applicable to future batches.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Random effects,Biopharmaceutical research,,,,,,,15-Nov-10,mredman@fhcrc.org,,Mary Redman,Assistant Member,Fred Hutchinson Cancer Research Center,"1100 Fairview Ave N, M3-C102",206-667-4767,,mredman@fhcrc.org,Prospective Predictive Biomarker Discovery and Validation using Targeted Maximum Likelihood,1,Mary,W,Redman,Fred Hutchinson Cancer Research Center,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Drug discovery in cancer clinical trials is complicated by the currentthought paradigm that most new agents (so-called targeted therapies)will only be active in small subsets of patients.  In order to definepossible subsets, the drugs targets and best method and measure ofthe targets need to be identified.  Generally most phase II studiesare not adequately powered to determine a possibly predictivebiomarker leaving this determination to the phase III setting. However, prospective validation of a biomarker predictive of treatmentefficacy following a phase III trial is generally infeasible for avariety of reasons.   In 2005, Freidlin and Simon proposed theBiomarker Adaptive design to prospectively discover and validate apredictive biomarker signature in one trial.  In this talk we proposean alternative method to defining the predictive biomarker set usingtargeted maximum likelihood (van der Laan & Rubin, 2006) and applythis approach to a study being planned within the Southwest OncologyGroup.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,TRUE,Clinical trials,Cancer applications,,,,,,,14-Nov-10,mrelliot@umich.edu,,Michael Elliott,,University of Michigan,Dept. of Biostatistics,734-647-5160,,mrelliot@umich.edu,Modeling and Classifying Womens Mensopausal Transition Patterns Using Menstrual Diary Data,1,Xiaobi,,Huang,University of Michigan,Michael,R,Elliott,University of Michigan,Sioban,D,Harlow,University of Michigan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Changes in women's menstrual patterns canpredict the onset of menopause. Using the TREMIN dataset that obtainedmenstrual cycle data from women throughout their reproductive life, we develop a a Bayesian change point model with eight parameters for each woman:mean cycle length at age 35, along with rate of change in mean cycle lengthbefore and after a latent changepoint age; and equivalent parameters for cycle variability. We then use estimates from this model to classifymenstrual patterns into subgroups using a K-medoids algorithm.  We thenrelate these subgroupsto age of menopause, age at menarche, number of births, as well as to existing standard menopausal transition markers. Our results suggest most mean andvariance changepoints are well aligned with transition markers,while some of them are not clearly associated. Women with highlyvariable cycles and/or weakly defined transitions can ``trigger' transitionmarkers long before the true transition begin. Thusmean and variance changepoints, which areidentified using data throughout women's late reproductive life,provide more comprehensive information about menopausal transition than previously defined transition markers.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Epidemiologic methods,Applied data analysis,,,,,,,15-Nov-10,mrosenbl@jhsph.edu,,Michael Rosenblum,Assistant Professor,"Dept. of Biostatistics, Johns Hopkins Bloomberg Sc","615 N. Wolfe St., Room E3616",508 648 8395,,mrosenbl@jhsph.edu,Targeted Maximum Likelihood Estimation for Dynamic Treatment Regimes,1,Michael,,Rosenblum,"Dept. of Biostatistics, Johns Hopkins Bloomberg School of Public Health",van der Laan,J,Mark,"Division of Biostatistics, University of California, Berkeley",Stephen,,Gange,"Dept. of Epidemiology, Johns Hopkins Bloomberg School of Public Health",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Targeted maximum likelihood estimation (TMLE) is a general methodologyfor constructing estimators in semiparametric and nonparametricmodels. In this talk, we first provide an overview of TMLE. We thenpresent a particular example where the goal is to estimate survivalunder adynamic treatment regime, based on observational data. We discuss howto implement a targetedmaximum likelihood estimator in this case. We apply this method to theproblem of estimating the effect of different rules for when toinitiate antiretroviral therapy, as a function of measured CD4 T-cellcount, for HIV-infectedindividuals.",FALSE,FALSE,,FALSE,TRUE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Causal inference,Longitudinal data,,,,,,,15-Nov-10,msammel@upenn.edu,,Mary Sammel,Associate Professor of Biostatistics,University of Pennsylvania,423 Guardian Drive,215-573-4887,,msammel@upenn.edu,Variability as a Predictor of Health in Longitudinal Studies,1,Mary,D,Sammel,"Department of BiostatisticsUniversity of Pennsylvania SOM",Michael,R,Elliott,"Department of Biostatistics and Survey Methodology Program, Institute for Social Research, University of Michigan",Jessica,,Faul,"Survey Methodology Program, Institute for Social ResearchUniversity of Michigan",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"To evaluate the effect of longitudinally measured risk factors on the subsequent development of disease, it is often necessary to calculate summary measures of these factors to capture features of the risk profile over time. The classic measurement error approach to modeling considers the correlation among repeated measurements as a nuisance and assumes that within-subject error has no association with the health outcome of interest, i.e. non-differential measurement error.  However, there is evidence that, at least in certain settings (Elliott 2007; Harlow et al. 2000; Sammel et al. 2001), underlying variability in subject measures may also be important in predicting future health outcomes of interest.  This talk will describe the development of a method for combining information from mean profiles and residual variance to predict categorical outcomes in a joint modeling framework. Both Bayesian and frequentist approaches to estimation are considered.  Trends and variability in word recall measures assessed bi-annually over 15 years are evaluated as predictors of dementia onset from the Health and Retirement Survey.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Longitudinal data,Measurement error,,,,,,,15-Nov-10,msidell@tulane.edu,,Margo Sidell,,ScD Candidate,6058 Camp St,7349954049,,msidell@tulane.edu,Comparison of high dimensional multivariate profiles with small sample sizes using u-scores,1,Margo,A,Sidell,Tulane University,Leann,,Myers,Tulane University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Recent studies have used u-scores to analyze single sample multivariate data (e.g., Wittkowski, et al 2004, 2008).  U, as described in these references, is a fairly crude measure of comparison between subjects.  Using similar logic, we devised a summary U-score statistic that allows more nuanced comparisons.  This summary U (Usum) can also be used to test for differences between two groups of subjects.  This may be a useful technique for the comparison of high dimensional multivariate profiles with small group sample sizes where traditional analysis methods are not appropriate. The distributions of Usum for various measure to sample ratios and overall sample sizes were estimated using simulations. The robustness of this method with respect to type I error and power was assessed for each of the data conditions including low, moderate, and high correlations between measures.",FALSE,FALSE,,FALSE,FALSE,FALSE,,contributedposter,,,,FALSE,FALSE,FALSE,FALSE,Applied data analysis,Multivariate methods,,,,,,,15-Nov-10,mtaub@jhsph.edu,,Margaret Taub,,Johns Hopkins Department of Biostatistics,Department of Biostatistics,510-517-3539,,mtaub@jhsph.edu,Detecting Genetic Variants with High-Throughput Sequencing,1,Margaret,,Taub,Johns Hopkins Department of Biostatistics,Ingo,,Ruczinski,Johns Hopkins Department of Biostatistics,Rafael,,Irizarry,Johns Hopkins Department of Biostatistics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"High-throughput sequencing is fast becoming a heavily used technology for detecting genetic variation in disease association studies, with the hope that detecting rare variants (which is challenging to do with genotyping microarrays) will help illuminate the genetic causes of common diseases.  Several successes have been achieved in identifying causative variants for Mendelian disorders using sequencing data, and many large consortium-based projects are moving forward with sequencing large numbers of samples with the aim of illuminating the genetic causes of common, complex diseases.  In this work, I present some of the challenges of accurately and completely determining genetic variants using sequencing data, comparing results from different sequencing strategies, including whole-genome resequencing, exome sequencing, and targeted resequencing, using data provided by my collaborators and publicly available data.  I will then discuss implications of these challenges for the detection and testing of variants associated with complex diseases.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,TRUE,Genomics,Statistical genetics,,,,,,,14-Nov-10,mueller@wald.ucdavis.edu,,Hans-Georg Mueller,Professor,UC Davis,Department of Statistics,530-219-1453,,mueller@wald.ucdavis.edu,Functional varying coefficient models for longitudinal data,1,Hans-Georg,,MŸller,"Department of StatisticsUniversity of California, Davis",Damla,,SentŸrk,"Department of StatisticsPennsylvania State University",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The proposed functional varying coefficient model provides aversatile and flexible analysis tool for relating longitudinalresponses to longitudinal predictors. Two key innovations are:(1) Representing varying coefficient functionsthrough auto- and cross-covariances of the underlyingstochastic processes, which is particularly advantageous for sparseand irregular designs, as often encountered in longitudinal studies;(2) Including history effects through a smooth history index function,to reflect settings, where notonly current, but also recent past values of the predictor timecourse impact the current value of the response time course.Asymptotic analysis yields consistency ofcoefficient and history index functions for sparse designs, includingasymptotic pointwise confidence bands.Implementation of this approach isillustrated with longitudinal primary biliary liver cirrhosisdata.",FALSE,FALSE,,FALSE,FALSE,TRUE,"Stat Analysis of Large Fct Data Sets SessionRecent Advances in Fct and Long Data AnalysisNew Fct Data Analysis Methods SessionNew Directions in Fct Data Analysis",invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Functional data analysis,Longitudinal data,,,,,,,15-Nov-10,munni.begum@gmail.com,,Munni Begum,Associate Professor,Ball State University,Department of Mathematical Sciences,7656175,,munni.begum@gmail.com,Graphical Models for High Dimensional Data,1,Munni,,Begum,Ball State University,Jay,,Bagga,Ball State University,Ann,,Blakey,Ball State University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Advances in science and information technology lead to high-dimensional data in many scientific fields. The common scenario of a small number of features (p) from a large number of experimental units (n) now had turned into a large p small n problem as the number of experimental units n is equal or even smaller than the number of features p. To address this problem there had been a surge in research activities offering data reduction methods and statistical inference. A general methodology based on probability and graph theories, coined as graphical models, can be applied efficiently to study the structure and computational issues in inference. Since bases for these models are conditional independence and Markov properties, complex dependence structure among a large number of stochastic variables can be studied efficiently. Although the general methodology is well developed, only a handful of these methods are implemented in practice. Motivation behind this research project comes from the challenges of analyzing large volume of high dimensional molecular interaction data. An essential research thrust of this project is to implement efficient parameterization, estimation algorithms, and model selection procedures to graphical models based on chain graphs and other relevant graphs.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Graphical models,High dimensional data,,,,,,,14-Nov-10,mwang36@emory.edu,,Ming Wang,,M.S.,1518 Clifton Rd NE,4042268975,,mwang36@emory.edu,Comparison and summary of criteria for working correlation structure and covariate selection in Generalized Estimating Equation,1,Ming,,Wang,Emory University,Lijun,,Zhang,Emory University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Correlated or clustered response data in biomedical studies are commonly analyzed by Generalized Estimating Equation (GEE), a marginal statistical method. Correctly specifying working correlation structure can enhance the efficiency of the parameter estimate, and covariates selection also affects the goodness-of-fit of GEE model. Thus, how to choose intracluster correlation matrix and covariates plays a vital role in fitting GEE regression models. We investigate the performances of three existing criteria, the Rotnitzky-Jewell criterion, a quasi-likelihood information criterion (QIC or QICU), and the marginal R2 via simulations and real examples, where independence, exchangeable, AR(1) and unstructured correlation structures are compared in each scenario. Programs in both SAS and R are presented for GEE models with Gaussian, binary and Poisson outcomes.",FALSE,FALSE,,FALSE,FALSE,FALSE,,contributedposter,,,,FALSE,FALSE,FALSE,TRUE,Variable subset selection/model selection,Longitudinal data,,,,,,,15-Nov-10,mwhi@mail.med.upenn.edu,,Matthew White,,University of Pennsylvania,2123 Spruce Street,8173203131,,mwhi@mail.med.upenn.edu,Adjustment for Measurement Error in Diagnostic Tests,1,Matthew,T,White,"University of Pennsylvania School of MedicineCenter for Clinical Epidemiology and Biostatistics",Sharon,X,Xie,"University of Pennsylvania School of MedicineCenter for Clinical Epidemiology and Biostatistics",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Repeated measurements of a biomarker vary within a subject due to measurement error.  Sources of measurement error include variability within individual over time and variability in the test.  A naive approach ignores the error, biasing the sensitivity and specificity of the test and giving the erroneous impression that the biomarker is not effective.  We propose bias-correction approaches for estimating sensitivity and specificity as well as positive and negative predictive values when the test is subject to measurement error.  We derive their asymptotic properties.  We then perform simulations to compare our approaches to naive approaches in estimates of sensitivity and specificity as well as positive and negative predictive values.  The proposed methods have broad biomedical applications (e.g., renal disease, Alzheimer's disease) and are illustrated using a biomarker study in Alzheimer's disease.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Measurement error,ROC analysis,,,,,,,15-Nov-10,mxy170@psu.edu,,Mina Yoo,,PSU,1010 Stratford Court,814 3215644,814 3215644,mxy170@psu.edu,Assessment of agreement for intensive longitudinal data,1,Mina,,Yoo,The Pennsylvania State University,Runze,,Li,The Pennsylvania State University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Measurement agreement is an important consideration for many fields. It refers to the extent to which different methods, measurement instruments, or raters agree when evaluating the same underlying construct. A number of indices for measuring agreement have been developed. However, these measures make a major assumption: that the mean and variation are stable over time. With a widespread use of intensive longitudinal data (ILD), where assessments are collected at multiple time points (e.g. 20 or more) and are often characterized by a smooth curve and a time-varying variance, traditional approaches to assessing agreement are not appropriate. We propose a new index of agreement for ILD, the functional type of concordance correlation coefficient (FCCC), which is an extension of the concordance correlation coefficient. FCCC is robust against functional features of ILD, and separates the degree of agreement between measures from the time effect. FCCC summarizes the degree of agreement at each time point. As a result, the index is a function of time. We demonstrate it with an analysis of body temperature in obesity group during exercise trials.",FALSE,FALSE,,FALSE,FALSE,FALSE,,contributedposter,,,,FALSE,FALSE,FALSE,FALSE,Agreement,Longitudinal data,,,,,,,14-Oct-10,my2k@huskers.unl.edu,,Michael Black,,University of Nebraska-Lincoln,5704 Madison Ave,402-853-2022,,my2k@huskers.unl.edu,Incorporating individual risk probabilities into a group testing algorithm,1,Michael,S,Black,"Department of Statistics, University of Nebraska-Lincoln",Christopher,R,Bilder,"Department of Statistics, University of Nebraska-Lincoln",Joshua,M,Tebbs,"Department of Statistics, University of South Carolina, Columbia",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Key words: binary response; classification; identification; pooled testing; retesting; screeningSummary. Group (pooled) testing is often used to reduce the total number of tests needed to screen a large number of individuals for an infectious disease or some other binary characteristic. Traditionally, research in group testing has assumed each individual is independent with the same risk of positivity. More recently, there is a growing set of literature generalizing previous work in group testing to include heterogeneous populations so that each individual has a different risk of positivity. In this paper, we investigate the impact of acknowledging population heterogeneity on a commonly used group testing procedure known as halving. For this procedure, positive groups are successively split into two equal sized halves until all groups test negative or until individual testing occurs. We show that heterogeneity does not affect the mean number of tests when individuals are randomly assigned to sub-groups. However, when individuals are assigned to sub-groups based on their risk probabilities, we show that our proposed procedures reduce the number of tests by taking advantage of the heterogeneity. This is illustrated using chlamydia and gonorrhea screening data from the state of Nebraska.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Diagnostic and screening tests,Infectious disease models,,,,,,,03-Nov-10,myuan@isye.gatech.edu,,Ming Yuan,,Georgia Tech,755 Ferst Dr NW,4048942359,,myuan@isye.gatech.edu,Analysis of Discretely Sampled Functional Data,1,Ming,,Yuan,Georgia Tech,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The problem of estimating the mean or covariance function of random functions based on discretely sampled data arises naturally in functional data analysis. In this talk, we discuss optimal estimation of the mean and covariance function under both the common and independent designs. The analysis reveals interesting and different phase transition phenomena in the two cases. This talk is based on joint work with Tony Cai.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Functional data analysis,Machine learning,,,,,,,14-Nov-10,mzhangst@umich.edu,,Min Zhang,Assistant Professor,University of Michigan,1415 Washington Heights,919-2809155,734-763-2215,mzhangst@umich.edu,Semiparametric estimator for differences in restricted mean lifetimes in observational studies,1,Min,,Zhang,University of Michigan,Douglas,,Schaubel,University of Michigan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Restricted mean lifetime is often of direct interest in epidemiologicstudies involving censored survival times. Differences in the quantitycan be used as a basis for comparing several groups. For example,kidney transplant surgeons, nephrologists and of course patients areinterested in comparing post-transplant lifetimes among various typesof transplant in order to assist in clinical decision-making. As thefactor of interest is not randomized, covariate adjustment is neededin order to account for imbalances in confounding factors. In thispaper, using semiparametric theory, we propose an estimator fordifferences in restricted mean lifetimes while accounting for confoundingfactors. The proposed methods involve building working models for thetime-to-event and group assignment mechanisms. We show that theproposed estimator possesses the double robust property; i.e., wheneither one of the working models is correct, the estimator isconsistent and asymptoticallynormal. Simulation studies are conducted to assess its finite-sampleperformance and the method is applied to kidney transplant data.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Survival analysis,Causal inference,,,,,,,15-Nov-10,nab36.cornell@gmail.com,,Nikolay Bliznyuk,,Texas A&M University,433 Blocker Bldg,267-777-7654,,nab36.cornell@gmail.com,Efficient Interpolation of Computationally Expensive Posterior Densities with Variable Parameter Costs,1,Nikolay,,Bliznyuk,"Texas A&M University, Department of Statistics",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Bayesian inference using MCMC is computationally intractable when theposterior density $\pi$ of the parameter vector $\eta$ is expensive toevaluate.In many models, it is possible to identify a minimal subvector $\beta$of $\eta$ responsible for the expensive computation in the evaluationof $\pi$.  We propose two approaches, DOSKA and INDA, that approximate$\pi$ by interpolation in ways that exploit this computationalstructure to mitigate the curse of dimensionality inherent tointerpolation. DOSKA interpolates $\pi$ directly while INDAinterpolates $\pi$ indirectly by interpolating functions, e.g., aregression function, upon which $\pi$ depends. Our primarycontribution is derivation of a Gaussian processes interpolant thatprovably improves over some of the existing approaches by reducing theeffective dimension of the interpolation problem from $\dim(\eta)$ to$\dim(\beta)$. This allows a dramatic reduction of the number ofexpensive evaluations necessary to construct an accurate approximationof $\pi$ when $dim(\eta)$ is high but $dim(\beta)$ is low.  We illustrate the proposed approaches in a case study for aspatio-temporal semiparametric model for air pollution data in thegreater Boston area.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Computational methods,Bayesian methods,,,,,,,15-Oct-10,naim@unc.edu,,Naim U Rashid,,UNC-CH Biostatistics,"100 Spring Meadow Drive,#11202",9194487336,,naim@unc.edu,A General Mixture Regression Framework for The Detection of Biologically Relevant Loci from NGS Data,1,Naim,U,Rashid,UNC-CH Biostatistics,Wei,,Sun,UNC-CH Biostatistics,Joseph,,Ibrahim,UNC-CH Biostatistics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Chromatin immunoprecipitation (ChIP) followed by Next Generation Sequencing (ChIP-seq) and related methods have become essential for the detection of genome-wide sites of biological activity, providing new insights into cellular regulation and disease progression. While many tools exist to detect enriched loci in sequencing data, most are not general enough to handle the wide diversity in signal patterns representing various biological processes, ranging from narrow to broad and high signal-to-noise to low.  In addition, most methods cannot account for the effects of multiple confounding factors that may bias signal in genomic regions. To address this, we have developed a general three-component mixture regression framework called ZINBA that uses minimal assumptions to probabilistically partition the genome into enriched and background signal regions while adjusting for the effects of corresponding factors or signal covariates. Using ZINBA, we demonstrate for the first time that the effects of confounding factors are not consistent across datasets and even genomic regions with the same data. We also show that ZINBA consistently calls biologically relevant regions of enrichment across a wide variety of Next Generation Sequencing datasets, signal  patterns, and experimental conditions.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,TRUE,Genomics,Cancer applications,,,,,,,15-Nov-10,nathan.pugh06@gmail.com,,Nathan Pugh,,University of Pittsburgh,1019 Allegheny Ave.,7173778196,,nathan.pugh06@gmail.com,Use of Outlier-sum statistics for identifying informative brain regions in the analysis of Magnetic Resonance Imaging Data,1,Nathan,,Pugh,University of Pittsburgh,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The outlier-sum statistic is a biologically-derived method for identifying genes that are differentially expressed in a subset of the diseased group or the group of interest.  We explore the application of the outlier-sum statistic for the analysis of MRI data.  These data sets often contain 200 or more regions obtained from a limited set of subjects.  In genetics analysis, using a t-test for finding differences between groups has low power when only a subset of the group of interest is differentially expressed.  The outlier-sum statistic gains its power by identifying genes that are differentially expressed in only a subset of the region of interest.  The outlier-sum statistic is robust with respect to the size of the subset.  The goal of the analysis is to identify regions that are informative to distinguish between two different groups of elderly subjects participating in a clinical trial examining the effectiveness of a drug given to slow the onset of dementia in healthy normal control subjects.  The properties of the outlier-sum statistic for this application are also examined in a simulation study.",FALSE,FALSE,,FALSE,FALSE,FALSE,,contributedposter,,,,FALSE,FALSE,FALSE,FALSE,Imaging,Applied data analysis,,,,,,,12-Nov-10,ncai@ncsu.edu,,Na Cai,,North Carolina State University,704 Ryan Ct.,9192721790,,ncai@ncsu.edu,Analysis of longitudinal data with time-varying dependence on observation times,1,Na,,Cai,North Carolina State University,Wenbin,,Lu,North Carolina State University,Hao,,Zhang,North Carolina State University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In analysis of longitudinal data, longitudinal outcomes are oftenassumed to be independent of observation times. In practice,observation times may be informative and correlated with longitudinaloutcomes. Without considering existing correlations, the resultingestimators could be biased. In this article, we propose to jointlymodel longitudinal outcomes and observation times via shared randomeffects and nonparametric functions. The modeled correlations can bevery flexible and even time-dependent. A two-stage estimationprocedure is developed to estimate parameters of primary interest. Theresulting estimators are proved to be consistent and asymptoticallynormal. The performance of our proposed method are evaluated byintensive simulation studies. And, a real data is analyzed by ourproposed method.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Joint models for longitudinal and survival data,Longitudinal data,,,,,,,15-Nov-10,neenjuly@email.unc.edu,,Jeanine Matuszewski,,University of North Carolina at Chapel Hill,201 NC Hwy 54 Apt 618,3152694781,,neenjuly@email.unc.edu,Asymptotic Properties of an R2 Statistic for Fixed Effects in the Linear Mixed Model,1,Jeanine,,Matuszewski,University of North Carolina at Chapel Hill,Lloyd,,Edwards,University of North Carolina at Chapel Hill,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Asymptotic Properties of an R-2 Statistic for Fixed Effects in the Linear Mixed Model The R-2 statistic has become a widely used tool when analyzing data in the linear univariate setting. There are many R2 statistics for the linear mixed model but their properties are not well established. There is a recently proposed R-2 statistic for fixed effects based on the Wald F test in the linear mixed model that has several desirable features. The statistic has a semi-partial form and a correspondence to the Hotelling-Lawley trace multivariate measure of association. In this paper, the focus is on the asymptotic properties of R-2. A simulation study is used to illustrate the impact of covariance structure misspecification, varying the denominator degrees of freedom method and estimation techniques. Covariance structure misspecification and denominator degrees of freedom methods substantially impact theasymptotic behavior of R-2 while the estimation technique does not.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,TRUE,Other,Longitudinal data,Linear Mixed Models,,,,,,14-Nov-10,nels@vt.edu,,Nels Johnson,,Virginia Tech,834 Orchard Street,703 350 6045,,nels@vt.edu,Measurement Error in 1-1 Matched-Case Control Studies,1,Nels,G,Johnson,Virginia Polytechnic Institute and State University,Inyoung,,Kim,Virginia Polytechnic Institute and State University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In epidemiological research, matched case-control studies are popular.Measurement error of covariates is a modeling problem that often needsto be addressed. However, there is no statistical approach to handleboth problems together. We propose a Bayesian method for measurementerror models in 1-1 matched case-control studies, assuming the erroris additive and Gaussian. We extend this method from a linear functionof predictors to unknown functions using regression splines. Weaddress some issues that arise when using regression splines inconditional logistic regression models that do not exist in theunconditional model when measurement error is present.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Measurement error,Bayesian methods,,,,,,,12-Nov-10,nhs3@pitt.edu,,Nilesh Shah,,Graduae Student,5630 Hobart St,734-347-1592,,nhs3@pitt.edu,Discrimination index for latent group-based trajectory models,1,Nilesh,,Shah,University of Pittsburgh,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In clinical research, patient care decisions are often easier to makeif patients are classified into a manageable number of groups based onhomogeneous risk patterns.  Investigators can use latent group-basedtrajectory modeling (Nagin, 2005) to estimate the posteriorprobabilities that an individual will be classified into a particulargroup.  Although this method is increasingly used in clinicalresearch, there is currently no measure that can be used to determinewhether an individual's group assignment has a high level ofdiscrimination.  In this study, we propose a discrimination index andprovide confidence intervals of the probability of the assigned groupfor each individual.  We used two different methods (the delta methodand the bootstrapping procedure) to obtain the standard error of thisindex.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Latent variables,Longitudinal data,,,,,,,11-Oct-10,nhzhang@umich.edu,,Nanhua Zhang,,"Department of Biostatistics, University of Michiga","1415 Washington Hgts, 4th floor",734-358-6490,,nhzhang@umich.edu,A Pseudo Bayesian Shrinkage Approach to Regression with Missing Covariates,1,Nanhua,,Zhang,"Department of Biostatistics, University of Michigan",Roderick,J. A.,Little,"Department of Biostatistics, University of Michigan",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We consider the regression of outcome Y on regressors W and Z withsome values of W missing, when our main interest is the effect of Z onY, controlling for W. Three common approaches to regression withmissing covariates are (a) complete-case analysis (CC), which discardsthe incomplete cases, and (b) ignorable likelihood methods, which baseinference on the likelihood based on the observed data, assuming themissing data are missing at random (Rubin, 1976), and (c) nonignorablemodeling, which posits a joint distribution of the variables andmissing data indicators. Another approach that has not received muchattention is to drop the regressor variables containing missing valuesfrom the regression modeling (DV, for drop variables). DV is mostuseful when either (I) the regression coefficient of W is zero or (II)W and Z are uncorrelated. We propose a pseudo Bayesian approach forregression with missing covariates, which compromizes between the CCand DV estimates. We illustrate favorable properties of the method bysimulation, and apply the proposed method to a liver cancer study.Extensions of the method to more than one missing covariates and togeneralized linear models are also discussed.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,TRUE,Missing data,Bayesian methods,,,,,,,12-Nov-10,nichole.carlson@ucdenver.edu,,Nichole Carlson,Associate Professor,"University of Colorado Denver, Dept. of Biostatist","13001 E 17th PL, MS B119",303-724-4354,,nichole.carlson@ucdenver.edu,A comparison of statistical methods for characterizing pulses in time series of hormone data,1,Nichole,E,Carlson,"University of Colorado Denver,Department of Biostatistics and Informatics",Kenneth,,Horton,"University of Colorado Denver,Department of Biostatistics and Informatics",Gary,K,Grunwald,"University of Colorado Denver,Department of Biostatistics and Informatics",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Many endocrine systems are regulated by pulsatile hormones.  Understanding changes that occur in pulsatile hormone secretion in relation to disease, genetic, or environmental factors is of major interest.  Pulsatile hormones are secreted intermittently in boluses rather than continuously over time.  To study pulsatile secretion, researchers collect time series of hormone concentrations every few minutes for an extended period of time.  The goal is to estimate hormone secretion features such as frequency, location, duration, and amount of pulsatile and non-pulsatile secretion and compare these features between groups.  In the past decade many statistical approaches have been developed to estimate pulsatile secretion; however, investigations have focused on one specific hormone.  Thus, we lack a broader understanding of the performance of these new methods on a range of hormones that may have very different patterns and statistical challenges.  This work investigates the performance, strengths, and weaknesses of six newer statistical approaches for pulsatile hormone data.  We compare the performance of these newer methods with the existing 'gold standard' method of deconvolution (Veldhuis and Johnson, 1992).  Using a variety of hormone data collected in physiology studies, as well as simulated data, we offer guidance as to what methods work best for each hormone.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Applied data analysis,Nonlinear models,,,,,,,08-Nov-10,nick.sabbe@ugent.be,,Nick Sabbe,,UGent,Coupure Links 653,0032 486 54 46 75,,nick.sabbe@ugent.be,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,FALSE,FALSE,,FALSE,FALSE,FALSE,,,,,,FALSE,FALSE,FALSE,FALSE,,,,,,,,,08-Nov-10,niehui@wharton.upenn.edu,,Hui Nie,,University of Pennsylvania,3730 Walnut Street,2673256034,,niehui@wharton.upenn.edu,Inference for the Effect of Treatment on Survival Probability in Randomized Trials with Noncompliance and Administrative Censoring,1,Hui,,Nie,"Department of Statistics, The Wharton School, University of Pennsylvania",Jing,,Cheng,"Division of Oral Epidemiology, Dental Public Health, UCSF School of Dentistry",Dylan,S,Small,"Department of Statistics, The Wharton School, University of Pennsylvania",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In many clinical studies with a survival outcome, administrativecensoring occurs when follow-up ends at a pre-specified date and manysubjects are still alive. An additional complication in sometrials is that there is noncompliance with the assigned treatment. Forthis setting, we study the estimation of the causal effect oftreatment on survival probability up to a given time point among thosesubjectswho would comply with the assignment to both treatment and control. Wefirst discuss the standard instrumental variable method for survivaloutcomes and parametric maximum likelihood methods, and then developan efficient plug-in nonparametric empirical maximum likelihoodestimation (PNEMLE) approach. The PNEMLE method does not make anyassumptions on outcome distributions, and makes use of the mixturestructure in the data to gain efficiency over the standardinstrumental variable method. Theoretical results of the PNEMLE arederived and the method is illustrated by an analysis of data from abreast cancer screening trial. From our limitedmortality analysis with administrative censoring times 10 years intothe follow-up, we find a significant benefit of screening is presentafter 4 years (at the 5% level) and this persists at 10 years follow-up.",FALSE,FALSE,,FALSE,FALSE,FALSE,,contributedposter,,,,FALSE,FALSE,FALSE,TRUE,Causal inference,Clinical trials,,,,,,,15-Nov-10,ninghao008@gmail.com,,Ning Hao,Visiting Assistant Professor,The University of Arizona,617 N. Santa Rita Ave.,6099336978,,ninghao008@gmail.com,Group Iterative Sure Independent Screening,1,Ning,,Hao,The University of Arizona,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We consider regression problems in which the predictors possess agroup structure. The goal is to select important groups efficiently inthe ultrahigh dimensional setting, when the number of groups is muchlarger than the sample size. The ultrahigh setting is common incontemporary data sets. In Genome-Wide Association Study, importantSNPs and genes are to be selected in a pool consisting of tens ofthousands of SNPs within thousands of genes while the sample size isusually about a few hundreds. Penalization approaches such as groupLASSO and group MCP are not efficient in solving ultrahigh dimensionalproblems. We use correlation learning approach and generalize theIterative Sure Independent Screening (ISIS) procedure to the settingof group selection.  Group ISIS is proposed for group selection. Anapplication in Genome-Wide Association Study is shown as well.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,High dimensional data,Variable subset selection/model selection,,,,,,,12-Nov-10,nlazar@stat.uga.edu,,Nicole Lazar,Professor,University of Georgia,Department of Statistics,(706) 542-0632,,nlazar@stat.uga.edu,Social Network Models for fMRI,1,Nicole,A.,Lazar,"Department of Statistics, University of Georgia",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The spatiotemporal correlation in fMRI data is a challenge to theiranalysis.  Although a fair bit of attention has been devoted to thetemporal aspect, the spatial correlation has in general been moredifficult.  This is because the nature of the correlation does notlend itself to the common assumptions of spatial modeling; brainregions that are physically remote from each other might still exhibitstrong correlation due to similar function, for example.  In this talk,I discuss the use of social network models as one way of incorporatingthe spatial dependencies in the data to discover areas of activation.In this framework, voxels are the 'actors' in the network, and the'social relations' are described by patterns of co-activation.  I willdemonstrate the approach on a comparative study of schizophrenia patients, their unaffected relatives, and unrelated controls, all performing an inhibitory eye movement task.  This is joint work with Ana Bargo, Abhyuday Mandal, Jennifer McDowelland Lynne Seymour.",TRUE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Imaging,Spatial/temporal modeling,,,,,,,28-Sep-10,nlfw9@mail.missouri.edu,,Ni Li,,"Department of Statistics, University of Missouri","601 S. Providence Rd, Apt 704i",573-814-9412,,nlfw9@mail.missouri.edu,Semiparametric Transformation Models for Joint Analysis of Observation and Recurrent Event Processes,1,Ni,,Li,"Department of Statistics, University of Missouri",Liuquan,,Sun,,Jianguo,,Sun,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In longitudinal follow-up studies each subject may experience multipleoccurrences of an event and the rate of the event occurrences is ofprimary interest. Panel count data usually occur in the situationswhere subjects can be observed only at discrete time points ratherthan continuously and therefore only cumulative counts for the eventoccurrences are observed. The observation times may vary from subjectto subject and more importantly, it may be informative about theunderlying recurrent event process. A class of semiparametrictransformation models is proposed to characterize the effect of thecovariates on the mean function of recurrent event process. The modelsare much more flexible than the existing ones and include proportionalmean model and additive mean model as special cases. For inference,estimating equation approaches are developed and the resultingestimators are shown to be consistentand asymptotically normal. An extensive simulation study is conductedand indicates that the proposed approach works well for practicalsituations. An illustrative example is provided.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,TRUE,Estimating equations,Longitudinal data,,,,,,,12-Nov-10,nliu@uab.edu,,Nianjun Liu,,The University of Alabama at Birmingham,"1665 University Boulevard, 420A",001-205-975-9190,001-205-975-2541,nliu@uab.edu,Statistical methods for Rare Variants Identification,2,Wan-Yu,,Lin,"Department of BiostatisticsThe University of Alabama at Birmingham",Nianjun,,Liu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Genome-wide association studies have successfully identified manycommon single nucleotide polymorphisms associated with complex humandiseases. However, there remains a large portion of the heritability,that cannot be explained by these common variants, for complexdiseases. Exploring rare variants associated with diseases is nowcatching more and more attention. Several methods have been proposedfor rare variants identification recently. Among them, thefixed-threshold approaches, the weighted-sum method, andvariable-threshold approach are more effective in combining theinformation of multiple variants in a functional unit, and arecommonly used in practice. In this work, we evaluate the performanceof these methods, and our proposed method. Based on our analyses onthe simulated data, we find that our method performs better than othermethods, which are comparable with each other.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Statistical genetics,Applied data analysis,,,,,,,15-Nov-10,nwangaa@umich.edu,,Naisyin Wang,,University of Michigan,"University of Michigan, 445E West Hall",979-491-6079,,nwangaa@umich.edu,The Use of Multiple Functional Data As Predictors,1,Naisyin,,Wang,University of Michigan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We study the scenario that multiple functional observations (curves) were collected from the same individual.  Due, in part, to the fact that these functional observations are correlated, it raises a challenge on how to properly utilize these correlated curves as predictors. We propose a weighting scheme so that, instead of facing the deterioration caused by problems such as high multi-collinearity, one takes advantages of the availability of multiple observed curves within the same subject.  The use of the proposed approach will be illustrated through analysis of simulated and read data.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Functional data analysis,Nonparametric methods,,,,,,,12-Nov-10,nzhang@amgen.com,,Nan Zhang,,Amgen Inc.,1407 Oak Trail St.,8054471647,,nzhang@amgen.com,Impact of Variability on the Criteria of Biosimilarity in Assessing Follow-on Biologics,2,Nan,,Zhang,Amgen Inc.,Jun,,Yang,Amgen Inc.,Shein-Chung,,Chow,Duke University School of Medicine,Eric,,Chi,Amgen Inc.,,,,,,,,,,,,,,,,,,,,,,,,,"With larger variation in biological products compared to small molecular drugs, it is suggested that the assessment of biosimilarity of follow-on biologics (FOBs) should take into consideration of variability, in addition to average as standard in bioequivalence test in small molecule drugs. Recent research on assessing variability in biosimilarity of FOBs has been focused on direct assessment of variances, individual biosimilar index aggregating average and variability, and comparison of the entire distributions. However, the choice of biosimilarity limits for evaluating FOBs was not investigated in the literatures. In this article, we first explored the impact of variability on biosimilarity limits for the average biosimilarity assessment and draw the appropriate limits for highly variable biological products. In the second part, we tried to determine the corresponding biosimilarity limits that should be used in other biosimilarity criteria so the relationship of biosimilarity limits across different evaluation criteria was established and the impact of variability on the choice of biosimilarity limits was assessed for each evaluation criterion.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Biopharmaceutical research,Health policy applications,,,,,,,11-Nov-10,oel@umich.edu,,Oliver Lee,,University of Michigan,3755 Green Brier Blvd Apt 260B,9739600131,,oel@umich.edu,A Permutation Test for Random Effects in Generalized Linear Mixed Models,1,Oliver,,Lee,University of Michigan,Thomas,,Braun,University of Michigan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Performing inference on random effects is challenging because underthe null hypothesis the variance components are located on theboundary of their parameter space.  In earlier work, we proposedpermutation methods useful for testing for the inclusion of randomeffects in linear mixed models (LMMs) based on permutations ofweighted residuals both among- and within-subjects and showed thatthese permutation tests are valid and have power comparable to othermethods.  In our current work, we extend our methods to test for theinclusion or exclusion of random effects in generalized linear mixedmodels (GLMMs).  The novelty in our approach lies in the use ofworking residuals that are generated by approximating the GLMM by aLMM.  We prove the approximate exchangeability of these workingresiduals and present simulation results showing that our test isvalid and has power comparable to existing asymptotic methods.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Random effects,Longitudinal data,,,,,,,08-Nov-10,ofer.harel@uconn.edu,,Ofer Harel,,University of Connecticut,"215 Glenbrook rd, unit 4120",860-486-6989,,ofer.harel@uconn.edu,Comparing Regression Coefficients Between Nested Models for Clustered Data with Generalized Estimating Equations,3,Jun,,Yan,"Department of Statistics, University of Connecticut",Robert,,Aseltine,"Institute for Public Health Research, University of Connecticut Health Center",Ofer,,Harel,"Department of Statistics, University of Connecticut",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Comparing regression coefficients between models when one model isnested within another is of great practical interest when twoexplanations of a given phenomenon are specified as linear models. Thestatistical problem is whether the coefficients associated with agiven set of covariates change significantly when other covariates areadded as controls. Methods for such comparison exist for independentdata but do not apply when data are clustered such as longitudinalor familial data. Under the framework of generalized estimatingequations, we develop statistical methods for such comparison. Theproperties of the proposed estimator of the difference in regressioncoefficients between two models are studied asymptotically and forfinite samples. Data example is presented.",FALSE,FALSE,,FALSE,FALSE,TRUE,"Due to the Jewish holiday, I will not be able to present on Monday.",invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Longitudinal data,Hierarchical models,,,,,,,05-Nov-10,ogburn@post.harvard.edu,,Elizabeth Ogburn,PhD candidate,Harvard University Department of Biostatistics,655 Huntington Avenue,(617) 835-4468,,ogburn@post.harvard.edu,Variation Independent Parameterization and Doubly Robust Estimation of the Multiplicative Local Average Treatment Effect with Binary Outcome,1,Elizabeth,L,Ogburn,Harvard University Department of Biostatistics,Thomas,S,Richardson,,James,,Robins,,Andrea,,Rotnitzky,,,,,,,,,,,,,,,,,,,,,,,,,,"Consider a study in which the effect of a binary treatment on anoutcome is confounded by variables which are unmeasured and thereforecannot be controlled for. An instrument is a variable that is relatedto the treatment but to neither the unmeasured confounders nor theoutcome (e.g. treatment assignment in a clinical trial with non-randomnon-compliance). Under certain assumptions instrumental variablemethods give unbiased estimates of the treatment effect where standardstatistical methods cannot. In particular, under the monotonicityassumption that there are no defiers in the population, instrumentalvariable methods can estimate the effect of treatment amongcompliers on both the additive and multiplicative scales (the localaverage treatment effect, LATE, and local average multiplicativetreatment effect, LAMTE, respectively). For a continuous outcome andhigh-dimensional covariates X, doubly robust and locally efficientestimation procedures are available for the estimation of LATE(x) andLAMTE(x). However, for a binary outcome, the two components of thedata distribution which must be modeled in order to achieve doublyrobust and locally efficient estimation of LAMTE(x) are not variationindependent, and therefore until now no such estimator has beenavailable. We propose a variation independent reparameterization andintroduce the resulting estimator.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,TRUE,Other,Causal inference,Instrumental variable methods,,,,,,12-Nov-10,olivier.thas@UGent.be,,Olivier Thas,,Ghent University,Coupure Links 653,+32-486-578974,,olivier.thas@UGent.be,"An integrated Bayesian lasso and multiple imputation framework, with applications to a biomarker selection problem",1,Nick,,Sabbe,"Ghent University, Department of Applied Mathematics, Biometrics and Process Control",Olivier,,Thas,"Ghent University, Department of Applied Mathematics, Biometrics and Process Control",Jean-Pierre,,Ottoy,"Ghent University, Department of Applied Mathematics, Biometrics and Process Control",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Variable selection for prediction models is often achieved through the lasso, particularly in a high dimensional predictor setting. Due to the high dimensionality, however, it is very unlikely that all predictor observations are observed. When missing at random may be assumed, it is no realistic solution to delete observations row-wise, because this procedure may reduce the sample size too much. A multiple imputation procedure is more appropriate. In this paper we present a framework that integrates the lasso and multiple imputation, both in their Bayesian formulation, and we apply the method to a biomarker selection problem. 		We developed a hierarchical Bayesian model for the logistic lasso, and implemented the resulting Gibbs sampler in an R package. Repeating this with a reasonable number of imputed datasets, and correctly combining the samples from the posterior distributions allows us to approximate  the posterior mode, which is thus the lasso estimator. The posterior distribution incorporates the imputation variance. 	Finally, we applied the method to a study for selecting genetic biomarkers for the prediction of adverse effects from radio therapy for throat cancer patients. The adverse effect is modeled as a binary outcome.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Missing data,Biomarkers/surrogate markers,,,,,,,12-Nov-10,olshen@yahoo.com,,Adam Olshen,,"University of California, San Francisco","1450 3rd Street, MC 0128",415-514-9406,,olshen@yahoo.com,Methods for parent-specific analysis of SNP array data,1,Adam,B,Olshen,"Department of Epidemiology and Biostatistics and Helen Diller Family Comprehensive Cancer Center,University of California, San Francisco",Richard,A,Olshen,"Department of Health Research and Policy,Stanford University",Henrik,,Bengtsson,"Department of Epidemiology and Biostatistics,University of California, San Francisco",Pierre,,Neuvial,"Department of Statistics,University of California, Berekely",Paul,,Spellman,Lawrence Berkeley National Laboratory,Venkatraman,E,Seshan,"Department of Epidemiology and Biostatistics,Memorial Sloan-Kettering Cancer Center",,,,,,,,,,,,,,,,,"SNP arrays provide additional information to that given by traditionalcopy number arrays.  In particular, they allow estimation of parent-specific copy number (PSCN) instead of just total copy number.  A number of methods have been developed to examine PSCN.  We will evaluate these methods and address issues including paired versus unpaired samples, normal contamination, and ploidy.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Genomics,Microarray analysis,DNA Copy Number,,,,,,01-Nov-10,omalley@hcp.med.harvard.edu,,A James O'Malley,Associate Professor of Statistics,Harvard Medical School,Department of Health Care Policy,617-432-3493,617-432-0173,omalley@hcp.med.harvard.edu,Genetic Alleles as Instrumental Variables for Peer Effects,1,A James,,O'Malley,Harvard Medical School,J Niels,,Rosenquist,Massachusetts General Hospital,Alan,M,Zaslavsky,Harvard University,Nicholas,A,Christakis,Harvard University,,,,,,,,,,,,,,,,,,,,,,,,,"We develop instrumental variables (IVs) methodology for estimation of peer effects given longitudinal social network data, considering the candidacy of genetic alleles as IVs for illustration. Because genes are randomly assigned at birth and so predispose individuals to certain health traits such as higher body mass index (BMI) or obesity they appeal as ideal instrument variables. However, because genes can manifest in phenotypes (e.g., BMI) at any point during an individuals life, we argue that a longitudinal model with lagged values of the phenotype in all individuals as covariates is necessary for the IV assumptions to be plausible. We derive a general methodological approach that accommodates heterogeneity in peer effects across different types of relationships and moderation of peer effects by covariates in the context of both network influence models (net effect of all peers) and dyadic influence models (total effect of a single peer). Methods are illustrated for the phenotype BMI and two genetic alleles that have been linked to obesity as IVs using data from the Framingham heart study.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Causal inference,Longitudinal data,,,,,,,11-Nov-10,ombao@stat.brown.edu,,Hernando Ombao,Professor,Brown University,"121 South Main Street, 7th Floor",401-863-9538,,ombao@stat.brown.edu,Modeling Dependence in a Network of Brain Signals,1,Hernando,,Ombao,Brown University,Cristina,,Gorrostieta,Brown University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"One of the most fascinating aspects of studying brain signals is their temporal dynamics. Our collaborators have been studying dependence between brain regions and how that dependence may vary according to experimental conditions. Although there are several ways of characterizing cross-dependence, in this talk we shall focus on non-parametric spectral-based measures (e.g., coherence and partial coherence) which allow one to identify the frequency bands that drive the linear association between two signals. In the first part of the talk, we shall give an overview of these measures and their generalizations to the non-stationary setting. In the second part of the talk, we develop a spectral-autoregressive model for characterizing more complex types of spectral-temporal dependence that allow one to investigate, for example, how activity in the alpha band at one channel during one time period predict activity in the beta band at another channel at next time period. This method will be applied to an  electroencephalographic data recording during a visual-motor task.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Imaging,Time series,,,,,,,15-Nov-10,ombowe@uab.edu,,Omar,PhD Student,University of Alabama at Birmingham,1665 University Drive,205-266-4903,,ombowe@uab.edu,"Accessing the precision and bias of Intra-class correlation coefficient estimation, Type I error rate, and Power in Generlaized Mixed Linear Models",1,Omar,B,Mbowe,University of Alabama at Birmingham,Dr David,,Redden,University of Alabama at Birmingham,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The statistical complexity of the analysis of cluster randomized trials is well documented.In cluster randomized trials,clusters,such as schools, are assigned to different interventions.Since members within each cluster share some common characteristics,the observations nested within cluster may be correlated.Therefore,the intraclass correlation (ICC) must be estimated to examine the power and sample size.A simulation study assessed the bias and precision of ICC estimation,Type I error rate and power varying the number of clusters,cluster sizes,correlations,and distributional assumptions.Estimation by generalized estimating equations(GEE) and generalized linear mixed models(GLMM) was evaluated.It was observed that, for GEE, the estimation of ICC was robust across number of clusters, cluster sizes, correlations, and distributional assumptions.However,for GLMM,the estimation of ICC and precision of the estimates varied greatly. Furthermore, as shown by other researchers,Type I error rates for GEE were inflated when the number of clusters was small but converged to the nominal 0.05 as the number of clusters increased regardless of magnitude of ICC, correlation and distribution of random effects.In contrast,the Type I error rate did not always converge to the nominal level for GLMM.Results will be presented demonstrating the effect of violation of distributional assumptions for both GEE and GLMM.",FALSE,FALSE,,FALSE,FALSE,FALSE,,contributedposter,,,,FALSE,FALSE,FALSE,FALSE,Clustered data methods,Clinical trials,,,,,,,14-Nov-10,opugac1@uic.edu,,Oksana Pugach,,Institute for Health Research and Policy at UIC,"1747 W Roosevelt Rd, Room 558",3124139397,,opugac1@uic.edu,Developing the sampling approach to measure the food and physical activity environment,1,Oksana,,Pugach,"Institute for Health Research and Policy, University of Illinois at Chicago, Chicago, IL",Dianne,C,Barker,"Public Health Institute, Oakland, CA",Frank,J,Chaloupka,"Institute for Health Research and Policy, University of Illinois at Chicago, Chicago, IL",Lisa,,Powell,"Institute for Health Research and Policy, University of Illinois at Chicago, Chicago, IL",Sandy,,Slater,"Institute for Health Research and Policy, University of Illinois at Chicago, Chicago, IL",Leah,,Rimkus,"Institute for Health Research and Policy, University of Illinois at Chicago, Chicago, IL",,,,,,,,,,,,,,,,,"Background: Most of the studies that measure food and physicalactivity environment as determinants of obesity among adolescents useperceived measure or do census of all venues found on the ground. Whena study is nation-wide and requires objective information, arepresentative sample of venues is usually the most feasible. Thispaper describes a sampling approach to measure the community venuesthat was developed and successfully implemented in 154 Bridging theGap communities, defined as the middle and high school catchment areasin the US in 2010. Methods: Two commercial databases, Dun&Bradstreetand InfoUSA, were used for business sampling frame development. Weadjusted for the known undercoverage and bias of each of thecommercial databases by implementing the half-open interval method andpositive predictive values for business type. Results: A total of11,145 businesses were screened for eligibility and classification,resulting in 6021 open and eligible businesses in the originalsampling frame. With the adjustment, 4019 businesses were sampled fromthis frame, and an additional 4950 businesses were to be discoveredon the ground. Discussion: We overcame the known limitations ofcommercial business databases, and  developed a more accurate samplingframe for a representative sample of venues in the food and physicalactivity environment in our Bridging the Gap communities.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Survey research data,Power analysis/sample size,,,,,,,04-Nov-10,ozgekaradag@hacettepe.edu.tr,,…zge Karada,,Hacettepe University,ozgekaradag@hacettepe.edu.tr,+903122977900,,ozgekaradag@hacettepe.edu.tr,Missing Value Estimation in Repeated-Measures ANOVA,1,…zge,,Karadag,Hacettepe University,Serpil,,Aktas,Hacettepe University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In statistical researches missing value estimation has been a very substantial problem. Because an incomplete data set is not efficient, it can lead to serious bias in estimation of parameters and also increases the estimation variances. So, these kinds of drawbacks decrease the analysis power.  In recent years, with the purpose of solving missing value problem, some strategies have been developed such as maximum likelihood (ML) based methods, Bayes and multiple imputation method. But, in longitudinal studies where missing data often appears, more complicated methods are required such as EM algorithm which is an iterative method for computing ML estimates with incomplete data. Since it is difficult to measure all subjects in the study at the same time points, missing data problem often occurs in repeated measures. Therefore, in repeated measure designs data are usually incomplete because of non-observed values. Repeated measures ANOVA design requires a complete array of data. Thus missing value estimation is an important aspect for repeated measures (RM) ANOVA.The methods mentioned above are also used for the missing value estimation in RM ANOVA. The aim of this study is to use EM algorithm as alternatively and compare it to the other missing value estimation methods for in RM ANOVA designs.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Missing data,Hierarchical models,,,,,,,12-Nov-10,pangdu@vt.edu,,Pang Du,Professor,Virginia Tech,406-A Hutcheson Hall,540-231-7613,,pangdu@vt.edu,Estimation and Variable Selection for High-dimensional Logistic Models,1,Pang,,Du,Virginia Tech,Pan,,Wu,University of Rochester,Hua,,Liang,University of Rochester,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"This paper concerns high-dimensional logistic regression models wherethe dimension of covariates $p$ diverges with the sample size $n$. Under mild assumptions, we first established the asymptotic normalityfor the maximum likelihood estimators of the unknown coefficientvector, which is a long due result given the recent interests invariable selection for such models. We further develop a variableselection procedure through the optimization of a nonconcave penalizedlikelihood.  We showed the oracle property under a rather generalassumption that $p$ can diverge in an exponential rate of $n$.  Ouroptimization algorithm combines some recent developments,including the concave convex procedure and the coordinate descentalgorithm, in solving regularization problems. Through extensivesimulations, we show the promise of the proposed procedure in varioushigh-dimensional logistic regression settings.  An application to geneexpression data from a breast cancer study illustrates the use of themethod.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Variable subset selection/model selection,High dimensional data,,,,,,,15-Oct-10,paramita.saha@nih.gov,,Paramita  Saha Chaudhuri,,National Institute of Environmental Health Science,P.O. Box 12233 Mail Drop A3-03,206-225-3843,919-541-4311,paramita.saha@nih.gov,Summarizing the Time-dependent ROC curve and its Application to Comparison of Predictive Accuracy,1,Paramita,,Saha Chaudhuri,"Biostatistics BranchNational Institute of Environmental Health Sciences, NIH",Patrick,J,Heagerty,"Department of BiostatisticsUniversity of Washington",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"A major objective for development of novel markers is to ensure thatsubjects with different risk profiles are classified correctly. Beforeintroducing markers as a detection tool for a time-to-event outcome,it is important to ensure their accuracy using measures liketime-dependent sensitivity, specificity, ROC curve, etc. For alongitudinally measured marker, use of a fixed marker threshold forscreening may not reflect the time-dependent changes in the marker andthe test-positive threshold may need to be updated over time tocontrol for a fixed low false positive fraction at all screenings. Insuch repeated applications, overall proportion of test positivesubjects at a fixed false positive threshold may provide a usefulsummary measure of accuracy and help compare overall accuracy ofmarkers. We propose to summarize such time-dependent predictiveaccuracy of a continuous marker via a summary survival ROC curve. Thefalse-positive fractions are varied to produce overall true positivefraction (Total True Positive - TTP) and plot the resulting pairs (FP,TTP) that produce an ROC curve that is a weighted average oftime-dependent ROC curves where weights are determined by thecorresponding failure-time distribution. The resulting ROC curvesummarizes the predictive accuracy that is accrued over timecorresponding to different FP thresholds.",FALSE,FALSE,,FALSE,TRUE,TRUE,Roundtables  R5 How to publish and flourish,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,ROC analysis,Epidemiologic methods,,,,,,,15-Nov-10,parkj3@mail.nih.gov,,Ju-Hyun Park,,National Cancer Institute,6120 Executive Blvd,301-496-3233,,parkj3@mail.nih.gov,Bayesian modeling for the number of underlying susceptibility loci and their effect size distribution in Genome-wide association studies,1,Ju-Hyun,,Park,"National Cancer Institute, NIH",Nilanjan,,Chatterjee,"National Cancer Institute, NIH",Raymond,J.,Carroll,Texas A&M University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Observing the recent successes in identifying substantial numbers of susceptibility loci associated with several traits of interest, the literature has discussed whether further genome-wide association studies can help to find missing pieces of heritability for traits. Using the information from the discovered susceptibility loci, Park et al. (2010, Nature Genetics) implemented a nonparametric approach to estimate the distribution of effect sizes for the discovered loci, followed by estimating the number of underlying loci within the observed effect sizes; hence, the heritability explained by such loci. In this presentation, we consider the same problem in the parametric framework with the Bayesian perspective. The likelihood construction consists of two parts: Binomial sampling from the unknown number (N) of underlying loci with unconditional probability of detecting susceptibility loci specific to a study and the biased-sampling likelihood for effect sizes of the identified loci, which is modeled as a finite mixture of Exponential distributions. Parameters of interest, including N, are assigned appropriate priors and an efficient MCMC algorithm is developed for posterior computation.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Statistical genetics,Bayesian methods,,,,,,,29-Oct-10,patricia@statcollab.com,,Patricia Feeney,Biostatistician,Statistics Collaborative,1625 Massachusetts Av NW #600,2022479700,,patricia@statcollab.com,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,FALSE,FALSE,,FALSE,FALSE,FALSE,,,,,,FALSE,FALSE,FALSE,FALSE,,,,,,,,,08-Nov-10,paul@hcp.med.harvard.edu,,Sudeshna Paul,,"postdoctoral fellow, Harvard Medical School",180 longwood Avenue,7655863284,,paul@hcp.med.harvard.edu,Longitudinal modeling of relationships in social networks,1,Sudeshna,,Paul,Harvard Medical School,A James,,O'Malley,Harvard Medical School,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Statistical analysis of the dynamic features of networks has beenchallenging due to the complex structure of networks and lack oflongitudinal observations on real networks. In this work we focus onthe simultaneous modeling of relationship (tie) formation anddissolution in a network over time. Our modeling strategy is based onspecifying a model for the bivariate relationship among each pair ofindividuals (dyads) in the network. In the case of binaryvalued-relationships, the relationship status of a dyad at any giventime follows a four-component multinomial distribution. AssumingMarkov dependence, the multinomial transition probabilities of dyadicrelationship status are modeled using a novel model involving nodespecific random effects and that accounts for dependence fromhigher-order network phenomena such as transitivity. Model parametersare estimated using Bayesian analysis implemented via Markov chainMonte Carlo (MCMC). The model is evaluated using simulated data andapplied to longitudinal data on a social network of friendshiprelationships and health traits.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Longitudinal data,Hierarchical models,,,,,,,12-Nov-10,pberg@lilly.com,,Paul H. Berg,,Eli Lilly and Company,Lilly Corporate Center,317-276-0395,,pberg@lilly.com,A Leadership Development Program for Statisticians in the Pharmaceutical Industry,1,Paul,H,Berg,Eli Lilly and Company,Walter,W,Offen,Eli Lilly and Company,Gary,R,Sullivan,Eli Lilly and Company,Yoko,,Tanaka,Eli Lilly and Company,Sandra,L,Toledo Marquette,Eli Lilly and Company,Ilker,,Yalcin,Eli Lilly and Company,Aarti,S,Shah,Eli Lilly and Company,,,,,,,,,,,,,"Developing leaders with scientific, therapeutic area, and business knowledge is essential for statistics organizations in the pharma industry.  We built a leadership development program with three main goals:  (1) improve statisticians ability to lead and influence innovation, knowledge management and operational excellence; (2) get statisticians involved in critical business decision making across the value chain; and (3) attract, develop, and retain the best leaders.  The first part of the program is targeted to all statisticians; it includes a competency database, examples of leaders in statistics, and leadership seminars.  The second part of the program is targeted to statisticians with high leadership potential; it includes 4 multi-day, highly interactive events that include exposure to other internal and external leaders.  Assessment of leadership skills is surveyed periodically.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Other,Biopharmaceutical research,Leadership,,,,,,15-Nov-10,pearsonsm@vcu.edu,,Stephanie Pearson,,Virginia Commonwealth University,104 Gallop Place,757-358-2456,,pearsonsm@vcu.edu,Empirical Bayes Characterization for a Weighted-Sum of Environmental Chemical Concentrations,1,Stephanie,M,Pearson,"Graduate Student, Virginia Commonwealth University",Roy,T,Sabo,"Professor, Virginia Commonwealth University",Nitai,D,Mukhopadhyay,"Professor, Virginia Commonwealth University",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Exposures to endocrine disrupting chemicals (EDC) can consist of many chemicals, from different sources with different effects on hormonal function. Cases of many chemicals are commonly handled with a whole-mixture approach, where a set of chemical concentrations is transformed into one representative value. Most whole-mixture approaches, such as summing chemical concentrations, can mask the relationships between individual chemicals and some endocrine response, especially where relative potencies are unavailable. In an effort to create a whole-mixture methodology that maintains information on individual chemicals, a fully Bayesian approach to estimating a weighted sum of the EDC concentrations is presented. Empirical Bayes methods are used to specify informative prior distributions for the chemical-specific weights, while standard methods are used to characterize prior information for regression and variance parameters. MCMC methods are used to establish posterior inference on the relationship between the weighted mixture sum and an endocrine response. This weighted-sum approach achieves parametric parsimony with respect to the number of regression estimates, yet captures the contributions of individual chemicals to the overall mixture relationship via the estimated weights. Simulation studies compare this methodology with standard whole-mixture approaches; an application of this technique is provided using endocrine and exposure data from the NHANES database.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Bayesian methods,Toxicology/dose-response,,,,,,,15-Nov-10,pei-fang.su@vanderbilt.edu,,Pei-Fang Su,,Vanderbilt University,1901 Convent Pl. Apt 10,615-579-7360,,pei-fang.su@vanderbilt.edu,Survival Analysis with Compound Covariate for Omics Data,1,Pei-Fang,,Su,"Division of Cancer Biostatistics, Department of Biostatistics, Vanderbilt University",Heidi,,Chen,"Division of Cancer Biostatistics, Department of Biostatistics, Vanderbilt University",Xi,,Chen,"Division of Cancer Biostatistics, Department of Biostatistics, Vanderbilt University",Yu,,Shyr,"Division of Cancer Biostatistics, Department of Biostatistics, Vanderbilt University",,,,,,,,,,,,,,,,,,,,,,,,,"In high-dimensional omics research, pathway or gene set analysis is widely used. In order to reduce the dimensionality of the data set, a straightforward method is to combine information of all genes in the same pathway into a single score, named the compound covariate. For the purpose of building a prediction model, the Cox regression model is always used to assess whether association exists between the compound covariate and survival outcomes. A common method for creating a score is to use the estimated coefficient or statistic of univariate Cox regression as the weight of each gene in the pathway. However, the score in the Cox model should not be treated as an observed covariate. In addition, the p-value of the score in the Cox model is not valid. In this paper, we correct these problems using the concept of measurement error and split the sample fully at random. Moreover, we thoroughly assess the performance of two well-known estimated weights, parameter estimatedand Wald statisticsweight, through simulation studies for a pre-specified pathway. Finally, the implementation of the proposed method is used for a real data set.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,High dimensional data,Survival analysis,,,,,,,15-Nov-10,Peng.Wei@uth.tmc.edu,,Peng Wei,Assistant Professor,University of Texas School of Public Health,1200 Pressler Dr,713-500-9565,713-500-9530,Peng.Wei@uth.tmc.edu,Incorporating multiple gene networks into gene-based analysis of genome-wide association data,1,Peng,,Wei,"Division of Biostatistics and Human Genetics Center,University of Texas School of Public Health",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Genome-wide association studies (GWAS) have rapidly become a standard method for disease gene discovery. To overcome the limitations of single-SNP analysis, there have been increasing efforts recently on GWAS pathway analysis, aiming at combining SNPs with moderate signals. However, a major drawback of current pathway-based methods is that interactions among genes within a pathway are ignored and genes are treated as exchangeable, leading to inefficient use of biological prior knowledge and loss of power. Here we propose a flexible Bayesian hierarchical model to incorporate genome-wide gene-gene interaction information embedded in multiple gene networks, such as gene regulatory and protein-protein interaction networks, into gene-based analysis of GWAS data. We carry out parameter estimation and inference based on MCMC samples in a fully Bayesian framework. Applications to real GWAS datasets, together with simulation studies, demonstrate the extra power gained by integrating multiple gene networks with GWAS data.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Statistical genetics,Genomics,,,,,,,08-Nov-10,peng@email.sc.edu,,Yanlei Peng,,University of South Carolina,"Department of Statistics, 216 LeConte College",9152026657,,peng@email.sc.edu,"A retrospective analysis of the association of dust storms and respiratory hospitalizations in El Paso, Texas, using a case-crossover study design",1,Yanlei,,Peng,University of South Carolina - Columbia,Joan,G,Staniswalis,University of Texas at El Paso,Sara,E,Grineski,University of Texas at El Paso,Tom,,Gill,University of Texas at El Paso,,,,,,,,,,,,,,,,,,,,,,,,,"Dust storms, blowing dust and related phenomena frequently occur in El Paso, Texas, but little is known to date about their respiratory health effects. The association between dust events and hospitalization for respiratory illnesses was evaluated through a case-crossover study design. The goal was to ascertain the respiratory health effect of dust events on El Paso residents, adjusted for weather and other pollutants, and to explore potential harmfulness on different subgroups of residents. A case-crossover study allows patients to serve as their own controls, in order to reduce confounding. For the population of El Paso County, residents were 10.3% more likely to be hospitalized for a respiratory illness on a day with a synoptic-scale dust event than on a day without a dust storm or with only convective dust, adjusting for other weather and air pollution covariates gave a similar finding. Only for the subgroup of adults, there was a significant increase in respiratory hospitalizations three days after a dust event occurred. This case-crossover study of a large dataset reveals a significant effect of dust storms on hospitalization of El Paso, Texas residents for respiratory diseases, whether adjusted for weather- pollution covariates or not. This research contributes to filling the gap in scientific research about dust's effect on respiratory health in the United States.",FALSE,FALSE,,FALSE,FALSE,FALSE,,contributedposter,,,,FALSE,FALSE,FALSE,TRUE,Environmental and ecological applications,Experimental design,,,,,,,15-Nov-10,perez@rti.org,,Jeniffer Iriondo Perez,,RTI International,3040 Cornwallis Road,919-5416140,,perez@rti.org,Modeling CD4 cell counts over time in HIV-infected adults in Central Africa,1,Jeniffer,,Iriondo Perez,RTI International,Hrishikesh,,Chakraborty,RTI International,Godfrey,,Woelk,RTI International,Jennifer,,Hemingway-Foday,RTI International,Jamie,E,Newman,RTI International,IeDEA Central Africa Study Group,,,IeDEA Central Africa Study Group,,,,,,,,,,,,,,,,,"An estimated 22 million people were living with HIV in sub-Saharan Africa at the end of 2008, making it the most affected region in the world. It is known that HIV slowly infects and destroys CD4 T-cells compromising the immune system and making patients more susceptible to opportunistic infections such as tuberculosis. For this reason, CD4 cell counts are used clinically as a measure of HIV disease prognosis, disease staging and effectiveness of antiretroviral therapy (ART). Two different models were developed to estimate changes in CD4 cell counts over time: 1) a linear mixed-effects model with a patient-specific random intercept and a random slope for time was used to examine longitudinal changes in the CD4 cell count after ART initiation; and 2) a piecewise linear mixed-effect model to determine the change in slopes with a change point set at the time of tuberculosis infection, allowing the slope of CD4 cell count to change before, during and after TB infection. Data from the International Epidemiologic Database to Evaluate AIDS (IeDEA) project was used to illustrate these models.",FALSE,FALSE,,FALSE,FALSE,FALSE,,contributedposter,,,,FALSE,FALSE,FALSE,FALSE,Longitudinal data,Generalized linear models,,,,,,,22-Sep-10,pfkuan@email.unc.edu,,Pei Fen Kuan,PhD,University of North Carolina Chapel Hill,102 Timber Hollow Ct Apt 209,919 966 8150,,pfkuan@email.unc.edu,A statistical framework for Illumina DNA methylation arrays,1,Pei Fen,,Kuan,University of North Carolina at Chapel Hill.,Sijian,,Wang,University of Wisconsin at Madison.,Xin,,Zhou,University of North Carolina at Chapel Hill.,Haitao,,Chu,University of Minnesota at Minneapolis.,,,,,,,,,,,,,,,,,,,,,,,,,"The Illumina BeadArray is a popular platform for profilingDNA methylation, an important epigenetic event associated with genesilencing and chromosomal instability. However, current approachesrely on an arbitrary detection p-value cutoff for excluding probes andsamples from subsequent analysis as a quality control step, whichresults in missing observations and information loss. It is desirable tohave an approach that incorporates the whole data, but accounts forthe different quality of individual observations. We first investigateand propose a statistical framework for removing the source of biasesin Illumina Methylation BeadArray based on several positive controlsamples. We then introduce a weighted model based clustering calledLumiWCluster for Illumina BeadArray that weights each observationaccording to the detection p-values systematically and avoidsdiscarding subsets of the data. LumiWCluster allows for discovery ofdistinct methylation patterns and automatic selection of informativeCpG loci. We demonstrate the advantages of LumiWCluster on twopublicly available Illumina GoldenGate Methylation data sets (ovariancancer and hepatocellular carcinoma).",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Genomics,Statistical genetics,,,,,,,02-Nov-10,phil.reiss@nyumc.org,,Philip T. Reiss,,New York University,"215 Lexington Ave., 16th floor",917-494-0260,,phil.reiss@nyumc.org,Nonlinear dependence of functional responses on scalar predictors,1,Philip,T.,Reiss,New York University and Nathan Kline Institute,Lei,,Huang,New York University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Regression with functional responses and scalar predictors is a basic tool of functional data analysis.  The popular varying-coefficient model paradigm assumes that the response functions depend linearly on the predictors.  But in some applications involving functions sampled on a dense grid, interest may center on nonlinear dependence on a predictor, and on how such nonlinearity varies along the function.  We present a novel multidimensional smoothing approach, in which smooth dependence on the predictor is estimated optimally for each point of the function, while smoothness of the fitted-value functions is preserved.  The ideas are illustrated with a neurodevelopmental application in which entire brain images are treated as functional responses.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Functional data analysis,Imaging,,,,,,,17-Sep-10,phsu@azcc.arizona.edu,,Chiu-Hsieh (Paul) Hsu,,University of Arizona,1295 N. Martin A232,5206265054,,phsu@azcc.arizona.edu,A Nonparametric Multiple Imputation Approach for Data with Missing Covariate Values with Application to Colorectal Adenoma Data,1,Chiu-Hsieh,,Hsu,University of Arizona,Qi,,Long,Emory University,Yisheng,,Li,MD Anderson Cancer Center,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Measurements of biomarkers in a clinical study are often obtained for only a small subset of the study participants. For those whose biomarker data were not collected, the measurements may be regarded as missing data. Ignoring these missing measurements may result in either a loss of efficiency or bias in the estimation of the parameters of interest in the data analysis. In this paper, a nearest neighbor-based multiple imputation approach is proposed to recover missing biomarker information while estimating the association between the clinical endpoint and the biomarker. To conduct the imputation, two working models are used to define an imputing set. One is a linear regression model for predicting the missing values. The other is a logistic regression model for predicting the probabilities of missingness. This imputation approach is expected to be robust to misspecifications of either of the two working models and the underlying distribution of the data. We demonstrate the method on the baseline data from a colorectal polyp prevention trial, where 50% of the participants had missing serum 25(OH)D. The results indicate that the proposed approach may improve efficiency and reduce bias in estimating the marginal association between any large baseline metachronous colorectal adenomas and serum 25(OH)D by using the predictive covariates to select imputing sets for missing observations.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Missing data,Cancer applications,,,,,,,15-Nov-10,pjschult@ncsu.edu,,Phillip Schulte,,North Carolina State University,601 Hinsdale St. Apt. 3,651-717-5608,,pjschult@ncsu.edu,A comparison of Q- and A- learning methods for estimating optimal treatment regimes,1,Phillip,J,Schulte,North Carolina State University,Marie,,Davidian,North Carolina State University,Anastasios,A,Tsiatis,North Carolina State University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In clinical practice, physicians must make a sequence of treatmentdecisions throughout the course of a patient's disease based onevolving patient characteristics. At key decision points, there may beseveral treatment options and no consensus regarding which option isbest.  An algorithm for sequential treatment assignment at keydecision points, based on evolving patient characteristics, is calleda treatment regime. The statistical problem is to estimate the optimaltreatment regime, i.e., that which maximizes expected outcome acrossthe study population, based on data from a properly designed clinicaltrial or observational data. Q- and A-reinforcement learning are twomethods that have been proposed for estimating the optimal treatmentregime.  While both methods involve developing statistical models forpatient outcomes, A-learning is more robust, as it relaxes someassumptions on the outcome model.  However, this additional robustnesscomes at a cost of increased variability and a bias-variance tradeoffbetween Q- and A-learning. We explore this bias-variance tradeoffthrough the accuracy of parameter estimation and the estimation ofexpected outcome for the estimated optimal treatment regime undervarious scenarios with different degrees of model misspecification.For simplicity, we focus on a single treatment decision point.",FALSE,FALSE,,FALSE,TRUE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Other,Clinical trials,Optimal Treatment Regimes,,,,,,09-Nov-10,pkolm@christianacare.org,,Paul Kolm,Director of Biostatistics,Christiana Care Health System,131 Continental Drive,302-623-0671,302-623-0669,pkolm@christianacare.org,COMPARISON OF METHODS FOR COUNTERING SELECTION BIAS IN COMPARATIVE EFFECTIVENESS STUDIES OF MEDICAL THERAPIES IN  NONRANDOMIZED PATIENT DATABASES,1,Paul,,Kolm,"Christiana Care Health SystemNewark, DE",Paulo,,Carita,"sanofi-aventis R&DParis, France",Alice,,Guiraud,"Keyrus BiopharmaLevallois- Perret, France",Christine,,Taniou,"Alios Conseil Boulogne-Billancourt, France",Edward,,Ewen,"Christiana Care Health SystemNewark, DE",Claudine,,Jurkovitz,"Christiana Care Health SystemNewark, DE",William,S,Weintraub,"Christiana Care Health SystemNewark, DE",,,,,,,,,,,,,"Randomized trials are the gold standard for research studies comparing effectiveness of medical therapies.  However, observational data, particularly from electronic health records (EHR), or patient registries, have become important sources for comparative effectiveness research.  Observational studies pose numerous challenges, including selection bias, missing clinical and laboratory data, and potentially limited subject enrollment due to the nature of the disease and outcomes of interest.  The purpose of this study was to compare methods of analyzing cost-effectiveness of rhythm control vs. rate control strategies for atrial fibrillation (AF) patients included in a patient registry where treatment strategies were not randomized.  Covariate adjustment, propensity score matching, inverse probability weighting, and no adjustment were applied to these data.  As expected, results varied according to methods of analysis.  We discuss the implications of the differences and strategies for decision making.",FALSE,FALSE,,FALSE,FALSE,FALSE,,contributedposter,,,,FALSE,FALSE,FALSE,FALSE,Applied data analysis,Biopharmaceutical research,,,,,,,10-Nov-10,pmukhopadhyay@kumc.edu,,Purna Mukhopadhyay,Research Assistant Professor,University of Kansas Medical Center,5620 W 133rd Terrace Apt 611,5732020714,913-588-0252,pmukhopadhyay@kumc.edu,Sieve Bootstrap Prediction Intervals for Multivariate ARMA processes with Non-Gaussian Innovations,1,Purna,,Mukhopadhyay,University of Kansas Medical Center,V.A,,Samaranayake,Missouri University of Science and Technology,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Existing nonparametric bootstrap methods for obtaining prediction intervals for vector autoregressive moving average (ARMA) processes require apriori knowledge of the autoregressive and moving average orders, p, q respectively. The sieve bootstrap method developed for stationary and invertible univariate processes overcomes this limitation. We implement a modified version of the sieve bootstrap method to multivariate ARMA processes and show, through a Monte Carlo study, that the procedure produces prediction intervals that achieve nominal or near nominal coverage probabilities. The robustness of this method under non-normality is tested using different error distributions and Monte Carlo results show that the coverage remains at nominal or near nominal levels under several non-normal distributions.",FALSE,FALSE,,FALSE,FALSE,FALSE,,contributedposter,,,,FALSE,FALSE,FALSE,TRUE,Multivariate methods,Computational methods,,,,,,,12-Oct-10,polyna.khudyakov@channing.harvard.edu,,Polyna Khudyakov,Research Fellow,"Department of Biostatistics, Harvard School of Pub","70 Centre street, apt. 3D",857-222-0027,,polyna.khudyakov@channing.harvard.edu,Test for Equality of Baseline Hazard Functions for Correlated Survival Data using Frailty Models,1,Polyna,,Khudyakov,Department of Biostatistics at Harvard School of Public Health,Malka,,Gorfine,Faculty of IE&M at the Technion - Israel Institute of Technology,Paul,,Feigin,Faculty of IE&M at the Technion - Israel Institute of Technology,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In this work we provide a new class of test statistics for hypothesis testing of the equality of the baseline hazard functions for correlated survival data under frailty models. The asymptotic distribution of the test statistics is investigated theoretically under the null hypothesis and certain local alternatives. We also provide a simple variance estimator. The properties of the test statistics, under finite sample size, is being studied by an extensive simulation study and we verify the control of Type I error and our proposed sample size formula. The utility of our proposed estimating technique is illustrated by the analysis of the call center data of an Israeli commercial company that processes up to 100,000 calls per day and the analysis of the breast cancer data of the Washington Ashkenazi Kin-Cohort family study (WAS).",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Survival analysis,Applied data analysis,,,,,,,28-Oct-10,pwang@fhcrc.org,,Pei Wang,Associate Member,Fred Hutchinson Cancer Research Center,"1100 Fairview Ave N., M2-B500",2066674175,,pwang@fhcrc.org,A regularized Hotelling's  T2 test for pathway analysis in proteomic studies,4,Lin,S,Chen,"Department of Biostatistics, University of Chicago",Debashis,,Paul,"Department of Statistics, University of California, Davis",Ross,L.,Prentice,"Division of Public Health Sciences, Fred Hutchinson Cancer Research Center",Pei,,Wang,"Division of Public Health Sciences, Fred Hutchinson Cancer Research Center",,,,,,,,,,,,,,,,,,,,,,,,,"Recent proteomic studies have identified proteins related tospecific phenotypes. In addition to marginal association analysisfor individual proteins, analyzing pathways may yield additionalvaluable insights. Proteins within the same biological pathway maycorrelate with one another in a complicated way, and type I errorrates can be inflated if such correlations are incorrectly assumedto be absent. The inflation tends to be more pronounced when thesample size is very small or there is a large amount of missingnessin the data, as is frequently the case in proteomic discoverystudies. To tackle these challenges, we propose a regularizedHotelling's T2 (RHT) statistic together with anon-parametric testing procedure, which effectively controls thetype I error rate and maintains good power in the presence ofcomplex correlation structures and missing data patterns. Weinvestigate asymptotic properties of the RHT statisticunder pertinent assumptions and compare the test performance withfour existing methods through simulation examples. We apply theRHT test to a hormone therapy proteomics data set, andidentify several interesting biological pathways for which bloodserum concentrations changed following hormone therapy initiation.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Multivariate methods,Proteomics,,,,,,,08-Oct-10,pwestgat@umich.edu,,Philip Westgate,PhD Candidate,University of Michigan,1423 Natalie Ln Apt 203,734-904-8894,,pwestgat@umich.edu,The Effect of Cluster Size Imbalance and Covariates on the Efficiency of QIF,1,Philip,M,Westgate,University of Michigan,Thomas,M,Braun,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Generalized Estimating Equations (GEE), introduced by Liang and Zeger (1986, Biometrika 73, 13-22), are commonly used for the analysis of correlated data. Qu, Lindsay, and Li (2000, Biometrika 87, 823-836) proposed the use of Quadratic Inference Functions (QIF) as an alternative method in order to increase estimation efficiency when the working covariance structure is misspecifed. Due to this theoretical property and other advantages over GEE, QIF appears in the literature to be a better method to employ. However, the impacts of covariates and imbalanced cluster sizes on the efficiency of QIF have not been studied.  We give theoretical explanation and empirical evidence that when utilizing this structure, covariates and cluster size imbalance can cause QIF to be much less efficient than GEE when the number of clusters is small to moderate. We also argue that this relative loss in efficiency is mostly credited to the empirical nature of weighting used by QIF. We demonstrate through simulation studies covering a variety of general scenarios the degree of efficiency loss, and compare QIF and GEE in the analysis of a rat litter intervention trial.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Estimating equations,Applied data analysis,,,,,,,27-Oct-10,pxf16@case.edu,,Pingfu Fu,Associate Professor,Case Western Reserve University,10900 Euclid avenue,216-368-3911,,pxf16@case.edu,Does oral dose-modified chemotherapy have effect on CD4 lymphocyte count and HIV-1 plasma RNA?,1,Pingfu,,Fu,Case Western Reserve University,Walter,,Mwanda,University of Nairobi,Jackson,,Orem,Makerere University,Guang,,Zeng,Texas A&M University-Corpus Christi,Scot,,Remick,West Virginia University,,,,,,,,,,,,,,,,,,,,,"There are no data on the effect of chemotherapy on CD4+ lymphocyte andHIV-1 plasma RNA levels in patients with AIDS-related non-Hodgkin'slymphoma in East Africa. It is critical to have an understanding ofthe immunologic effects of anticancer therapy on underlying HIVinfection in this setting, since the majority of these patients do nothave access to antiretroviral therapy. With 49 patients treated withlomustine, VP-16, cyclophosphamide and procarbazine, some patients hadmissing value, left and / or right censored value on CD4 count andviral load due to laboratory detection limit. We explore variousstatistical methods including EM estimation procedure for mixedeffects models, multiple imputation approach and Tobit models to dealdata with such issues. All methods show a consistent conclusion thatoral chemotherapy has modest effect on CD4 counts and no adverseeffect on underlying viral replication.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Clinical trials,Longitudinal data,,,,,,,15-Nov-10,pyao@niu.edu,,ping yao,,Northern Illinois University,"209K Wirtz Hall,",8157530853,,pyao@niu.edu,Joint modeling of missing data due to drop-out and death in obesity and depression longitudinal studies,1,Ping,,Yao,Northern Illinois University,Arlene,,Keddie,Northern Illinois University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Missing data is very common phenomena in longitudinal or survey based studies. According to the missing mechanism, there are missing completely  at random(MCAR) , missing at random(MAR) and missing not at random(MNAR).  There are two main estimation methods based on maximum likelihood and generalized estimating equation. But for missing data in studies of the elderly, high rate of death are often observed in studies of elderly populations.  We will get biased estimation if the death and non-participation are treated at same missing pattern. Joint model  can estimate the probability of death and non-participation respectively.This study is motivated by the old  Mexican-American  obesity and depression longitudinal  studies data set. There are four waves studies  from 1994 to 2001. There are about 3050 subjects at baseline, about 2000 at second wave and 1800 at final wave. The missing subjects at each wave are caused by  death and non-participation. The joint modeling of missing  due to drop-out and death is developed to treat them differently in the analysis and inverse probability generalized estimating equation is used to estimate the parameters.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Longitudinal data,Missing data,,,,,,,15-Nov-10,qiangchen@mail.nih.gov,,Qiang Chen,,National Institute of Mental Health,"9000 Rockville Pike, Bldg10-3C432B",301-594-1244,,qiangchen@mail.nih.gov,Random Forests for Exploring Functional Connectivity in fMRI,1,Qiang,,Chen,NIMH,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Although numerous methods have been developed to better capturefunctional connectivity in human brain in fMRI study, most of themneglect interactions among different brain regions. The goal of thisstudy is to explore functional connectivity using Random Forestregression. Random Forests (RF) method is a collection ofclassification trees grown on bootstrap samples. When RF is used innonlinear multiple regression, it not only generates variableimportance measures, but also takes into account interactions amongvariables. The importance of variable could be employed in measuringbrain connectivity during fMRI task. RF-based method will be comparedwith other functional connectivity methods.",FALSE,FALSE,,FALSE,FALSE,FALSE,,contributedposter,,,,FALSE,FALSE,FALSE,FALSE,Imaging,Variable subset selection/model selection,,,,,,,02-Nov-10,qiwei.liang@altria.com,,Qiwei Liang,,Senior Biostatistician,601 East Jackson Street,8043346863,,qiwei.liang@altria.com,A nonparametric longitudinal statistical model for biomarkers of exposure to cigarette smoking,1,Qiwei,,Liang,Altria Client Service Inc.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,FALSE,FALSE,,FALSE,FALSE,FALSE,,,,,,FALSE,FALSE,FALSE,FALSE,,,,,,,,,13-Oct-10,quic0038@umn.edu,,Harrison Quick,,University of Minnesota,8151 33rd Ave S Unit 409,507-304-1668,,quic0038@umn.edu,Assessing the Impact of Alcohol Establishment Density on Violent Crime in Minneapolis Neighborhoods Using Univariate and Multivariate Conditionally Autoregressive Models,1,Harrison,S,Quick,"Division of Biostatistics, University of Minnesota",Traci,L,Toomey,"Division of Epidemiology, University of Minnesota",Bradley,P,Carlin,"Division of Biostatistics, University of Minnesota",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"As has been shown in numerous studies, alcohol misuse and abuse canresult in a number of adverse consequences important to the publichealth of a community, including increased crime rates.  Recentstudies in the area have begun to utilize statistical methods thataccount for spatial autocorrelation when assessing the associationbetween the density of alcohol establishments and various crimes.  Inthis project, the relationship between the density of alcoholestablishments in the neighborhoods of Minneapolis and their crimerates will be investigated.  What sets this study apart from many ofits predecessors is the variety of types of violent crimes beinganalyzed, and the statistical methods being used.  In addition tousing the standard, univariate conditionally autoregressive model,crimes will also be grouped together to be analyzed using amultivariate conditionally autoregressive model.  By doing this, wehope to not only inform the public health community of the potentialrisks associated with increased alcohol establishment density, butalso learn when the multivariate approach is most beneficial.",FALSE,FALSE,,FALSE,TRUE,FALSE,,studentaward_submission_poster,,,,FALSE,FALSE,FALSE,FALSE,Spatial/temporal modeling,Bayesian methods,,,,,,,01-Nov-10,quw104@psu.edu,,Qing Wang,,"Department of Statistics, Pennsylvania State Unive",Room 325 Thomas Building,8143215584,,quw104@psu.edu,Topics in U-Statistics and Risk Estimation,1,Qing,,Wang,"Department of Statistics, Pennsylvania State University",Bruce,G,Lindsay,"Department of Statistics, Pennsylvania State University",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We consider estimating the variance of a general U-statistic when itis used as an unbiased estimator of the parameter of interesttheta=E(K) where K is the kernel function. Long establishedresults demonstrate the asymptotic normality of U-statistics andtheir asymptotic variance under regularity conditions. However,these asymptotic results are based on the assumption that the samplesize n goes to infinity; they are not so reliable when n is notlarge or the kernel size m is not negligible compared with n. Weconsider an alternative approach to estimate its variance with arelatively simple form. This variance estimator is the best unbiasedand therefore is applicable even for the cases that m/n is a fixedfraction. In addition, two resampling schemes have been developed,both of which provide an unbiased realization of the unbiased varianceestimator.In order to further investigate the proposed method, we apply it in risk estimation under the context of nonparametric density estimation. Weconstructed U-statistic form risk estimators based on L2 loss andKullback-Leibler loss respectively. To evaluate the proposed varianceestimator in risk estimation, we have carried out a simulationcomparison with some bootstrap variance estimators.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Nonparametric methods,Exact methods,,,,,,,15-Nov-10,qzhou@hsph.harvard.edu,,Qian Zhou,Postdoctoral Fellow,Harvard School of Public Health,655 Huntington Avenue,617-480-3909,617-432-5619,qzhou@hsph.harvard.edu,Subgroup Specific Incremental Value of New Markers for Risk Prediction,1,Qian,,Zhou,"Department of Biostatistics, Harvard School of Public Health",Yingye,,Zheng,"Public Health Science Division, Fred Hutchinson Cancer Research Center",Tianxi,,Cai,"Department of Biostatistics, Harvard School of Public Health",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In many clinical applications, prognostic markers with higher accuracy are often expensive and/or invasive. Understanding when measurement of new markers is necessary to provide added accuracy to existing prediction tools could lead to more cost effective disease management. In developing guidelines to determine whether a subject with an initial prognosis needs further assessment, it is important to quantify and evaluate the incremental value of the additional assessment. In this talk, we propose to estimate the risk of t-year survival based on an initial model with routine variables only and an updated model by adding the new markers. Then we develop procedures for making inference about the discriminatory ability of the updated model among each of the risk groups determined by the initial model. Simultaneous interval estimation procedures are provided to account for sampling variation and multiple testing. Simulation studies suggest that our proposed procedures work well in finite sample. The proposed procedures are applied to the Framingham Offspring Study to examine the added value of an inflammation marker, C-Reactive Protein, on top of the traditional Framingham Risk Score for predicting 10-year risk of CVD.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Biomarkers/surrogate markers,ROC analysis,,,,,,,13-Nov-10,rahulm@stanford.edu,,Rahul  Mazumder,,"Phd Student, Department of Statistics, Stanford Un","390 Serra Mall, Sequoia Hall, Department of Statistics,",6507968428,,rahulm@stanford.edu,Regularization algorithms for Learning Large Incomplete Matrices,1,Rahul,,Mazumder,"Phd Student, Stanford Statistics.",Trevor,,Hastie,"Professor Departments of Statistics; and  Health, Research and Policy  ;  Stanford University",Robert,,Tibshirani,"Professor  Departments of  Health, Research and Policy;  and Statistics;  Stanford University",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In many real life examples, data available is in the form of a largematrix where only a few (1 - 2 %) of potentially billions of entriesare observed. The task is to `fill' out the remaining entries exploiting row /column interactions --- popularly dubbed as the matrixcompletion problem.  Examples include collaborative filtering (webapplications), missing data imputation in biological problems and manymore. This ill-posed problem is tackled by assuming some statisticallymeaningful  'sparsity' assumption on the underlying parameter/  matrix of interest --- like low-rank,  regularization on the singularvectors of the matrix and variants thereof. We develop tractable largescale algorithms for convex relaxations for these class of problems,explore connections with conventional variants and discuss theirproperties. We also show their performances in real-life examples.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Machine learning,Missing data,,,,,,,15-Nov-10,raj153@psu.edu,,Roman Jandarov,Grad Student,Penn State University,315 W Beaver Ave Apt 12,8144410868,,raj153@psu.edu,Emulating a gravity model to infer the spatiotemporal dynamics of an infectious disease,1,Roman,,Jandarov,"Department of Statistics, Penn State University",Murali,,Haran,"Department of Statistics, Penn State University",Ottar,,Bjornstad,"Department of Entomology and Center for Infectious Disease Dynamics, Penn State University",Bryan,,Grenfell,"Department of Ecology and Evolutionary Biology, Princeton University",,,,,,,,,,,,,,,,,,,,,,,,,"Extremely contagious, acute, immunizing childhood infections like measles can exhibit spatiotemporal dynamics that depend on the nature of spatial contagion and spatiotemporal variations in population structure and demography. We study a metapopulation model for regional measles dynamics that uses a gravity coupling model and a time series susceptible-infected-recovered (TSIR) model for local dynamics. Standard maximum likelihood or Bayesian inference for this model is infeasible as there are potentially tens of thousands of latent variables in the model and each evaluation of the likelihood is expensive. We develop an efficient discretized MCMC algorithm for Bayesian inference with these expensive likelihood evaluations. However, we find through a simulation study that parameter estimates are biased and simulations at the obtained parameter settings do not explain some important biological characteristics of the data. We propose fitting a Gaussian process (GP) model to forward simulations of the gravity model at a number of parameter settings. Based on the GP-based emulator we perform a full Bayesian analysis of a given data set. This approach allows us to conveniently study posterior distributions of the key parameters of the gravity model and has number of advantages over the classic likelihood based inference.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Infectious disease models,Bayesian methods,,,,,,,15-Nov-10,rajarshi@ksu.edu,,Rajarshi Dey,Graduate student,Kansas State University,923 Fremont St,3522354783,,rajarshi@ksu.edu,Nonparametric Tests for Equality of Distributions Based on Precedence Probabilities,1,Rajarshi,,Dey,"Graduate Student, Kansas State University",Paul,I,Nelson,"Professor, Kansas State University",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Let  X(i) be a random variable with continuous distribution functionF(i) ;  i=1,2,...,K. Using precedence probabilities, we propose andexplore a class of nonparametric tests based on independent randomsamples for the null hypothesis that all distribution functions areequal. One of these tests, designed to find any type of differenceamong the distributions, performs well in cases where thedistributions differ only in location, only in scale or both inlocation and scale. Another member of this class is effective intesting for the volume under the Receiver Operating Characteristicsurface , which, for  K = 2 , is widely used in medical studies as asummary index of diagnostic accuracy. Comparisons to the performanceof standard tests for these two types of problems will be presented toshow the proposed tests as a viable alternative to the standardprocedures.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Nonparametric methods,ROC analysis,,,,,,,14-Nov-10,rena_sun@hotmail.com,,Jie (Rena) Sun,,University of Michigan,1420 Washington Heights,7348464331,,rena_sun@hotmail.com,CUSUMs for monitoring survival outcomes with dependent censoring,1,Jie (Rena),,Sun,University of Michigan,John,D,Kalbfleisch,University of Michigan,Douglas,,Schaubel,University of Michigan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Cumulative Sum (CUSUM) charts are often utilized to monitor processes for quality control and quality improvement purposes. In essence, a CUSUM chart compares the cumulative observed outcomes to the cumulative expected outcomes derived from a null or reference model. In survival analysis settings, existing CUSUM methods assume independent censoring, which may not hold in practice. We propose a CUSUM that allows for dependent censoring by incorporating inverse probability of censoring weighting. We also implement a graphical approach using a Cumulative Sum (CUSUM) to monitor center outcomes.  Large-sample properties of the proposed methods are derived, with their applicability to finite samples evaluated through simulation.  The proposed methods are used to monitor center-specific mortality among patients wait listed for liver transplantation.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Survival analysis,Health policy applications,,,,,,,12-Oct-10,renajsun@umich.edu,,Jie (Rena) Sun,,University of Michigan,1420 Washington Heights,734-846-4331,,renajsun@umich.edu,A Risk-Adjusted O-E CUSUM with a V-mask for Monitoring Medical Outcomes,1,Jie (Rena),,Sun,University of Michigan,John,D,Kalbfleisch,University of Michigan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Motivated by a risk-adjusted one-sided CUSUM procedure within a continuous time setting, we introduce an O-E (Observed-Expected) CUSUM along with a V-mask decision criterion to simultaneously monitor for failure time outcomes that are worse than expected or better than expected. Appropriate V-masks are obtained for facilities of different sizes by controlling the false alarm rate over a period of given length, and simulation studies are conducted to test the performanceof the proposed method, and to compared it to the one-sided CUSUM approach. A case study is carried out for 58 liver transplant programs, using the proposed O-E CUSUM, the one-sided CUSUM, and methods currently in use for flagging programs for review. The use of CUSUM methods forquality improvement is stressed.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Survival analysis,Health policy applications,,,,,,,09-Nov-10,renke.zhou@uth.tmc.edu,,Renke Zhou,,"School of Public Health, Uinversity of Texas at Ho",7900 Cambridge Street,713-792-2453,,renke.zhou@uth.tmc.edu,A semi-parametric joint model for semi-competing risk data,1,Renke,,Zhou,"School of Public Health, University of Texas at Houston;University of Texas at M.D.Anderson Cancer Center",Jing,,Ning,"School of Public Health, University of Texas at Houston",Weiwei,,Wang,"Clinical and Translational Science, University of Texas at Houston",Melissa,,Bondy,University of Texas M. D. Anderson Cancer Center,,,,,,,,,,,,,,,,,,,,,,,,,"We propose an approach that uses a joint bivariate survival model forthe semi-competing risk problem, in which a terminal event (usuallydeath) censors an intermediate event (disease process landmark), butnot vice versa. In the study about the distribution of theintermediate event, we cannot treat the terminal event as independentcensoring since the two events are correlated and most likely there issome effect of the intermediate event on the residual survival. Toinvestigate the pattern of association between those two events, aplot of conditional hazard ratio is used based on a nonparametricmethod in the upper wedge data where both of the events are observed.Then the proper Archimedean copula is selected to formulate the jointsurvival distribution. The frailty can be estimated by thepseudo-maximum likelihood of the two-stage semi-parametric method.Simulations are performed to check the model. We apply the model tothe analysis of time to recurrence and time to death in the data ofthe Early Stage Breast Cancer Repository (ESBCR) cohort study from TheUniversity of Texas M.D. Anderson Cancer Center.",FALSE,FALSE,,FALSE,FALSE,FALSE,,contributedposter,,,,FALSE,FALSE,FALSE,FALSE,Survival analysis,Cancer applications,,,,,,,15-Oct-10,renxx014@umn.edu,,Qian Ren,,Division of Biostatistics University of Minnesota,13800 Chestnut Dr.,6122459113,,renxx014@umn.edu,Multivariate Spatial Factor Analysis With Missingness Using Gaussian Predictive Processes,1,Qian,,Ren,Division of Biostatistics University of Minnesota,Sudipto,,Banerjee,Division of Biostatistics University of Minnesota,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Multivariate spatial data often arise in the natural and environmentalsciences, where inferential requirements entail joint modeling ofseveral correlated outcome variables. Hierarchical factor analysis(FA) models posit that a smaller set of latent variables can capturemultivariate dependencies, thereby reducing the model dimension. Inthe spatial context, dimension reduction is also required with respectto the number of observed locations. Here, we demonstrate how adimension-reducing low-rank spatial process (called a predictiveprocess) leads to a class of computationally feasible spatial factoranalysis model, thereby reducing the computational burden. An adaptiveMarkov chain Monte Carlo (MCMC) algorithm was developed for estimationwith an emphasis toward missing data. The missing data problem inspatial factor analytic settings is complicated by the spatialmisalignment of outcomes.  We present sampling-based methods thatcondition on the observed data and recover the full posteriordistribution of the missing values (along with model parameters) in aBayesian predictive framework. Various additional modeling andimplementation issues are discussed as well and we will illustrate ourmethodology with simulated data as well as an environmental data set.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Spatial/temporal modeling,Environmental and ecological applications,,,,,,,26-Oct-10,rex@mdanderson.org,,Peter F. Thall,Professor,M.D. Anderson Cancer Center,Department of Biostatistics,713 784 4162,713-563-4243,rex@mdanderson.org,Optimizing the Concentration and Bolus of a Drug Delivered by Continuous Infusion,1,Peter,F.,Thall,"Department of Biostatistics,  M.D. Anderson Cancer Center",Aniko,,Szabo,"Department of Population Health, Medical College of Wisconsin",Hoang,Q,Nguyen,"Department of Biostatistics,  M.D. Anderson Cancer Center",Catherine,M,Amlie-Lefond,"Department of Neurology, Neurosurgery and Radiology, Medical College of Wisconsin",Osama,O,Zaidat,"Department of Neurology, Neurosurgery and Radiology, Medical College of Wisconsin",,,,,,,,,,,,,,,,,,,,,"We consider treatment regimes in which an agent is administered continuously at a specified concentration until either a therapeutic response is achieved or a predetermined maximum infusion time is reached.  In some settings, a portion of the planned maximum total amount may be administered as an initial bolus. For such regimes, the amount of the agent received by the patient depends on the time to response. An additional complication arises when response is evaluated periodically, since the response time is interval censored. We address the problem of designing a clinical trial in which such response time data and a binary toxicity indicator are used together to jointly optimize the concentration and the size of the initial bolus. We propose a sequentially adaptive Bayesian design that chooses the optimal treatment for each patient by maximizing the posterior mean utility, defined in terms of the joint efficacy-toxicity outcome. The methodology is illustrated by a clinical trial of tissue plasminogen activator (tPA) infused intra-arterially as rapid treatment for acute ischemic stroke.  The fundamental problem is that too little tpA may not dissolve the clot that caused the stroke, but too much may cause a symptomatic intra-cranial hemorrhage, which often is fatal.",FALSE,FALSE,,FALSE,FALSE,TRUE,Invited paper session 'Practical Applications of Dynamic Treatment Regimes',invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Clinical trials,Bayesian methods,,,,,,,11-Nov-10,rgoyal@hsph.harvard.edu,,Ravi Goyal,,Harvard University,9A Ware St,3036214776,,rgoyal@hsph.harvard.edu,The role of network analysis in prevention of HIV infection,1,Ravi,,Goyal,Harvard University,Joseph,,Blitzstein,Harvard University,Victor,,DeGruttola,Harvard University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Efforts at prevention of HIV or other infectious diseases can be aided by an understanding of the transmission networks along which infection spreads.  However, it can be challenging to identify the most valuable network features to estimate and to obtain sufficiently reliable estimates of them, particularly in the setting of sexually transmitted infections.  This presentation will discuss how network features can improve prediction of epidemic characteristics and therefore, the impact of prevention strategies, compared to egocentric data alone.  We will address the question: Given all relevant ego-centric data does additional information about the underlying sexual network still improve understanding of the spread of disease? In particular, we will investigate the impact of graphical properties on the spread of infection.  We then consider estimation of network features from a sample of a network; our focus will be on estimating the degree-degree mixing matrix.  In addition we will discuss the use of the estimated degree mixing matrix for network construction.  Such construction is valuable in the development of epidemic models that can be used for testing potential value of intervention strategies though simulation.  The methods will be investigated using a data set characterizing the sexual network in Likoma Island, Malawi.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Other,Infectious disease models,Network Analysis,,,,,,08-Nov-10,rguo2010@gmail.com,,RUIXIN GUO,,University of North Carolina - Chapel Hill,109 TIMBER HOLLOW CT,9196273259,,rguo2010@gmail.com,Bayesian Lasso for Semiparametric Structural Equation Models,1,Ruixin,,Guo,"University of North Carolina, Chapel Hill",Hongtu,,Zhu,"University of North Carolina, Chapel Hill",Sy-Miin,,Chow,"University of North Carolina, Chapel Hill",,,,"University of North Carolina, Chapel Hill",Joseph,G,Ibrahim,"University of North Carolina, Chapel Hill",,,,,,,,,,,,,,,,,,,,,"It has been great interest in developing various nonlinear structural equation models and associated statistical inferences including both estimation and model selection. This paper is to develop a general semiparametric structural equation model (SSEM) in which the structural equation is composed of nonparametric functions of exogenous latent variables and fixed covariates on latent endogenous variables. A spline model representation is developed to approximate these nonparametric functions in the structural equation and the Bayesian Lasso method couple with a Markov Chain Monte Carlo (MCMC) algorithm is used to for simultaneous estimation and model selection. The proposed method is evaluated using a simulation study and its utility is illustrated in a real data analysis. Results demonstrate that our method can accurately estimate the unknown parameters and correctly identify the true underlying model.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Latent variables,Applied data analysis,,,,,,,12-Nov-10,rhmoore@mail.med.upenn.edu,,Renee Moore,Assistant Professor of Biostatistics,University of Pennsylvania School of Medicine,Blockley Hall 204,2158981606,,rhmoore@mail.med.upenn.edu,Estimating Longitudinal HIV RNA Data Subject to a Limit of Detection using Constrained Bayes Methodology,1,ReneŽ,H,Moore,"University of PennsylvaniaDepartment of Biostatistics and Epidemiology",Robert,H,Lyles,"Emory UniversityDepartment of Biostatistics and Bioinformatics",Amita,K,Manatunga,"Emory UniversityDepartment of Biostatistics and Bioinformatics",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Estimating subject-specific mean levels of HIV RNA often is of interest in epidemiological studies.  However, estimation of mean HIV RNA levels is complicated by the fact that HIV RNA levels can fall below or above the assay's (measuring instrument's) limit of detection (LOD).  Therefore, each subject may have a combination of observed HIV RNA levels and of levels subject to the LOD that are simply reported as greater than lower LOD and/or higher than upper LOD. In previously presented work, we have shown that Constrained Bayes (CB) methodology adapted to accommodate data subject to a LOD is superior in matching the true assumed distribution of the random effects (e.g. mean and variance; parameter histogram) than the commonly utilized Bayes estimate that has the known limitation of shrinkage toward the overall population mean. In this presentation, we extend the CB LOD methodology to predict HIV RNA levels at a specified meaningful time point (e.g. time of pregnancy, time of exposure, time transitioned from HIV to AIDS).  We apply this CB LOD methodology to a real dataset and in simulation studies and compare it to the Bayes estimate and customary ad hoc methodology used to handle data subject to a LOD.",FALSE,FALSE,,FALSE,FALSE,TRUE,ENAR Diversity Workshop,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Epidemiologic methods,Random effects,,,,,,,15-Nov-10,rhoffmann@mcw.edu,,Raymond G. Hoffmann,Professor,"QHS, Pediatrics",Medical College of Wisconsin,414-955-7634,414-955-6331,rhoffmann@mcw.edu,A comparison of QTL methods for pharmaco-genomic data,1,Raymond,G,Hoffmann,Medical College of Wisconsin,Thomas,J,Hoffmann,"University of California, San Francisco",Pippa,M,Simpson,Medical College of Wisconsin,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Pharmacologic models are often based on multi-compartment modelsto model the uptake, the distribution and the excretion of the medication.This will usually involve several elements of a genetic pathway andmultiple genes and their corresponding SNPS.  Depending on theprevalence of the genetic variants and the type of genetic model -dominant, recessive, additive or additive plus interaction - differentmethods may have more power.  The specific aim of this study was toexamine the sensitivity and power of the common methods for thesemulti-gene models to handle different genetic and pharmacologic(PK/PD) models. In particular one, two and three compartment modelsare used to model the phenotype. Both independent and pathway modelsare considered for the genotype.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,TRUE,Pharmacokinetic/pharmacodynamics (PK/PD) modeling,Statistical genetics,,,,,,,15-Nov-10,richard.emsley@manchester.ac.uk,,Richard Emsley,MRC Research Fellow,"Health Sciences - Biostatistics, The University of",4.304 Jean McFarlane Building,+441613068002,,richard.emsley@manchester.ac.uk,Equivalence of rank preserving structural models and instrumental variable models for causal mediation analysis,1,Richard,A,Emsley,"Health Sciences - Methodology, School of Community Based Medicine, The University of Manchester, UK",Frank,,Windmeijer,"Centre for Market and Public Organisation, Department of Economics, The University of Bristol, UK",Hanhua,,Liu,"Health Sciences - Methodology, School of Community Based Medicine, The University of Manchester, UK",Paul,,Clarke,"Centre for Market and Public Organisation, Department of Economics, The University of Bristol, UK",Ian,R,White,"MRC Biostatistics Unit, Cambridge, UK",Graham,,Dunn,"Health Sciences - Methodology, School of Community Based Medicine, The University of Manchester, UK",,,,,,,,,,,,,,,,,"New statistical approaches have been proposed for causal mediation analysis that acknowledges the likely presence of unmeasured confounding between the mediator and the outcome.  These methods include using instrumental variables and structural mean models, principal stratification and the rank preserving structural model estimated by an iterative g-estimation procedure.We investigate the equivalence the rank-preserving structural model for causal mediation analysis estimated by g-estimation and instrumental variables estimated by 2SLS, using a function of the compliance score as the instrument variable.  The method is applicable to a binary mediator, and can be applied in two stages: firstly we estimate the compliance score as a function of baseline covariates and secondly we use a function of the compliance score and its interaction with randomisation as an instrument for the endogenous mediator.  This approach can easily be implemented within standard statistical software.We illustrate a mathematical proof of the equivalence of the two methods and use simulation studies to verify this, before analysing data from several psychological treatment trials.  We conclude that the rank preserving model estimated by g-estimation and a two-stage least squares approach using the function of the compliance score as instruments are identical.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Causal inference,Clinical trials,,,,,,,08-Nov-10,rickma@umich.edu,,Yu Ma,,University of Michigan,"Biostatistics Department, University of Michigan,",7343580636,,rickma@umich.edu,Estimation of medical costs associated with recurrent events in the presence of a terminating event,1,Yu,,Ma,University of Michigan,Douglas,E.,Schaubel,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In the biostatistical literature, many methods have focused on estimating medical costs. However, few have been developed under a framework where subjects experience both recurrent events (e.g., hospitalizations) and a terminating event (e.g., death); a frequently occurring data structure.. We propose novel methods which contrast group-specific cumulative mean costs, contingent on recurrent event and survival experience. Our proposed methods utilize a form of hierarchical modeling: a proportional hazards model for the terminating event; a proportional rates model for the conditional recurrent event rate given survival; and a linear model for cost, given hospitalization. Mean cost, viewed as a process over time, is estimated by combining fitted values from each of the afore-listed models. Large sample properties are derived, while simulation studies are conducted to assess finite sample properties and to evaluate robustness under misspecified models. We apply the proposed methods to data obtained from the Kidney Epidemiology and Cost Center, which motivated our research.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Survival analysis,Estimating equations,,,,,,,15-Nov-10,rjcook@uwaterloo.ca,,Richard Cook,Professor,University of Waterloo,200 University Avenue West,519-888-4567,519-746-1875,rjcook@uwaterloo.ca,On Model Misspecification with Composite Endpoints,1,Richard,J,Cook,University of Waterloo,Longyang,,Wu,University of Waterloo,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Composite endpoints are routinely adopted in multi-center trials ofmany health conditions. Despite the widespread use of composite endpoints there has beenrelatively little attention paid to the statistical properties ofassociated estimators of treatment effect. We formulate multivariatesurvival models by linking two marginal failure time distributionswith proportional hazards through a copula function.  A Cox regressionmodel for the time to the first of these two events would be typicallyadopted for a composite endpoint analysis and we examine theasymptotic and empirical properties of the estimator arising from thismodel. We point out that even when the treatment effect is the samefor the two component event times the limiting value of the  estimatorbased on the composite endpoint is inconsistent. Marginal methods forthe analysis of multivariate failure time data yield consistentestimators of treatment effect and  are therefore preferred.  We illustrate the methods by application toa recent asthma study.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Survival analysis,Clinical trials,,,,,,,13-Nov-10,rjeffries@ucla.edu,,Robin Jeffries,,Health Research Association,3220 Midvale Ave,530-624-0428,,rjeffries@ucla.edu,Modeling response errors in repeated self-report surveys: an example of Multiple Editing for categorical data.,1,Robin,A,Jeffries,"University of California, Los Angeles",Robert,E,Weiss,"University of California, Los Angeles",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Conflicting answers to survey questions, and inconsistent responses toidentical repeated questions such as gender, exist in longitudinalself-report surveys. Deterministic data editing techniques correctthese errors but subsequent analysis assumes the edit is correct anddoes not allow for edit error. We propose models to perform multipleedit in direct analogy with multiple imputation.  We multiply editerroneous data under a model and combine the multiply edited data setsusing Rubins rules for combining multiply imputed data sets.  Thisrequires a model for the missing correct data given the clearlyincorrect responses.  We illustrate this process by considering aBayesian latent variable model for student reports of being born inthe US and how that varies as a function of age and ethnicity. Weillustrate a conditional probit model of cell probabilities forcontingency tables with what should be a structural zero and apply itto model the probability the student knows about and uses a condomdistribution program on campus. The motivating data set consists of afour year sample from a longitudinal intervention study on Los Angelesmiddle- and high-school students.",FALSE,FALSE,,FALSE,FALSE,FALSE,,contributedposter,,,,FALSE,FALSE,FALSE,FALSE,Measurement error,Bayesian methods,,,,,,,15-Nov-10,rkennedy@ms.soph.uab.edu,,Richard Kennedy,Postdoctoral Fellow,University of Alabama-Birmingham,1665 University Boulevard,205-975-9148,,rkennedy@ms.soph.uab.edu,Biomarker Enrichment in Clinical Trials:  Caveats from the ADNI Dataset,1,Richard,E,Kennedy,"Department of Biostatistics, University of Alabama-Birmingham",Gary,,Cutter,"Department of Biostatistics, University of Alabama-Birmingham",Lon,,Schneider,"Departments of Psychiatry, Neurology, and Gerontology, University of Southern California",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Biomarkers may be used to enrich samples in clinical trials fortreatment responders in Alzheimer's disease (AD) and other conditions. Successful use of biomarkers depends critically on the prevalence ofbiomarker positive individuals and the magnitude of the differentialresponse to treatment for biomarker positive and negative individuals. However, the simulation strategy and analytic methods can also play amajor role in determining the potential usefulness of a particularbiomarker.  We illustrate the problems that may be encountered whereanalyses using slope testing led to markedly different conclusionsfrom analyses using only change from baseline to endpoint. This isillustrated by using the Alzheimer's Disease Neuroimaging Initiativedataset. Such discrepancies have significant implications for thescreening of biomarkers using simulations.",FALSE,FALSE,,FALSE,FALSE,FALSE,,contributedposter,,,,FALSE,FALSE,FALSE,FALSE,Biomarkers/surrogate markers,Clinical trials,,,,,,,14-Oct-10,rli2@emory.edu,,Ruosha Li,,"Department of Biostatistics & Bioinformatics, Emor",222 Druid Oaks NE,4046951156,,rli2@emory.edu,Quantile regression adjusting for dependent censoring,1,Ruosha,,Li,"Department of Biostatistics & Bioinformatics, Emory University",Limin,,Peng,"Department of Biostatistics & Bioinformatics, Emory University",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Quantile regression has received increased attention in survivalanalysis by its flexibility, robustness and comprehensiveness.Most of available quantile regression methods for survival datarequire independent censoring, which, however, is often violated inpractice. In this work, we concern quantile regression in arealistic scenario where the survival endpoint and censoring may be dependentand postulate a semi-competing risks relationship, forexample, a landmark event of disease is subject to censoring frominformative dropout. We propose estimation and inference proceduresthat allow us to flexibly examine covariate effects on the eventtime of interest as well as the informativeness of censoring. Anefficient and stable algorithm is provided for implementing the newmethod. We establish the asymptotic properties of the resultingestimators including uniformly consistency and weak convergence.Extensive simulation studies suggest that the proposed methodperforms well with small to moderate sample sizes. We illustrate thepractical utility of our proposals through an application to an AIDSclinical trial.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Survival analysis,Multivariate survival,,,,,,,15-Nov-10,rlin@smu.edu,,Runqi Lin,,Southern Methodist University,5349 Amesbury Drive Apt#510,469-831-6568,,rlin@smu.edu,Integrative Analysis of DNA Copy Number and Gene Expression,3,Guanghua,,Xiao,"Department of Clinical Sciences, University of Texas Southwestern Medical Center at Dallas, TX",Xinlei,,Wang,"Department of Statistical Science, Southern Methodist University",Runqi,,Lin,"Department of Statistical Science, Southern Methodist University",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Array comparative genomic hybridization (CGH) and single nucleotidepolymorphism (SNP) arrays can be used to detect genomic DNA copynumber alterations, which are closely related to the development andprogression of cancer. Such alterations, including amplifications anddeletions, can result in significant changes in gene expression. Agene is called a tumor driver gene if its copy number variation leadsto the change in gene expression, and hence plays a key role in tumorgenesis. Integrative analysis of the copy number data (i.e., the arrayCGH or SNP data) and gene expression data simultaneously can not onlyimprove the statistical power for identifying the tumor driver genes,but also provide a comprehensive picture of biological mechanisms.While a large number of approaches have been proposed to analyze thecopy number data alone, there is still lack of statistical methodologyfor integrative analysis of the copy number and gene expression data.In this paper, we will adopt a Bayesian approach relying on the hiddenMarkov model (HMM) to incorporate the information from the geneexpression and copy number data and identify tumor driver genes.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Bayesian methods,Microarray analysis,Joint Modeling,,,,,,15-Nov-10,rlyoung@partners.org,,Robin Bliss,,Orthopedic and Arthritis Center for Outcomes Resea,"Brigham and Women's Hospital , Brigham Circle - 4th Floor, Suite 16",617-525-8532,,rlyoung@partners.org,Estimating distance to care: Is distance between zip code centroids a good enough proxy?,1,Robin,,Bliss,"Orthopedic and Arthritis Center for Outcomes Research, Brigham and Women's Hospital, Harvard Medical School",Jeffrey,N,Katz,"Orthopedic and Arthritis Center for Outcomes Research, Brigham and Women's Hospital, Harvard Medical School",Elizabeth,A,Wright,"Orthopedic and Arthritis Center for Outcomes Research, Brigham and Women's Hospital, Harvard Medical School",Elena,,Losina,"Orthopedic and Arthritis Center for Outcomes Research, Brigham and Women's Hospital, Harvard Medical School",,,,,,,,,,,,,,,,,,,,,,,,,"Spatial accessibility of health care is often assessed by drivingdistance between patient residence and clinic.  Data to derive directdriving distances are rarely available.  While the distance betweenzip code centroids, often available from administrative data, isfrequently used as a proxy of driving distance, its validity hasreceived little study.  We sought to validate the use of distancebetween the zip code centroids as a proxy for driving distances. Actual driving distances between patient residence and clinic wereobtained from commercial software (MapQuest). We built linearregression models to predict actual distances from the distancesbetween zip code centroids and other widely available US Census data. We used a split sample design to develop and validate the models.  Wefound that distance between zip code centroids is an inadequate proxyfor driving distances. The use of urban, suburban, or ruralcategorization of census tracts improves estimates of driving distance(AIC=1511.8) when compared to estimates using zip code distance alone(AIC=1516.0). These data suggest that zip code centroids can provide avalid estimator of driving distance for epidemiologic research whenaugmented by urban/rural categorization.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Spatial/temporal modeling,Health services research,,,,,,,11-Nov-10,robert.platt@mcgill.ca,,Robert Platt,,McGill University,Montreal Children's Hospital Research Institute,514-934-1934x23288,514-412-4331,robert.platt@mcgill.ca,An information criterion for specification of marginal structural models,1,Robert,W,Platt,McGill University,Stephen,R,Cole,University of North Carolina,Daniel,,Westreich,Duke University,M. Alan,,Brookhart,University of North Carolina,Enrique,F,Schisterman,National Institutes of Health,,,,,,,,,,,,,,,,,,,,,"Marginal structural models were developed as a semiparametric alternative to the G-computation formula to estimate causal effects of exposures. In practice, these models are often specified using parametric regression. As such, the usual conventions regarding regression model specification apply. This paper outlines strategies for marginal structural model specification, and considerations for the functional form of the exposure metric in the final structural model. We propose a quasi-likelihood information criterion (QIC) for marginal structural models, and demonstrate properties of this criterion, and its relation to the underlying counterfactual model. We illustrate some approaches to model selection on the estimation of the effect of breastfeeding duration on infant weight at one year. We consider a range of potential models, and compare them visually and using our quasi-likelihood information criterion. We demonstrate the properties of our QIC using simulation. The marginal structural model specified should reflect the scientific question being asked, but can also assist in exploration of other plausible but closely related questions. In marginal structural models, as in any regression setting, correct inference typically depends on correct model specification.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Causal inference,Variable subset selection/model selection,,,,,,,08-Oct-10,robertp@ksu.edu,,Robert Poulson,GTA,Kansas State University,101 Dickens Hall,(785)532-0527,,robertp@ksu.edu,Treatment Heterogeneity and Individual Qualitative Interaction,1,Robert,S,Poulson,Kansas State University,Gary,L,Gadbury,Kansas State University,David,B,Allison,University of Alabama at Birmingham,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"High variability in treatment effects across individuals has been recognized as an important consideration in clinical studies. Surprisingly, little attention has been given to evaluating this variability in design of clinical trials or analyses of resulting data. High variation in a treatmen's efficacy or safety across individuals (referred to herein as treatment heterogeneity) may have important consequences because the optimal treatment choice for an individual may be different from that suggested by a study of average effects.  We call this an individual qualitative interaction (IQI), borrowing terminology from earlier work - referring to a qualitative interaction (QI) being present when the optimal treatment varies across groups of individuals. At least three techniques have been proposed to investigate treatment heterogeneity: techniques to detect a QI, use of measures such as the density overlap of two outcome variables under different treatments, and use of cross-over designs to observe individual effects.  We elucidate underlying connections among them, their limitations and some assumptions that may be required. We do so under a potential outcomes framework that can add insights to results from usual data analyses and to study design features that improve the capability to more directly assess treatment heterogeneity.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,TRUE,Causal inference,Health policy applications,,,,,,,20-Sep-10,ronald@biostat.wisc.edu,,Ronald Gangnon,Asst Professor,University of Wisconsin,603 WARF,6082650688,,ronald@biostat.wisc.edu,Estimating the Minimum Rate and Identifying the Best Region,1,Ronald,E,Gangnon,"Department of Population Health SciencesDepartment of Biostatistics and Medical InformaticsUniversity of Wisconsin",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Excess mortality in a population of interest is the number of deathsthat should not have occurred or could have been avoided underdifferent conditions. In application, excess mortality is assessedrelative to the observed mortality rate in some well-performingsubgroup of the population, e.g. the best county in the United States.In realistic situations where the county populations are often smalland highly variable, estimation of the minimum (reference) mortalityrate and identification of the best (reference) county can bedifficult even if data are aggregated over several years. We considera Bayesian hierarchical Poisson regression model for data on all-causemortality by age, gender and county in the United States from1999-2005. We identify point estimates of both the minimum mortalityrate and the county with the minimum mortality rate under plausibleloss functions as well as appropriate assessments of posterioruncertainty.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Spatial/temporal modeling,Hierarchical models,,,,,,,15-Nov-10,rong_liu@merck.com,,rong liu,,"Merck & Co., Inc",5555 canteen court,215-652-4685,,rong_liu@merck.com,Statistical evaluation of follow-on biologics in preclinical space,1,Rong,,Liu,"Merck & Co., Inc.",Robert,,Capen,"Merck & Co., Inc.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"As more biologic products goes off patent protection, development of follow-on biologic products (biosimilars) has gained much attention from both biotechnology industry and regulatory agencies. Unlike small molecules, relative large variability inherent in the biologics and different study conditions than cross-over design present statistical challenges to well establish bioequivalence methodology for small molecules. This is true for evaluation of similarity of follow-on biologics in preclinical space as well. Different approaches have been proposed for clinical evaluation of the similarity of follow-on biologics such as scaled bioequivalence test, modification of scaled bioequivalence test. In this talk, we will present the utilities of different proposed approaches in preclinical space. Their potential problem and our current practice at Merck will also be presented through a real case study.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,"Biologics, pharmaceuticals, medical devices",Biopharmaceutical research,,,,,,,15-Nov-10,rpeng@jhsph.edu,,Roger Peng,,Johns Hopkins University,615 N Wolfe St,4109552468,,rpeng@jhsph.edu,Statistical issues with estimating the health effects of particulate matter constituents,1,Roger,D,Peng,Johns Hopkins University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The move towards more focused control of airborne particulate matter (PM) is hindered by a limited understanding of the toxicity of various components of the PM mixture and of the sources that may contribute injurious particles. Promulgating a more refined US National Ambient Air Quality Standard (NAAQS), incorporating PM chemical components, other characteristics, or specific sources, requires a more complete scientific foundation than is currently available.  The U.S. Environmental Protection Agency (EPA) established the PM Speciation Trends Network (STN) to measure more than 50 PM2.5 chemical components, in addition to total mass. This network includes over 50 National Air Monitoring Stations (NAMS) and over 200 State and Local Air Monitoring Stations (SLAMS).  However, the use of monitoring data on chemical components raises new statistical issues related to the spatial heterogeneity of those components and errors made in assigning group average exposures.  We investigate the potential biases incurred by using these new data and describe methods for adjusting risk estimates from time series studies of air pollution and health.",TRUE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Environmental and ecological applications,Spatial/temporal modeling,,,,,,,10-Nov-10,rpique@gmail.com,,Roger Pique-Regi,,University of Chicago,920 E 58th ST CLSC 417,17738340933,,rpique@gmail.com,Statistical framework for mapping cell-type specific transcription factor binding from DNase-seq assays,1,Roger,,Pique-Regi,"Department of Human Genetics, The University of Chicago",Jacob,F,Degner,"Department of Human Genetics, The University of Chicago",Athma,A,Pai,"Department of Human Genetics, The University of Chicago",Daniel,J,Gaffney,"Department of Human Genetics, The University of Chicago",Yoav,,Gilad,"Department of Human Genetics, The University of Chicago",Jonathan,K,Pritchard,"Department of Human Genetics, The University of Chicago",,,,,,,,,,,,,,,,,"More accurate and complete maps of the gene regulatory sites bound by transcription factors (TFs) in different cell-types/conditions are essential for achieving a better understanding of global gene regulation. We developed a probabilistic framework, CENTIPEDE, that integrates experimental data such as histone modifications, DNase-seq, or FAIRE with genomic annotation to predict which motif locations are actively bound by a transcription factor (TF). CENTIPEDE starts from all matches to a given a given motif obtained either from TRANSFAC/JASPAR databases or novel motifs candidates generated by words enriched in open chromatin sites. Then we fit an unsupervised mixture model in which there are two kinds of sites (labeled ``bound' and ``unbound'). The two classes of sites are characterized by specific distributions for each of the measured data types that are estimated using an EM (expectation maximization) algorithm.Using data from the ENCODE project we show that the sites predicted by the CENTIPEDE model using DNase-seq data agree very closely with ChIP-seq measurements of TF-binding (average AUC=99.0%, across 12 TFs in two ENCODE cell-lines). We then use our new approach to create a map of TF-binding in lymphoblastoid cell-lines with  827,000 active  sites (posterior probability >99.0%) for 239 known TFs motifs, and for 49 novel sequence motifs.",TRUE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Genomics,Computational methods,,,,,,,27-Oct-10,rsabo@vcu.edu,,Roy T. Sabo,Assistant Professor of Biostatistics,Virginia Commonwealth University,"730 East Broad St., Theater Row",804-828-3047,804-828-8900,rsabo@vcu.edu,Bayesian analysis of unbalanced and unequally spaced familial data using a generalized Markov dependence structure,1,Roy,T.,Sabo,"Department of Biostatistics,Virginia Commonwealth University",Zheng,,Lu,"Department of Biostatistics,Virginia Commonwealth University",Yihao,,Deng,"Department of Mathematical Sciences,Indiana University Purdue University Fort-Wayne",N.,R.,Chaganty,"Department of Mathematics and Statistics,Old Dominion University",,,,,,,,,,,,,,,,,,,,,,,,,"This research focuses on the analysis of familial data that exhibit age-dependent associations between parents and children. The generalized Markov correlation structure can be adapted to model associations both between parents and children and between children, which requires specification of two pairs of non-linearly related correlation and dampening parameters. This complex parameterization precludes both traditional likelihood and moment-based estimation. Alternatively, hybrid Gibbs-Metropolis methods can adequately model the non-linear joint distributions between correlation and dampening parameters, and the acceptance sampling mechanism can be adjusted to account for the positive definite ranges of all dependence parameters. Regression parameter estimation incorporating the age-dependent generalized markov association structure is then feasible. A contextual example is provided using metabolic and body composition data from the Fels Longitudinal Study, where relationships between insulin resistance, as measured by the homeostasis model assessment method, and measures of adiposity are analyzed within one-parent (maternal) families with between 2 and 6 children.",FALSE,FALSE,,FALSE,TRUE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Bayesian methods,Longitudinal data,,,,,,,15-Nov-10,rscharpf@jhsph.edu,,Robert B Scharpf,Assistant Professor,Johns Hopkins University,"550 N. Broadway, Suite 1131",410-614-7837,,rscharpf@jhsph.edu,Tackling batch effects and estimating copy number in high-throughput genotyping arrays,1,Robert,B,Scharpf,Johns Hopkins University,Ingo,,Ruczinski,Johns Hopkins University,Benilton,,Carvalho,CRUK Cambridge Research Institute,Matthew,,Ritchie,The Walter and Eliza Hall Institute of Medical Research,Rafael,A,Irizarry,Johns Hopkins University,,,,,,,,,,,,,,,,,,,,,"Submicroscopic changes in chromosomal DNA copy number dosage are common and have been implicated in many heritable diseases and cancers.  Recent high-throughput technologies have a resolution that permits the detection of copy number alterations spanning thousands of basepairs.  However, the raw intensities are highly noisy and susceptible to batch effects. Neither preprocessing with quantile normalization nor post-processing by segmentation or hidden Markov models lessen the impact of batch effects on downstream measures of copy number-phenotype association.  Batch effects are particularly problematic in genome-wide association studies as the logistics of preparing DNA and processing thousands of arrays often involves multiple laboratories or changes over calendar time to the reagents and laboratory equipment.  Our work extends previous model-based approaches for copy number estimation by explicitly modeling batch effects and using shrinkage to improve locus-specific estimates of copy number uncertainty.  Key features of our approach include the use of genotype calls at biallelic markers to develop robsut batch- and locus-specific estimates of background and signal without relying on training data. Simple statistical summaries for assessing the impact of batch effects in large studies are proposed, as well as a hidden Markov model that incorporates the batch-adjusted copy number and uncertainty.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Microarray analysis,High dimensional data,statistical genetics,,,,,,14-Oct-10,rshinoha@jhsph.edu,,Russell Shinohara,,PhD Candidate,951 Fell St. #723,203-499-8480,,rshinoha@jhsph.edu,A broad symmetry criterion for nonparametric validity of parametrically-based tests in randomized trials,1,Russell,T,Shinohara,"Department of Biostatistics,Johns Hopkins University,Baltimore, MD",Constantine,E,Frangakis,"Department of Biostatistics,Johns Hopkins University,Baltimore, MD",Constantine,G,Lyketsos,"Department of Psychiatry,Johns Hopkins Bayview Hospital,Baltimore, MD",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Pilot phases of a randomized clinical trial often suggest that aparametric modelmay be an accurate description of the trial's longitudinaltrajectories. However parametric models are often not used for fearthat they may invalidate tests of null hypotheses of equality betweenthe experimental groups. Existing work has shown that when, for sometypes of data, certain parametric models are used, the validity fortesting the null is preserved even if the parametric models areincorrect. Here, we provide a broader and easier to checkcharacterization of parametric models that can be used to increasepower and that preserve the nonparametric validity of testing the nullhypothesis, i.e., even when the models are incorrect. We demonstrateour results in a clinical trial of depression in Alzheimer's patients.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Clinical trials,Nonparametric methods,,,,,,,02-Nov-10,rui_chen@urmc.rochester.edu,,Rui Chen,,University of Rochester Medical Center,601 Elmwood Avenue,585-275-6692,,rui_chen@urmc.rochester.edu,Quasi- and pseudo-maximum likelihood estimators for discretely observed continuous-time Markov branching processes,1,Rui,,Chen,University of Rochester,Ollivier,,Hyrien,University of Rochester,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"This presentation deals with quasi- and pseudo-likelihood estimation in a class of continuous-time multi-type Markov branching processes observed at discrete points in time. Conventional and conditional estimation are discussed for both approaches. We compare their properties and identify situations where they lead to asymptotically equivalent estimators. Both approaches possess robustness properties, and coincide with maximum likelihood estimation in some cases. Quasi-likelihood functions involving only linear combinations of the data may be unable to estimate all model parameters. Remedial measures exist, including the resort either to non-linear functions of the data or to conditioning the moments on appropriate sigma-algebras. The method of pseudo-likelihood may also resolve this issue. We investigate the properties of these approaches in two examples: the pure birth process, the linear birth-and-death process. Simulations studies are conducted to evaluate performance in finite samples.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Estimating equations,Time series,,,,,,,29-Oct-10,Russ.Wolfinger@jmp.com,,Russ,Director of Scientific Discovery and Genomics,SAS Institute Inc.,SAS Campus Dr.,919-531-6695,,Russ.Wolfinger@jmp.com,Dynamic Inference of Potentially Causal Relationships Across Clinical Safety Domains,1,Russ,,Wolfinger,"SAS Institute, Inc.",Kelci,,Miclaus,"SAS Institute, Inc.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We present a data-driven workflow for determining potentially causal relationships among events, findings, and interventions from the following CDISC domains:  Adverse Events (AE), Concomitant Medications (CM), Electrocardiograms (EG), Labs (LB), Medical History (MH), plus any binary variables included in the subject-level ADSL data set from ADaM.   Standard MedRA Query (SMQ) terms can also be included.  The workflow involves: clustering of domain incidence indicator variables, selection of clusters of interest, partial correlation analysis to adjust for confounding, and cross-validation model comparison as an independent cross-check.  Accompanying intuitive visual displays include heatmaps, dendrograms, eigenprojections, and comparison circles.  The methodology can aid both in validating anticipated connections and in discovering novel ones.  A data set from a real clinical trial provides illustration.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Clinical trials,Graphical models,,,,,,,06-Oct-10,rvogel@georgiasouthern.edu,,Robert L. Vogel,"Professor, Biostatistics",Georgia Southern University,Jiann-Ping Hsu College of Public Health,478-361-7275,,rvogel@georgiasouthern.edu,A More Efficient Nonparametric Test of Symmetry Based on the Overlapping Coefficient Using Extreme Ranked Set Sample,1,Robert,L.,Vogel,Georgia Southern University,Hani,,Samawi,Georgia SOuthern University,Barbara,,Weaver,Medical Center of Central Georgia,Joseph,,Van de Water,Mercer University School of Medicine,,,,,,,,,,,,,,,,,,,,,,,,,"In this paper we provide a more efficient nonparametric test of symmetry based on the empirical overlap coefficient using kernel density estimation applied to an extreme ranked set sample. Our investigation reveals that our proposed test of symmetry is more powerful than all available tests of symmetry.  Intensive simulation is conducted to examine the power of the proposed test. An illustration is provided using cardiac output and body weight of neonates in a neonatal intensive care unit.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Nonparametric methods,Computational methods,,,,,,,12-Nov-10,rw@math.aau.dk,,Rasmus Waagepetersen,Professor,Aalborg University,Fredrik Bajersvej 7G,+45 9940 8856,,rw@math.aau.dk,Decomposition of variance for spatial Cox processes,1,Rasmus,P.,Waagepetersen,"Department of Mathematical SciencesAalborg UniversityDenmark",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Spatial patterns of rain forest tree locations are influenced by manyfactors including e.g. spatially varying environmental conditions,seed dispersal, infectious diseases, and gap creation by catastrophicevents like hurricanes. One natural question is loosely speaking `howmuch of the spatial variation' in the spatial distribution of rainforest trees can be attributed to each of these factors ? Spatial Cox point processes provide a useful framework for addressingthis question where the points represent locations of trees. A Coxprocess is driven by a random intensity function  where conditional onthe random intensity function, the Cox process becomes aninhomogeneous Poisson process. Different sources of variation can conveniently be modeled via the random intensity function of the Coxprocess.In the talk we discuss various approaches to decompose variance and toestimate components of variance for Cox processes where the randomintensity function depends either linearly or log-linearly onenvironmental covariates.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Spatial/temporal modeling,Environmental and ecological applications,,,,,,,11-Nov-10,rxia@mdanderson.org,,Rui Xia,,"The University of Texas MD Anderson Cancer Center,",1515 Holcombe Blvd.,713-745-0882,,rxia@mdanderson.org,An E-M algorithm for rapidly fitting mixture regression models to test imputed data in genome-wide association studies,1,Rui,,Xia,"1. The University of Texas at Houston, School of Public Health2.Department of Epidemiology, M. D. Anderson Cancer Center",Paul,,Scheet,"Department of Epidemiology, M. D. Anderson Cancer Center",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"For genome-wide association (GWA) studies, it has become common practice to impute genotypes at genetic markers (ie. single nucleotide polymorphisms; SNPs) that were not measured directly by microarrays or SNP chips.  Rather, by leveraging known patterns of genetic variation from large panels of densely-genotyped individuals (such as those in HapMap and the 1000 Genomes Project), researchers can assess genetic association with phenotype at millions of SNPs in a thousands of individuals from a case-control or cohort study in which a few hundred thousand SNPs were measured directly. These unobserved genotypes are imputed and have associated posterior probabilities from population genetic theory.   A Mixture likelihood framework for testing imputed genotypes can be applied with a Nelder-Mead algorithm has been shown to be helpful in settings where there exist large genetic effects, as expected from pharmacogenetic and eQTL mapping studies, and modest imputation accuracies. However, this comes with substantial computation cost. Here we present an alternative method, based on an EM algorithm, which attempts to maximize the equivalent observed-data likelihood.  We compare its performance under different settings of allele frequencies, effect sizes, and genetic models.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Statistical genetics,Computational methods,,,,,,,12-Nov-10,ryanmay@unc.edu,,Ryan May,,University of North Carolina - Chapel Hill,112 NC Hwy 54 Apt G5,360-610-9930,,ryanmay@unc.edu,Joint Modeling of Longitudinal and Survival Data with Missing and Left-Censored Time-Varying Covariates,1,Ryan,C,May,University of North Carolina at Chapel Hill,Joseph,G,Ibrahim,University of North Carolina at Chapel Hill,Haitao,,Chu,University of Minnesota,Stephen,R,Cole,University of North Carolina at Chapel Hill,,,,,,,,,,,,,,,,,,,,,,,,,"We propose a joint model for longitudinal and survival data with time-varying covariates subject to detection limits and ignorable intermittent missingness.  The model is motivated by data from the Multicenter Aids Cohort Study (MACS), in which HIV+ subjects have viral load and CD4 cell counts measured at repeated visits along with survival data.  We model the longitudinal component of the joint model via a generalized linear mixed model (GLMM), predicting the trajectory of CD4 cell counts with viral load and other covariates.  The viral load data is subject to both left-censoring due to detection limits (17%) and ignorable intermittent missingnes (27%).  The survival component of the joint model looks at death due to AIDS, and is taken as a Cox proportional hazards model.  The longitudinal and survival models are linked via the trajectory function of the GLMM, which is included in the survival component. A Bayesian analysis is conducted on the MACS data using the proposed model.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Joint models for longitudinal and survival data,Bayesian methods,,,,,,,15-Oct-10,rzhang@email.unc.edu,,Ruiwen Zhang,,"STOR, Uni. of North Carolina at Chapel Hill","STOR, Uni. of North Carolina at Chapel Hill",9192593536,,rzhang@email.unc.edu,Regression Spline Model for Neural Spike Train Data,1,Ruiwen,,Zhang,"Dept. of Statistics and Operation ResearchUniversity of North Carolina at Chapel Hill",Young,K,Truong,"Dept. of BiostatisticsUniversity of North Carolina at Chapel Hill",Haipeng,,Shen,"Dept. of Statistics and Operation ResearchUniversity of North Carolina at Chapel Hill",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Neuroscience experiments and neural spike train data have specialfeatures that present novel and exciting challenges for statisticalresearches. Several standard statistical procedures, widely used inother fields of science have found their way into mainstreamapplication in neuroscience data analysis. Given the firing times ofan ensemble of neurons, an integrate several inputs and fire model isintroduced based on the conditional intensity function approach. Thisis different from the existing methods where the intensity function isapproximated by discretization with the sampling intervals chosenarbitrary. In this paper, we model the log conditional intensityfunction directly by employing a polynomial spline function for thetarget or response spike train and a tensor product of splines for thepeer or predictor spike trains. The parameters are defined by thoseused in constructing the polynomial splines, and they will beestimated by the maximum likelihood method. The statistical propertiesof this procedure will be evaluated using a simulated experiment and areal data set involving 15 peers of neural spike trains. Our modelcaptures the underlying spontaneous firing of the target as well asthe stimulus inputs from its peers, and both in continuous time.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,TRUE,Nonparametric methods,Time series,,,,,,,14-Oct-10,rzhu@bios.unc.edu,,Ruoqing Zhu,,"Department of Biostatistics, University of North C","Department of Biostatistics, University of North Carolina at Chapel Hill",419-378-0372,,rzhu@bios.unc.edu,Recursively Imputed Survival Trees,1,Ruoqing,,Zhu,"Department of Biostatistics, University of North Carolina at Chapel Hill",Michael,R.,Kosorok,"Department of Biostatistics, University of North Carolina at Chapel Hill",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We propose recursively imputed survival tree (RIST) regression for right-censored data. This new nonparametric regression procedure uses a novel recursive imputation approach combined with extremely randomized trees that allows significantly better use of censored data than previous tree based methods, yielding improved model fit and reduced prediction error. Simulation studies and data analyses demonstrate the superior performance of RIST compared to previous methods.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Survival analysis,Nonlinear models,,,,,,,04-Nov-10,s.tsonaka@lumc.nl,,Roula Tsonaka,Dr,Medical Statistics & Bioinformatics - Leiden Unive,"Post Zone S5-P, PO Box 9600",+31-(0)71-5269722,,s.tsonaka@lumc.nl,A two-stage mixed-effects model approach for pathway analyses in candidate gene studies,1,Roula,,Tsonaka,"Medical Statistics and Bioinformatics, Leiden University Medical Center, Leiden, The Netherlands",Jeanine,J,Houwing-Duistermaat,"Medical Statistics and Bioinformatics, Leiden University Medical Center, Leiden, The Netherlands",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In genetic association studies a pathway analysis can be more powerfulthan the separate analysis of multiple genetic variants and can offerunique insights into the genetic basis of many common human diseases.The goal of a pathway analysis is to study the joint effect ofmultiple single nucleotide polymorphisms (SNPs) which belong tocertain genes and these genes are assumed to be involved in a commonbiological function. Currently few approaches acknowledge the withinand between genes correlations when testing for pathway effects. Thus,here we propose a two-stage approach which in the first stage uses amixed-effects model with a general random-effects structure to capturethe linkage disequilibrium between the SNPs, and in the second stagetests for pathway effects using the empirical Bayes estimates of therandom effects of the first stage as covariates in the model for thelongitudinal phenotype. The advantage of this approach is its broadapplicability, since it can be used for any phenotypic outcome, anygenetic model and can be implemented with standard statistical software.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Statistical genetics,Random effects,,,,,,,10-Nov-10,sahakrk@ccsu.edu,,Krishna K. Saha,Associate Professor,Central CT State University,1615 Stanley Street,860-832-2840,,sahakrk@ccsu.edu,"Profile Likelihood Based Confidence Interval for the Dispersion Parameter in Count Data, with Applications to Tumor Data",1,Krishna,K,Saha,"Department of Mathematical SciencesCentral Connecticut State University1615 Stanley StreetNew Britain, CT 06050, USA",Debaraj,,Sen,"Department of Mathematics and StatisticsConcordia University, Montreal, Quebec, H3G 1M8, Canada",Chun,,Jin,"Department of Mathematical SciencesCentral Connecticut State University1615 Stanley StreetNew Britain, CT 06050, USA",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The importance of the dispersion parameter in counts occurring in toxicology, biology, clinical medicine, epidemiology and other similar studies is well known. A couple of procedures for the construction of confidence intervals of the dispersion parameter have been investigated, but little attention has been paid to the accuracy of its confidence interval. In this paper, we introduce the profile likelihood (PL) approach and the hybrid profile variance (HPV) approach for computing the confidence intervals of the dispersion parameter in counts based on the negative binomial model. The nonparametric bootstrap (NPB) approach based on the maximum likelihood estimates of the dispersion parameter is also considered. We then compare our proposed approaches with asymptotic approaches based on the maximum likelihood (ML) and the restricted maximum likelihood (REML) estimates of the dispersion parameter as well as the parametric bootstrap (PB) approach based on the ML estimates of the dispersion parameter. As assessed by Monte Carlo simulations, the PL approach has the best small-sample performance, followed by REML, HPV, NPB, and PB approaches. Example to tumor data is presented.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Generalized linear models,Applied data analysis,,,,,,,15-Oct-10,saharzz@umich.edu,,sahar zangeneh,,University of Michigan,436 West Hall 1085 South University Ave,7347305027,,saharzz@umich.edu,Two-stage semiparametric Bayesian model-based inference for the finite population total in probability proportional to size samples,1,Sahar,Z,Zangeneh,University of Michigan,Roderick,AJ,Little,University of Michigan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In probability proportional to size sampling, the sizes fornon-sampled units are not required for the usual Horvitz-Thompson (HT)or Hajek estimates, and this information is rarely included in publicuse data files. However, Zheng and Little (2003 JOS) show thatincluding the sizes of the non-sampled units as predictors in a splinemodel can result in improved estimates of the finite population total,without strong parametric assumptions. We use a penalized spline modelto predict the outcome for the non-selected units based on thepredicted sizes. We compare the precision of the HT estimate, andBayesian estimates of the population total when the population sizesof nonsampled units are (a) known, and (b) estimated, using a BayesianBootstrap model with weakly informative prior distributions. Thevariance of the latter estimator can be decomposed into a componentfor estimating the non-sampled sizes and a component from the splineprediction model with known sizes, allowing us to assess the gain ininformation when the non-sampled sizes are available. Numericalstudies indicate that the proposed estimator offers improvements incomparison to the alternative models.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,TRUE,Survey research data,Bayesian methods,,,,,,,15-Nov-10,salexeeff@fas.harvard.edu,,Stacey Alexeeff,,Harvard School of Public Health,"677 Huntington Avenue, 4th Floor",401-215-6665,,salexeeff@fas.harvard.edu,Testing for the effect of a genetic pathway in longitudinal data:  Kernel Machine regression,1,Stacey,E,Alexeeff,Harvard School of Public Health,Arnab,,Maity,North Carolina State University,Xihong,,Lin,Harvard School of Public Health,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"There is a growing scientific interest to test for genetic effects ondisease by considering a set of genes that may be on the samebiological pathway.  Genes within a pathway may interact in functionalways to influence the progression of disease.  Kernel Machineregression has been introduced as a way to model a pathway effect,either parametrically or nonparametrically.  We consider KernelMachine regression for the testing of a genetic pathway effect in thelongitudinal/clustered data setting.  Specifically, we consider thecase where a continuous disease outcome is measured repeatedly,possibly over time, for each subject.  We develop a score-based teststatistic for testing the effect of the genetic pathway for thisscenario, accounting for the within-subject correlation in the outcomevariable.  In addition, we present a simulation analysis to test thepower for specific within-subject correlation structures, and wecompare the performance to using the test without accounting for thecorrelation.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Genomics,Longitudinal data,,,,,,,12-Oct-10,sam.lendle@gmail.com,,Sam Lendle,,UC Berkeley,101 Haviland Hall,336-972-2725,,sam.lendle@gmail.com,Group testing for case identification with correlated responses,1,Samuel,D,Lendle,UNC Chapel Hill Dept. of Biostatistics,Michael,G,Hudgens,UNC Chapel Hill Dept. of Biostatistics,Bahjat,F,Qaqish,UNC Chapel Hill Dept. of Biostatistics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"This paper examines group testing procedures where units within agroup (or pool) may be correlated. The expected number of tests perunit (i.e., efficiency) of hierarchical and matrix based procedures isderived based on a class of models of exchangeable binary randomvariables. The effect of the arrangement of correlated units withinpools on efficiency is then examined. In general, when correlatedunits are arranged in the same pool, the expected number of tests perunit decreases, sometimes substantially, relative to arrangementswhich ignore information about correlation.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Other,Experimental design,Group testing or composite sampling,,,,,,06-Nov-10,samaitra@umich.edu,,Samopriyo Maitra,Associate Professor,University of Michigan Department of Biostatistics,1415 Washington Heights,7345461459,,samaitra@umich.edu,Analysis of Periodontal Data using Circular Statistics,1,Samopriyo,,Maitra,"University of Michigan Department of Biostatistics",Thomas,,Braun,"University of Michigan Department of Biostatistics",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Periodontal disease is a common cause of tooth loss among adults inthe United States. The disease severity  is usually quantified usingmeasurements on a number of clinical parameters most common of whichis clinical attachment level (CAL). We propose the use of circularstatistics to analyze periodontal data in order to determine the meanlocations of periodontitis in the mouth. Visualizing the mouth as acircle and the teeth as points located on the circumference of thecircle, we intend to determine the mean locations of affected teeth.We assume the directions of affected teeth, as determined by theirtooth averaged CAL values, to be observations from a Von Misesdistribution. The mean directions are modeled as a function oftooth-level and mouth-level covariates using a circular-linearregression model. Because multiple teeth from a subject arecorrelated, we use a generalized estimating equation approach. Weconsider inference on the basis of a bias corrected robust varianceestimator. The estimator is shown to provide a consistent varianceestimate for moderately small sample sizes as is common for mostperiodontal studies.  We examine the performance of our methods viasimulation using data derived from an actual clinical trial ofperiodontitis.",FALSE,FALSE,,FALSE,FALSE,FALSE,,contributedposter,,,,FALSE,FALSE,FALSE,FALSE,Spatial/temporal modeling,Longitudinal data,,,,,,,08-Nov-10,samurphy@umich.edu,,Susan Murphy,Prof of Statistics,University of Michigan,"439 West Hall, 1085 S. Univ.",734-647-3684,,samurphy@umich.edu,Inverse Preference Elicitation for Dynamic Treatment Regimes,3,Dan,,Lizotte,"Dept. of StatisticsUniversity of Michigan439 West Hall, 1085 S. Univ.Ann Arbor, MI 48109-1107",Michael,,Bowling,"Department of Computing ScienceUniversity of AlbertaEdmonton, AlbertaCanada T6G 2E8",Susan,,Murphy,"Dept. of StatisticsUniversity of Michigan439 West Hall, 1085 S. Univ.Ann Arbor, MI 48109-1107",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Dynamic Treatment Regimes (DTRs) provide a framework for developingdata-driven treatment rules that optimize a single specified long-termhealth outcome.  However, this approach is problematic when there isno single outcome that is appropriate to optimize for all patients.For example, in the treatment of schizophrenia, both symptom reductionand side-effect burden are important considerations, but none of theavailable treatments works best according to both of these outcomes. We present an extension of the Q-learning algorithm for estimatingDTRs that makes three important contributions. First, it allows us tosimultaneously compute the optimal DTR for all possible convextradeoffs of two conflicting outcomes, and provides a novelperspective on preference-based decision making that we call 'inversepreference elicitation' where we can identify, for each treatment, thepreferences for which that treatment is optimal. Second, our approachis more computationally efficient than previous approaches for similarproblems. Third, it is more flexible than previous approaches in thatit allows for the use of linear models to estimate treatment qualityas a function of patient state. We show how our method could be usedto produce a clinical decision support tool that incorporates patientand doctor preferences.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Computational methods,Health policy applications,,,,,,,09-Nov-10,sangwook.kang@uconn.edu,,Sangwook Kang,,University of Connecticut,215 Glenbrook Rd. U-4120,919-923-2629,,sangwook.kang@uconn.edu,Group Variable Selection in Cardiopulmonary Cerebral Resuscitation Data for Veterinary Patients,4,Young joo,,Yoon,Konkuk University,Cheolwoo,,Park,University of Georgia,Erik,,Hofmeister,University of Georgia,Sangwook,,Kang,University of Connecticut,,,,,,,,,,,,,,,,,,,,,,,,,"Cardiopulmonary cerebral resuscitation (CPCR) is a procedure to restore spontaneous circulation in patients with cardiopulmonary arrest (CPA). While animals with CPA generally have a lower success rate of CPCR than people do, CPCR studies in veterinary patients have been limited. In this talk, we construct a model for predicting success or failure of CPCR, and identifying and evaluating factors that affect the success of CPCR in veterinary patients. Due to reparametrization using multiple dummy variables or close proximity in nature, many variables in the data form groups,and thus a desirable method should take this grouping feature into account in variable selection. To accomplish these goals we propose an adaptive group bridge method for a logistic regression model. The performance of the proposed method is evaluated under two different setups and compared with other regression methods such as the group lasso and group minimax concave penalty. Using the logistic group bridge model, we analyze the CPCR data for veterinary patients in Hofmeister et al. (2009). We compare the result from the proposed method with theirs, who used a traditional stepwise regression method, and discuss their implications on the practice of veterinary medicine.",FALSE,FALSE,,FALSE,FALSE,TRUE,Chairing an invited preliminary program: 'Statistical Learning Methods in High Dimensional Data Analysis',oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Other,Variable subset selection/model selection,Application in veterinary medicine,,,,,,15-Nov-10,saonli@umn.edu,,Saonli Basu,Assistant Professor,University of Minnesota,A 460 Mayo Building MMC 303,6126242135,6126260660,saonli@umn.edu,A Bayesian Partitioning Model for Detection of Multi-locus Interaction in Case-Control Studies,1,Saonli,,Basu,"Division of Biostatistics, University of Minnesota",Xiang,,Li,"Division of Biostatistics, University of Minnesota",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Analyses focusing on individual SNP ignore the possibility ofinteractions among SNPs. Each SNP or gene alone may have little or noeffect on risk of disease, but together may increase the risksubstantially. The joint behavior of genetic variants is oftenreferred to as epistasis or multi-locus interaction. We have proposedhere a Bayesian partitioning model to detect such multi-locusinteraction. Our model clusters genotypes according to the directionof association, and computes, via Markov chain Monte Carlo, theposterior probability that each marker set is associated with thedisease. Since the number of parameters to model multi-locusinteraction grows exponentially with the number of SNPs, we propose apair-wise scoring approach to approximate high order interactions. Weillustrate and compare our model with existing approaches throughextensive simulation studies. We demonstrated the superiority of ourapproach in detecting multi-locus interaction in our simulationstudies. We also jointly analyzed SNPs in different pathways to detectassociation with acute rejection in kidney transplant patients andidentified several SNPs including the ones that cannot be detectedthrough single SNP analysis.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Genomics,Variable subset selection/model selection,,,,,,,15-Nov-10,sarahmarks3@gmail.com,,Sarah Marks,,Emory University,222 Forkner Dr #7,404-378-6537,,sarahmarks3@gmail.com,Statistical methods for the analysis of yeast  growth phenotypes to reveal functional relationships between genes,1,Sarah,,Marks,Emory University,Alan,,Marks,Georgia Gwinnett College,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The yeast S.cerevisiae serves as an important model organism forunderstanding human disease and complex biological processes.  Yeastgrowth phenotypes are commonly used in these modeling efforts toassess the functional role of specific mutations in genes. Despite theease of collecting quantitative growth data, most studies continue torely on binary classification of phenotypes as growth or no growthor other qualitative evaluation. In this work, we provide aquantitative method for analyzing yeast growth curves and suggest thatthis data may be used to reveal important functional relationshipsbetween genes. A library of haploid yeast knockouts was screened forresistance to the anti-cancer drug edelfosine. Over 100 of theseknockout strains were found to be resistant and further data wascollected, enabling us to fit these curves with a biologicallymeaningful logistic model. Data reduction techniques are employed toenable cluster analysis of this data to show functional relationshipsbetween genes.",FALSE,FALSE,,FALSE,TRUE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Statistical genetics,Genomics,,,,,,,14-Oct-10,saranv@mail.med.upenn.edu,,Saran Vardhanabhuti,,"Department of Biostatistics, University of Pennsyl",3600 Chestnut Street,9253361521,,saranv@mail.med.upenn.edu,A Hierarchical Bayesian Model for Estimating and Inferring Differential Isoform Expression for Multi-Sample RNA-Seq Data,1,Saran,,Vardhanabhuti,"Department of Biostatistics and Epidemiology, University of Pennsylvania",Mingyao,,Li,"Department of Biostatistics and Epidemiology, University of Pennsylvania",Hongzhe,,Li,"Department of Biostatistics and Epidemiology, University of Pennsylvania",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"RNA-seq data has drastically changed our ways of studying the transcriptomes in providing more precise estimates of gene expressions, including isoform-specific expressions. Most of the available methods for RNA-seq data focus on one sample at a time. We present a Bayesian hierarchical model for multi-sample RNA-seq data analysis in order to simultaneously estimate the isoform-specific expressions and to identify the differentially expressed isoforms. Our model has the advantage of borrowing information across all the samples in estimating the expression levels, which can improve the estimates drastically for low abundance isoforms. Furthermore, our model can easily incorporate the sample-specific covariates on gene expression, which facilitates the isoform-specific differential expression analysis. Simulation studies demonstrated that this Bayesian multi-sample approach can lead to better estimate of isoform-specific expressions and higher power to detect differential expressions by borrowing information across the samples, specially for the isoforms of low abundances. We illustrate our methods using the RNA-seq data of 10 Yoruban and 10 Caucasian individuals.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,TRUE,Genomics,Statistical genetics,,,,,,,15-Nov-10,schen33@emory.edu,,Shuo Chen,,Emory University,"1518 Clifton Rd., N.E., 3rd Floor",404-357-8265,,schen33@emory.edu,Bayesian spatio-temporal hierarchical modeling for fMRI data,1,Shuo,,Chen,Emory University,Lijun,,Zhang,Emory University,DuBois,,Bowman,Emory University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The high-dimensional spatio-temporal fMRI data provides novel insightsinto brain neuropathophysiology, however, the data analysis steps arechallenging. The conventional two stage general linear model procedureis subject to the loss of the information of spatial and temporalindependence. In this talk, we propose a general group-level Bayesianhierarchical model with conditional autoriegressive (CAR) prior toaccount for region-level spatial dependence based on their temporalprofiles. We use two examples: a resting-state fMRI data set and atask fRMI data set for the purpose of illustration. The simulation isconducted for model validation and comparison.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Imaging,Bayesian methods,,,,,,,10-Nov-10,schoi6@mdanderson.org,,Sangbum Choi,,MD Anderson Cancer Center,1800 El Paseo 1502,6083355059,,schoi6@mdanderson.org,Semiparametric Transformation Frailty Models for Survival Cure Data,1,Sangbum,,Choi,MD Anderson Cancer Center,Xuelin,,Huang,MD Anderson Cancer Center,Yi-Hau,,Chen,Academia Sinica,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We propose a class of semiparametric transformation models for survival cure data. The class of cure models is motivated by the proportional hazards frailty regression models with discrete frailty, and it includes some existing survival cure models as special cases. By incorporating short- and long-term effects separately, the proposed models can explain non-proportional hazards structures along with cured proportions. An efficient and simple algorithm based on martingale process is developed to locate the nonparametric maximum likelihood estimators (NPMLEs). Unlike existing EM-based methods for cure models, the consistent variance estimators for both finite- and infinite-dimensional parameters can be directly obtained, safely avoiding near-nonidentifiability problem embedded in semiparametric cure models. The NPMLEs are shown to be consistent and asymptotically normal, and their asymptotic variances achieve the semiparametric efficiency bound. Simulation studies are conducted to examine the finite sample properties of the proposed estimators. A case study of stage III soft tissue sarcoma (STS) data is considered to illustrate the proposed method.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Survival analysis,Nonparametric methods,,,,,,,24-Sep-10,scohen@ahrq.gov,,Steven B. Cohen,"Director, Center for Financing, Access and Cost Trends",Agency for Healthcare Research and Quality,540 Gaither Road,3014271466,3014271276,scohen@ahrq.gov,The Impact of Survey Design Modifications on Health Insurance Coverage Estimates in a National Longitudinal Health Care Survey,1,Steven,B,Cohen,Agency for Healthcare Research and Quality,Trena,M,Ezzati-Rice,Agency for Healthcare Research and Quality,Marc,,Zodet,Agency for Healthcare Research and Quality,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"National health insurance coverage estimates are critical to policymakers and others concerned with access to medical care and the cost and sources of payment for that care. The Medical Expenditure Panel Survey (MEPS) is one of the core health care surveys in the U.S. that serves as a primary source for these essential national health insurance coverage estimates. In 2007, the survey experienced two dominant survey design modifications: (1) a new sample design attributable to the sample redesign of the National Health Interview Survey, and (2)an upgrade to the CAPI platform for survey instrument, moving from a DOS to a Windows based environment. This study examines the impact of these survey design modifications on the national estimates of insurance coverage. The surveys overlapping panel design and its longitudinal features are particularly well suited to assess the impact of survey redesign modifications. Attention is given to assessing the level of convergence in coverage estimates based on the alternative designs as well as the alignment of model based analyses that discern which factors are associated with health insurance classifications. The presentation concludes with a discussion of strategies that may yield additional improvements in the accuracy for these critical policy relevant survey estimates.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Survey research data,Health policy applications,,,,,,,15-Nov-10,seonjool@email.unc.edu,,seonjoo lee,,UNC-CH,318 Hanes Hall,919-951-9851,,seonjool@email.unc.edu,NONPARAMETRIC INDEPENDENT COMPONENT ANALYSIS FOR COLORED SOURCES,1,Seonjoo,,Lee,"Department of Statistics and Operations Research, UNC-CH",Haipeng,,Shen,"Department of Statistics and Operations Research, UNC-CH",Young,,Truong,"Department of Biostatistics, UNC-CH",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The talk deals with Independent Component Analysis where the sourcesare correlated within each source, which is often true in applicationssuch as fMRI and EEG analysis. Existing methods typically work withmarginal densities to separate the sources from the mixture, while wehave more important information for the data such as correlationstructures. We proposed a new ICA method on the spectral domain toincorporate correlation structure via nonparametric spectral densityestimation. The resulting estimates are very accurate in the multiplesimulations.",FALSE,FALSE,,FALSE,FALSE,FALSE,Not the last day,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Imaging,Functional data analysis,,,,,,,29-Oct-10,Seung.W.Hyun@ndsu.edu,,Seung Won Hyun,,North Dakota State University,4924 47th St S #201,701-212-5517,,Seung.W.Hyun@ndsu.edu,Desgins for estimating EC50,1,Seung Won,,Hyun,North Dakota State University,Nancy,,Flournoy,"University of Missouri, Columbia",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The EC50 is the dose that produces the 50% response. To estimate the EC50, doses are usually selected in a design space that is restricted to be between a minimum dose and the peak dose. In many cases, dose-response functions have a downturn at high doses. If researchers ignore the downturn by restricting the design space up to the peak dose, there must be some loss of information to estimating the EC50. This paper analyze the loss of information and changes of designs to estimate the EC50 due to restricting the design space. For a biologically motivated model that incorporates a downturn in the response function, we obtain the c-optimal design for estimating the EC50. We also presents c-optimal designs and uniform design for estimating the EC50 using the restricted design space.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Toxicology/dose-response,Experimental design,,,,,,,13-Oct-10,seunghee@mail.med.upenn.edu,,Seunghee Baek,PhD candidate,"Department of Biostatistics, University of Pennsyl",Hanyang apt. 72-914,82-10-9174-3905,,seunghee@mail.med.upenn.edu,"A Copula-based Model for Longitudinal Data with Bivariate Binary Outcomes,with Application to Depression Data",1,Seunghee,,Baek,"Department of Biostatistics, University of Pennsylvania",Andrea,B,Troxel,"Department of Biostatistics, University of Pennsylvania",Scarlett,L,Bellamy,"Department of Biostatistics, University of Pennsylvania",Thomas,R,Ten Have,"Department of Biostatistics, University of Pennsylvania",Steven,,Palmer,,,,,,,,,,,,,,,,,,,,,,"This paper presents an extended application of max-infinitely divisible (max-id) copulas to bivariate longitudinal data. To allow a complex correlation structure, the distribution of the current observation of each bivariate outcome is modeled conditional on the previously observed values. These conditional distributions are constructed using a max-id copula that allows flexible dependence among outcomes via copula parameters. We applied this approach to investigate the factors affecting outcomes measuring depression in patients receiving primary care. Major depression disorder (MDD) diagnosis and the Hamilton rating scale (HAMD) were the two correlated primary outcomes of interest. MDD and HAMD were measured at three time points during the study. We introduced covariate information including several predictors and time into the univariate probability using the standard logistic regression model.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Multivariate methods,Longitudinal data,,,,,,,15-Nov-10,sg147@stat.duke.edu,,Souparno Ghosh,,"Post Doctoral Associate, Dept. Statistical Science","632 South Lasalle Street, Apt H",8609337594,,sg147@stat.duke.edu,Attaching Uncertainty to Deterministic Spatial Interpolations,1,Souparno,,Ghosh,"Post Doctoral Associate, Department of Statistical Sciences, Duke University, Durham, NC",Alan,E,Gelfand,"Professor, Department of Statistical Sciences, Duke University, Durham, NC",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Deterministic interpolation algorithms such as the Cressmaninterpolation or RST interpolation  schemes are widely used tointerpolate environmental variables such as weather data and pollutantexposure but are unsatisfying in that they fail to provide anyuncertainty assessment.  Such schemes are not model-based in that theymerely provide a set of rules by which point-level data isinterpolated to a grid.  This setting differs from the case where thedeterministic model is essentially a mapping from inputs to outputsand a joint model can be used to assign uncertainty.  Here, we proposea general approach to handle the non model-based setting.  We firstformulate a useful notion of uncertainty and then show, with externalvalidation data, that we can attach uncertainty using a convenientversion of a data fusion model.  We also clarify the distinctionbetween this setting and the more usual case where we are trying tobuild an explanatory model to explain an environmental surface.We discuss two settings for such interpolation, one where the valuesare continuous such as temperature and the other where the values havea point mass say at 0 such as with precipitation.  We work within ahierarchical Bayesian framework and illustrate with two simulated dataexamples as well as a real precipitation map from the Cape FloristicRegion in South Africa.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Bayesian methods,Spatial/temporal modeling,,,,,,,14-Oct-10,sgrif@mail.med.upenn.edu,,Sandra Griffith,,University of Pennsylvania,503 Blockley Hall,2158342868,,sgrif@mail.med.upenn.edu,Nonparametric estimation of a heaping mechanism from precise and heaped self-report data,1,Sandra,D,Griffith,University of Pennsylvania,Saul,,Shiffman,University of Pittsburgh,Daniel,F,Heitjan,University of Pennsylvania,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Open-ended numerical measures, often used in self-report to assess quantities or frequencies, can exhibit a form of measurement error termed heaping, which occurs when quantities are reported withvarying levels of precision.  Digit preference is a special case ofheaping where the preferred values are round numbers.  Dailycigarette counts, for example, commonly exhibit heaps at multiplesof  2, 5, 10, and 20 when measured byretrospective recall.  As heaping can introduce substantial bias toestimates, conclusions drawn from data subject to heaping aresuspect.  Because more precise measurements are not customarilyavailable, methods to estimate the true underlying distribution fromheaped data depend on unverifiable assumptions about the heapingmechanism. A data set in which subjects reported cigaretteconsumption by both a precise method (ecological momentaryassessment using a hand-held electronic device) and amore traditional, imprecise method (timeline followback, or periodicretrospective recall) allows us to forgo the usual assumptions. Toexploit these unique data, we propose a nonparametric method toestimate the conditional distribution of the heaping mechanism giventhe precise measurement. We measure uncertainty in the estimatedheaping mechanism with a stratified bootstrap approach. Applicationto our data suggests that recall errors are a more important sourceof bias than actual heaping.",FALSE,FALSE,,FALSE,TRUE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Measurement error,Nonparametric methods,,,,,,,01-Nov-10,shanhong_guan@merck.com,,Shanhong Guan,,Merck & Co.,351 N. Sumneytown Pike,(267)305-1272,,shanhong_guan@merck.com,Sample Size Re-estimation Using Adaptive Tests and Generalized Likelihood Ratio: A Comparative Study,1,Shanhong,,Guan,Merck & Co.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"One of the important challenges in planning clinical trials is determining the sample size at the designing stage. Despite great effort, incorrect assumptions associatedwith the design parameters, for example population variance or treatment effect size, could lead to underpowered study and fail to show an effect. Several different methods have beenproposed to allow for re-estimation of sample size at the interim stage of the trial. These methods naturally lead the adaptive multi-stage clincial trial designs, in which case teststatistic can be constructed based on combination of the stage-wise p-values, assuming the condition of p-clud property is satisfied. In this talk, we will investigate the sample sizemodification method based on conditional power using different combination functions of p-values in a two-stage design setting. Numerical studies are performed to evaluate theoperating characteristics of these methods. An application to the trial design is illustrated and discussion on these methods is presented.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Adaptive design/adaptive randomization,Power analysis/sample size,,,,,,,11-Nov-10,shawpa@niaid.nih.gov,,Pamela Shaw,Dr.,BRB/NIAID,"6700A Rockledge Drive, Room 5230",301-451-2450,,shawpa@niaid.nih.gov,A novel rank test for a time-to-event outcome that incorporates information on a surrogate event,1,Pamela,A,Shaw,"Biostatistics Research Branch, National Institute of Allergy and Infectious Diseases, NIH",Michael,P,Fay,"Biostatistics Research Branch, National Institute of Allergy and Infectious Diseases, NIH",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We present a new group level test for bivariate time-to-event data, where one event can be considered a surrogate for the other. This type of data arises commonly when an event of interest, such as survival, is infrequently observed and data on a surrogate (time to remission, time to cancer progression, etc.) are instead collected. In this setting, a time-to-first type endpoint is frequently considered, but this may not be adequate or appropriate to summarize patient outcomes. We propose a rank-based test that considers information on both a short-term surrogate event and the long-term true event of interest. The proposed test allows for interval-censored outcomes and incorporates information from the bivariate survival distribution. The method is illustrated with a real data example. The relative performance of the proposed method with other common approaches, such as the time-to-first analysis, is examined with a numerical study.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Multivariate survival,Survival analysis,,,,,,,11-Nov-10,sheinchow@yahoo.com,,Shein-Chung Chow,,Duke University School of Medicine,"2424 Erwin Rd., Hock Suite 1102, Room 11068",919-668-7523,,sheinchow@yahoo.com,The Use of biosimilar index for assessment of follow-on biologics,1,Shein-Chung,,Chow,"Duke University School of Medicine, Durham, North Carolina, USA",Eric,,Chi,"Amgen, Inc., Thousand Oaks, California, USA",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"When an innovator biological product is going off patient, biopharmaceutical and/or biotech companies may file applications for regulatory approval of follow-on biologics (or biosimilars). Unlike the small molecular drug products, the complexity and heterogeneity of the molecular structure, complicated manufacturing process, different analytical methods, and possibility of severe immunogenecityreactions make evaluation of equivalence (similarity) between follow-on biologics and the innovator product a great challenge for both scientific community and regulatory agencies. In this paper, we will provide an overview of the current regulatory requirements for approval of follow-on biologics. Statistical considerations including design, criteria, fundamental biosimilarity assumption and statistical methods for assessment of Biosimilarity are discussed. In addition, a newly developed biosimilar index based on reproducibility probability of claiming Biosimilarity is proposed. The proposed biosimilar index may also be considered for addressing drug interchangeability in terms of switching and alternating under appropriate study design.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Biopharmaceutical research,Pharmacokinetic/pharmacodynamics (PK/PD) modeling,,,,,,,10-Nov-10,shenhaipeng@gmail.com,,Haipeng Shen,Associate Professor,University of North Carolina at Chapel Hill,353 Hanes Hall,9199621358,,shenhaipeng@gmail.com,Sparse Regularization of Principal Component Analysis,1,Haipeng,,Shen,University of North Carolina at Chapel Hill,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Principal component analysis (PCA) is a ubiquitous multivariateanalysis technique for dimension reduction.  Maximizing variance of astandardized linear combination of variables is the standard textbooktreatment of PCA.  A different approach is by way of fitting low rankapproximations to the data matrix, and this approach is intimatelyconnected to the singular value decomposition (SVD). Exploration ofsuch connection suggests efficient ways to impose sparsityregularizations on PCA or SVD, resulting in techniques such as sparsePCA and sparse SVD. Applications of the techniques will beillustrated. Theoretical insights under High-Dimension Low-Sample-Sizeasymptotics will also be discussed.",TRUE,FALSE,,FALSE,FALSE,TRUE,Preferred to be scheduled on Monday afternoon and onwards,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,High dimensional data,Multivariate methods,,,,,,,27-Oct-10,shenx002@umn.edu,,Xiaotong Shen,Professor,University of Minnesota,School of Statistics,6126247098,,shenx002@umn.edu,Necessary and sufficient conditions towards high-dimenisonal feature selection,1,Xioaotong,,Shen,University of Minnesota,Wei,,Pan,University of Minnesota,Yunzhang,,Zhu,University of Minnesota,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"High-dimensional feature selection has become increasingly crucial for seeking parsimonious models in parameter estimation. For selection consistency, we derive one necessary and sufficient condition formulated on the notion of degree-of-separation. The minimal degree of separation is required for consistency, and consistency is achieved by constrained L0-regularization and its computational surrogate, at thedegree of separation slightly exceeding the minimal level.This permits up to exponentially many features in the sample size, regardless of if a true model exists. In contrast, their unconstrained counterparts do so in presence of a true model, as in the parametric case. In this sense, L0- regularization and its surrogate are optimal in feature selection against any method. More importantly,  sharper parameter estimation and prediction are resulted from such selection, which, otherwise, is impossible in absence of a good selection rule.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,High dimensional data,Machine learning,,,,,,,13-Nov-10,shli@jhsph.edu,,Shanshan Li,,Johns Hopkins School of Public Health,615 N. Wolfe Street E3038,443-799-0929,,shli@jhsph.edu,Two-stage decompositions for analysis of fMRI data,1,Shanshan,,Li,Johns Hopkins University,Brian,,Caffo,Johns Hopkins University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In this manuscript, we use a two-stage decomposition for the analysisof functional magnetic resonance imaging (fMRI). In the first stage,spatial independent component analysis is applied to the group fMRIdata to obtain common brain networks (spatial maps) andsubject-specific mixing matrices (time courses). In the second stage,functional principal component analysis is utilized to decompose themixing matrices into population-level eigenvectors andsubject-specific loadings. Simulation studies suggest the ability ofthe decomposition methods to recover population brain networks and themajor direction variation of the mixing matrices. We furtherdemonstrate the utility of these decompositions in a case-controlfunctional logistic regression model. The method is applied to a novelfMRI study of Alzheimer's disease risk under a verbal pairedassociates task. We found empirical evidence of alternative ICA-basedmetrics of connectivity in clinically asymptomatic at risk subjectswhen compared to controls.Key words: fMRI; independent component analysis; principal componentanalysis; functional logistic regression; functional connectivity.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Imaging,Functional data analysis,,,,,,,15-Nov-10,shoben.1@osu.edu,,Abigail B Shoben,Assistant Professor,The Ohio State University,College of Public Health,614-293-4600,,shoben.1@osu.edu,Mean-Variance Relationships in Longitudinal Group Sequential Trials,1,Abigail,B,Shoben,The Ohio State University,Scott,,Emerson,University of Washington,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In group sequential trials, interim analyses are performed for ethicaland financial considerations. In order to perform such analyses,estimates of the statistical information at the time of the interimanalysis relative to the amount of statistical information at the endof the trial are needed. We consider potential difficulties due tomean-variance relationships in the longitudinal setting, such as achanging Poisson rate over time. The amount of heteroscedasticitybetween measurements at different times affects the informationgrowth. This fact implies that the information growth over time willbe different for different alternatives in the setting of amean-variance relationship. We found that this relationship can causedifficulties in extreme settings, but that adjusting for the observedinformation growth at the end of the study is sufficient to maintaintype I error rates in most realistic circumstances. An additionalconcern is that the covariance of the interim and final statistics maynot follow the assumed independent increments form due to using aninefficient statistic. We illustrate circumstances in which the lackof independent increments may cause departures from the nominal type Ierror rate, but show that in most common circumstances existing groupsequential methodology can be used.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Clinical trials,Longitudinal data,,,,,,,14-Nov-10,shojaie@umich.edu,,Ali Shojaie,,University of Michigan,"439 West Hall, 1085 South University Ave",7347863463,,shojaie@umich.edu,Pathway Enrichment Analysis using P-value Selection,1,Ali,,Shojaie,University of Michigan,Xiangfei,,Qi,University of Michigan,Moulinath,,Banerjee,University of Michigan,George,,Michailidis,University of Michigan,,,,,,,,,,,,,,,,,,,,,,,,,"Assessing the enrichment of biological pathways is a critical problemin systems biology, which has received much attention in recent years.However, available methods either do not provide an asymptoticanalysis of the properties of test statistics, or are based on strongsimplifying assumptions that do not hold in real applications. Thispaper proposes a new methodology for assessing the significance ofbiological pathways, with desirable asymptotic and small sampleproperties. The proposed method is based on a perturbed version ofregular p-values, which result in simultaneous reduction in falsepositive and false negative rates. The performance of the newmethodology is assessed on variety of simulated and real dataexamples, and advantages in comparison to available methodologies arediscussed.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Multiple testing,Nonparametric methods,,,,,,,11-Nov-10,shorvath@mednet.ucla.edu,,Steve Horvath,,"University of Los Angeles, California","695 Charles E. Young Drive South, Box 708822",310 825 9299,,shorvath@mednet.ucla.edu,Statistics for measuring network module preservation,1,Steve,,Horvath,"Biostatistics and Human Genetics, University of California, Los Angeles",Peter,,Langfelder,"Human Genetics, University of California, Los Angeles",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In many network applications, one is interested in determining which of the properties of a network module change across conditions. For example, to validate the existence of a module, it is desirable to show that it is reproducible (or preserved) in an independent test network. Here we study several types of network preservation statistics that do not require a module assignment in the test network. We distinguish network preservation statistics by the type of theunderlying network. Some preservation statistics are defined for a general network (defined by an adjacency matrix)while others are only defined for a correlation network (constructed on the basis of pairwise correlations betweennumeric variables). Our applications show that the correlation structure facilitates the definition of particularly powerful module preservation statistics.  We illustrate that evaluating module preservation is in general different from evaluating cluster preservation. We find that it is advantageous to aggregate multiple preservation statistics into summary preservation statistics. We illustrate the use of these methods in several gene co-expression network applications.  Our simulation studies and applications show that module preservation statistics are useful for studying differences between the modular structure of networks.",TRUE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Other,Microarray analysis,networks,,,,,,15-Nov-10,shu-chih_su@merck.com,,Shu-Chih Su,,Merck,131 Church Rd Apt 10F,2673051651,,shu-chih_su@merck.com,Adaptive design with application to a vaccine clinical trial,1,Shu-Chih,,Su,Merck,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"An adaptive design has the built-in flexibility to allow modifications to the enrollment and statistical strategy of ongoing clinical trials to mitigate the risk of non-valid assumptions of the underlying true drug/vaccine efficacy. It is also commonly seen in many trials to combine several subgroup populations into one trial to provide adequate power for the study due to the enrollment challenges.  In this work, adaptive design for a vaccine clinical trial with time-to-event endpoint on patients with solid tumor malignancy or hematologic malignancy was used for demonstration. Based on one Phase I study, the result suggested that vaccine efficacy in one population may be lower in another group.  If vaccine efficacy for one group is substantially lower than for the other group, there is risk that the primary hypothesis, based on the incidence rate in the combined populations, may fail even if good efficacy is observed in one subgroup population. To mitigate this risk, an adaptive design with built in futility analyses was conducted for each individual subpopulation with conditional criteria for stopping the study in one or both populations if vaccine efficacy is very low.",FALSE,FALSE,,FALSE,FALSE,FALSE,,contributedposter,,,,FALSE,FALSE,FALSE,TRUE,Adaptive design/adaptive randomization,Clinical trials,,,,,,,18-Oct-10,shyun@uscupstate.edu,,Seunggeun Hyun,Assistant Professor,University of South Carolina Upstate,Division of MCS,864-503-5228,,shyun@uscupstate.edu,Proportional hazards model for competing risks data with missing cause of failure,1,Seunggeun,,Hyun,"Division of Mathematics and Computer Science,University of South Carolina Upstate",Jimin,,Lee,"Department of Mathematics,University of North Carolina Asheville",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We consider the semiparametric proportional hazards model for the cause-specific hazard function in analysis of competing risks data with missing cause of failure. The inverse probability weighted equation and augmented inverse probability weighed equation are proposed for estimating the regression parameters in the model, and their theoretical properties are established for inference. Simulation studies demonstrate that the augmented inverse probability weighted estimator is doubly robust and the proposed method is appropriate for practical use. The methodology is illustrated with bone marrow transplant data.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Survival analysis,Missing data,,,,,,,23-Oct-10,sid.stat.iitk@gmail.com,,Siddhartha Mandal,,Doctoral Student,416 W.Cameron Ave,9194027102,,sid.stat.iitk@gmail.com,Statistical inference for dynamic systems governed by differential equations with applications to toxicology,1,Siddhartha,,Mandal,University of North Carolina at Chapel Hill,Pranab,K,Sen,University of North Carolina at Chapel Hill,Shyamal,D,Peddada,National Institute of Environmental Health Sciences,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Stochastic and deterministic differential equations are used to describea wide variety of biological and physiological phenomena. Forexample, in Physiologically based pharmacokinetic (PBPK) models,differential equations explain the absorption, distribution, metabolismand excretion (ADME) of a compound in the human or animal body.Usual approaches for parameter estimation in such situations includenon-linear least squares and Bayesian hierarchical modeling. However,a common challenge with these problems is the lack of explicitequations/models that relate response variable to the explanatoryvariables.Recent functional data analysis methods indicate the use ofbasis functions to bypass this problem. This talk focuses on estimationand inference of the model parameters, taking into account thevariability within and between multiple subjects, while exploiting thestructure implied by the system of differential equations. Large samplebehavior of the parameter estimates are also explored. Applicationof the methods are shown using simulated and real life data oncompartmental and state space models.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Pharmacokinetic/pharmacodynamics (PK/PD) modeling,Functional data analysis,,,,,,,15-Nov-10,siddique@northwestern.edu,,Juned Siddique,Assistant Professor,Northwestern University,Department of Preventive Medicine,312-908-9241,,siddique@northwestern.edu,Generating Multiple Imputations From Multiple Models to Incorporate Model Uncertainty in Nonignorable Missing Data Problems,1,Juned,,Siddique,Northwestern University,Ofer,,Harel,University of Connecticut,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We present a framework for generating multiple imputations when the missing data are assumed to be nonignorably missing. Imputations are generated from more than one model in order to incorporate uncertainty regarding what is the 'correct' imputation model. Parameter estimates based on the different imputation models are combined using the rules of nested multiple imputation. Through the use of simulation, we investigate the impact of imputation model uncertainty on post-imputation inferences and show that incorporating model uncertainty can improve the coverage of parameter estimates. We also apply our method to a longitudinal depression treatment study. Our method provides a simple approach for formalizing subjective notions regarding nonresponse so that they can be easily stated, communicated, and compared.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Missing data,Applied data analysis,,,,,,,14-Nov-10,sinha@stat.tamu.edu,,Samiran Sinha,,Texas A&M UNiversity,"Department of Statistics, TAMU 3143",9798453160,,sinha@stat.tamu.edu,A Semiparametric Correction to Score Tests in the Presence of Errors-in-covariate in the  Generalized Linear Model,1,Samiran,,Sinha,"Department of Statistics, Texas A&M University",Jenny,X,Sun,"School of Public Health, Boston University",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We consider the generalized linear model where the response variable Yis related with X and Z. The variable X is not observed, rather anerror prone measurement W is observed in the data, and the traditionaladditive measurement error model may not be enough to explain thesurrogate relationship.  Let beta1 and beta2 be the coefficientsassociated with X and Z.  The naive score tests for testing any hypothesis regrading beta1 orbeta2 may turn out to be biased test.  Therefore,  we propose acorrection to the score tests for testing hypothesis related to beta1and beta2. The performance of the proposed tests are judged via simulation studies. The proposed tests are also applied to real datasets.",FALSE,FALSE,,FALSE,FALSE,FALSE,"with the following invited session entitled 'Disease Mapping and Spatial Regression asEmerging Tools for Surveillance Epidemiology'",oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Generalized linear models,Epidemiologic methods,,,,,,,15-Nov-10,sinhad@stat.fsu.edu,,debajyoti sinha,professor,"department of statistics, florida state university",3042 st andrews way,8508771887,,sinhad@stat.fsu.edu,Joint estimation for multivariate longitudinal binary outcomes with missing data:  An application to AIDS study,1,debajyoti,,sinha,"department of statistics, Florida State University",STUART,,LIPSITZ,"DIVISION OF GENERAL MEDICINE, Brigham and Womens Hospital, HARVARD MEDICAL SCHOOL",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In a large, prospective longitudinal study designed to monitor cardiacabnormalities in children born to HIV-infected women, there aremultiple binary outcomes (e.g., abnormal heart rate, abnormal bloodpressure, abnormal heart wall thickness) of heart function over time.In the presence of missing responses, longitudinal marginal models formultiple outcomes often use generalized estimating equations (GEE)(Liang and Zeger, 1986) under the assumption of a missing completelyat random (MCAR) mechanism. When the missing data mechanism is missingat random (MAR), that is the probability of missing a particularoutcome at a time-point depends on observed values of that outcome andthe remaining outcomes at other time points, we propose two jointestimation procedures of the regression parameters. The firstprocedure uses a single modified GEE based on an EM-type algorithm andthe second one is based on likelihood of the fully specified model ofthe multivariate binary responses and missing mechanism.  Analysis ofour motivating study illustrate the application of the methods.Further, we show that under an MAR mechanism, our joint estimationprocedures produce almost unbiased estimates, whereas estimates fromstandard GEE can lead to substantial bias.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Longitudinal data,Multivariate methods,,,,,,,07-Oct-10,sjzhang@stat.tamu.edu,,Saijuan Zhang,,Texas A&M University,"Department of Statistics, Texas A&M University",9797395371,,sjzhang@stat.tamu.edu,"A New Multivariate Measurement Error Model with Zero-Inflated Dietary Data, and its Application to Dietary Assessment",1,Saijuan,,Zhang,"Department of Statistics, Texas A&MUniversity, 3143 TAMU, College Station, Texas 77843-3143, U.S.A.",Douglas,,Midthune,"Biometry Research Group, Division of Cancer Prevention, National Cancer Institute, 6130 ExecutiveBoulevard, EPN-3131, Bethesda, Maryland 20892-7354, U.S.A.",Patricia,M.,Guenther,"Center for Nutrition Policy and Promotion, U.S. Department of Agriculture, 3101 Park Center Drive,Ste. 1034, Alexandria, Virginia 22302, U.S.A.",Susan,M.,Krebs-Smith,"Applied Research Program, Division of Cancer Control and Population Sciences, National Cancer Institute,6130 Executive Boulevard, EPN-4005, Bethesda, Maryland 20892, U.S.A.",Victor,,Kipnis,"Biometry Research Group, Division of Cancer Prevention, National Cancer Institute, 6130 ExecutiveBoulevard, EPN-3131, Bethesda, Maryland 20892-7354, U.S.A.",Kevin,W.,Dodd,"Biometry Research Group, Division of Cancer Prevention, National Cancer Institute, 6130 ExecutiveBoulevard, EPN-3131, Bethesda, Maryland 20892-7354, U.S.A.",Dennis,W.,Buckman,"Information Management Services, Inc., 12501 Prosperity Drive, Silver Spring, Maryland 20904, U.S.A.",Janet,A.,Tooze,"Department of Biostatistical Sciences,Wake Forest University, School of Medicine, Medical Center Boulevard,Winston-Salem, North Carolina 27157, U.S.A.",Laurence,S.,Freedman,"Gertner Institute for Epidemiology and Health Policy Research, Sheba Medical Center, Tel Hashomer52161, Israel",Raymond,J.,Carroll,"Department of Statistics, Texas A&MUniversity, 3143 TAMU, College Station, Texas 77843-3143, U.S.A.","In the United States the preferred method of obtaining dietary intakeis the 24-hour recall, yet the measure of most interest is usualintake. Thus, usual dietary intake is assessed with measurement error.Also, some dietary components are episodically consumed so that24-hour recall data are zero-inflated. In addition, dietary componentsare often correlated with each other. Nutritionists are interested inexploring them collectively to capture overall dietary patterns.Finally, it is often preferable to analyze the amount of a dietarycomponent relative to the amount of energy in a diet. The quest to understand overall dietary patterns of usual intake hasto this point reached a standstill. There are no statistical methodsavailable to model such complex multivariate data with its measurementerror and zero inflation. This paper proposes the first such model andthe first workable solution to fit such a model. The methodology isillustrated through an application to estimating the populationdistribution of the Healthy Eating Index-2005 among children aged 2-8in the United States. We pose a number of interesting questions andprovide answers that were not previously within the realm ofpossibility, and we indicate ways that our approach can be used toanswer other questions of importance to nutritional science and publichealth.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,TRUE,Measurement error,Multivariate methods,,,,,,,11-Nov-10,skmathur@olemiss.edu,,Sunil Mathur,Professor,University of Mississippi,"Hume 325, Department of Mathematics",662-513-3497,,skmathur@olemiss.edu,A Generalized Test Statistic to Identify Differentially Expressed Genes,1,Sunil,,Mathur,University of Mississippi,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"DNA microarray allows the monitoring of expression levels in cells for thousands of genes simultaneously. A generalized test statistic to identify differentially expressed genes using microarray data is presented. The proposed test statistic is highly robust against extreme values and does not assume the distribution of parent population. Simulation studies show that the generalized test is more powerful than some of the commonly used methods, such as two-sample t-test, Mann-Whitney U-test and Significance Analysis of Microarray (SAM). It is found that the proposed test identifies more differentially expressed genes than its competitors with low false discovery rate (FDR) when applied to microarray data. The asymptotic distribution of the test statistic, and the p-value function are discussed. The application of proposed method is shown by using a synthetic and a real-life data.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Microarray analysis,Nonparametric methods,Testing of Location,,,,,,14-Oct-10,skundu@email.unc.edu,,Suprateek Kundu,,"Biostatistics, UNC Chapel Hill","462 Melanie Court,NC 27514, USA",19194027127,,skundu@email.unc.edu,Single Factor Transformation Priors for Density Regression,1,Suprateek,,Kundu,"Biostatistics, UNC Chapel Hill",David,,Dunson,"Department of Statistical Sciences, Duke University",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Although mixture modeling has formed the backbone of the literature onBayesian density estimation incorporating covariates, the use ofmixtures leads to some well known disadvantages. Avoiding mixtures, wepropose a flexible class of priors based ona random transformation of a uniform latent variable. These priors arerelated to Gaussian process latent variable models proposed in themachine learning literature. For densityregression, we model the response and predictor means as distinctunknown transformation functions dependent on the same underlyinglatent variable, thus inducing dependencethrough a single factor. The induced prior is shown to have desirableproperties including large support and posterior consistency. Wedemonstrate advantages over Dirichlet processmixture models in a variety of simulations, and apply the approach toan epidemiology application.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Bayesian methods,Latent variables,,,,,,,10-Nov-10,slee2@iwu.edu,,Seung-Hwan Lee,Professor,Illinois Wesleyan University,PO Box 2900,309-556-3421,,slee2@iwu.edu,Modeling Bivariate Weibull Distributions using Archimedean Copulas,1,Seung-Hwan,,Lee,"Department of MathematicsIllinois Wesleyan University",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Archimedean copulas are used to construct bivariate Weibulldistributions.  Co-movement structures of variables are analyzedthrough the copulas, where tail dependence between the variables isexplored with more flexibility. Based on  Kolmogorov-Smirnov typedistance between the copula distribution and its empirical version, acopula that best fits data is selected, and some goodness-of-fit testsof the copula are performed. For multiple myeloma data, it was foundthat relationship between survival time of a patient and level ofhemoglobin is well described by Clayton copula. The Archimedeancopulas are used to estimate Value at Risk from which we forecast theprobable longest survival time.",FALSE,FALSE,,FALSE,FALSE,FALSE,,contributedposter,,,,FALSE,FALSE,FALSE,FALSE,Multivariate survival,Computational methods,,,,,,,13-Nov-10,SLIPSITZ@PARTNERS.ORG,,Stuart Lipsitz,,Brigham and Women's Hospital,Division of General Medicine,6175258559,,SLIPSITZ@PARTNERS.ORG,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,FALSE,FALSE,,FALSE,FALSE,FALSE,,,,,,FALSE,FALSE,FALSE,FALSE,,,,,,,,,03-Nov-10,slooney@mcg.edu,,Stephen W. Looney,Professor,Medical College of Georgia,"1120 15th Street, AE - 1014",706-721-4846,706-721-6294,slooney@mcg.edu,Much Ado About Almost Nothing:  Methods for Dealing With Limited Data,1,Stephen,W,Looney,"Dept. of BiostatisticsMedical College of Georgia1120 15th St., AE-1014Augusta, GA  30912-4900",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Applied statisticians are often confronted with statistical inferenceproblems dealing with situations in which there appear to be no data,or data of only limited usefulness.  For example, when attempting tofind a confidence interval for a binomial proportion, the sample maycontain no successes.  Such a scenario could be encountered, forexample, when attempting to estimate the incidence of an extremelyrare side effect associated with the administration of a newlydeveloped drug.  Other statistical inference situations in which theremay be no or only limited data include estimating an odds ratio whenone of the cells in a 2x2 table is empty, estimating a risk ratio whenone of the groups experiences none of the outcome of interest,estimating Cohens measure of agreement, kappa, when one of the cells(or perhaps a row or column total) is zero, and incorporatingobservations below the limit of detection into a statistical analysis. In this presentation, we illustrate each of these scenarios with realdata and describe the preferred methods for handling each of them.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Other,Applied data analysis,analysis of messy data,,,,,,14-Nov-10,slustgar@bu.edu,,Stephanie Lustgarten,,Boston University,73 Highland St #1,6177338056,,slustgar@bu.edu,Non-Parametric Bayesian Methods for Prediction of Event Times for Analysis with Failure-Time Data,1,Stephanie,,Lustgarten,Boston University (Doctoral Student),Gheorghe,,Doros,Boston University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In clinical trials with failure-time primary outcomes, statistical information is determined by accumulated events.  Interim and final analyses are performed after a pre-specified number of events have been observed.  The timing of these analyses represent important milestones in the conduct of the study; it is of interest to predict when a pre-specified number of events will be observed based on accumulating data.  Parametric and semi-parametric methods have been proposed for event prediction when data are right censored.  In cases when the underlying failure time distribution is unknown or accumulated events are relatively sparse, these methods may not provide accurate or efficient prediction.  We propose a method to predict the number of events that is a fully Bayesian non-parametric approach in modeling the survival probabilities that is more flexible and generalizes to interval censored data.  We use a Gibbs sampler to sample survival distribution estimates from the posterior of the survival distribution to obtain point and interval estimates for the specified number of events.  We compare the accuracy and precision of this approach to proposed parametric and semi-parametric methods.  In summary, the proposed method offers greater flexibility and based on our studies has the ability to match or outperform existing methods.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Clinical trials,Bayesian methods,,,,,,,14-Oct-10,smcclin@emory.edu,,Shannon McClintock,PhD candidate,Emory University,3111 Vista Brook Drive,404 895 9033,,smcclin@emory.edu,Estimation of Vaccination Coverage Using a Constrained Logistic Model,1,Shannon,K,McClintock,Emory University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Estimation of population vaccination coverage is a challenging taskthat has been previously accomplished by simple point estimation or bysurvival analysis methods. We explore two versions of a logistic modelto estimate vaccination coverage. The first is a logistic modelhistorically used with continuous growth data; the second modelreparameterizes the numerator of the first, hence naturallyconstraining parameter estimates. Due to computational challenges inestimation of constrained parameters, we explore three methods ofestimation for both models (nonlinear least squares, maximumlikelihood estimation, and Bayesian estimation). While computationalstability can be highly dependent on the design matrix, simulationresults show that all methods of estimation produce comparableestimates and model results. These methods were applied to the 2003Kenya Demographic and Health Surveys to estimate the samplevaccination coverage of the combined diphtheria, pertussis, andtetanus vaccine series. The application to the real data set producedsimilar results among the two models with the three methods ofestimation. The method of estimation should be chosen based on thespecific research application, and we recommend utilizing the secondmodel presented in order to naturally enforce parameter constraints.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Constrained estimation/order restricted inference,Nonlinear models,,,,,,,04-Nov-10,smo@mcw.edu,,Shuyuan Mo,,Medical College of Wisconsin,8701 Watertown Plank Road,4149554214,,smo@mcw.edu,Group sequential tests for long-term survival comparison,1,Shuyuan,,Mo,"Division of Biostatistics, Medical College of Wisconsin",Brent,R,Logan,"Division of Biostatistics, Medical College of Wisconsin",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In clinical trials, sometimes the hazard rates are anticipated to benonproportional, resulting in potentially crossing survival curves, sothat researchers are interested in which treatment has betterlong-term survival. In this case, the logrank test and the weightedlogrank test may not be appropriate or efficient, because they aresensitive to differences in survival at any time and don't just focuson long-term outcomes. Also in a prospective clinical trial, patientsare entered sequentially over calendar time, so that group sequentialdesigns may be considered for ethical, administrative and economicconcerns. Here we developed group sequential methods for testing thenull hypothesis that the survival curves are identical after apre-specified time point t0. Several classes of tests are considered,including an integrated difference in survival probabilities after t0,and linear or quadratic combinations of two component test statistics(pointwise comparisons of survival at t0 and comparisons of hazardrates after t0). Joint distributions of group sequential teststatistics are derived. We examine the type I errors, stoppingprobabilities, and powers of these tests through simulation studiesunder the null and different alternatives, and we apply them to a realbone marrow transplant clinical trial.",FALSE,FALSE,,FALSE,TRUE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Survival analysis,Clinical trials,,,,,,,10-Nov-10,songfeng@gmail.com,,Songfeng Wang,,"Department of Epidemiology and Biostatistics, Univ",800 Sumter St Room 205,319-400-6154,,songfeng@gmail.com,A Bayesian Normal Mixture Accelerated Failure Time Spatial Model and its Application to Prostate Cancer,1,Songfeng,,Wang,"Department of Epidemiology and Biostatistics, University of South Carolina, Columbia, SC 29208, USA",Jiajia,,Zhang,"Department of Epidemiology and Biostatistics, University of South Carolina, Columbia, SC 29208, USA",Andrew,B,Lawson,"Division of Biostatistics and Epidemiology, College of Medicine, Medical University of South Carolina, Charleston, SC 29425, USA",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In United States, prostate cancer is the third most common cause ofdeath from cancer in men of all ages and the most common cause ofdeath from cancer in men over age 75.  It has been recognized that theincidence of the prostate cancer is high in African Americans,  andits occurrence and progression may be impacted by geographical factors.The use of the proportional hazards (PH) model for survival analysiswith spatial random effects is questionable due to the proportionalhazards assumption. As an alternative, the accelerated failure time(AFT) spatial model can be used to investigate the relationshipbetween survival time and possible effects like geographicaldifferences and racial disparities. In this paper, we develop aBayesian accelerated failure time (AFT) spatial model with normalmixture distribution as the error term distribution. Extensivesimulations show that the proposed model provides decent flexibilityfor a variety of parametric error distributions. The proposed modelcan be easily implemented in WinBUGS with the code provided. Theproposed model is applied to 2000-2007 Louisiana prostate cancer dataset from the Surveillance, Epidemiology, and End Results (SEER)Program of the National Cancer Institute.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Cancer applications,Survival analysis,,,,,,,03-Nov-10,songhuiming@gmail.com,,huiming song,,uc riverside,3382 kentucky st,9517328858,,songhuiming@gmail.com,Bayesian analysis of MTD models,1,huiming,,song,"University of California, Riverside",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"MTD (Le, Martin, and Raftery, 1996) and BMTD (Hassan and Lii, 2006)can be used to model data with scratches, outliers effectively. Inboth papers EM algorithm is used for parameter estimation. The mixturemodel can be treated as missing data problem.Assume each the data point comes from one of the k groups (here wethink k is fixed known) with the distribution we use to model thedata, but we dont know which group does it come from. Suppose thereis an unobservable variable indicates which group does the data begenerated. Then it becomes the missing data problem. Our job is tofind the value of the parameters in the distribution we model the data(÷) as well as the weight of each group the data point comes from (Ë).",FALSE,FALSE,,FALSE,TRUE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Bayesian methods,Machine learning,,,,,,,15-Nov-10,sonja.greven@stat.uni-muenchen.de,,Sonja Greven,,"Department of Statistics, Ludwig-Maximilians-Unive",Ludwigstr. 33,+498921803803,,sonja.greven@stat.uni-muenchen.de,Longitudinal Functional Principal Component Analysis,1,Sonja,,Greven,"Department of Statistics, Ludwig-Maximilians-University Munich",Ciprian,,Crainiceanu,"Department of Biostatistics, Johns Hopkins University",Brian,,Caffo,"Department of Biostatistics, Johns Hopkins University",Daniel,,Reich,"Translational Neuroradiology Unit, Neuroimmunology Branch, National Institute of Neurological Disorders and Stroke, National Institutes of Health",,,,,,,,,,,,,,,,,,,,,,,,,"We introduce models for the analysis of functional data observed atmultiple time points. The dynamic behavior of functional data isdecomposed into a time-dependent population average, baseline (orstatic) subject-specific variability, longitudinal (or dynamic)subject-specific variability, subject-visit-specific variability andmeasurement error. The model can be viewed as the functional analog ofthe classical mixed effects model where random effects are replaced byrandom processes. Methods have wide applicability and arecomputationally feasible for moderate and large data sets.Computational feasibility is assured by using principal componentbases for the functional processes. The methodology is motivated byand applied to a diffusion tensor imaging (DTI) study designed toanalyze differences and changes in brain connectivity in healthyvolunteers and multiple sclerosis (MS) patients.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Functional data analysis,Longitudinal data,,,,,,,15-Nov-10,spes@uw.edu,,Siobhan Brown,,ROC Clincial Trials Center,1107 NE 45th St,206-616-0465,,spes@uw.edu,Information Growth in Cluster Crossover Clinical Trials,1,Siobhan,P,Brown,"ROC Clinical Trials Center, University of Washington",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Cluster-randomized clinical trials, where the unit of randomization isa cluster, community, or other group, are common in medical research.This method of randomization is often chosen because the nature of theintervention requires that it be applied at a community level, whenimplementing the treatment involves the training of health careprofessionals, or due to other logistical constraints. These designscan facilitate the administration of a clinical trial when usedappropriately, but do introduce a correlation structure into the datathat must be taken into account at analysis time.Cluster-crossover trials are similar in structure to clusterrandomized trials but have the added feature that each cluster israndomized to all treatments in sequence. Because a cluster serves asits own control, these designs are more efficient than simple clusterrandomized trials. Of course, the additional design complexity must beconsidered when choosing an analysis method. Additionally, theselection of a cluster-crossover design can complicate monitoring of astudy, as the information at an interim analysis will not beproportional to the total number of enrolled subjects. We investigatedhow the timing and frequency of crossover impacts information growthover the course of a cluster-crossover study.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Clinical trials,Clustered data methods,,,,,,,08-Nov-10,spxl@hacettepe.edu.tr,,Serpil,Dr,Hacettepe University,"Hacettepe University, Department of Statistics",+90-312-2977930,,spxl@hacettepe.edu.tr,MODELING AND ESTIMATING RATES,1,Serpil,,Aktas,"Hacettepe University, Ankara, Turkey",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"When the count of an event is observed within a group or over an interval, it is called a rate which is a mean of a special kind of frequency distribution. For example, unemployment rates, mortality rates, incidence rates are widely used in demographic studies. A Poisson model for a rate can be represented as a function of some predictor variables.  Besides, to compare two different rates, estimated rate ratio is used. Point and interval estimates for the rates are obtained by exponentiating the point estimates and confidence limits for the log rates. In this paper, modeling the rate is described using infant mortality rates data.",FALSE,FALSE,,FALSE,FALSE,TRUE,Statistical modeling,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Applied data analysis,Generalized linear models,,,,,,,14-Nov-10,srao@bios.unc.edu,,Shangbang Rao,,"Department of Biostatistics, UNC-CH","108 Shadowood Drive,Apt. X",9193603243,,srao@bios.unc.edu,Penalized Multiscale Adaptive Model for Regularizing High Angular Resolution Diffusion Imaging,1,Shangbang,,Rao,"Department of Biostatistics, The University of North Carolina at Chapel Hill, Chapel Hill, NC 27599-7420",Hongtu,,Zhu,"Department of Biostatistics, The University of North Carolina at Chapel Hill, Chapel Hill, NC 27599-7420",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Neuroimaging studies often aim to analyze imaging data with complexspatial correlation structures and activation patterns on a 2D surfaceor in a 3D volume. High angular resolution diffusion imaging (HARDI)has recently been of great interest in characterizing non-Gaussiandiffusion processes.The goal of this article is to develop a penalizedmultiscale adaptive model (PMAM )for regularizing high angularresolution diffusion imaging. One important goal is to obtain moreaccurate fits ofthe apparent diffusion processes(ADC) in these non-Gaussian regions,thus overcoming the limitations of classical diffusion tensor imaging.Compared with the existing voxel-wise ADC regularizing method (MaximeDescoteaux etc. 2006), PMAM has three unique features: being spatial,being hierarchical, and being adaptive. PMAM uses K-mean method tocluster all voxels into different clusters, creates a small spherewith a given radius at each location , analyzes all observations inthe sphere of each voxel in each cluster, and then uses theseconsecutively connected spheres across all voxels to capture spatialdependence among imaging observations. PMAM builds hierarchicallynested spherers by increasing the radius of a spherical neighborhoodaround each voxels and utilizes information in each of the nestedspheres at each voxel. Finally, PMAM combines imaging observationswith adaptive weights in the voxels within th esphere of the currentvoxel to adaptively calculate parameter estimates.",FALSE,FALSE,,FALSE,FALSE,FALSE,,contributedposter,,,,FALSE,FALSE,FALSE,FALSE,Imaging,Hierarchical models,,,,,,,15-Nov-10,sshshoh1105@gmail.com,,sunghee,postdoctoral research associate,Yale Medical School,Department of Genetics Yale Medical School of Medicine,2038231718,,sshshoh1105@gmail.com,A statistical trajectory model over time series in mRNA-Seq count data,1,Sunghee,,OH,"Department of Genetics, Yale Medical School",Hongyu,,Zhao,"Department Genetics and Biostatistics, Yale Medical School",James,P.,Noonan,Department of Genetics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We provide a novel and statistically differential/trajectory model for time series of counts, which account for discreteness and over-dispersion to define a global pattern of gene expression during dynamic transcriptomics using simulated data sets and Solexa/Illumina mRNA-Seq real data application.  Trajectory time series analysis to identify genes with significant changes during the time course has a potential area of study for applications, including genomics, evolutionary biology, developmental biology as well as clinical medicine. In times series studies, a variety of statistical models and tools have been developed in capturing and comparing variation in expression over time based on microarray experiment. To the best of our knowledge, this is the first solid study to thoroughly define a statistical trajectory across times points in next generation sequencing (NGS) data. We present a non-parametric model based on rank approach and parametric-driven model based on Markov Chain Monte Carlo EM algorithm (MCMC) for time course gene expression count data in mRNA-Seq. Specifically, our trajectory approach is further applied to exploit a comparative analysis in cross-species gene regulatory module network by identifying significantly (highly) species-conserved (common) and species-specific (unique) trajectories.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Other,Microarray analysis,next generation sequencing or mRNA-Seq,,,,,,14-Oct-10,ssmehta@purdue.edu,,Shraddha Mehta,,Student,250 N. University Street,6128197615,,ssmehta@purdue.edu,Bayesian Sufficient Dimension Reduction in Survival Analysis,1,Shraddha,S,Mehta,"Department of Statistics, Purdue University, West Lafayette, IN",Surya,T,Tokdar,"Department of Statistical Science, Duke University, Durham, NC",Bruce,A,Craig,"Department of Statistics, Purdue University, West Lafayette, IN",Jayanta,K,Ghosh,"Department of Statistics, Purdue University, West Lafayette, IN",,,,,,,,,,,,,,,,,,,,,,,,,"Logistic Gaussian process priors have been used in nonparametricBayesian density estimation and sufficient dimension reduction in anonparametric regression setting. In this paper, we will describe theextension of these approaches to survival analysis. The methodsimultaneously estimates the covariate subspace and the conditionaldensity given this subspace.  Sufficient dimension reduction approachprovides the most parsimonious representation of the covariate spacein relation to the density. The Bayesian density estimation alsoallows for nonlinear covariate effects. Simulation studies are used tocompare this method with random survival forests and Cox'sproportional hazards model in terms of identifying covariateimportance and predicting survival. They show that our method resultsin more consistent covariate selection and more accurate predictionwhen the assumption of proportional hazards is violated.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Survival analysis,Nonparametric methods,,,,,,,14-Oct-10,ssostat@gmail.com,,Soyoung Jeon,,University of North Carolina at Chapel Hill,"1900 Baity Hill Drive, Apt 321",919-923-7424,,ssostat@gmail.com,Max-stable Processes for Threshold Exceedances in Spatial Extremes,1,Soyoung,,Jeon,Department of Statistics and Operations Research/ University of North Carolina at Chapel Hill,Richard,L,Smith,Department of Statistics and Operations Research/ University of North Carolina at Chapel Hill,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Multivariate extreme value theory is concerned with modelling the joint extremal behavior of environmental data such as rainfall precipitations, snow depths or daily temperatures. Max-stable processes are the natural generalization of extremal dependence structures to infinite dimensions arising from the recently developed extension of multivariate extreme value theory. However, there has not been previously developed the threshold approach of max-stable processes. Padoan, Ribatet and Sisson (2010) proposed the maximum composite likelihood approach for fitting max-stable processes to avoid the complexity and unavailability of the multivariate density function.We propose to extend the threshold version of max-stable processes and apply the composite likelihood method to it. We establish consistency and asymptotic normality of the estimator for the threshold method of max-stable processes. The method is illustrated by application of temperature data in North Carolina, United States.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Spatial/temporal modeling,Environmental and ecological applications,,,,,,,15-Nov-10,stacey.slone@uky.edu,,Stacey Slone,Biostatistician,University of Kentucky,Markey Cancer Center,859-323-1723,,stacey.slone@uky.edu,COMPARISON OF ANALYTIC METHODS FOR TOXICITY IN PHASE II STUDIES,1,Stacey,A,Slone,"Markey Cancer Center, University of Kentucky",Brent,,Shelton,"Markey Cancer Center, University of Kentucky",John,,Rinehart,University of Kentucky,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"While toxicity is a common outcome in Phase II cancer studies, thepresentation and analytic methods chosen are diverse.  Some studiesreport the incidence per patient whereas others report the incidenceper cycle.  The summarization method selected dictates the statisticalmethod applied and each has advantages and disadvantages.  Forinstance, if toxicity analyses are based on incidence per patient, theoverall tolerance and efficacy of the study treatment is ignored. Patients receiving only one course of treatment are weighted equallywith those receiving multiple courses which can result in biasedcomparisons.  Similarly, the effect of cycle, or time, must beconsidered in building models based on incidence per cycle.  Typicallyin this scenario, missing data due to death and dropouts is missing atrandom and must be handled as such.  Graphical reviews of the data areessential for model selection.  Methods evaluated will include thelogistic model for the per patient analyses and for the per cycleanalyses, a GEE repeated measures model with and without cycle, aweighted GEE repeated measures model including cycle, and new advancesin GEE modeling.  These various methods will be contrasted using datafrom a Phase II lung cancer study involving treatment with dexamethosone.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Cancer applications,Missing data,,,,,,,13-Nov-10,staceyadunlop@yahoo.com,,Stacey A. Dunlop,Student,Student,310 Robert E. Lee Drive,910 392-9736,,staceyadunlop@yahoo.com,Bayesian Benchmark Dose Estimator for the Logistic Extra Risk Function,1,Stacey,A.,Dunlop,Student,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Toxicologists are interested in estimating the dose level of a hazardous agent for a specified level of risk.  Common methodology used to determine this dose level is Benchmark Dose.  However, most algorithms use frequentist methods to estimate this dose level, which are approximate when doing inference.  We propose a Bayesian framework for Benchmark Dose that uses prior information about Benchmark Dose and R(0).  A simulation study illustrates the usefulness of this approach.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Bayesian methods,Environmental and ecological applications,,,,,,,09-Nov-10,stvjc@channing.harvard.edu,,Vincent J Carey,Associate Professor of Medicine (Biostatistics),"Channing Laboratory, Harvard Medical School",181 Longwood Ave,6175252265,617 731 1541,stvjc@channing.harvard.edu,Working covariance model selection for generalized estimating equations,1,Vincent,J,Carey,"Channing Laboratory, Harvard Medical School",You-Gan,,Wang,"University of Queensland, Australia",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The efficiency of estimates of regression parameters of marginalmodels for clustered responses is impacted by accuracy of choices ofboth the working correlation, and the working mean-variancerelationship.  This talk reviews the construction, computation, andperformance of criteria to guide selection of the combination ofcorrelation and variance models in applications of generalizedestimating equations.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Longitudinal data,Estimating equations,,,,,,,15-Nov-10,suh@mail.montclair.edu,,Haiyan Su,,Montclair State University,1 Normal Ave,973-655-3279,,suh@mail.montclair.edu,Fiducial generalized p-Values for testing zero-Variance components in linear mixed-effects models,3,Xinmin,,Li,"Department of Statistics, Shandong University of Technology,  China",Hua,,Liang,"Department of Biostatistics and Computational Biology, University of Rochester Medical Center, New York",Haiyan,,Su,"Department of Mathematical Sciences, Montclair State University, Montclair, New Jersey",Hulin,,Wu,"Department of Biostatistics and Computational Biology, University of Rochester Medical Center, New York",,,,,,,,,,,,,,,,,,,,,,,,,"Linear mixed-effects models are widely used in analysis of longitudinal data. However, testing for zero-variance components of random effects has not been well resolved in statistical literature,although some likelihood-based procedures have been proposed and studied. In this article,we propose a generalized p-value based method in coupling with fiducial inference to tackle thisproblem. The proposed method is also applied to test linearity of the nonparametric functions inadditive models. We provide theoretical justifications and develop an implementation algorithmfor the proposed method. We evaluate its finite-sample performance and compare it with that ofthe restricted likelihood ratio test via simulation experiments. We illustrate the proposed approachusing an application from a nutritional study",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Longitudinal data,Computational methods,,,,,,,14-Oct-10,suk35@pitt.edu,,Sunghee Kim,,"Biostatistics, University of Pittsburgh","326 Parran Hall, 130 DeSoto St.",908-420-0789,,suk35@pitt.edu,BLUP(REMQL) Estimation of a Correlated Random Effects Negative Binomial Hurdle Model,1,Sunghee,,Kim,"Biostatistics, Graduate School of Public Health, University of Pittsburgh",Roslyn,A.,Stone,"Biostatistics, Graduate School of Public Health, University of Pittsburgh",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Summary: Bed days is a potentially useful metric of efficiency in clinical studies involving the hospital admission decision. However, this metric involves excess zeros, possible overdispersion, and possible clustering (in multi-site studies). A random effects negative binomial hurdle model can account for each of these issues. We extend this model to include correlation between the two component parts and implement best linear unbiased prediction (BLUP)-type estimation with restricted maximum quasi-likelihood (REMQL). This approach offers computational advantages over maximum likelihood (ML) in a generalized linear mixed model (GLMM) setting. Simulations show that the proposed approach performs well for linear predictors and variance components under a plausible range of bivariate correlation. The Emergency Department Community Acquired Pneumonia (EDCAP) study motivates this work and illustrates the methods.Key words: Excess zeros; Overdispersion; Generalized linear mixed model; Maximum likelihood; Best linear unbiased prediction (BLUP)-type estimation; Restricted maximum quasi-likelihood",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Categorical data,Random effects,,,,,,,15-Nov-10,sundaramr2@mail.nih.gov,,Rajeshwari Sundaram,Principal Investigator,National Institutes of Health,"Room 7B05, BBB, DESPR",301-435-6946,301-402-2084,sundaramr2@mail.nih.gov,Estimation in Multistage Models in Presence of Informative Observation Times,1,Rajeshwari,,Sundaram,Eunice Kennedy Shriver National Institute of Child Health and Human Development,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Multistage models are used to describe individuals moving through a succession of stages corresponding to distinct states (e.g., healthy, diseased, diseased with complications, dead). The resulting data can be considered to be a form of multivariate survival data containing information about the transition times and the stages occupied. We consider progressive multistage models in which individuals traverse through stages in a possibly semi-Markovian manner. Our motivation for considering such a framework comes from modeling the progression of human spontaneous labor, where a woman passes through a succession of stages leading to delivery. We construct estimates of stage occupation probabilities and marginal cumulative transition hazards and various other quantities of interest under semiparametric models for the multiple examination time points. We illustrate our estimators through simulation and an application to data from National Collaborative Perinatal Project.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Multivariate survival,Survival analysis,,,,,,,08-Oct-10,sungkyu@email.unc.edu,,Sungkyu Jung,,University of North Carolina at Chapel Hill,University of North Carolina at Chapel Hill,919-593-0453,,sungkyu@email.unc.edu,Analysis of Principal Nested Spheres,1,Sungkyu,,Jung,University of North Carolina at Chapel Hill,Ian,L,Dryden,University of Nottingham,J. Steve,,Marron,University of North Carolina at Chapel Hill,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"A general framework for a novel non-geodesic decomposition of highdimensional spheres or high dimensional shape spaces for planarlandmarks is discussed. The decomposition, Principal Nested Spheres,finds a sequence of submanifolds with decreasing intrinsic dimensions,which can be interpreted as an analogue of Principal ComponentAnalysis (PCA). In a number of real datasets, an apparent onedimensional mode of variation curving through more than one geodesiccomponent is captured in the lowest dimensional Principal Nest Sphere(PNS). While analysis of PNS provides intuitive and flexibledecomposition of the high dimensional sphere, an interesting specialcase of PNS results in finding principal geodesics, similar to thosefrom previous approaches to manifold PCA. An adaptation of PNS toKendall's shape space is discussed, and a computational algorithm forfitting PNS is proposed. The result of PNS provides a coordinatesystem to visualize the data structure, and an intuitive summary ofprincipal modes of variation, as exemplified by several interestingshape data sets.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Nonlinear models,Nonparametric methods,,,,,,,04-Oct-10,sunj@missouri.edu,,(Tony) Jianguo Sun,,University of missouri,146 Middlebush Hall,573-882-6667,,sunj@missouri.edu,Analysis of Recurrent Event Studies with Incomplete Information and Complex Structure,1,(Tony) Jianguo,,Sun,University of Missouri,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"This talk discusses the analysis of recurrent event studies in which only incomplete information is avaliable and the observationprocess may be informative.  Specifically, we consider panel count data,which often occur in many studies concerning the occurrence rates ofcertain recurrent events of interest.  For this, most of the existing statistical approaches assume that the observation process is independent or noninformative about the underlying recurrent event process of interest.In many situations, however, this may not be true or realistic.That is, the observation process may depend on or be related with the recurrent event process.  This talk discusses some inference problemsrelated to such panel count data.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Joint models for longitudinal and survival data,Missing data,,,,,,,02-Nov-10,svitlana@jimmy.harvard.edu,,Svitlana Tyekucheva,,Dana-Farber Cancer Institute,"CLS11007, 44 Binney str",(617)632-3628,,svitlana@jimmy.harvard.edu,Integrating diverse genomic data using gene sets,1,Svitlana,,Tyekucheva,"Dana-Farber Cancer Institute, Harvard School of Public Health",Luigi,,Marchionni,Johns Hopkins University,Rachel,,Karchin,Johns Hopkins University,Giovanni,,Parmigiani,"Dana-Farber Cancer Institute, Harvard School of Public Health",,,,,,,,,,,,,,,,,,,,,,,,,"Current high-throughput technologies allow to collect versatile genomic data such as gene expression, copy number variation, methylation, and mutation status . Gene sets analysis (GSA) allows for concise biological interpretation of experimental results, and better reproducibility (as compared to traditional gene-by-gene approach). Therefore, GSA provides an attractive framework for integration of these diverse data types within large genomic studies. We introduce two general set-based data integration approaches: computing integrated gene-to-phenotype association scores, followed by conventional gene sets analysis (Integration+GSA), and using a consensus significance score after all data types are analyzed individually (GSA+Integration). We compare, and systematically evaluate several examples of the proposed approaches using simulated data, and demonstrate their application to cancer genome studies.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Cancer applications,High dimensional data,,,,,,,18-Sep-10,szhang@live.unthsc.edu,,Shun Zhang,,University of North Texas Health Science Center,3125 Sondra Drive,8178967968,,szhang@live.unthsc.edu,Physical Activity and Leukocyte DNA Methylation in a Cancer-free Population,1,Shun,,Zhang,University of North Texas Health Science Center,Fangfang,,Zhang,Tufts University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Purpose: DNA methylation is an important system regulating gene expression. We aim to examine the relationship between physical activity and global methylation in leukocyte DNA.Methods: Physical activity was measured using accelerometer for four consecutive days  among 161 participants enrolled in the North Texas Healthy Heart Study aged 45-75. Daily physical activity was estimated for 131 subjects who provided e 2 days of valid accelerometer data.  Genomic DNA methylation was measured using bisulfite conversion of DNA and real time PCR for LINE-1 in leukocytes.Results: The average moderate and vigorous physical activities were 2.0 hrs/wk and 0.1 hrs/wk respectively in this cancer-free population. The level of physical activity declined with increased energy intake. Non-Hispanic white were more active than non-Hispanic black and Hispanics whereas non-Hispanic black had the lowest level of physical activity among three racial/ethnic groups. Subjects who were physically inactive were at an increased risk of DNA hypomethylation than those physically active (OR= 2.3, 95%CI: 0.9-5.9). And the association was stronger among non-Hispanics as compare to Hispanics (among Hispanics, OR=3.7, 95%CI: 1.1-11.8; among non-Hispanics, OR=1.3, 95%CI: 0.3-6.7).",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_poster,,,,FALSE,FALSE,FALSE,FALSE,Cancer applications,Survey research data,,,,,,,14-Oct-10,szhao@hsph.harvard.edu,,Sihai Dave Zhao,,Harvard University Department of Biostatistics,"655 Huntington Ave., Building 2 SPH 4th Floor",617-582-8776,,szhao@hsph.harvard.edu,A new class of estimating equation-based Dantzig selectors with applications to clinical trials and cancer genomics,1,Sihai,D,Zhao,Harvard University Department of Biostatistics,Yi,,Li,Harvard University Department of Biostatistics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We propose a new class of estimating equation-based Dantzig selectorsthat can achieve simultaneous estimation and variable selection in theabsence of a likelihood function, even when the number of covariatesexceeds the number of samples. Our research was motivated by practicalproblems encountered in two studies: a clinical trial of therapies forhead and neck cancer, and a genomics study of multiple myelomapatients. These problems proved difficult to analyze under thelikelihood setting and must instead be approached with estimatingequations. We prove nonasymptotic probability bounds on the accuracyof our estimator, report extensive simulation results, and use ourmethod to analyze the aforementioned problems.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Variable subset selection/model selection,High dimensional data,,,,,,,29-Oct-10,takashi.funatogawa@vanderbilt.edu,,Takashi Funatogawa,,Visiting Scholor,"Cancer Biostatistics Center, Vanderbilt-Ingram Cancer Center, 691 Preston Building",615-818-9190,,takashi.funatogawa@vanderbilt.edu,Analysis of covariance with pre-treatment measurements in randomized trials under the cases that covariances and post-treatment variances differ between groups,1,Takashi,,Funatogawa,"Department of Biostatistics, Vanderbilt University School of Medicine",Ikuko,,Funatogawa,"Department of Biostatistics, Vanderbilt University School of Medicine",Yu,,Shyr,"Department of Biostatistics, Vanderbilt University School of Medicine",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"When primary endpoints of randomized trials are continuous variables, ANCOVA with pre-treatment measurements as a covariate is often used to compare two treatment groups. In ANCOVA, equal slopes (coefficients of pre-treatment measurements) and equal residual variances are commonly assumed. However, random allocation only guarantees equal variances of pre-treatment measurements. Unequal covariances and variances of post-treatment measurements indicate unequal slopes and, usually, unequal residual variances. For non-normal data with unequal covariances and variances of post-treatment measurements, it is known that ANCOVA with equal slopes and equal variances provides an asymptotically normal estimator for the treatment effect. However, the asymptotic variance of the estimator differs from the variance estimated from a standard formula, and its property is unclear. Furthermore, the asymptotic properties of ANCOVA with equal slopes and unequal variances are unclear. In this study, we examine the asymptotic properties of ANCOVA with equal slopes using the variance estimated from a standard formula for the non-normal data. We show that the actual alpha rate of ANCOVA with equal variances is asymptotically at a nominal level under equal sample sizes. That of ANCOVA with unequal variances is asymptotically at a nominal level, even under unequal sample sizes.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Biopharmaceutical research,Clinical trials,,,,,,,14-Oct-10,tamikart@stat.fsu.edu,,Tamika Royal-Thomas,,Florida State University,310 Pennell Circle,850-545-3947,,tamikart@stat.fsu.edu,Interrelating of Longitudinal Processes: A Pseudolikelihood Approach,1,Tamika,Y,Royal-Thomas,"Department of Statistics, Florida State University",Daniel,,McGee,"Department of Statistics, Florida State University",Debajyoti,,Sinha,"Department of Statistics, Florida State University",Clive,,Osmond,"Tropical Medicine Research Institute, University of the West Indies",Terrence,,Forrester,"Tropical Medicine Research Institute, University of the West Indies",,,,,,,,,,,,,,,,,,,,,"Predicting coronary heart disease (CHD) has been researchedextensively and there are still areas to uncover.  Some of these areasinclude what happens during the early stages of human developmentwhich occurs inside the womb in pregnancy.  This work examines firstlythe univariate longitudinal outcome of child's blood pressure and howthat is predicted by maternal and in utero longitudinal attributesduring pregnancy.  We use maximum likelihood estimates through randomeffects model to model this interrelationship.  A further step isbuilt on when bivariate models of child's longitudinal systolic anddiastolic blood pressure are utilized as outcome variables. Trivariatemodels of blood pressure and pulse rate are explored also where themaximum likelihood approach is compared to the pseudolikelihoodapproach. Joint modeling of multivariate longitudinal profiles is doneand the extension of the traditional likelihood method is utilized inthis paper and compared to the maximum likelihood estimates. Themodels developed here focus on whether the process in mothers predictsfetal development which then predicts the future cardiovascular healthof the child.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Longitudinal data,Applied data analysis,,,,,,,15-Nov-10,tanzy_love@urmc.rochester.edu,,Tanzy Love,Dr,University of Rochester,Dept of BioStat and Comp Bio,585-276-5559,,tanzy_love@urmc.rochester.edu,Latent Mixture Analysis of Effect Modification,1,Tanzy,M,Love,University of Rochester,Sally,W,Thurston,University of Rochester,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In environmental toxicology, effect modification is the interactionbetween a categorical covariate and an exposure.  Instead of using ameasured variable to modify the exposure effect, we model effectmodification by a latent variable in two ways.  In the first case,this variable is independent of any observed covariates and in thesecond case is functionally related to several socioeconomic variables.The Seychelles Child Development Study (SCDS) is testing thehypothesis that prenatal exposure to low doses of MeHg from maternalconsumption of fish is associated with the child's developmentaloutcomes. No deleterious relationships between exposure to MeHg and cognitive functions have been identified in the primary analysis of the main cohort. However, secondary analysis of this cohort found an effect modification by both caregiver IQ and income (Davidson et al. 1999). They showed that children with higher IQ caregivers and higher incomehad a significant positive relationship between Mercury levels andintelligence.  Our work refines these conclusions by identifying threesignificant subpopulations with different relationships betweenMercury and intelligence.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Latent variables,Bayesian methods,,,,,,,15-Nov-10,tao_lu@urmc.rochester.edu,,tao lu,,university of rochester,503 university park,8134644179,,tao_lu@urmc.rochester.edu,High Dimensional ODEs Coupled with Mixed-Effects Modeling Techniques for Dynamic Gene Regulatory Network Identification,1,tao,,lu,university of rochester,hua,,liang,university of rochester,hongzhe,,li,University of Pennsylvania,hulin,,wu,university of rochester,,,,,,,,,,,,,,,,,,,,,,,,,"Gene regulation is a complicated systematic process. The interactionof many genes and their products forms an intricate biologicalnetwork. Identification of this dynamic network will help usunderstand the biological process in a systematic way. However, theconstruction of such a complete dynamic network system is challengingmainly due to computational constraint for a high-dimensional networksystem. In this article we propose to use a set of ordinarydifferential equations (ODE), coupled with dimensional reduction byclustering and mixed-effects modeling techniques, to model the dynamicgene regulatory network (GRN). We are able to annotate the identifiedmodules through function enrichment analysis. Some interestingbiological findings are discussed. The proposed procedure is apromising tool for constructing a general dynamic GRNand more complicated dynamic networks.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Microarray analysis,High dimensional data,longitudinal data,,,,,,05-Oct-10,taowang@mcw.edu,,Tao Wang,Dr.,Medical College of Wisconsin,Division of Biostatistics,414-955-4339,414-955-6513,taowang@mcw.edu,On re-parameterization of expected genotypic values in genetic models of quantitative traits,1,Tao,,Wang,"Division of Biostatistics, Institute for Health and Society, Medical College of Wisconsin",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,FALSE,FALSE,,FALSE,FALSE,FALSE,,,,,,FALSE,FALSE,FALSE,FALSE,,,,,,,,,15-Nov-10,tatiyana.apanasovich@jefferson.edu,,Tatiyana Apanasovich,Assistant Professor,Thomas Jefferson,1015 Chestnut St,(215) 955-3697,(215) 503-3804,tatiyana.apanasovich@jefferson.edu,A Valid Matern Class of Cross-Covariance Functions for Multivariate Random Fields with any Number of Components,1,Tatiyana,V,Apanasovich,"Division of\ Biostatistics, Thomas Jefferson University, Philadelphia, PA 19107",Marc,G.,Genton,"Texas A&M University, College Station, TX 77843-3143, USA",Ying,,Sun,"Texas A&M University, College Station, TX 77843-3143, USA",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We introduce a valid parametric family of cross-covariance functionsfor multivariate spatial random fields where each component has acovariance function from a well-celebrated Mat\'ern class. Unlikeprevious attempts, our model indeed allows for various smoothnessesand rates of correlation decay for any number of vector components.We present the conditions on the parameter space that result in validmodels with varying degrees of complexity. Practical implementations,including reparametrizations to reflect the conditions on theparameter space and  an iterative algorithm to increase the computationalefficiency, are  discussed. We perform various Monte Carlo simulationexperiments to explore the performances of our approach in terms ofestimation and cokriging. The application of the proposed multivariateMat\'ern model is illustrated on two meteorological datasets:Temperature/Pressure over the Pacific Northwest (bivariate) andWind/Temperature/Pressure in Oklahoma (trivariate).",FALSE,FALSE,,FALSE,TRUE,TRUE,RT10: Statistical Methodology Grants From NSF and EPA,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Spatial/temporal modeling,Environmental and ecological applications,,,,,,,15-Nov-10,tchen@bios.unc.edu,,Ting-Huei,,University of North Carolina at Chapel Hill,"2701 Homestead Road, APT 603",626 254 3162,,tchen@bios.unc.edu,A Multivariate Penalized Regression Method for eQTL Mapping,1,Ting-Huei,,Chen,"Department of Biostatistics, University of North Carolina, Chapel Hill",Wei,,Sun,"Department of Biostatistics, University of North Carolina, Chapel Hill",Fred,A.,Wright,"Department of Biostatistics, University of North Carolina, Chapel Hill",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"A main goal of expression quantitative trait locus (eQTL) studies isto dissect the genetic factors contributing to the variation ofgene-expression. In most studies, tens of thousands of expressiontranscripts and genetic markers are measured. One common strategy isto analyze each transcript separately. However, it is well-known thatseveral genes could be co-regulated and linked to some common eQTLs.The trait-by-trait mapping strategy fails to take into account thecorrelation between transcripts, which might lead to a loss of power.We propose a multivariate penalized regression method for eQTL mappingthat incorporates the correlation structure among transcripts and isapplicable for the high dimension low sample size setting. Extensivesimulations and real data studies show the superior performance of ourmethod on the improvement in power and precision of eQTL mapping.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Statistical genetics,Variable subset selection/model selection,,,,,,,15-Nov-10,tdjtdj@umich.edu,,Timothy D. Johnson,Associate Professor,University of Michigan,1415 Washington Heights,734 936-1007,,tdjtdj@umich.edu,Identifying Spatial Differences in Multiple Sclerosis Subtypes via a Marked Log Gaussian Cox Process,1,Timothy,D.,Johnson,University of Michigan,Thomas,E.,NIchols,University of Warwick,Ernst-Wilhelm,,Radue,University Hospital Basel,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Multiple Sclerosis (MS) is a disease in which the myelin sheaths surrounding the axons of the brain and spinal cord are damaged.  This leads to dymelination and scarring of the white matter tracks in the brain.  There are four main categories of MS: 1) relapsing/remitting, 2) secondary progressive, 3) progressive relapsing and 4) primary progressive.  Researchers are interested in whether there are differences in location, size and intensity of MS lesions in these different subtypes.  To answer this question we model the locations of MS lesions, as well as lesion size, by a marked Log Gaussian Cox Process (LGCP).  The marks in the process are the lesion volumes.  Estimation is performed within the Bayesian framework.  We estimate the LGCP on the entire 3D image  via the Fast Fourier Transform (FFT).  Computational efficiency is realized by parallelizing the FFT algorithm and performing the calculations on a graphical processing unit.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Imaging,Bayesian methods,,,,,,,04-Nov-10,telba.irony@fda.hhs.gov,,Telba Irony,Dr.,FDA - Center for Devices and Radiological Health,10903 New Hampshire Ave.,301-796-6044,,telba.irony@fda.hhs.gov,Bayesian Medical Device Clinical Trials in the Regulatory Setting,1,Telba,,Irony,"Division of BiostatisticsCenter for Devices and Radiological HealthFood and Drug Administration",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The use of Bayesian statistics in analyses of medical device clinical trials for premarket submissions to the Food and Drug Administration has increased considerably in recent years. In the medical device arena, Bayesian analysis is particularly helpful in several cases due to availability of prior information. In addition, it provides flexibility to analyze data when interim analyses are performed and when statisticians must deal with prediction, meta-analyses, and missing data.In this presentation we will explain Bayesian statistics in a nutshell, discuss some designs and techniques that have been successfully used in premarket applications, provide some advice on using the Bayesian approach in the regulatory setting, and summarize what has been happening at the Center for Devices and Radiological Health at the FDA. The connection of Bayesian methods and decision analysis in the regulatory setting will be also explored.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Bayesian methods,Clinical trials,,,,,,,15-Nov-10,thaddeus.tarpey@wright.edu,,Thaddeus Tarpey,Professor,Wright State University,120 MM Building,(937) 775-2861,,thaddeus.tarpey@wright.edu,Meta-Regression and the Ecological Fallacy in Depression Treatment Studies,1,Thaddeus,,Tarpey,Wright State University,Eva,,Petkova,New York University,Lei,,Huang,New York University,Liping,,Deng,,,,,,,,,,,,,,,,,,,,,,,,,,"The efficacy of modern antidepressants has been called into questionon the basis of studies utilizing meta-regression in some recentpublications. We obtained results similar to a published meta-analysisby performing a meta-analysis on data we have available from severaldepression clinical trials.  However, if instead of a meta-analysis,the raw data is analyzed separately for each study, the results changedramatically. We argue that the difference in the results are due tothe ecological fallacy. Furthermore, to gain a better understanding ofthe conflicting results, the meta-regression model with a continuousresponse and a continuous predictor is framed in the context of finiteand infinite mixture models with the goal of quantifying the meaningof the slope in a meta-regression study.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Other,"Biologics, pharmaceuticals, medical devices",meta analysis,,,,,,14-Nov-10,theodore.holford@yale.edu,,Theodore Holford,,Yale University,60 College St,2037852838,2037856912,theodore.holford@yale.edu,Estimation of air pollution dispersion from nonpoint sources,1,Theodore,R,Holford,Yale University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Air pollutants can arise from sources that are not single points butlines or polygons that circumscribe geographic regions.  One exampleof such a source is pollution from traffic exhaust which has putativeadverse health effects.  Exposure at a particular point resulting fromaerosol dispersion may be complicated by layout of roads, trafficdensity, meteorology, land use and topography.  Exposure from line orpolygon sources can be expressed as an integral of an unknown functionwhich can be estimated from a response that depends on the pollutantthat is dispersed from the line or region.  It is known that when thedispersion function is represented as a linear model, nonparametricdispersion functions which take the form of step, polynomial or splinemodels can be estimated using a single step setup of relevantregressor variables that are included in a generalized linear model. This approach is extended to the case in which the dispersion functioncan be described using a generalized linear model resulting in aconditional generalized linear model.  The method is illustrated usingdata from a study of asthma severity in Connecticut children.  Theresults provide estimates of the effect of exposure to traffic on riskof asthma symptoms.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Environmental and ecological applications,Epidemiologic methods,,,,,,,09-Nov-10,tielin.qin@gmail.com,,Tielin Qin,,Emory University,1518 Clifton Road,4044094458,,tielin.qin@gmail.com,Bayesian Analysis of Repeated Compositional Data,1,Tielin,,Qin,"Department of Biostatistics & Bioinformatics,Emory University",Vicki,S,Hertzberg,"Department of Biostatistics & Bioinformatics,Emory University",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Compositional data can be viewed as the positive vectors whose components are the proportion or percentage of whole. Compositional data play an important role in many disciplines. We are motivated by the need to examine the different subpopulation of white blood cells in the Protective Immunity Project (PIP) study conducted at the Emory Transplant Center. The data obtained from this study is the compositional data with repeated measurements. We proposed a Bayesian model for analyzing compositional data with repeated measurements. Markov chain Monte Carlo (MCMC) was used for inference in the Bayesian model. Several diagnostic techniques were used for model checking and a simulation study was conducted to evaluate the proposed model performance.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Bayesian methods,Multivariate methods,,,,,,,15-Nov-10,tliu@stat.brown.edu,,Tao Liu,,Brown Univ,4 Stanley Ave,401-569-8869,,tliu@stat.brown.edu,Optimal Use of Selective Viral Load Testing for HIV Treatment Monitoring in Resource Limited Settings,1,Tao,,Liu,Brown University,Joseph,,Hogan,Brown University,Rami,,Kantor,Brown University and Lifespan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The WHO guidelines for monitoring HIV treatment failure inresource-limited settings (RLS) are based on clinical markers and canresult in high error rates. Viral load (VL) testing can be consideredthe `gold standard` but is limited by its cost. In RLS, identificationof patient subpopulation in which VL testing is most beneficial would beprogrammatically advantageous. We develop a diagnostic algorithm thatcombines information on CD4 counts with selective use of VL testingfor diagnosing HIV treatment failure. We assume that VL testing isavailable only for a certain percentage of visits. Our algorithm makesoptimal use of the VL test results in the sense that, for a fixed VLavailability, the misdiagnosis rate is minimized. Specifically, basedon CD4 markers, our algorithm classifies an individual patient as`high risk` (diagnosed as treatment failure), `low risk` (as viralsuppressed), or `intermediate risk`. A ROC-type analysis is described to characterize such algorithms.  For a given constraint on VL availability (e.g. 25%), the best`intermediate` subpopulation can be determined by constrained optimization.A data set from the Miriam ICDB database (RI, USA) was analyzed whichshows that treatment failure diagnosis can be substantially improvedby selective use of VL testing. Such methodology can be long-termcost-efficient.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Diagnostic and screening tests,ROC analysis,,,,,,,11-Oct-10,tnolen@bios.unc.edu,,Tracy Nolen,,University of North Carolina - Chapel Hill,"3101 McGavran-Greenberg, CB#7420",9196197343,,tnolen@bios.unc.edu,Randomization-Based Inference within Principal Strata,1,Tracy,L,Nolen,"Department of Biostatistics, University of North Carolina - Chapel Hill",Michael,G,Hudgens,"Department of Biostatistics, University of North Carolina - Chapel Hill",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In randomized studies, treatment comparisions conditional on intermediate post-randomization outcomes using standard analytic methods do not have a causal interpretation. An alternate approach entails treatment comparisons within prinicipal strata defined by the potential outcomes for the intermediate outcome that would be observed under each treatment assignment. In this paper, we develop methods for randomization-based inference within principal strata. The proposed methods are compared with existing large-sample methods as well as traditional intent-to-treat approaches. This research is motivated by HIV prevention studies where few infections are expected and inference is desired within the always-infected principal stratum, i.e., all individuals who would become infected regardless of randomization assignment.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Causal inference,Exact methods,,,,,,,15-Nov-10,to166@columbia.edu,,R. Todd Ogden,,Columbia University,Dept. of Biostatistics,212-342-1247,,to166@columbia.edu,Functional regression models with wavelets,1,Todd,,Ogden,Columbia University,Yihong,,Zhao,Columbia University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Regression of a scalar response on functional predictors (or signals), such as spectra or images, presents a major challenge when, as is typically the case, the dimension of the signals far exceeds the number of signals in the dataset.  Fitting such a model meaningfully requires some form of dimension reduction.  Some approaches to this problem include the extension of common multivariate methods to the functional situation by penalizing roughness.  This talk will focus on the use of wavelets to express the predictors, converting the problem into a linear regression problem with many potential predictors.  This talk will cover some of the various possibilities for fitting these models.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Functional data analysis,Imaging,,,,,,,04-Nov-10,tombraun@umich.edu,,Thomas M. Braun,Associate Professor,University of Michigan Department of Biostatistics,1415 Washington Heights,734 936-9844,,tombraun@umich.edu,Permutation Tests for Random Effects in Linear Mixed Models,1,Thomas,M,Braun,University of Michigan Department of Biostatistics,Oliver,,Lee,University of Michigan Department of Biostatistics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Inference regarding the inclusion or exclusion of random effects in linear mixed models is challenging because the variance components are identically zero under the null hypothesis, a value that lies on the boundary of the parameter space. As a result, the asymptotic null distribution of traditional Wald, score, and likelihood ratio tests will not have the typical chi-squared distribution. Although it has been proved that the correct asymptotic distribution is a mixture of chi-squared distributions, the appropriate mixture distribution is rather cumbersome and non-intuitive when the null and alternative hypotheses differ by more than one random effect.  We present two statistics, one that is a function of the Best Linear Unbiased Predictors (BLUPs) and one that is the traditional likelihood ratio test statistic, both of which are intrinsically functions of weighted residuals, with the weights determined by the variance components. The null permutation distributions of both statistics are computed by permuting the residuals both within- and among-subjects and are valid both asymptotically and in small samples. We examine the size and power of our tests via simulation under a variety of settings and compare our results to those of other published methods.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Longitudinal data,Functional data analysis,,,,,,,18-Oct-10,tpgarcia@stat.tamu.edu,,Tanya Garcia,,Texas A&M University,3143 TAMU,4088967184,,tpgarcia@stat.tamu.edu,Semiparametric estimators for restricted moment models with measurement error,1,Tanya,P,Garcia,Texas A&M University,Yanyuan,,Ma,Texas A&M University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Root-n consistent, asymptoticallynormal and locally efficient estimators are constructed for regression with errors in covariates andan unspecified model error distribution.Until now, root-n consistent estimators for this setting were notattainable exceptfor special cases, such as a polynomial relationship between theresponse and mismeasured variables.Our method is the first to deliver root-n consistent estimators whenthe distributions for boththe model error and the mismeasured variable are unknown and can be misspecified.The estimators are based on thesemiparametric efficient score which is calculated under several possibly incorrectdistribution assumptions resulting from the misspecified model errordistribution, from the misspecified error-prone covariates'distribution, or from both.A simulation study demonstrates that our method is robust andoutperforms methods which either ignore measurement error, or allowmeasurement error but require a correctly specified model errordistribution.A real data example illustrates the performance ofour method.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Measurement error,Estimating equations,,,,,,,14-Oct-10,trpatel@ucla.edu,,Trina,,UCLA,14556 Magnolia Blvd #110,714-883-9517,,trpatel@ucla.edu,Toxicity Profiling of Engineered Nanomaterials via Multivariate Dose Response Surface Modeling,1,Patel,,Trina,"UCLA School of Public Health, Department of Biostatistics",Donatello,,Telesca,"UCLA School of Public Health, Department of Biostatistics",SAJI,,GEORGE,UCLA California NanoSystems Institute,ANDRE,E,Nel,"UCLA Department of Medicine, Division of NanoMedicine.UCLA California NanoSystems Institute.",,,,,,,,,,,,,,,,,,,,,,,,,"In-vitro high throughput screening (HTS) assays for the assessment ofengineered nano particles provide an opportunity to learn how theseparticles interact at the cellular level, particularly in relation toinjury pathways.  Unfortunately, these types of assays arecharacterized by small sample sizes, high measurement error and highdimensionality. In particular, these types of assays allow forsimultaneous observation of multiple toxicity pathways measured acrossan array of doses and durations of exposure. In this article, wepropose a Bayesian hierarchical model for toxicity profiling. We modeleach outcome over a two dimensional dose response surface. Ahierarchical framework is used to account for the multivariate natureof the data by modeling the dependence between outcomes and therebycombining information and borrowing strength across toxicity pathways. In this framework we are able to provide a relatively flexible modelthat also provides inference on various risk assessment parameters. Wediscuss applications of this model to data on eight nano particlesevaluated in relation to four cytotoxicity parameters.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Toxicology/dose-response,Hierarchical models,,,,,,,15-Nov-10,tsengul@med.miami.edu,,Tulay Koru-Sengul,Assistant Professor,"University of Miami, Miller School of Medicine",Department of Epidemiology and Public Health,3052432618,,tsengul@med.miami.edu,A Comparison of Techniques for Analyzing Left-Censored Biomarker Data with Application to Secondhand Smoking Research,1,Tulay,,Koru-Sengul,University of Miami,John,D,Clark,University of Miami,Lora,E,Fleming,University of Miami,David,J,Lee,University of Miami,,,,,,,,,,,,,,,,,,,,,,,,,"Statistical analyses of data including biomarker measurements belowthe limit of detection (LOD) are complicated since precisequantitative levels cannot always be determined. Researchers workingwith biomarker data inevitably have to deal with data containingnon-detects, and must decide how to combine non-detects with valuesabove the LOD for analysis. The choice of an appropriate strategy fordealing with data affected by LODs requires an understanding of bothexperimental and statistical procedures. Until now, the commonpractice has been to impute a single value, such as a half of thedetection limit, for each measurement below the LOD, and to thenconduct the analysis under the assumption that the imputed values arethe actual observed values. By simulation studies, we will comparecommonly used parametric/non-parametric techniques such as completecase analysis, single and multiple imputation, reverse Kaplan-Meiermethod, logistic regression model for analyzing biomarkers withmeasurement values below the LOD. Since the analytic issues withsecondhand smoke exposure biomarkers such as serum cotinine, ametabolite of nicotine, arise due to a large percentage ofmeasurements below the LOD, the methods will be applied to a datasetfrom Secondhand Smoking Research. This work was funded in byFAMRI-2009, NIH-F30-ES015969, and NIOSH-R01-OH003915.",FALSE,FALSE,,FALSE,FALSE,TRUE,"I, Tulay Koru-Sengul, am a member of the local organizing committee in Miami. I am not sure at this point whether I will have any scheduling conflict.",presentation_or_poster,,,,FALSE,FALSE,FALSE,TRUE,Missing data,Epidemiologic methods,,,,,,,22-Oct-10,tsofer@hsph.harvard.edu,,Tamar Sofer,,PhD student,"655 Huntington Avenue SPH2, 4th Floor",6177926194,,tsofer@hsph.harvard.edu,Sparse association analysis of multivariate response; effect of air particles on DNA methylation in a gene set,1,Tamar,,Sofer,PhD student,Arnab,,Maity,,Brent,,Coull,,Andrea,,Baccarelli,,Joel,,Shwartz,,Xihong,,Lin,,,,,,,,,,,,,,,,,,"We investigate methods for modeling the association between a collection of covariates and a high dimensional response. The proposed approaches quantify the relationship between the two sets of variables using the correlation between linear predictors formed from each set of variables. We present three methods for sparse outcome selection that account for the fact that a large number of variables in the response vector are likely not associated with the covariates of interest. The first method, step-forward Canonical Correlation Analysis (CCA), is a step-wise procedure that successively adds outcome variables to the linear combination of outcomes. At each step, the procedure selects the outcome variable that maximizes the canonical correlation between the two sets of variables, defined as the correlation between the two linear combinations of variables. The second method, Sparse Outcome Selection (SOS) CCA, includes in a CCA analysis all outcome variables for which the overall P-value from a linear regression relating that outcome to the covariates is smaller than some pre-specified threshold. Therefore, both the step-CCA and the SOS-CCA calculate the regression parameter estimates using CCA. The last method, SOS Principal Components Analysis (PCA) is similar to the SOS-CCA method, but the coefficient estimates for the outcome vector are calculated using principal components analysis and the coefficient estimates for the covariates are calculated using simple univariate regression. We also consider three criteria, which we term scores, for outcome variable selection. We compare the performance of both the three methods and the scores via simulation. Results demonstrate that the performance of the methods depend on the covariance structure of the data, and that the proposed methods improve upon existing shrinkage- based methods that make simple independence assumptions for the outcome and exposure vectors. We apply the methods to analyze data on the association between pathway-specific gene methylation and exposure to airborne particulate matter.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Applied data analysis,Variable subset selection/model selection,,,,,,,14-Nov-10,tspark@stats.snu.ac.kr,,Taesung Park,Professor,Seoul National University,Department of Statistics,+82-2-880-8924,,tspark@stats.snu.ac.kr,Gene-Gene Interaction Analysis for Clustered Phenotypes,4,Ik Soo,,Huh,Seoul National University,Sohee,,Oh,Seoul National University,Seungyeoun,,Lee,Sejong University,Taesung,,Park,Seoul National University,,,,,,,,,,,,,,,,,,,,,,,,,"Most common complex diseases are often affected by multiple genes and environmental factors. Thus, the investigation of gene-gene and gene-environment interactions plays an important role in understanding the genetic architecture of complex traits. Many different methods have been proposed to analyze gene-gene interactions in genetic association studies. However, most these methods have focused on the single binary phenotype. In most genetic association studies, a binary phenotype is derived from multiple (quantitative) clustered phenotypes. We propose a new method for performing association analysis for clustered phenotypes. Through simulation studies, we compare the power of the clustered analysis with that of single binary analysis and show that our approach has a higher power than the single binary phenotype analysis. The proposed method is applied to a large scale data from a genome-wide association study in Korea.",FALSE,FALSE,,FALSE,TRUE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Statistical genetics,Genomics,,,,,,,26-Oct-10,ttwu@umd.edu,,Tongtong Wu,Assistant Professor,University of Maryland,2234B SPH Building,3014053085,,ttwu@umd.edu,Variable Selection for High-Dimensional Panel Count Data,1,Tongtong,,Wu,"Department of Epidemiology & BiostatisticsUniversity of Maryland, College Park",Xin,,He,"Department of Epidemiology & BiostatisticsUniversity of Maryland, College Park",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"This talk explores one exceptionally fast algorithm for selectingrelevant predictors for the response process of panel count data. Based on the lasso penalized pseudo-objective function derived from anestimating equation, coordinate descent accelerates estimation ofregression coefficients.  The coordinate descent algorithm is capableof handling underdetermined problems where the number of predictorsfar exceeds the number of cases.  It relies on a tuning constant thatcan be chosen by generalized cross-validation. Our tests on simulatedand real data demonstrate the virtue of penalized regression in modelbuilding and prediction for panel count data in high-dimensional settings.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,High dimensional data,Computational methods,,,,,,,20-Sep-10,tvanderw@hsph.harvard.edu,,Tyler VanderWeele,,Harvard School of Public Health,677 Huntington Avenue,617-432-7855,,tvanderw@hsph.harvard.edu,"Mediation and interaction: the case of genetic variants on 15q25.1, smoking and lung cancer",1,Tyler,J,VanderWeele,Harvard School of Public Health,Kofi,,Asomaning,Harvard School of Public Health,David,C,Christiani,Harvard School of Public Health,Xihong,,Lin,Harvard School of Public Health,,,,,,,,,,,,,,,,,,,,,,,,,"Methods developed for causal mediation analysis with a dichotomousoutcome, applicable to case-control studies via prevalence weighting,are presented and used to resolve a question concerning direct andindirect effects in genetic epidemiology.  Genome-wide associationstudies have identified variants on chromosome 15q25.1 that increasethe risk of both lung cancer as well as nicotine dependence andassociated smoking behavior.  However, there remains debate as towhether the effect on lung is direct or operates through pathwaysrelated to smoking behavior.  Of the three studies that initiallyreported the associations, two suggested that the association wasdirect and one that it was primarily through nicotine dependence.Thorgeirsson and co-authors note also a third possibility: that thevariant may increase individuals vulnerability to the harmful effectof tobacco smoke.  For two SNPs, rs8034191 and rs1051730, on 15q25.1,we estimated from 1836 cases and 1452 control the indirect effectmediated by smoking (cigarettes per day), the direct effect throughother pathways and the overall proportion mediated.  The effect of thevariants on lung cancer mediated through smoking appears to be smallerthan the independent effect through other pathways.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Statistical genetics,Causal inference,,,,,,,09-Nov-10,tvangene@its.jnj.com,,Tony Vangeneugden,Head Clinical Biostatistics Anti-Infective & Vaccine,"Janssen, Pharmaceutical Companies of J&J",Turnhoutseweg 30,+32473551169,+3214641920,tvangene@its.jnj.com,Correlation from Logit- and Probit-Beta-Normal Models for Hierarchical Binary Data,1,Tony,JP,Vangeneugden,"Janssen, Pharmaceutical Companies of J&J",Geert,,Molenberghs,"I-BioStat, Universiteit Hasselt, B-3590 Diepenbeek, Belgium, I-BioStat, Katholieke Universiteit Leuven, B-3000 Leuven, Belgium",Geert,,Verbeke,"I-BioStat, Katholieke Universiteit Leuven, B-3000 Leuven, Belgium",Clarice,GB,Demetrio,"Universidade de Brasilia, Dept. de Estatistica,  Brasilia, Brasil",,,,,,,,,,,,,,,,,,,,,,,,,"In hierarchical data settings often the association between repeated measurements attracts at least part of the scientific interest. Quantifying the association frequently takes the form of a correlation function, including but not limited to intraclass correlation. Approximate correlation functions for longitudinal sequences of general data type, Gaussian and non-Gaussian, have been derived based on generalized linear mixed-effects models (GLMM). Here, we consider the extended model family proposed by Molenberghs et al (2009). This family flexibly accommodates data hierarchies, intra-sequence correlation, and overdispersion. The family allows for closed-form means, variance functions, and correlation function, for a variety of outcome types and link functions (Vangeneugden et al 2009). Unfortunately, for binary data with logit link, closed forms cannot be obtained. This is in contrast with the probit link, for which such closed forms can be derived. It is therefore that we concentrate on the probit case. Next to the general situation, some important special cases such as exchangeable clustered outcomes receive attention because they produce insightful expressions. The closed-form expressions (Vangeneugden et al 2010) are contrasted with the generic approximate expressions and with approximations derived for the so-called logistic-beta-normal combined model.",TRUE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Applied data analysis,Clustered data methods,,,,,,,04-Nov-10,tzheng@stat.columbia.edu,,Tian Zheng,Associate Professor,"Department of Statistics, Columbia University",1255 Amsterdam Ave,212-851-2134,212-851-2164,tzheng@stat.columbia.edu,Statistical methods for studying social networks using aggregated relational data,1,Tian,,Zheng,"Department of Statistics, Columbia University",Tyler,H.,McCormick,"Department of Statistics, Columbia University",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Survey questions of the form 'How many X's do you know?' allow a convenient and fast collection of aggregated relational data (ARD) from one's social network and have become a common means of learning about populations that are hard to reach or survey directly. McCarty et al. (2001), for example, take X to be individuals who are HIV positive, are homeless, or were recently raped to estimate the size of these traditionally hard-to-count populations. In this talk, we will discuss several recent statistical methodological developments for analyzing ARD to study features of social networks such as extent of social structure such as clustering and assortative mixing. We will also introduce methods to extract demographic information about the hard-to-reach populations using ARD. Design suggestions for future ARD studies will also be proposed.",TRUE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Latent variables,Survey research data,,,,,,,22-Oct-10,ulysses.diva@bms.com,,Ulysses A. Dvia,,Bristol-Myers Squibb Co.,5 Research Parkway,203-677-5004,,ulysses.diva@bms.com,Estimating the Probability of Sustained Virologic Response to Treatment Against Hepatitis C Virus Infection Under Response-Guided Two-Stage Randomization Designs,1,Ulysses,A,Diva,Bristol-Myers Squibb Co.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"A common goal of studies evaluating new treatments against Hepatitis C virus (HCV) infection is to compare different combinations of treatments and treatment durations, in the form of response-guided treatment (RGT) strategies, with respect to the probabilities of achieving sustained virologic response at 24 weeks after treatment cessation (SVR24). Two-stage randomization designs (TSRD) could be used in these setting. Under a TSRD, patients are initially randomized to one or more treatments, usually as add-on to the current standard of care (SOC). Those who achieve a protocol-defined response (PDR) to the initial treatment are then randomized either to continue receiving treatment or to stop treatment early. However, under a TSRD, simple approaches of estimating the probability of SVR24 (ie, by ignoring or by conditioning on the PDR status) do not directly evaluate RGT strategies. An estimator for SVR24 based on the inverse-probability weighting (IPW) framework is proposed. The IPW estimator in this setting is shown to be consistent, asymptotically normal, and has an attractive intent-to-treat interpretation. Properties of this estimator are investigated using simulations.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Clinical trials,Biopharmaceutical research,,,,,,,29-Oct-10,valeri.v.fedorov@gsk.com,,Valerii Fedorov,Dr,GSK,1250 South Collegeville Rd,610-917 5499,,valeri.v.fedorov@gsk.com,Best intention designs in early clinical trials,1,Valerii,V,Fedorov,GlaxoSmithKline,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"For decades statisticians have been contributing to creation and improvement of optimal experimental design methods in model fitting, hypothesis testing, parameter estimation and optimal control. In most of these areas these methods worked flawlessly. However in a few cases (mostly in optimal control) some of the intuitively attractive approaches failed. Clearly that in clinical trials the direct application or reinvention of optimal experimental design methods may lead to unexpected and undesirable results. Medical ethics, huge expenses, and interactions with regulatory agencies call for more meticulous analysis of stochastic models and experimental designs. Often the initial enthusiasm about seemingly ethically attractive or (mathematically) efficient designs quickly disappears after thorough mathematical analysis combined with Monte-Carlo simulations. I consider a few simple models to illuminate the above.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Experimental design,Biopharmaceutical research,,,,,,,13-Nov-10,veera@mdanderson.org,,Veera Baladandayuthapani,Assistant Professor,"Dept. of Biostatistics, MD Anderson Cancer Center",1515 Holcombe Blvd,7135634268,,veera@mdanderson.org,Bayesian Sparse Graphical Models for Classification with application to Protein Expression  data,1,Veera,,Baladandayuthapani,University of Texas MD Anderson Cancer Center,Rajesh,,Talluri,Texas A&M University,Bani,K,Mallick,Texas A&M University,Yuan,,Ji,University of Texas MD Anderson Cancer Center,Kevin,R,Coombes,University of Texas MD Anderson Cancer Center,,,,,,,,,,,,,,,,,,,,,"Reverse-phase protein array (RPPA) analysis is a powerful, relatively new platform that allows for high-throughput, quantitative analysis of protein networks.  One of the challenges that currently limit the potential of this technology is the lack of methods that allow for accurate data modeling and identification of related networks and samples.  Such models may improve the accuracy of biological sample classification based on patterns of protein network activation, and provide insight into the distinct biological relationships underlying different cancers. We propose a Bayesian sparse graphical modeling approach motivated by RPPA data using selection priors on the conditional relationships in the presence of class information. Our method allows for intuitive integration of a priori network information directly in the model and allows for posterior inference on the network topologies both within and between groups.   We apply our methodology to a RPPA data set generated from panels of human breast cancer and ovarian cancer cell lines.  We demonstrate that the model is able to distinguish the different cancer cell types more accurately than several existing models and to identify differential regulation of components of a critical signaling network between these cancers.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Graphical models,Bayesian methods,,,,,,,15-Nov-10,vica@mail.med.upenn.edu,,Victoria Gamerman,,University of Pennsylvania,423 Guardian Drive,215-746-8154,,vica@mail.med.upenn.edu,Parametric and Non-Parametric Methods for Estimating Conditional Survival,1,Victoria,,Gamerman,"Department of Biostatistics & Epidemiology, Center for Clinical Epidemiology and Biostatistics, University of Pennsylvania, Philadelphia, Pennsylvania, USA",DuPont,,Guerry,"Department of Medicine, University of Pennsylvania, Philadelphia, Pennsylvania, USA",Phyllis,A,Gimotty,"Department of Biostatistics & Epidemiology, Center for Clinical Epidemiology and Biostatistics, University of Pennsylvania, Philadelphia, Pennsylvania, USA",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"There is an extensive body of literature in clinical oncology onconditional survival (CS) and on differential CS both over time andbetween groups. These papers focus on estimates of five-year CS, forexample, for increasing patient survival time post-diagnosis. Thestatistical properties of estimators of CS, required for appropriatestatistical inference, have not been studied. In this study, we comparethe statistical properties of CS estimates using non-parametric andparametric methods. Non-parametric CS estimators are obtained from thesurvival distribution estimated using the Kaplan-Meier method and theparametric estimators are based on maximum likelihood theory assumingan underlying Weibull distribution. We developed estimators for thevariances and covariances among the CS estimates required formultivariate analysis. In both cases, we demonstrate that estimates ofCS are correlated and that disregarding such correlation can greatlyreduce the power of statistical inference. We use simulations toinvestigate the performance of the proposed methods both with andwithout censored observations. Finally, we use our proposedmethodology to evaluate changes in CS over time for patients withmelanoma using survival data from the National Cancer Institute'sSurveillance, Epidemiology and End Results (SEER) registry.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Cancer applications,Survival analysis,,,,,,,14-Oct-10,viswanat@email.unc.edu,,Shankar Viswanathan,,"Dept of Biostatistics, The University of North Car","CB# 7420, McGavran-Greenberg Hall",919-923-4525,,viswanat@email.unc.edu,Statistical Methods for Recurrent Events Data in the Presence of Terminal Event and Missing Covariate Information: Application to India Renal Transplantation Study,1,Shankar,,Viswanathan,"Department of Biostatistics,The University of North Carolina at Chapel Hill",Jianwen,,Cai,"Department of Biostatistics,The University of North Carolina at Chapel Hill",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In many clinical and epidemiological studies, recurrent events ofinterest such as infections in immunocompromised patients or injuriesin athletes occur. Often the interest is to examine the relationshipbetween covariates and recurrent events. However, in many studies,some of the covariates collected involve missing information due tovarious reasons. Under such missingness, commonly practiced method isto analyze complete cases only in which the estimated parameters maybe biased or inefficient. We present a method for estimating theparameters in the marginal rate model for analyzing recurrent eventdata in the presence of terminal events. We adopt a weightedestimating equation approach with missing data assumed to be missingat random (MAR) for estimating the parameters. The parameters areestimated via weighted expectation-maximization (EM) algorithm.Simulation studies showed that our proposed estimators for theregression parameters are in general approximately unbiased and thevariance estimates perform well. Our method is effective in reducingthe bias and improving the efficiency of parameter estimates. Weapplied the proposed method to the Indian renal transplant cohort datafor illustration.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Multivariate survival,Missing data,,,,,,,21-Oct-10,vli@ucla.edu,,Gang Li,Dr.,UCLA,650 Charles E Young Dr.,310-206-5865,,vli@ucla.edu,Estimate Treatment Efficacy Among Latent Subgroups of a Randomized Clinical Trial,2,Lily,L,Altstein,UCLA,Gang,,Li,UCLA,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Subgroup analysis arises in clinical trials research when we wish toestimate a treatment effect on a specific subgroup of the populationdistinguished by baseline characteristics. Many trial designs inducelatent subgroups such that subgroup membership is observable in onearm of the trial and unidentified in the other. This occurs, forexample, in oncology trials when a biopsy or dissection is performedonly on subjects randomized to active treatment. We discuss a generalframework to estimate a biological treatment effect on the latentsubgroup of interest when the survival outcome is right-censored. Ourframework builds on the application of instrumental variables methodsto all or-none treatment noncompliance. We derive a computationalmethod to estimate model parameters and provide guidance on itsimplementation in standard software packages. The research isillustrated through an analysis of a seminal melanoma trial thatproposed a new standard of care for the disease and involved a biopsythat is available only on patients in the treatment arm.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Survival analysis,Clinical trials,,,,,,,12-Nov-10,vzipunni@jhsph.edu,,Vadim Zipunnikov,,Johns Hopkins School of Public Health,"615 North Wolfe, E3136",443-2878752,,vzipunni@jhsph.edu,Partial linearity and likelihood-based inference for GLMMs,1,Vadim,,Zipunnikov,"Johns Hopkins School of Public Health, Department of Biostatistics",James,,Booth,"Cornell University, Department of Biological Statistics and Computational Biology",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The likelihood function for a GLMM involves an integral over thedistribution of the random effect. The integral is generallyintractable analytically and hence some form of approximation must beused in practice to enable likelihood-based inference. A partiallinearity of the integrand is a major feature of the GLMM likelihoodintegral. However, this property is often being overlooked by manyexisting approximations. We develop two alternative computationalprocedures which effectively exploit partial linearity and drasticallyreduce computational complexity. We will demonstrate that bothapproaches significantly outperform competing fitting procedures inmany situations.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Hierarchical models,Generalized linear models,,,,,,,11-Nov-10,wafei@umich.edu,,fei wang,,"Department of Biostatistics, University of Michiga",2014 Medford Rd,7342767410,,wafei@umich.edu,Analyzing merged longitudinal data using estimating equation approach,1,Fei,,Wang,"Department of Biostatistics, University of Michigan, Ann Arbor, MI, U.S.A.",Lu,,Wang,"Department of Biostatistics, University of Michigan, Ann Arbor, MI, U.S.A.",PETER X.-K.,,Song,"Department of Biostatistics, University of Michigan, Ann Arbor, MI, U.S.A.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Merging data from similar studies has drown increasing attention in biomedical studies to address different practical needs. In this paper, we consider two major issues in merging longitudinal datasets collected from similar studies. First, we develop a rigorous hypothesis testing approach based on quadraticinference function (QIF) to examine the validity of data merging. Second, we propose a joint estimation procedure that enables us to analyze the merged data and account for different within-subject correlations and follow-up schedules in different studies. We establish the corresponding large sampleproperties for the proposed test and estimation procedure. Using simulation studies, we compare our method with some popular existing methods such as meta analysis, generalised estimating equation and linear mixed-effects model. It is shown that our method appears to be robust in the type I error control against the misspecification of working correlation structures. In addition, our joint estimation procedure shows an improvement in estimation efficiency on the set of common regression coefficients when data merging is validated.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Longitudinal data,Estimating equations,,,,,,,04-Nov-10,waheda@edc.pitt.edu,,Abdus S. Wahed,Associate Professor,University of Pittsburgh,130 Desoto St #318C,412-624-3053,,waheda@edc.pitt.edu,Evaluating Joint Eects of Induction-Salvage Treatment Regimes on Overall Survival in Acute Leukemia,1,Abdus,S,Wahed,"Department of Biostatistics, University of Pittsburgh",Peter,F,Thall,"Dept. of Biostatistics, M.D. Anderson Cancer Center",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In typical leukemia treatment, a patient receives an initial,frontline treatment, but also one or more subsequent treatments, mostoften chosen adaptively by the physician based on the patientsprevious history of treatments and observed outcomes. Thus, comparison of treatments in different stages ignoring previoustreatments would be viewed as a comparison conditional on progressingto that stage. The appropriate statistical methodology would be toform dynamic treatment regimes (DTR) based on the frontline treatment,intermediate responses and subsequent treatments and then compare theoverall survival (OS) across possible DTRs. Methods of analyzingsurvival data involvingDTRs proposed in the literature are mostly based on G-computation andinverse-probability-weighting (IPW). While these methods provide validresults, they fail to provide insight into the interdependence amongcovariates and component survival times (e.g. time to diseaseprogression, time to death from disease progression, time to treatmentresistance, and time to death from resistance). In this study, wepropose a likelihood-based approach that not only allow comparison ofOS across DTRs, but also provides a tool for assessing therelationship between components of OS and covariates.",FALSE,FALSE,,FALSE,FALSE,TRUE,Short Course SC7,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Adaptive design/adaptive randomization,Survival analysis,,,,,,,12-Nov-10,wallmel@pi.cpmc.columbia.edu,,Melanie Wall,Professor of Biostatistics,Columbia University,1051 riverside drive,212-543-5448,,wallmel@pi.cpmc.columbia.edu,Spatial Latent Class Analysis Model for Spatially Distributed Multivariate Binary Data,1,Melanie,M,Wall,Columbia University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"A spatial latent class analysis model that extends the classic latent class analysis model by adding spatial structure to the latent class distribution through the use of the multinomial probit model is introduced.  Linear combinations of independent Gaussian spatial processes are used to develop multivariate spatial processes that are underlying the categorical latent classes. This allows the latent class membership to be correlated across spatially distributed sites and it allows correlation between the probabilities of particular types of classes at any one site. The number of latent classes is assumed fixed but is chosen by model comparison via cross-validation. An application of the spatial latent class analysis model is shown using soil pollution samples where 8 heavy metals were measured to be above or below government pollution limits across a 25 square kilometer region. Estimation is performed within a Bayesian framework using MCMC and is implemented using the OpenBUGS software.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Latent variables,Hierarchical models,,,,,,,15-Nov-10,wang@wald.ucdavis.edu,,Jane-Ling Wang,Professor,"University of California, Davis",Dept. Statistics,530-219-1454,530-752-7099,wang@wald.ucdavis.edu,Sliced Inverse Regression for Functional and Longitudinal Data,1,Jane-Ling,,Wang,"University of California, Davis",Wei,,Yu,Genentech Inc.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Sliced inverse regression (Li, 1991) is an appealing dimensionreduction method that was developed for regression models withmultivariate covariates. The aim of this talk is to extend it to bothfunctional and  intermittently measured longitudinal covariates. Compared to previous work in dimension reduction with functionalcovariates (Ferre, 2003 and 2005), where the whole trajectories ofrandom functional covariates are assumed to be observed completely,our approach allows for longitudinal covariates that are recordeddiscretely and intermittently.  We develop asymptotic theory for thenew procedure and show, under some regularity conditions, theestimated directions attain the optimal rate of convergence.Simulation studies and data analysis are also provided to demonstratethe performance of our method.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Longitudinal data,Nonparametric methods,,,,,,,12-Oct-10,wang165@illinois.edu,,Peng Wang,,"Department of Statistics, University of Illinois a",101 Illini Hall,2178198375,2172447190,wang165@illinois.edu,Conditional Inference Functions for Mixed-Effects Models with Unspecified Random-Effects Distribution,1,Peng,,Wang,"Department of Statistics, University of Illinois at Urbana-Champaign",Guei-Feng,,Tsai,"Center for Drug Evaluation, Taipei, Taiwan",Annie,,Qu,"Department of Statistics, University of Illinois at Urbana-Champaign",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In longitudinal studies, mixed-effects models are important for addressingsubject-specific effects. However, most existing approachesassume a normal distribution for random effects,  and this couldaffect the bias and efficiency of the fixed-effects estimator.Even in  cases where the estimation of the fixed-effects is robustwith a misspecified distribution of the random effects, theestimation of the random effects could be invalid.  We propose a newapproach to estimatefixed and random effects using conditional quadratic inferencefunctions. The new approach does not require the specification oflikelihood functions or a normality assumption for random effects. It canalso accommodate serial correlation between observations within thesame cluster,in addition to the mixed-effectsmodeling. Other advantages include notrequiring the estimation of unknown variance components associatedwith the random effects, or nuisance parameters associated with theworkingcorrelations. Real data example on periodontal disease study andsimulations are used tocompare the new approach with the penalized quasi-likelihoodapproach and SAS GLIMMIX procedure.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,TRUE,Random effects,Longitudinal data,,,,,,,15-Nov-10,wanghao793@gmail.com,,WANG HAO,,University of Pittsburgh,259 Melwood Ave. 507,4122251346,,wanghao793@gmail.com,Association analysis of bivariate recurrent event data with marks,1,Hao,,Wang,University of Pittsburgh,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In this article, we are interested in the association between components of the bivariate recurrent event data with marks, which can be modeled by bivariate compound Poisson process(CPP). We study CPP in a broader class: Levy process, whose dependence structure is constructed by Levy copula. We consider a semi-parametric inference procedure, which estimates the marginal distribution non-parametrically and then the dependence parameters of Levy copula by a maximum likelihood approach. A simulation study investigates the small sample performance of the estimators. Finally, we applied our method to the Danish fire insurance data.",FALSE,FALSE,,FALSE,FALSE,FALSE,,contributedposter,,,,FALSE,FALSE,FALSE,TRUE,Multivariate survival,Nonparametric methods,,,,,,,12-Nov-10,wanlu@mail.med.upenn.edu,,Wanlu Deng,,"Department of Biostatistics and Epidemiology, Univ","205 S 42ND ST, APT A4",609-933-3463,,wanlu@mail.med.upenn.edu,Learning causal protein-signaling networks with stability control,1,Wanlu,,Deng,"Department of Biostatistics and EpidemiologyUniversity of Pennsylvania, School of Medicine",Zhi,,Geng,,Hongzhe,,Li,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"A directed acyclic graph (DAG) is a powerful tool to represent the structure of protein-signaling network, which can explore the causal relationships among multiple interacting molecules. Since there may not be enough information to discover causal structures completely from observational data, we develop an approach of recursive structure learning of DAG by integrating the information from data of intervention experiments. Furthermore, we present a stability-based approach for choosing alpha (the probability of committing a Type I error) for all the hypothesis tests used in learning DAG. This approach can asymptotically recover all the true causal relationships, that is, when sample size becomes larger, the selected model will include all the true edges with high probability. Meanwhile, it controls the instability of the whole graph, while traditional methods can only control the Type I error of each hypothesis test separately. We demonstrate the methods using simulations and analysis of single cell flow-cytometry data.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Graphical models,Causal inference,,,,,,,15-Nov-10,web10@pitt.edu,,Wenzhu Bi,,University of Pittsburgh,"PUH B-938, UPMC",412-849-4218,,web10@pitt.edu,A feature selection method to allow clustering with scattered samples,1,Wenzhu,,Bi,"Department of BiostatisticsUniversity of Pittsburgh",George,C,Tseng,"Department of BiostatisticsUniversity of Pittsburgh",Lisa,A,Weissfeld,"Department of BiostatisticsUniversity of Pittsburgh",Julie,C,Price,"Department of Radiology and BiostatisticsUniversity of Pittsburgh",,,,,,,,,,,,,,,,,,,,,,,,,"It is well known that the performance of clustering methods for highdimensional datasets, i.e. p >> n, may vary from one data set toanother. One reason may be that regular clustering methods use all ofthe features, even when not all of the features are helpful todistinguish the clusters; another reason may be that the clusteringmethods may be forcing scattered noisy samples into the clusters. Wepropose a method combining feature selection and resampling techniquesfor the aforementioned problems. The feature selection method, i.e.sparse clustering, utilizes a penalty to limit the number of featuresin the clustering algorithm, so that only a subset of the features arefinally chosen for group discrimination. The resampling techniquerepeatedly samples the data to construct stable and tight clusterswhile allowing for scattered samples outside of these clusters.  We apply the proposed method to neuroimaging data.  The focus is onthe analysis of voxel-level data and the identification of a subset ofvoxels that can be used to classify subjects into groups.  We presentan example using an unspecified radiotracer to identify groups ofsubjects with varying amounts of tracer.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,TRUE,High dimensional data,Imaging,,,,,,,14-Nov-10,weich@umich.edu,,Wei Chen,,University of Michigan,1980 Traver Rd,7342762128,,weich@umich.edu,LD-aware variant calling and phasing method for next generation sequencing in trios,1,Wei,,Chen,"Center for Statistical GeneticsDepartment of BiostatisticsUniversity of Michigan",Bingshan,,Li,"Center for Statistical GeneticsDepartment of BiostatisticsUniversity of Michigan",Yun,,Li,University of North Carolina at Chapel Hill,Serena,,Sanna,"Center for Statistical GeneticsDepartment of BiostatisticsUniversity of Michigan",Carlo,,Sidore,"Center for Statistical GeneticsDepartment of BiostatisticsUniversity of Michigan",Fabio,,Busonero,"Center for Statistical GeneticsDepartment of BiostatisticsUniversity of Michigan",Goncalo,,Abecasis,"Center for Statistical GeneticsDepartment of BiostatisticsUniversity of Michigan",,,,,,,,,,,,,"Next generation sequencing provides a deeper catalog of human genetic variation and possibilities for direct detection of causal variants. Most of the current variant calling algorithms can only handle unrelated samples and systematic evaluations of sequencing data of families are not available up to date. We propose an efficient and accurate variant calling method for shotgun sequencing data of trios. It incorporates both linkage disequilibrium (LD) patterns and family constrains within the trio together into a widely used hidden markov model in imputation, which takes advantage of similar stretches of chromosomes shared between individuals. This method provides a tool of variant calling and haplotype phasing in advance for many ongoing sequencing projects including trios. We simulate shotgun sequencing data in genotype likelihood format (GLF) at various depths with two sequencing error rates. Our simulations show that sequencing trios can have higher genotype calling accuracy and better haplotype inference comparing to same number of unrelated individuals.  This method has been applied to ongoing SardiNIA sequencing project. The preliminary result shows that the mismatch rate could be reduced to nearly half of the current approach ignoring the relatedness. A C++ package will be available to public soon.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Statistical genetics,Genomics,,,,,,,10-Nov-10,weihua.cao@fda.hhs.gov,,Weihua Cao,,FDA,10993 New Hampshire Ave,301-796-6262,,weihua.cao@fda.hhs.gov,"Improved Doubly Robust Estimation When Data Are Monotonely Coarsened, with Application to Longitudinal Studies with Dropout",3,Anastasios,,Tsiatis,North Carolina State University,Marie,,Davidian,North Carolina State University,Weihua,,Cao,FDA,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"A routine challenge is that of making inference on parameters in astatistical model of interest from longitudinaldata subject to dropout, which are a special case of the more generalsetting of monotonely coarsened data. Considerablerecent attention has focused on doubly robust (DR) estimators, whichin this context involve positing models for both themissingness (more generally, coarsening) mechanism and aspects of thedistribution of the full data, that have the appealingproperty of yielding consistent inferences if only one of these modelsis correctly specified. DR estimators have been criticizedfor potentially disastrous performance when both of these models areeven only mildly misspecified. We propose a DR estimatorapplicable in general monotone coarsening problems that achievescomparable or improved performance relative to existingDR methods, which we demonstrate via simulation studies and byapplication to data from an AIDS clinical trial.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Missing data,Longitudinal data,,,,,,,09-Nov-10,weisun@email.unc.edu,,Wei Sun,,UNC Chapel Hill,1100 NC highway 54 Bypass Apt 24,310-430-8650,,weisun@email.unc.edu,A statistical framework for Expression Quantitative Trait Loci (eQTL) Mapping using RNA-seq Data,1,Wei,,Sun,"Department of Biostatistics, UNC Chapel Hill",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The study of gene expression Quantitative Trait Loci (eQTL) is attracting great research interests due to its power to dissect the genetic basis of gene expression and to bridge genetic variations and complex diseases. Several statistical methods have been developed for eQTL mapping when gene expression is measured by microarray. Recently, high-throughput sequencing techniques have become popular approaches to measure RNA abundance (i.e., RNA-seq), and it is expected to replace microarray in the near future. Using RNA-seq, expression level can be measured by the total number of sequence reads per gene, which we refer to as the Total Read Count (TReC). TReC measurement is sequencing-analog to expression levels measured by microarray, although TReC is more accurate and more sensitive. Traditional eQTL methods could be applied to TReC measurement given it is properly normalized. However, RNA-seq also provides the information of allele specific expression (ASE), which is not available from microarray. In this paper, we develop a statistical framework to map eQTL using RNA-seq data by TReC, ASE, or both measurements. Our new methods show significantly higher power than existing approach in both simulation and real data analyses. We also discuss the design issues of RNA-seq experiments.",FALSE,FALSE,,FALSE,FALSE,TRUE,I will chair the invited session 'Statistical Methods for High-throughput Sequencing Data',oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Genomics,Statistical genetics,,,,,,,14-Nov-10,wenjie@unc.edu,,Wenjie Chen,,"University of North Carolina, Chapel Hill","318 Hanes Hall, CB#3260, UNC",919-901-0552,,wenjie@unc.edu,Nomparametric Approach for Hemodynamic Response Function Modeling in Functional MRI,1,Wenjie,,Chen,University of North Carolina at Chapel Hill,Haipeng,,Shen,University of North Carolina at Chapel Hill,Young,,Truong,University of North Carolina at Chapel Hill,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Functional Magnetic Resonance Imaging (fMRI) is a medical imagingtechnique for studying brain function. FMRI is non-invasive and it canbe used to capture the response of the brain to various tasks. Theresponse to a brief, intense period of neural stimulation is calledhemodynamic response function (HRF). Modeling HRF is essential toidentify the brain activation by exploring the relationship betweenthe experimental stimulus and the response. We propose the methods to adapt to all kinds of experiment design andimprove the  estimator's efficiency. By building on the existing work,we extend the nonparametric approach to different experiment designs,and the HRF modeling to the multivariate form adapt to the multipletypes of stimuli. The corresponding multivariate hypothesis testing isalso developed to identify the brain activation or to compare the HRFsunder different stimuli. To promote the estimation efficiency, wesuggest using weighted least square in the multiple system ofregression by spectral methods. Furthermore, we illustrate the methods by using both simulation andread data analysis, which shows that the multiple HRFs can beidentified and HRF estimation efficiency got improved by our methods.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Imaging,Time series,,,,,,,21-Oct-10,whjiang1981@gmail.com,,Wenhua Jiang,,Johns Hopkins University,11922 New Country Ln,732-789-6972,,whjiang1981@gmail.com,A shared-parameter model for the estimation of longitudinal concomitant intervention effects,3,Colin,,Wu,"National Heart, Lung and Blood Institute",Xin,,Tian,"National Heart, Lung and Blood Institute",Wenhua,,Jiang,"School of Medicine, Johns Hopkins University",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We investigate a change-point approach for modeling and estimating theregression effects caused by a concomitant intervention in alongitudinal study. Since a concomitant intervention is oftenintroduced when a patient's health status exhibits undesirable trend,statistical models without properly incorporating the intervention andits starting time may lead to biased estimates of the interventioneffects. We propose a shared-parameter change-point model to evaluatethe pre- and post-intervention time trends of the response, anddevelop a likelihood-based method for estimating the interventioneffects and other parameters. Application and statistical propertiesof our method is demonstrated through a longitudinal clinical trial indepression and heart disease and a simulation study.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Longitudinal data,Random effects,,,,,,,15-Nov-10,whou@biostat.ufl.edu,,Wei Hou,Assistant Professor,University of Florida,"1329 SW 16th St., Room 5130",3522650111-86565,,whou@biostat.ufl.edu,Modeling Cure Rates Using the Survival Distribution of the General Population,1,Wei,,Hou,University of Florida,Keith,,Muller,University of Florida,Michael,,Milano,University of Rochester,Paul,,Okunieff,University of Florida,Myron,,Chang,University of Florida,,,,,,,,,,,,,,,,,,,,,"In clinical trials, it is often observed that a certain percentage ofsubjects are cured following treatment. Most of the models for curerate are parametric and of a mixture type. It is usually assumed thatthe population is divided into two subpopulations so that a subject iseither cured with probability p or is not cured with probability(1-p). Farewell (1982) proposed that the probability p is a logisticfunction of some prognostic factors and treatment arms and thesurvival of non-cured subjects follow a Weibull distribution.  In themixture model, it is usually assumed that cured subjects will neverdie. We believe that this kind of definition of being cured isunrealistic. In the proposed research, we redefine a cured subject bya subject who completely gets rid of the disease and therefore, itssurvival follows the survival function of the general population. Oursimulation studies show that the proposed method reduces the bias ofthe estimated cure rate.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Survival analysis,Cancer applications,,,,,,,15-Nov-10,william.valdar@unc.edu,,William Valdar,Assistant Professor,University of North Carolina at Chapel Hill,120 Mason Farm Road,9198432833,,william.valdar@unc.edu,"An hierarchical Bayesian mixed model for characterizing genetic, sex, and parent-of-origin effects in diallel crosses of model organisms",1,William,,Valdar,University of North Carolina at Chapel Hill,Alan,,Lenarcic,University of North Carolina at Chapel Hill,Gary,,Churchill,"Jackson Laboratory, Bar Harbor",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The diallel is a genetics breeding design for model organisms such as mice that crosses all individuals with each other. When applied to inbred strains it characterizes effects of genetic background on a measured phenotypic outcome. However, its analysis is traditionally both intricate and highly sensitive to missing data and experimental imbalance. These drawbacks have deterred many geneticists from its use. We describe a hierarchical mixed model that decomposes the observed patterns in the diallel into biologically intuitive components while providing shrinkage estimation for individual parameters and while accommodating and modeling outliers through an infinite mixture of normals model. An efficient MCMC implementation, available as a free R package, allows a rapid model search via DIC, as well as posterior predictions for paramters and missing data. This method unlocks the diallel's potential to characterize genetic, heterosis and parent-of-origin effects for both sexes. We expect this robust, powerful and highly flexible tool will stimulate researchers to re-examine existing diallel data, generate new diallel data, and more coherently use the information in the diallel to guide next-step experimental crosses.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Statistical genetics,Hierarchical models,,,,,,,29-Sep-10,wjw@stat.tamu.edu,,Jiawei Wei,,Department of Statistics / Texas A&M University,3143 TAMU,979-450-2741,979-845-3144,wjw@stat.tamu.edu,Robust Estimation for Homoscedastic Regression in the Secondary Analysis of Case-Control Data,1,Jiawei,,Wei,Department of Statistics / Texas A&M University,Raymond,J,Carroll,Department of Statistics / Texas A&M University,Ursula,U,Muller,Department of Statistics / Texas A&M University,Ingrid,Van,Keilegom,Universite catholique de Louvain,Nilanjan,,Chatterjee,"Division of Cancer Epidemiology and GeneticsNational Cancer Institute",,,,,,,,,,,,,,,,,,,,,"Primary analysis of case-control studies focuses on the relationshipbetween disease (D) and a set of covariates of interest (Y,X). Asecondary application of the case-control study, often invoked inmodern genetic epidemiologic association studies, is to investigatethe interrelationship between the covariates themselves. The task iscomplicated due to case-control sampling. Previous work has assumed aparametric distribution for Y given X and derived semiparametricefficient estimation and inference without any distributionalassumptions about X. In this paper, we take up the issue of estimation of a regressionfunction when Y given X follows a homoscedastic regression model, butotherwise the distribution of Y is unspecified. The semiparametricefficient approaches can be used to construct semiparametric efficientestimates, but they suffer from a lack of robustness to the assumedmodel for Y given X. We take an entirely different and novel approachin the case that the disease is rare. We show how to estimate theregression parameters in the rare disease case even if the assumedmodel for Y given X is incorrect, and thus the estimates aremodel-robust. Simulations and empirical examples are used toillustrate the approach.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Epidemiologic methods,Nonparametric methods,,,,,,,15-Nov-10,wkim@usf.edu,,Wonkuk Kim,Assistant Professor,University of South Florida,Mathematics & Statistics,813-974-9551,813-974-2700,wkim@usf.edu,Score tests to copy number polymorphism data under non-differential errors,1,Wonkuk,,Kim,University of South Florida,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Copy number calls are commonly less accurate than SNP calls in genetic research. In a genetic case-control study, when each observation is classified into one of categories based on a continuous measurement, the chi-square test of independence or the linear trend test on the categorized data may be applied to test an association. The score tests to the raw measurements are applied to test the equality of two vectors of mixing proportions. The relative efficiencies of the score tests to the commonly used tests with classified data are calculated. The proposed tests are more powerful than the chi-square test of independence or the linear trend test applied to the classified copy number data.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Statistical genetics,Power analysis/sample size,,,,,,,15-Nov-10,wkleiber@uw.edu,,William Kleiber,Post-graduate Scientist,National Center for Atmospheric Research,1830 W Centennial Dr Unit 307,206-715-6457,,wkleiber@uw.edu,Matern Cross-Covariance Functions for Multivariate Random Fields,1,William,P,Kleiber,"National Center for Atmospheric Research, Institute for Mathematics Applied to Geosciences, Boulder, CO",Tilmann,,Gneiting,"Institut fur Angewandte Mathematik, Universitat Heidelberg, Germany",Martin,,Schlather,"Institut fur Mathematische Stochastik, Universitat Gottingen, Germany",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We introduce a flexible parametric family of matrix-valued covariancefunctions for multivariate spatial random fields, where eachconstituent component is a Matern process. The model parameters areinterpretable in terms of process variance, smoothness, correlationlength, and colocated correlation coefficients, which can be positiveor negative. Both the marginal and the cross-covariance functions areof the Matern type. In a data example on error fields for numericalpredictions of surface pressure and temperature over the NorthAmerican Pacific Northwest, we compare the bivariate Matern model tothe traditional linear model of coregionalization.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Spatial/temporal modeling,Multivariate methods,,,,,,,14-Nov-10,wktwktwkt@gmail.com,,Wesley Thompson,,UCSD,2855 Andover Ave,7607292821,,wktwktwkt@gmail.com,A Bayesian Method for Simultaneous Smoothing and Functional Connectivity of Event-Related fMRI Data,2,Dongli,,Zhou,University of Pittsburgh,Wesley,K,Thompson,"University of California, San Diego",Wesley,,Thompson,,Wesley,,Thompson,,Wesley,,Thompson,,Wesley,,Thompson,,Wesley,,Thompson,,Wesley,,Thompson,,Wesley,,Thompson,,Wesley,,Thompson,,"This talk propose a region-of-interest multivariate approach for simultaneously obtaining the underlying noise-free BOLD response and determining network functional connectivity (FC) among several regions in an event-related fMRI design. It has been shown that the degree of temporal smoothing is crucial for determining levels of FC (Zhou et al, submitted). We develop a Bayesian methodology which obtains graphical model relationships on the coefficients of basis functions used to smooth the event-related time series. The stimulus-locked noise-free BOLD time series are obtained by a reduced rank smoothing-spline.  The covariance matrix of the random coefficients is estimated after application a a covariance selection prior distribution.  Extensions are also considered for non-normally distributed coefficients.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Bayesian methods,Functional data analysis,,,,,,,12-Oct-10,wonyull@email.unc.edu,,Wonyul Lee,,University of North Carolina at Chapel Hill,Department of Statistics and Operations Research,919-923-3548,,wonyull@email.unc.edu,Simultaneous Multiple Response Regression and Inverse Covariance Matrix Estimation via Penalized Gaussian Maximum Likelihood,1,Wonyul,,Lee,"Department of Statistics and Operations Research,University of North Carolina at Chapel Hill",Yufeng,,Liu,"Department of Statistics and Operations Research,University of North Carolina at Chapel Hill",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Multivariate regression is a common statistical problem in practice. For problems with multiple response variables available, one common approach is to apply the univariate response regression technique separately on each response variable. Although it is simple and popular, the univariate response approach ignores the information among response variables. In this paper, we propose two new methods for utilizing joint information among response variables. Both methods are in a penalized likelihood framework with weighted L1 regularization. The proposed methods provide sparse estimators of conditional inverse covariance matrix of response vector given explanatory variables as well as sparse estimators of regression parameters. Our first approach is to estimate the regression coefficients with plug-in estimated covariance matrices, and our second approach is to estimate the regression coefficients and the covariance matrix simultaneously. Asymptotic properties of our methods are explored. Through several simulated examples, we demonstrate that the proposed methods perform competitively in terms of prediction and variable selection. Moreover, we apply our methods to a real Glioblastoma cancer data set. We make use of both gene expression data and microRNA data and demonstrate interesting networks among microRNAs given gene expressions obtained by our joint method.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Machine learning,Variable subset selection/model selection,,,,,,,05-Nov-10,woodard@cornell.edu,,Dawn Woodard,Prof.,Cornell University,"ORIE, 206 Rhodes Hall",919-593-4531,,woodard@cornell.edu,HARK: A New Approach for Regression with Functional Predictors,1,Dawn,B,Woodard,"Cornell UniversitySchool of Operations Research and Information Engineering",Ciprian,,Crainiceanu,Johns Hopkins University,David,,Ruppert,Cornell University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Motivated by a large and complex dataset from the Sleep Heart HealthStudy, we propose a new method for regression using functionalpredictors.  We use a parsimonious and scientifically interpretablerepresentation of the functional predictors, designed for data thatexhibit features such as spikes, dips, and plateaus whose frequency,location, size, and shape varies across subjects.  We propose fullBayesian inference of the joint functional and exposure models, andgive a method for efficient computation.We contrast our approach with existing state-of-the-art methods forregression with functional predictors, and show that our method ismore effective and efficient for data that include features occurringat varying locations.  We apply our methodology to the Sleep HeartHealth Study, in order to better understand the relationship betweensleep characteristics and health outcomes.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Functional data analysis,Bayesian methods,,,,,,,14-Oct-10,wu26@mailbox.sc.edu,,Wensong Wu,,Department of Statistics,University of South Carolina,803-777-3785,,wu26@mailbox.sc.edu,Bayes Multiple Decision Functions,1,Wensong,,Wu,"Department of Statistics, University of South Carolina",Edsel,A,Pena,"Department of Statistics, University of South Carolina",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In this paper, a general form of the Bayes multiple decision functions(BMDF) with respect to a class of cost-weighted loss functions isintroduced. An algorithm of finding the BMDF is provided based uponposterior expectations. In particular, loss functions such as falsediscovery proportion (FDP), false nondiscovery proportion (FNP), andmissed discovery proportion (MDP) are considered, and the cost weightsare user-determined. Results are applicable in many settings includingmultiple hypothesis testing, multiple classification and prediction,and high-dimensional variable selection. A dependent data structure isallowed and is modeled through a class of frailty-induced Archimedeancopulas. In particular, non-Gaussian dependent data structure is ofinterest, especially in settings with failure-time data. Computationof the posterior expectations is facilitated by using Sequential MonteCarlo (SMC) algorithms. The proposed BMDF is illustrated in bothsimple-versus-simple and composite hypotheses settings.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Multiple testing,Bayesian methods,,,,,,,15-Nov-10,wucen@stt.msu.edu,,Yuehua Cui,,"Department of Statistics and Probability , Michiga",A413 Wells Hall,(517) 432-7098,,wucen@stt.msu.edu,Boosting signals in gene set association studies via selective SNP profiling,1,Cen,,Wu,"Department of Statistics and Probability, Michigan State University",Yuehua,,Cui,"Department of Statistics and Probability, Michigan State University",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Set-based genome-wide association studies based on genes or pathwayshave shown great promise in detecting genetic variants associated withcomplex diseases. These approaches are particularly useful whenvariants have small effects in a set and are difficult to be detectedwith single marker analysis. The set-based analysis uses a summarystatistic such as the maximum signal or average signal (e.g.,chi-square statistic) over all variants in a set to assess thesignificance of the set. The signal obtained with this treatment,however, could be potentially diluted when noisy variants are nottaken good care of. Imaging in a gene set with 20 SNP variants, only10 are associated with a disease. By averaging over 20, the signal forthe set would be smaller than the one obtained by averaging over 10,hence leading to low power. Thus, the selection of informative SNPsplays a crucial role in improving the efficiency of the set-basedassociation study. In this work, we propose an efficient SNPpre-selection method based on information content theory. We selectSNP variants by considering their relative information contribution toa disease status. Thus, our method is different from the usual tag SNPselection method. The relative advantage of pre-selecting SNP in aset-based association analysis is demonstrated through extensivesimulation studies and real data analysis.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Statistical genetics,Genomics,,,,,,,08-Oct-10,wwang@stat.fsu.edu,,wenting wang,,"Department of Statistics, Florida State University","Department of Statistics, Florida State University",8503396939,,wwang@stat.fsu.edu,Information Matrix Priors for Bayesian Survival Analysis,1,Wenting,,Wang,"Department of Statistics, Florida State University",Debajyoti,,Sinha,"Department of Statistics, Florida State University",Joseph,G.,Ibrahim,"Biostatistics Department, University of North Carolina, Chapel Hill",Maria,T.,Landi,"Division of Cancer Epidemiology and Genetics, National Cancer Institute",Neil,E.,Caporaso,"Division of Cancer Epidemiology and Genetics, National Cancer Institute",Kai,,Yu,"Division of Cancer Epidemiology and Genetics, National Cancer Institute",,,,,,,,,,,,,,,,,"For Bayesian  analysis of survival data, one often encounters the problem of how to specify a ``semi-automatic' prior for the unknown parameters, especially the parameters of interest. In this article, we propose the Information Matrix (IM)  and Information Matrix Ridge (IMR) priors for commonly used survival models including the Cox model (Cox 1972) and the cure rate model (Chen et al. 1999), and examine many of their desirable theoretical properties including sufficient conditions for the existence of the moment generating functions for these priors and corresponding posterior distributions. For these priors, we establish theoretical properties important in the study of thebehavior and robustness of the prior in a Bayesian analysis. Likethese priors' earlier counterparts (Gupta and Ibrahim 2009) for the Generalized Linear model, we show relationships of these priors with Jeffrey's prior and g-prior (Zellner 1986) for survival models, and demonstrate the advantage of these priors over the Jeffrey's prior and g-prior. We also compare the performance of these priors in practice compared to competing priors via the Bayesian evaluation of the relationship between lung cancer survival time and 66 single Nucleotide Polymorphisms SNPs in the 15q25 (76.4-76.8 Mb) region using data from the Genes, Environment, and Health Initiative (GEI) Lung Cancer Genomewide Association Study (GWAS).",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,TRUE,Bayesian methods,Survival analysis,,,,,,,14-Nov-10,wwang7@mdanderson.org,,Wenyi Wang,,UT MD Anderson Cancer Center,1400 Pressler St Unit 1410,713 792-5377,713 792-5377,wwang7@mdanderson.org,Statistical Methods for DNA Resequencing Analysis in Disease-Gene Studies,1,Wenyi,,Wang,"Department of Bioinformatics and Computational biology, the University of Texas MD Anderson Cancer Center",Peidong,,Shen,"Stanford Genome Technology Center, Stanford University",Sreedevi,,Thyagarajan,"Stanford Genome Technology Center, Stanford University",Curtis,,Palm,"Stanford Genome Technology Center, Stanford University",Lynn,,Pique,"Department of Pathology, Stanford University",Iris,,Schrijver,"Department of Pathology and Pediatrics, Stanford University",Ronald,W,Davis,"Stanford Genome Technology Center, Stanford University",Michael,,Mindrinos,"Stanford Genome Technology Center, Stanford University",Terence,P,Speed,"Department of Statistics, the University of California, Berkeley",Curt,,Scharfe,"Stanford Genome Technology Center, Stanford University","Resequencing arrays enable cost-efficient and high-throughput sequencing of candidate disease genes. Distinct from whole-genome SNP data, the resequencing data present very low frequencies of genetic variations from a reference sequence, and higher frequencies of sequencing errors. This motivated us to develop a new method, Sequence Robust Multi-array Analysis (SRMA). We extended multi-level mixture models previously deployed for SNP arrays to accurately call single heterozygous sample at rare variant positions. We demonstrate improved accuracy of our methods than existing algorithm, in a resequencing study of 39 candidate genes among healthy individuals and patients with mitochondrial diseases. Our accurate base-calling method allows meaningful downstream analysis of identified variants. It is applicable to any custom resequencing arrays and provides guidance for technological advances.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Genomics,Microarray analysis,sequencing,,,,,,12-Nov-10,wwo@lilly.com,,Walter Offen,Senior Research Fellow,Eli Lilly and Company,10649 Windjammer Circle,317-276-4865,,wwo@lilly.com,"Statisticians as Leaders:  Why it is increasingly important, and what it means",1,Walter,W,Offen,Eli Lilly and Company,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The role of statisticians in many settings is changing to where thereare greater expectations of leadership from statisticians.  However,statisticians receive very little leadership skill development ingraduate school.  I created this session on leadership to getperspectives from leaders in academia, government, and industry.  Mytalk will be a combination of serving as a discussant, tying togetherthe other talks, as well as providing a few key takeaways on howstatisticians can develop and strengthen their leadershipcapabilities, leading to greater impact in their jobs and beyond.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Other,Consulting,Leadership,,,,,,01-Nov-10,wxz123@psu.edu,,Wei Zhong,,"Department of Statistics, Penn State",325 Thomas Building,8143217555,,wxz123@psu.edu,A New Model-Free Sure Independence Screening for Ultra-High Dimensional Problems,2,Runze,,Li,"Department of StatisticsThe Pennsylvania State University",Wei,,Zhong,"Department of StatisticsThe Pennsylvania State University",Liping,,Zhu,Shanghai University of Finance and Economics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"High dimensional regression analysis has become increasingly importantin diverse fields of scientific research. In this paper we introduce anew model-free sure independent screening procedure to selectimportant predictors when the number p of predictors greatly exceedsthe sample size n. It allows us consider independent screening forgroup-wise predictors and multivariate responses. This proposedprocedure imposes little assumption on regression structure, so italso allows arbitrary regression relationship between y and x. Thisindicates that the new proposal selects important predictors in amodel-free manner. For theoretical properties, we demonstrate that theproposed independent screening procedure enjoys the rankingconsistency property, that is, it can rank important predictors in thetop consistently even when p>>n. Meanwhile, under some mildconditions, it has the sure screening property, that is, with a properthreshold, it can select all important predictors with probabilityapproaching to one as n goes to infinity. In addition, a correspondingiterative procedure is proposed to enhance its finite sampleperformance. Numerical examples through comprehensive simulations andan application indicate that the new proposal performs quite well in avariety of ultrahigh dimensional regressions.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,High dimensional data,Variable subset selection/model selection,,,,,,,15-Nov-10,wye@umich.edu,,Wen,Research Assistant Professor,University of Michigan,1415 Washington Heights,734-615-9051,,wye@umich.edu,Addressing Selective Mortality with Dynamic Cohort Analysis,1,Wen,,Ye,University of Michigan,Jersey,,Liang,University of Michigan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"For life course research, an ideal design would be to follow eachparticipant from the age of interest until the person's death. Yet nosuch data exist. Most data were collected using an acceleratedlongitudinal design, which involved multiple cohorts for a relativelyshort period of time.  Such a design is thought to allow researchersto study trajectories over a broad age range with data collectedduring a short duration. However, the confounding between age andcohort effects in conjunction with selective mortality often lead tobiased results.   Using simulation, we first demonstrate that estimates of cohortdifference in age-related trajectories can be severely biased, whendata derived from an accelerated longitudinal design are analyzed withpopular methods such as hierarchical linear and nonlinear models.Second, we argue that cohort effect should be conceptualizeddynamically in that it changes with age rather than being fixed at acertain value. Third, we propose a new method, dynamic cohort analysisthat yields unbiased estimate for cohort difference.  Finally, weillustrate this new method with data from the Health Retirement Study.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Demography and population studies,Longitudinal data,,,,,,,08-Nov-10,xcui@uab.edu,,Xiangqin Cui,,University of Alabama at Birmingham,1665 University BLVD,205-996-4154,,xcui@uab.edu,Length Bias Correction for RNA-seq Data in Gene Set Analyses,5,Liyan,,Gao,University of Alabama at Birmingham,Zhide,,Fang,Louisiana State University Health Sciences Center,Kui,,Zhang,University of Alabama at Birmingham,Degui,,Zhi,University of Alabama at Birmingham,Xiangqin,,Cui,University of Alabama at Birmingham,,,,,,,,,,,,,,,,,,,,,"Next-generation sequencing technology is being rapidly applied to quantifying transcripts (RNA-seq). However, the differential expression of longer transcripts is more likely to be identified than that of the shorter transcripts. This bias complicates the downstream gene set analysis (GSA) because the methods for GSA previously developed for microarray data are based on the assumption that genes with same effect size have equal probability (power) to be identified as significantly differentially expressed. We proposed two approaches for transcript-length adjustment for analyses based on Poisson models: 1) At individual gene level, we adjusted each gene's test statistic using the square root of transcript length followed by testing for gene set using the Wilcoxon Rank-Sum test. 2) At gene-set level, we adjusted the null distribution for the Fisher's exact test by weighting the identification probability of each gene using the square root of its transcript length. We evaluated these two approaches using simulations and a real dataset, and showed that these methods can effectively reduce the transcript-length biases. The top ranked GO terms obtained from the proposed adjustments show more overlaps with the microarray results.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Other,High dimensional data,Next-generation sequencing,,,,,,25-Oct-10,x-he@uiuc.edu,,Xuming He,Professor,University of Illinois,725 S. Wright,217-333-4792,217-244-7190,x-he@uiuc.edu,When can we rely on a uni-dimensional summary of high-dimensional data?,1,Xuming,,He,"University of IllinoisDepartment of Statistics",Xingdong,,Feng,National Institute of Statistical Science,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"A uni-dimensional summary is routinely used in gene expression indicesand assessments of skills in educational testing. It is prudent to askwhether gene expression data from a probeset can be well summarized bya single expression index, or whether the performance or ability of atest taker can be fairly represented by a single score. In someapplications, the uni-dimensional summary can be characterized by thefirst singular structure of a data matrix, sometimes ahigh-dimensional one.  In this talk, we demonstrate how a statisticalapproach can be developed to detect meaningful patterns beyond thefirst summary. The singular value decomposition plays a central rolein our approach.  Both theory and examples will be given in the talkto show that uni-dimensionality should not always be taken for grantedand that statisticians can help.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,High dimensional data,Applied data analysis,,,,,,,13-Oct-10,xhzhao26@gmail.com,,xinhua zhao,,University of Pittsburgh,1609 Settlers drive,412-6545258,412-9545265,xhzhao26@gmail.com,Latent Variable Models for Multiple Binary Outcomes in a Cluster Randomized Clinical Trial,1,Xinhua,,Zhao,"University of Pittsburgh Graduate School of Public Health, Pittsburgh, PA",Roslyn,A,Stone,"University of Pittsburgh Graduate School of Public Health, Pittsburgh, PA",Feifei,,Ye,"University of Pittsburgh School of Education, Pittsburgh, PA",Michael,J,Fine,"Center for Health Equity Research and Promotion, VA Pittsburgh Healthcare System, Pittsburgh, PA",,,,,,,,,,,,,,,,,,,,,,,,,"In clinical trials, multiple endpoints for treatment efficacy often are obtained, and data may be collected hierarchically. Statistical analyses become very challenging for such multidimensional hierarchical data, particularly with data collected at more than two levels. We propose a comprehensive latent approach using Bayesian estimation to assess an intervention effect on multiple binary outcomes from three-level hierarchical data.  This approach incorporates the correlation structure into one or more latent outcomes, and simultaneously regresses the latent outcome(s) on observed covariates. Random effects model the hierarchical structure. We illustrate the proposed one-latent trait and two-latent trait models in a 32-site cluster randomized clinical trial of three interventions to improve the quality of pneumonia care in the emergency department (ED) for outpatients and inpatients. Simulation studies are conducted to verify the accuracy of model estimation. This approach allows assessment of intervention effects with respect to multiple outcomes, accounts for structural missingness, identifies those outcomes that are most informative regarding the latent trait(s), and provides a summary measure of the 'quality of care' at each site.",FALSE,FALSE,,FALSE,TRUE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Latent variables,Clinical trials,,,,,,,15-Oct-10,xiangf@umich.edu,,Fang Xiang,,"Department of Biostatistics, University of Michiga",1415 Washington Heights,734-764-5450,,xiangf@umich.edu,Restricted Mean Models for Transplant Benefit and Urgency,1,Fang,,Xiang,"Department of Biostatistics, University of Michigan",Susan,,Murray,"Department of Biostatistics, University of Michigan",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Transplant benefit, defined by the OPTN Thoracic Committee, is thedays lived in one year if transplanted minus the days lived if nottransplanted. Urgency is the days lived during the next year if nottransplanted. In both definitions, accurate estimation of restrictedmean waitlist lifetime is required. Risk factors estimate urgency,with more urgent patients removed from the waitlist as they either dieor get transplanted. As a patient progresses, priority for transplant(censoring) changes accordingly. A patient's urgency is highly linkedto survival as well as time to censoring (transplant). Therefore, itis crucial to adjust for dependent censoring in modeling restrictedlifetimes. We develop a model for the restricted mean as a function ofcovariates, using pseudo observations that account for dependentcensoring. Simulation results show that our method performs well insituations comparable to the lung waitlist setting. A restricted meanmodel also estimates days lived post-transplant based on risk at thattime. Applying our waitlist and post-transplant restricted lifetimeestimates to patients waiting for transplant, we obtain correctedestimates of transplant benefit and urgency. The difference inallocation ranks, when properly accounting for dependent censoring,has high impact on the priority and timing of an organ offer for thesepatients.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,TRUE,Survival analysis,Health policy applications,,,,,,,05-Nov-10,xianhong.xie@einstein.yu.edu,,Xianhong Xie,,"Dept. of Epidemiology & Population Health, AECOM",1300 Morris Park Ave,718-430-3625,,xianhong.xie@einstein.yu.edu,Estimating Correlations Between Biomarkers With Repeated Measures and Left-Censoring due to Minimum Detection Levels,1,Xianhong,,Xie,"Dept. of Epidemiology & Population Health,Albert Einstein College of Medicine,Bronx, NY",Xiaonan,,Xue,"Dept. of Epidemiology & Population Health,Albert Einstein College of Medicine,Bronx, NY",Stephen,,Gange,"Department of Epidemiology, Johns Hopkins Bloomberg School of Public Health,Baltimore, MD",Howard,,Strickler,"Dept. of Epidemiology & Population Health,Albert Einstein College of Medicine,Bronx, NY",Mimi,,Kim,"Dept. of Epidemiology & Population Health,Albert Einstein College of Medicine,Bronx, NY",,,,,,,,,,,,,,,,,,,,,"Statistical approaches for estimating the correlation between twobiomarkers under repeated measurements and left-censoring due tominimum detection levels are lacking. We propose a linearmixed-effects model and estimate the parameters with the Monte CarloExpectation Maximization (MCEM) method. Inferences regarding the modelparameters and the correlation are performed by applying Louis'smethod and the delta method. Simulation studies were conducted tocompare the proposed MCEM method with the multiple imputation (MI)method and with two common ad hoc approaches: replacing the censoredvalues with the detection limit (DL) or with half of the detectionlimit (HDL). The results show that the performance of the MCEM withrespect to relative bias and coverage probability for the 95%confidence interval is superior to the DL and HDL approaches andexceeds that of the MI method at medium to high levels of censoring.The methods are illustrated with a real HIV data to estimatethe correlation between HIV viral loads measured at different reservoirs.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Longitudinal data,Missing data,,,,,,,12-Nov-10,xiaoxi.zhang@pfizer.com,,Xiaoxi Zhang,,Pfizer Inc.,235 E 42nd Street,2127336574,,xiaoxi.zhang@pfizer.com,Multiple Imputation Methods for ROC Analysis in the Presence of Missing Data,1,Xiaoxi,,Zhang,Pfizer Inc.,Qi,,Long,Emory University,Chiu-Hsieh,,Hsu,University of Arizona,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The receiver operating characteristics (ROC) curve is a widely used tool in evaluating the discriminative and diagnostic power of a biomarker. When the biomarker value is missing for some observations, the ROC analysis based solely on the complete cases loses efficiency, and more importantly, it is subject to potential bias. In this paper, we investigate nonparametric multiple imputation methods for ROC analysis when some biomarker values are missing and there are auxiliary variables that are fully observed and predictive of biomarker values and/or the missingness of biomarker values. The standard nonparametric imputation can suffer from the curse of dimensionality as the number of auxiliary variables increases. To address this problem, we propose new nonparametric imputation methods, which achieve dimension reduction through the use of one or two working models and provide a platform for a full range of ROC analysis. We conduct simulation studies to evaluate the finite sample performance of the proposed methods, and find that the proposed methods are robust to various types of model misidentification and outperform the standard nonparametric approach even when the number of auxiliary variables is moderate. We further illustrate the proposed methods using an observational study of maternal depression during pregnancy.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,ROC analysis,Missing data,,,,,,,29-Oct-10,xiawang.z@gmail.com,,Xia Wang,,National Institute of Statistical Sciences,19 T.W. Alexander Drive,919-685-9356,,xiawang.z@gmail.com,Bayesian Models in Biomarker Discovery Using Spectral Count Data in the Label-Free Shotgun Proteomics,1,Xia,,Wang,National Institute of Statistical Sciences,Nell,,Sedransk,National Institute of Statistical Sciences,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Spectral count is gaining popularity as an abundance measure  inlabel-free quantitative proteomics.  It has been used in the biomarkerdiscovery studies to detect differentially expressed proteins.  ABayesian hierarchical model using mixture priors is proposed to dealwith the challenges of few replicates, sparse counts, large number ofproteins, and unreliable variance estimation.  Compared to simplePoisson regressions and the QSpec model, the proposed method provideshigher sensitivity at a given FDR level.  The model is applied insynthetic datasets as well as multilab datasets from the ClinicalProtoemics Technology Assessment for Cancer (CPTAC) collaborative network.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Bayesian methods,Proteomics,,,,,,,15-Nov-10,xikong@jhsph.edu,,Xiangrong Kong,Dr.,Johns Hopkins University,615 N. Wolfe St.,410-614-4827,,xikong@jhsph.edu,A modeling framework for analysis of HPV incidence and persistence,1,Xiangrong,,Kong,Johns Hopkins Bloomberg School of Public Health,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"HPV infection is a common STD with over 40 genotypes identified in genital infections. Current HPV cohort studies often follow participants at pre-determined visits, such as every 6-months, and data generated from such studies can be described as clustered longitudinal binary data where correlation arises in two ways: the directionless clustering due to multiple genotypes tested within an individual, and the temporal correlation among the repeated measurements on the same genotype along time. Current analyses for identifying risk factors associated with HPV incidence/persistence (I/P) often either do not fully utilize information in the dataset or ignore the correlation between the multiple genotypes. Given the scientific definition of I/P, conditional probability modeling provides us a natural mathematical tool. We thus present a semi-parametric regression model for such data where full specification of the joint multivariate binary distribution is avoided by using conditioning argument to handle the temporal correlation and GEE to account for the correlation between the multiple genotypes. The model is applied to the HPV data from the Rakai male circumcision (MC) trial to evaluate efficacy of MC and also identify modifiable risk factors for I/P in men. A simulation study is performed to provide empirical information for future studies.",FALSE,FALSE,,FALSE,TRUE,TRUE,"SC7 Intro To Main Ideas & Basic Concepts Emp Proc W/ ExT6: Intro To the MCMC Procedure in SAS/STAT Software",oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Infectious disease models,Longitudinal data,,,,,,,12-Nov-10,xin.wang@mayo.edu,,Xin Wang,,Mayo Clinic,620 E center street,507-538-1774,,xin.wang@mayo.edu,Extensions of Random Forests for Genetic Data Analysis,1,Xin,,Wang,"Mayo Clinic, Biomedical Statistics and Informatics",Mariza,,de Andrade,"Mayo Clinic, Biomedical Statistics and Informatics",Colin,,Colby,"Mayo Clinic, Biomedical Statistics and Informatics",Marianne,,Huebner,"Mayo Clinic, Biomedical Statistics and Informatics",Robert,,Freimuth,"Mayo Clinic, Biomedical Statistics and Informatics",Joanna,,Biernacka,"Mayo Clinic, Biomedical Statistics and Informatics",,,,,,,,,,,,,,,,,"Random Forests (RFs) have been proposed for the analysis of the highly-dimensional single nucleotide polymorphism (SNP) data from genetic association studies. It is a machine learning technique that uses a collection of classification trees grown on bootstrap samples of observations, allowing a random subset of predictors to determine the best split at each node. RFs have been applied to large sets of SNPs, usually using individual SNPs as predictors, and producing variable importance measures for the SNPs.  A large number of trees are required in situations with many predictors, making the approach highly computationally intensive. Methods for assessing evidence for association with a phenotype at the gene, rather than SNP, level have been proposed for standard regression-based genetic association analyses, in order to reduce the data dimensionality and produce more interpretable results. For example, haplotype-based and principle component analyses have been used in this context. Here we propose a RF-based method that incorporates principle components (PCs) representing variation in each gene as the predictors. We also introduce a measure of gene level importance. Both SNP-based RF and PC-based RF are applied to data from a genome-wide association study of alcohol dependence. The prediction errors of the two methods are compared.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Statistical genetics,Machine learning,,,,,,,15-Nov-10,xingao@umich.edu,,Xin Gao,,"University of Michigan, School of Public Health, D",1415 Washington Heights,7343555968,,xingao@umich.edu,Assessing Causal Effect of Treatment Dosages with Self-selection,1,Xin,,Gao,"Department of BiostatisticsSchool of Public HealthUniversity of Michigan",Michael,R,Elliott,"Department of BiostatisticsSchool of Public HealthUniversity of Michigan",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"To make drug therapy as effective as possible, patients are often puton an escalating dosing schedule.  But patients may choose to take alower dose because of side effects.  Thus, even in a randomized trial,the dose level received is a post-randomization variable, andcomparison with the control group may no longer have a causalinterpretation.  Hence we use the potential outcomes framework todefine pre-randomization principal strata from the jointdistribution of doses selected under control and treatment arms, withthe goal of estimating the effect of treatment within the subgroups ofthe population who will select a given set of dose levels.  Whensubjects on the control arm cannot obtain treatment, these principalstrata are fully observed on treatment, but remain latent on control. Adverse event information can be used to identify the tolerated doselevel in the control arm.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Causal inference,Clinical trials,,,,,,,06-Oct-10,xingbinw@gmail.com,,Xingbin Wang,,Pittsburgh University,6357 CROMBIE ST,412-651-7366,,xingbinw@gmail.com,Statistical integration of weak-signal microarray studies with confounded clinical variables: application to human depression analysis,1,XINGBIN,,WANG,"Department of Biostatistics, University of Pittsburgh, Pittsburgh, PA 15261",Etienne,,Sibille,"Department of Psychiatry, University of Pittsburgh, Pittsburgh, PA 15261",George C.,,Tseng,"Department of Biostatistics, University of Pittsburgh, Pittsburgh, PA 15261",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Major depressive disorder (MDD) is a heterogeneous psychiatric illness with mostly un-characterized pathology, contributing to death by suicide, as well as the fourth most common cause of disability per the World Health Organization (WHO). To understand the genetics of MDD, gene expression analysis is one of methods to identify the biomarkers associated with MDD. Due to the very weak expression signal of MDD, a substantial clinical heterogeneity and small sample size, it is hard to identify consistent and robust biomarkers in an individual study .To achieve a more accurate and stable list of the differentially expressed (DE) genes and pathways associated with MDD, we propose a random intercept model (RIM) to account for the case-control paired design and confounded clinical variables such as alcohol, age, and antidepressant drug. An optimal random intercept model (oRIM) with variable selection is performed to accommodate the small sample size. Three popular meta-analysis methods (Fisher, inverse variance weighted, and maximum p-value) are then applied to detect biomarkers and pathway analysis are performed. The result shows increased statistical power from clinical variable adjustment, paired design modelling and meta-analysis in this genomic setting and more profound biological findings in MDD neurobiology.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Microarray analysis,Applied data analysis,mixed model,,,,,,12-Nov-10,xinhe@umd.edu,,Xin He,Assistant Professor,"University of Maryland, College Park",2234H SPH Building,301-405-2551,301-314-9366,xinhe@umd.edu,Variable Selection for Multivariate Panel Count Data,1,Xin,,He,"University of Maryland, College Park",Tongtong,,Wu,"University of Maryland, College Park",Richard,J,Cook,University of Waterloo,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In this talk, we consider the variable selection problem in thecontext of regression analysis of multivariate panel count data.Multivariate panel count data often occur in long-term studiesinvolving several types of recurrent events in which patients areexamined only at periodic follow-up assessments. Under a class ofmarginal mean models, we derive estimating equations via penalizationof the regression coefficients. Variable selection and parameterestimation can be performed simultaneously. An algorithm is presentedfor this method. We also establish the asymptotic and oracleproperties of the proposed parameter estimates. Simulation studies areconducted for practical situations, and the methodology is applied toa motivating study involving patients from an arthritis clinic.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Joint models for longitudinal and survival data,Multivariate survival,,,,,,,15-Nov-10,xiuhua.zhao@moffitt.org,,Xiuhua Zhao,Biostatistician,H. Lee Moffitt Cancer Center & Research Institute,12902 Magnolia Dr.,813 745 6210,813 745 6207,xiuhua.zhao@moffitt.org,Classification of Cancer Hazard Rate Curves into Five Order-Restricted Typologies,2,Michael,J.,Schell,"Biostatistics Core, H Lee Moffitt Cancer Center & Research Institute",Xiuhua,,Zhao,"Biostatistics Core, H Lee Moffitt Cancer Center & Research Institute",Vernon,,Sondak,"CUTANEOUS ONCOLOGY MMG, H. Lee Moffitt Cancer Center & Research Institute",George,,Simon,"School of Medicine, University of North Carolina",,,,,,,,,,,,,,,,,,,,,,,,,"The Kaplan-Meier curve provides a non-parametric fit for survival data, which renders it widely applicable to many survivorship problems, and accounts in part for its popularity.  However, there are some significant costs associated with its use, primarily in reduced precision of the estimates its yields compared to parametric alternatives.  Appropriate parametric analysis, however, requires additional understanding of survivorship. The hazard rate function is one of the fundamental functions in survival analysis.  However, it is rarely shown in research articles.  One reason for this is that it uses data from a narrow window of time.  Thus, a significant amount of data is required to produce reasonably accurate hazard rate curves.  Fortunately, the SEER registry system provides an easily available source for such data, and is used as the data source for our analysis. Twenty different cancer-cancer stage combinations of solid tumors were studied for 3 10-year periods. We classified them into one of five typologies based on the order-restricted pattern of their hazard function. Considering the bias-variance tradeoff in selecting a parametric model, we believe that the best fitting order-restricted hazard rate typology should be used instead of the KM fit.",FALSE,FALSE,,FALSE,FALSE,FALSE,,contributedposter,,,,FALSE,FALSE,FALSE,FALSE,Survival analysis,Cancer applications,,,,,,,12-Nov-10,xiwang@bios.unc.edu,,Xiaoshan Wang,,UNC-Chapel Hill,"401 NC HWY 54 Bypass, Apt E10",9192659070,,xiwang@bios.unc.edu,Adaptive trimmed likelihood estimation of polytomous logistic regression,1,Xiaoshan,,Wang,"Dept. of BiostatisticsGillings School of Global Publich HealthUNC-Chapel Hill",Pranab,K.,Sen,"Dept. of BiostatisticsGillings School of Global Publich HealthUNC-Chapel Hill",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The polytomous logistic regression models are used to describe the effect of explanatory variables on a multi-category response variable. Typically estimated by the maximum likelihood method, estimates are very sensitive to deviations from a model, such as overdispersion or data contamination. In the meantime, currently available robust methods are only for models with discrete covariates with which we can form grouped count data or contingency table, but not applicable to data with continuous covariates. To provide a robust estimation method in polytomous logistic regression for data with mixed covariates, we consider an adaptive trimmed likelihood estimator (ATLE) which using the forward searching algorithm to find the amount of trimming, with minimizing the trace of estimated covariance matrix of response categories' probabilities as the objective function. We describe theoretical properties of the proposed approach. Sensitivity to contaminations and leverage points, and performance of the proposed estimator is studied by extensive simulation. The proposed estimator appears to be robust when sample size is sufficiently large. The method is illustrated in a study of effects of sodium intake on four types of hypertension.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,TRUE,Other,Categorical data,Robust estimation,,,,,,15-Nov-10,xiwu.2.lin@gsk.com,,Xiwu Lin,,GlaxoSmithKline,1250 South Collegeville Rd,6109174897,,xiwu.2.lin@gsk.com,Searching for Clinically Interesting Subgroups Using Patient Rule Induction Method,1,Xiwu,,Lin,GlaxoSmithKline,Daniel,,Parks,GlaxoSmithKline,Jie,,Cheng,GlaxoSmithKline,Kwan,,Lee,GlaxoSmithKline,,,,,,,,,,,,,,,,,,,,,,,,,"Identifying patient subgroups that   show discernable differences in treatment effectiveness and/or safety profiles based on demographic and baseline variables is of major interest to clinicians and patients.  In this work, we have extended the capability of the Patient Rule Induction method (PRIM) to automatically handle the important application of searching for subgroups that have large differences  in treatment effectiveness when two treatments are compared.    Comparison to other related methods and the limitations of the proposed method will also be discussed. Simulation experiments and analysis of an actual medical data will be shown to illustrate the proposed method.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Other,Data mining/massive data sets,Subgroup analysis,,,,,,11-Nov-10,xjzhou@usc.edu,,Jasmine Zhou,Associate Professor,University of Southern California,1050 Childs Way,2137407055,,xjzhou@usc.edu,Analysis of Multi-dimensional Genomic Data,4,Shihua,,Zhang,University of Southern California,Chun-Chi,,Liu,University of Southern California,Wenyuan,,Li,University of Southern California,Jasmine,,Zhou,University of Southern California,,,,,,,,,,,,,,,,,,,,,,,,,"Cells are complex systems with multiple levels of organization thatinteract and influence each other. The precise coordination amongepigenetic, transcriptional, and translational regulation areessential in maintaining the function and robustness of the cellularsystems. However, the study of the coordination among thosemulti-level cellular activities has been hindered by the lack ofappropriate data resources, since most genomic studies focus on theglobal profiling at only one level, e.g. profiling of gene expressionsor protein abundances. More recently, the developments ofhigh-throughput genomics technology, especially the sequencingtechnology, have significantly facilitated the characterization ofbiological systems in multiple dimensions. In this talk, we discuss anovel approach to perform joint analysis of multi-dimensional genomicsprofiling of the same set of samples. We apply the method to the mRNA,miRNA, and methylation profiles of 385 ovarian tumor samples from theCancer Genome Atlas Project to study the coordination of thosedifferent regulatory levels. Our study has the potential in uncoveringthe cross-layer coordinated patterns and implications across multipleomic data.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Genomics,Computational methods,,,,,,,05-Nov-10,xlhuang@mdanderson.org,,Xuelin Huang,Dr.,University of Texas MD Anderson Cancer Center,1400 Pressler Street,713-794-4172,713-563-4243,xlhuang@mdanderson.org,Joint Accelerated Failure Time Models for Sequential Treatments,1,Xuelin,,Huang,University of Texas MD Anderson cancer Center,Jing,,Ning,University of Texas Health Science Center at Houston,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Currently for most types of cancer, patients usually go through the process of initial treatment, disease recurrence, and salvage treatments.  A common analysis approach for such data is to estimate the distribution of disease-free survival, i.e., the time to the first disease recurrence or death, whichever happens first. However, treating death similarly as disease recurrence may give misleading results.  We use joint accelerated failure time models to simultaneously analyze the effects of the initial treatment and salvage treatments on survival. Counterfactual outcomes are used in the regression models to evaluate causal effects of treatments. Simulation studies and real data analyses are provided for motivation, illustration and evaluation.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Survival analysis,Causal inference,,,,,,,15-Nov-10,xlin@hsph.harvard.edu,,Xihong Lin,Professor,Harvard University,"Building 2, Rm 419, Harvard School of Public Health",6174322914,,xlin@hsph.harvard.edu,Testing for the Association of the SNP/Gene Set and  Phenotypes Using an Efficient Adaptive Score Test,1,Xihong,,Lin,Harvard School of Public Health,TIanxi,,Cai,Harvard School of Public Health,Raymond,J,Carroll,Texas A&M University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Testing for the Association of the SNP/Gene Set and  Phenotypes Using an Efficient Adaptive Score Test SummaryIn recent years, genome-wide association studies (GWAS) have generated a large number ofvaluable datasets for assessing how genetic variations related to disease outcomes. However,the standard approach to analyzing GWAS, focusing on the marginal effects of single nucleotidepolymorphisms (SNPs), fails to capture the joint effects of multiple SNPs and oftenproduces non-reproducible results. SNP/gene-set analyses have been advocated asmore reliable and powerful approaches. Statisticalprocedures for testing the overall effect of a SNP/gene-set have been well studied in recent years.For example, score tests derived under an Empirical Bayes (EB) framework  have been proposed as powerful alternativesto the standard Raos p-degree freedom score test (Rao, 1948). The advantages of theseEB based procedures are most apparent when the genes are highly correlated due to thereduction in the degree of freedom. In this paper, we propose an adaptive score test whichupweights or downweights the contributions from each member of the gene-set based on theZ-scores of their effects. Such an adaptive procedure gains power over existing procedureswhen the signal is sparse and the correlation among the genes is not high. By combiningevidence between the EB based score test and the adaptive test, we further constructan omnibus test that attains a good power in most settings. The null distributions of theproposed test statistics can be approximated well either via simple perturbation proceduresor ‚2 approximations. Via extensive simulation studies, we demonstrate that the proposedprocedures perform well in finite sample. We apply the tests to a breast cancer GWAS toassess the overall effect of the FGFR2 gene on the risk of breast cancer.",FALSE,FALSE,,FALSE,FALSE,TRUE,"Please schedule this session on M or T, as I need back Tuesday night.",invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,High dimensional data,Genomics,,,,,,,11-Nov-10,xliu@urmc.rochester.edu,,Xiang Liu,,University of Rochester,"60 Crittenden Blvd, APT 632",5853504836,,xliu@urmc.rochester.edu,"Variable Selection in Semiparametric Cure Models based on Penalized Likelihood Principle, with Application to Breast Cancer Clinical Trials",1,Xiang,,Liu,"Department of Biostatistics and Computational BiolotyUniversity of Rochester Medical Center",Yingwei,,Peng,"Department of Community Health and EpidemiologyQueen's University",Dongsheng,,Tu,"Department of Community Health and EpidemiologyQueen's University",Hua,,Liang,"Department of Biostatistics and Computational BiolotyUniversity of Rochester Medical Center",,,,,,,,,,,,,,,,,,,,,,,,,"Survival data with a sizable cure fraction are commonly encountered in some cancer clinicalresearches and the semiparametric proportional hazards cure model has been recently used to analyze such data.As seen in the analysis of data from a breast cancer clinical trial, a variable selection approach is needed toidentify important factors in predicting the cure status and risk of breast cancer recurrence. However no specificvariable selection method for the cure model is available. In this paper, we present a novel variable selectionapproach with penalized likelihood for the cure model. The estimation can be implemented easily by combiningthe computational methods for penalized logistic regression and the penalized Cox proportional hazards modelsin the EM algorithm. The proposed approach is illustrated on data from a breast cancer study. Monte Carlosimulations are conducted to evaluate the performance of the proposed method.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,TRUE,Variable subset selection/model selection,Survival analysis,,,,,,,01-Nov-10,xtang@uams.edu,,Xinyu Tang,,UAMS,"1 Children's Way, Slot 512-43",5013646616,,xtang@uams.edu,Weighted Cumulative Treatment Estimation for Sequentially randomized Clinical Trials in the Presence of Non-proportional Hazards,1,Xinyu,,Tang,University of Arkansas for Medical Sciences,Abdus,S,Wahed,University of Pittsburgh,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Proportional hazards model is widely used in survival analysis toadjust for baseline covariates. Although Lokhnygina and Helterbrand(2007) introduced Cox regression methods for two-stage randomizationdesigns, their method can only be applied to test the equality of twotreatment regimes that share the same maintenance therapy. Moreover,their method does not allow auxiliary variables to be included in themodel.  Besides, in many medical studies, the treatment effect is notconstant over time. Wei and Schaubel (2008) proposed an estimator ofcumulative treatment effects based on treatment-specific cumulativebaseline hazards using a stratified proportional hazards model. Theirmodel assumed proportionality within treatment group andnon-proportionality across treatment groups. We propose a similarapproach to estimate the cumulative treatment effect for treatmentregimes from sequentially randomized clinical trials. Comparisonsamong treatment regimes are performed by testing the ratio of theestimated cumulative hazards. A simulation study was conducted toevaluate the performance of the estimators and proposed tests.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Survival analysis,Adaptive design/adaptive randomization,,,,,,,15-Nov-10,xtong@princeton.edu,,XIN TONG,,PRINCETON UNIVERSITY,Dept. OF ORFE,908-331-2379,,xtong@princeton.edu,A ROAD to Classification in High Dimensional Space,3,Jianqing,,Fan,Princeton University,Yang,,Feng,Columbia University,XIN,,TONG,Princeton University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"For high-dimensional classification, naively performing the Fisherdiscriminant rule leads to poor results due to diverging spectra andnoise accumulation. Therefore, researchers proposed independence rulesand sparse independence rules. However, in biological applications,there are often a group of correlated genes responsible for clinicaloutcomes, and the use of the covariance information can significantlyreduce misclassification rates.  To materialize the gain based onfinite samples, a Regularized Optimal Affine Discriminant (ROAD) isproposed.  ROAD selects an increasing number of features as thepenalization relaxes. Further benefits can be achieved when ascreening method is employed to narrow the feature pool before hittingthe ROAD. An efficient constrained coordinate-wise descent algorithm(CCD) is also developed to solve the optimization problem associatedwith the ROAD.  Sampling properties of oracle type are established.Simulation studies and real data analysis support our theoreticalresults and demonstrate the advantages of the new classificationprocedure under a variety of correlation structures. A delicate resulton continuous piecewise linear solution path for the ROAD optimizationproblem at the population level justifies the linear interpolation ofthe CCD algorithm.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,High dimensional data,Machine learning,,,,,,,01-Oct-10,xue.li@va.gov,,XUE LI,Biostatistician,Hines VA Cooperative Studies Program Coordinating,5000 South 5th Ave,708-202-4992,708-202-7081,xue.li@va.gov,A 3-Level Mixed-Effects Location Scale Model with An Application In Ecological Momentary Assessment (EMA) Data,1,XUE,,LI,"VA Cooperative Studies Program Coordinating Center, Hines, IL",Don,,Hedeker,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In studies using Ecological Momentary Assessment (EMA), or other intensive longitudinal data collection methods, interest frequently centers on changes in the variances, both within-subjects (WS) and between-subjects (BS). For this, Hedeker et al. (2008) developed a 2-level mixed model that treats observations as being nested within subjects and allows covariates to influence both the WS and BS variance, beyond their influence on the mean.  However, in EMA studies, subjects often provide many responses within and across days. To account for the possible systematic day-to-day variation, we developed a 3-level mixed location scale model that treats observations within days within subjects, and allows covariates to influence the variance at the subject, day, and observation level (over and above their usual effects on means) using a log-linear representation.   We provide details of a marginal maximum likelihood solution (ML) and demonstrate how SAS PROC NLMIXED can be used to obtain ML estimates in an alternative parameterization of our proposed 3-level model. The accuracy of this approach using NLMIXED was verified by simulation studies.  Data from an adolescent smoking study using EMA was analyzed to demonstrate this approach.  The analyses clearly showed the benefit of the proposed 3-level model over the existing 2-level approach.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Longitudinal data,Hierarchical models,,,,,,,14-Oct-10,xw2144@columbia.edu,,Xiaoru,,Columbia University,"Room 1021, SSW, 1255 Amsterdam Ave.",6462752476,,xw2144@columbia.edu,Log-rank-type tests for equality of distributions in high-dimensional spaces,1,Xiaoru,,Wu,Columbia University Department of Statistics,Zhiliang,,Ying,Columbia University Department of Statistics,Tian,,Zheng,Columbia University Department of Statistics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Motivated by applications inhigh-dimensional settings, we propose a novel approach to testingequality of two or more populations by constructing a class ofintensity centered score processes. The resulting tests areanalogous in spirit to the well-known class of weighted log-rankstatistics that is widely used in survival analysis. The teststatistics are nonparametric, computationally simple and applicableto high-dimensional data. We establish the usual large sampleproperties by showing that the underlying log-rank score processconverges weakly to a Gaussian random field with zero mean under thenull hypothesis and with a drift under contiguous alternatives. Forthe Kolmogorov-Smirnov-type and the von Mises-type statistics, wealso establish consistency result for any fixed alternative. As apractical means to obtain approximate cutoff points for the teststatistics, a simulation based resampling method is proposed, withtheoretical justification given by establishing weak convergence forthe randomly weighted log-rank score process. The new approach isapplied to a study of brain activation measured by functionalmagnetic resonance imaging when performing two linguistic tasks andalso to a prostate cancer DNA microarray data set.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,TRUE,Nonparametric methods,High dimensional data,,,,,,,15-Nov-10,yabing_mai@merck.com,,Yabing Mai,,Merck,126 East Lincoln Ave,7325946081,,yabing_mai@merck.com,Statistical Testing on Non-Proportional Hazards,1,Yabing,,Mai,Merck Research Laboratories,Zhen,,Chen,University of Rochester,Amarjot,,Kaur,Merck Research Laboratories,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"When the proportional hazards (PH) assumption does not hold, the score test based on Cox PH model is no longer optimal. It has been found that this loss of efficiency can be substantial when the magnitude of non-proportionality in hazards is large. In order to find testing procedures that can account for the non-proportional (NPH) hazards and retain high efficiency in statistical inference, we implemented an extensive review on alternative methods for the following four classes: weighted Kaplan-Meier test, piecewise exponential model, gamma frailty model and weighted log-rank test. Performances of these methods were assessed in terms of asymptotic relative efficiency and empirical power for a variety of scenarios of non-proportionalities. The NPH methods under review are found to be superior to Cox PH model and log-rank test in most of the NPH scenarios. The relative efficiencies among the NPH methods are found to be associated with the types of non-proportionality. To further study the robustness of these NPH methods, we also compared them with Cox PH model and log-rank test under the PH assumption.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Survival analysis,Applied data analysis,,,,,,,15-Nov-10,YahyaD@BaylorHealth.edu,,Yahya Daoud,Biosstatistician,Baylor Health Care System,8080 North Central Expressway,734.330.1240,,YahyaD@BaylorHealth.edu,Cox Model To Evaluate the Comparative Effectiveness of Oral Antidiabetic Drugs on Chronic Kidney Disease,1,Yahya,AH,Daoud,Baylor Health Care System,Dunlei,,Cheng,Baylor Health Care System,Neil,,Fleming,Baylor Health Care System,Rustam,,Kudyakov,Baylor Health Care System,Andrew,,Masica,Baylor Health Care System,,,,,,,,,,,,,,,,,,,,,"Methods: Generalized propensity score (GPS) is used to estimate the inverse probability weight (IPW). IPW Cox hazard ratio models were utilized to evaluate time to events. A retrospective cohort of newly diagnosed type 2 Diabetes (T2D) patients was analyzed. Patients used four oral antidiabetic drugs (OAD) classes. CKD outcomes were new-onset proteinuria and eGFR falling below 60 ml/min/1.73m2. Results: 798 (proteinuria) and 977 (eGFR) patients qualified for outcome analyses. IPW Cox models were adjusted for demographics, initial OAD therapy and other baseline clinical data. Each year of metformin ([adjusted hazard ratio; 95% CI] 0.70; 0.60, 0.82) and THZ (0.70; 0.53, 0.92) exposure was associated with a reduced risk of developing proteinuria. Sulfonylurea exposure did not have a significant effect on incident proteinuria. Risk of eGFR dropping to < 60 ml/min/1.73m2 decreased with each year of metformin exposure (0.73; 0.63, 0.84). Neither THZ nor sulfonylurea impacted eGFR decline to the threshold. Conclusions: IPW Cox models were ideal for comparative effectiveness assessments in newly diagnosed T2D patients. Metformin and THZ use was associated with a lower risk for developing incident proteinuria versus sulfonylureas. Metformin use was also associated with protection against eGFR decline to < 60 ml/min/1.73m2 compared to THZs and sulfonylureas.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Health services research,Consulting,,,,,,,11-Oct-10,yair.goldy@gmail.com,,Yair Goldberg,,UNC-CH,"Department of Biostatistics,",267-632-3796,,yair.goldy@gmail.com,Statistical Inference for Q-Learning with Support Vector Regression Under Right Censoring,1,Yair,,Goldberg,UNC-CH,Michael,R,Kosorok,UNC-CH,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We develop a methodology for Q-learning when the total reward is aright-censored survival time. The approach involves an adaptation ofsupport vector regression applicable to right-censored outcomes. Weestablished consistency and finite sample upper bounds. This researchquestion has implications in the design of personalized medicinetrials in cancer and in other life-threatening diseases.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Survival analysis,Machine learning,,,,,,,16-Oct-10,yan3@student.gsu.edu,,Yueheng An,,Georgia State University,"750 COE 7th floor, 30 Pryor Street",6784695841,,yan3@student.gsu.edu,Empirical Likelihood Confidence Intervals for ROC Curves with Missing Data,1,Yueheng,,An,Georgia State University,Yichuan,,Zhao,Georgia State University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The receiver operating characteristic, or ROC curve, is widelyutilized to evaluate the diagnostic performance of a test, in otherwords, the accuracy of a test to discriminate normal cases fromdiseased case. In biomedical studies, we often meet with missing data.In this situation, the regular inference procedures cannot be applieddirectly. In this paper, random hot deck imputation is used to obtaina 'complete sample'.  After that, empirical likelihood (EL) confidenceintervals are constructed for the ROC curves.  The empiricallog-likelihood ratio statistics is derived whose asymptoticdistribution is proved to be a weighted chi-square distribution. Theresults of simulation study show that the EL confidence intervalsperform well in terms of the coverage probability and average lengthfor various sample sizes and respondent rates. The main contributionof this paper is the extension of the previous studies aboutapplication of empirical likelihood ratio principle to ROC curve analysis.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_poster,,,,FALSE,FALSE,FALSE,FALSE,Empirical likelihood,ROC analysis,,,,,,,15-Nov-10,yang@stt.msu.edu,,Lijian Yang,Dr.,Michigan State University,Department of Statistics and Probability,517 353 6369,,yang@stt.msu.edu,Spline confidence envelopes for covariance function in dense functional\longitudinal data,4,Guanqun,,Cao,Michigan State University,Li,,Wang,University of Georgia,Yehua,,Li,University of Georgia,Lijian,,Yang,Michigan State University,,,,,,,,,,,,,,,,,,,,,,,,,"We consider nonparametric estimation of the covariance function fordense functional data using tensor product B-splines. The proposedestimator is computationally more efficient than the kernel-basedmethods. We develop both local and global asymptotic distributions forthe proposed estimator, and show that our estimator is as efficient asan oracle estimator where the true mean function is known.Simultaneous confidence envelopes are developed based on asymptotictheory to quantify the variability in the covariance estimator and tomake global inferences on the true covariance. Monte Carlo simulationexperiments provide strong evidence that corroborates the asymptotictheory. A real data example on Tecator infrared spectroscopy data isalso provided to illustrate the proposed method.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Functional data analysis,Longitudinal data,,,,,,,21-Oct-10,yangmi@missouri.edu,,Min Yang,Associate Professor,University of Missouri,146 Middelbush Hall,573-882-4075,,yangmi@missouri.edu,Adaptive optimal designs for dose-finding studies,2,Tianhua,,Wang,University of Missouri,Min,,Yang,University of Missouri,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"A complication for studying optimal designs in dose-finding studies is that information matrices and optimal designs depend on the unknown parameters. Thus the challenge in designing an experiment for such a model is that one is looking for the best design with the aim of estimating the unknown parameters, and yet one has to know the parameters to find the best design. One way to solve this problem is multi-stage designs, in which one needs to add design points on top of an existing design. Little is known how to conduct such designs. In this talk, a new procedure of deriving multi-stage optimal designs will be presented. We will demonstrate this procedure on Sigmoid Emax model.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Adaptive design/adaptive randomization,Experimental design,,,,,,,12-Nov-10,yanpin@ufl.edu,,YANPIN WANG,,UNIVERSITY OF FLORIDA,387 MAGUIRE VLG. 04,3528710087,,yanpin@ufl.edu,Modeling Correlation of Longitudinal Data based on Partial Autocorrelation with Bayreian Methods,1,YANPIN,,WANG,UNIVERSITY OF FLORIDA,MICHAEL,,DANIELS,UNIVERSITY OF FLORIDA,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Many parameters and positive-definiteness are two major obstacles inestimating and modeling a correlation matrix for longitudinal data. Inaddition, when the longitudinal data is incomplete, incorrectlymodeling the correlation matrix often results in bias in estimatingmean regression parameters.  In this paper, we introduce regressionmodels for partial autocorrelations using Fisher's z-transform as thelink function.  The partial autocorrelations proposed can freely varyin the interval (-1, 1) while maintaining positive definiteness of thecorrelation matrix. We propose a class of priors for the regressioncoefficients of the transformed partial autocorrelations and examinetheir behavior via simulations.The approach is illustrated on datafrom a longitudinal clinical trail.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Bayesian methods,Longitudinal data,,,,,,,03-Nov-10,yansong@gmail.com,,Song,,Yan,708 Chappell Dr Apt F,9194573207,,yansong@gmail.com,Joint Modeling of Primary Binary Outcome and Longitudinal Data Measured at Informative Observation Times,1,Song,,Yan,Ph.D. Candidate,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In some biomedical studies, we are interested in the relationshipbetween a primarybinary outcome and longitudinal data profiles that are possiblymeasured at informative observationtimes. In this paper, we propose a joint model to naturally studytheir associations. The joint modelconsists of three components: (1) a semiparametric mixed model (SPMM)for longitudinal covariates;(2) a multiplicative frailty model for informative observation times;and (3) a logistic model forprimary binary outcomes. These three submodels are correlated viashared subject-specific randomeffects. We develop an EM algorithm for computing the maximumlikelihood estimates (MLEs) ofthe parameters, and use an EM-aided numerical differentiation methodto estimate the variancecovariancematrix of MLEs. Our method is evaluated by simulations and is appliedto a data setfrom a longitudinal study at the New York University Fertility Center,aiming to investigate therelationship between a primary pregnancy outcome and early -humanchorionic gonadotrophin(beta-HCG) profiles among patients who received the in-vitrofertilization treatment.Key words: EM method; Informative observation times; Joint model;Longitudinal data; Maximumlikelihood estimation; Semiparametric mixed model.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,TRUE,Longitudinal data,Joint models for longitudinal and survival data,,,,,,,11-Oct-10,yanxun.xu@rice.edu,,Yanxun Xu,,Rice University,7675 Phoenix Dr  APT446,8067897736,,yanxun.xu@rice.edu,BM-Map: Bayesian Mapping of Multireads for Next-Generation Sequencing Data,1,Yanxun,,Xu,"Department of Statistics, Rice University",Yuan,,Ji,"Department of Biostatistics, The University of Texas M. D. Anderson Cancer Center",Han,,Liang,"Department of Bioinformatics & Computational Biology, The University of Texas M. D. Anderson Cancer Center",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Next-generation sequencing (NGS) as the newly emerging approach to produce genome-wide data, enable quick access to the deep and comprehensive genetic information. However, the process of the deciphering the code is not an easy task. The prevailing data analysis approach deals well with reads mapped to a unique location, but a significant proportion of reads, which align to multiple genomic loci, named multireads, are not easily tracked and distributed because of the ambiguity. Currently, the industry standard is to discard the multireads and only focus on the well-defined unique reads although a lot of useful or even crucial information is inevitably missing during this process, especially for the genes with similar sequences. To refine the read mapping, we develop a Bayesian model that computes the probability of mapping a multiread to each competing location. The probabilities are used for downstream analyses, such as the quantification of gene expression. The Bayesian model takes full advantage of the information stored in the unique reads, including the rates of sequencing errors in the upstream analysis, the likelihood of hidden nucleotide variations (e.g., SNPs), and the expression level of competing loci. We show through simulation studies and a yeast RNA-Seq analysis that the Bayesian method yields better mapping than the current leading method.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_poster,,,,FALSE,FALSE,FALSE,FALSE,Bayesian methods,Genomics,,,,,,,12-Oct-10,yc632@columbia.edu,,Ken Cheung,,Columbia University,722 West 168th Street,2123053332,,yc632@columbia.edu,Stochastic approximation with virtual observations for dose-finding on discrete levels,1,Ying Kuen,,Cheung,Columbia University,Mitch,,Elkind,Columbia University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Phase I clinical studies are experiments in which a new drug is administered to humans to determine the maximum dose that causes toxicity with a target probability.  As such, phase I dose-finding is often formulated as a quantile estimation problem.  For studies with a biologic endpoint, it is common to define toxicity by dichotomising the continuous biomarker expression.  In this talk, we propose a novel variant of the RobbinsMonro stochastic approximation that utilises the continuous measurements for quantile estimation.  The RobbinsMonro method has seldom seen clinical applications, because it does not perform well for quantile estimation with binary data and it works with a continuum of doses, which are generally not available in practice.  To address these two practical issues, we formulate the dose-finding problem as root-finding for the mean of a continuous variable, for which the stochastic approximation procedure is efficient.  To accommodate the use of discrete doses, we introduce the idea of virtual observation that is defined on a continuous dosage range.  Our proposed method inherits the convergence properties of the stochastic approximation, and its computational simplicity.  Simulations based on real trial data show that our proposed method improves accuracy compared to the continual reassessment method and produces robust results under model misspecification.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Adaptive design/adaptive randomization,Clinical trials,,,,,,,14-Oct-10,yeh7@pitt.edu,,Yen-Chih,Doctoral Student,University of Pittsburgh,"130 DeSoto Street, #309D",412-726-8683,412-624-2183,yeh7@pitt.edu,Weighted GEE for Response-Adaptive Treatment Regimes in Two-Stage Longitudinal Studies,1,Yen-Chih,,Hsu,Department of Biostatistics/University of Pittsburgh,Abdus,S,Wahed,Department of Biostatistics/University of Pittsburgh,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Two-stage longitudinal studies are common in the treatment of mentaldiseases, such as chronic forms of major depressive disorders.Outcomes in such studies often consist of repeated measurements ofscores, such as the 24-item Hamilton Rating Scale for Depression,throughout the duration of therapy. Two issues that make the analysisof data from such two-stage studies different from standardlongitudinal data are: (1) the randomization in the second stage forpatients who fail to respond in the first stage; and (2) the drop-outof patients which sometimes occurs before the second stage. In thisarticle, we show how the weighted generalized estimating equations(GEE) can be used to draw inference for treatment regimes fromtwo-stage studies. Specifically, we show how to construct weights anduse them in the GEE to derive consistent estimators of regime effects,and compare them. Large-sample properties of the proposed estimatorsare derived analytically, and examined through simulations. Wedemonstrate our methods by applying them to a depression dataset.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Estimating equations,Longitudinal data,,,,,,,01-Nov-10,yehuali@gmail.com,,Yehua Li,Assistant Professor,University of Georgia,204 Statistics Building,706-542-8232,,yehuali@gmail.com,Efficient semiparametric regression for longitudinal data with nonparametric covariance estimation,1,Yehua,,Li,University of Georgia,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"For longitudinal data, when the within-subject covariance ismis-specified, the semiparametric regression estimator could loseefficiency. We propose a method that combines the efficientsemiparametric estimator with nonparametric covariance estimation. Theproposed method is robust against mis-specification of covariancemodels. We show that kernel covariance estimation provides uniformlyconsistent estimators for the within-subject covariance matrices, andthe semiparametric profile estimator with substituted nonparametriccovariance is still semiparametrically efficient. The finite sampleperformance of the proposed estimator is illustrated by simulationstudies. In an application to CD4 count data from an AIDS clinicaltrial, we further extend the proposed method to a functional analysisof covariance model.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Longitudinal data,Nonparametric methods,,,,,,,01-Nov-10,yek2@pitt.edu,,Yeonhee Kim,,University of Pittsburgh,3420 Louisa st.,412 526 2816,,yek2@pitt.edu,Classification Methods for Censored Longitudinal Biomarker data,1,Yeonhee,,Kim,University of Pittsburgh,Lan,,Kong,University of Pittsburgh,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In biomarker discovery studies, investigators are often interested in the classification performance of a new biomarker. However, statistical evaluation becomes complex if the marker is measured repeatedly over time and the measurement is censored due to a detection limit. Inappropriate handling of these types of data causes a poor discrimination result and biased estimation. In this paper, we propose two classification methods for longitudinal censored data. We develop the discrimination analysis method based on the new scores that are derived from the likelihood function of the linear mixed model. As an alternative classification method, we also consider the joint modeling of binary outcome and censored longitudinal data. The discrimination performance is evaluated by area under the receiver operation characteristic curve. We compare our methods to the simple imputation methods through simulation study. The proposed methods are applied to predict 90-day mortality of the patients with community acquired pneumonia.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Biomarkers/surrogate markers,Longitudinal data,,,,,,,12-Nov-10,yfliu@email.unc.edu,,Yufeng Liu,Associate Professor,University of North Carolina at Chapel Hill,"354 Hanes Hall, CB 3260",9198431899,,yfliu@email.unc.edu,Data-Adaptively Weighted Large Margin Classifiers,1,Yufeng,,Liu,University of North Carolina at Chapel Hill,Yichao,,Wu,North Carolina State University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Large margin classifiers have been shown to be very useful in manyapplications. Important examples of large margin classifiers includethe Support Vector Machine and Boosting. Despite their flexibility andability in handling high dimensional data, many large marginclassifiers have serious drawbacks when the data are noisy, especiallywhen there are outliers in the data. In this paper, we propose a newweighted large margin classification technique. The weights are chosenadaptively with data. The proposed classifiers are shown to be robustto outliers and thus are able to produce more accurate classificationresults.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Machine learning,High dimensional data,,,,,,,14-Oct-10,yh2s@virginia.edu,,YANQING HU,,UNIVERSITY OF VIRGINIA,"278 PEYTON CT, APT 6",434-327-7920,,yh2s@virginia.edu,A New Method of Balancing Treatments for Covariates and its Properties,1,YANQING,,HU,"Department of Statistics, University of Virginia",FEIFANG,,HU,"Department of Statistics, University of Virginia",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Balancing treatment allocation for influential covariates is criticalin clinical trials. This becomes increasingly important, as more andmore biomarkers are found to be associated with different diseases intranslational research (genomics, proteomics, and metabolomics).Stratied permuted block randomization and the minimization method(Pocock and Simon, 1975) are the two most popular methods in practice.However, the stratied permuted block randomization fails to achievegood overall balance when the number of strata is large, whereas theminimization method also suffers from the drawback of largewithin-strata imbalance. Moreover, the theoretical bases of mostcovariate-adaptive procedures in the literature remain elusive. Inthis paper, we propose a new covariate-adaptive design that is able tocontrol various types of imbalances. We show that the differencebetween treatment assignments is a positive recurrent Markov chainunder certain conditions. Therefore, this new procedure yields morebalanced allocation theoretically. The advantages of the proposedprocedure are also validated by extensive simulation studies. Our workprovides a potential direction for future research in this area.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Adaptive design/adaptive randomization,Clinical trials,,,,,,,14-Nov-10,yhu@bios.unc.edu,,Yijuan Hu,,"Department of Biostatistics, UNC-CH","3103 McGavran-Greenberg Hall, CB #7420",919-357-6882,,yhu@bios.unc.edu,A Robust Likelihood-Based Framework for Disease Association Studies with Copy Number Variation,1,Yijuan,,Hu,"Department of Biostatistics, University of North Carolina at Chapel Hill",Danyu,,Lin,"Department of Biostatistics, University of North Carolina at Chapel Hill",Wei,,Sun,"Department of Biostatistics, Department of Genetics, University of North Carolina at Chapel Hill",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The advent of SNP array platforms that assay both SNPs and CNVs, such as Affymetrix SNP 6.0 and Illumina 1M arrays, enable direct inference of CNV effects on diseases via population association studies. We propose a framework for studyingallele-specific CNV effects, including studying total CNV effects as a specialcase. We can accommodate the data format from both Affymetrix and Illumina arrays. Weconsider all commonly used study designs, includingcross-sectional, case-control, and cohort studies. We allow fordifferential errors which is prevalent in case-control studies inparticular. We formulate the effects of CNVs on the phenotypethrough flexible regression models, which allow variousgenetic mechanisms and gene-environment interaction. We constructappropriate likelihoods, specifically the retrospective likelihoodfor case-control studies, and these likelihoods may involvehigh-dimensional parameters. We establish the identifiability ofthe parameters and the consistency, asymptotic normality, andefficiency of the maximum likelihood estimators. We developefficient and reliable numerical algorithms and conduct extensivesimulation studies to assess the performance of the proposedmethod. We illustrate our method by applying it to the GWAS dataof Schizophrenia.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Statistical genetics,Genomics,,,,,,,08-Oct-10,yhu3@uky.edu,,Yanling Hu,,University of Kentucky,300 Alumni Drive,859-699-9351,,yhu3@uky.edu,Censored Empirical Likelihood with Over-determined Hazard-type Constraints,1,Yanling,,Hu,University of Kentucky,Mai,,Zhou,University of Kentucky,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Qin and Lawless (1994) studied the empirical likelihood method withestimating equations. They obtained very nice asymptotic resultsespecially when the number of estimating equations is larger thanthe number of parameters (the so-called over-determined case). Westudy here a parallel setup to Qin and Lawless but uses ahazard-type empirical likelihood function and hazard-type estimatingequations. The advantage of using hazard is that censored data canbe handled easily. We obtained similar asymptotic results for themaximum empirical likelihood estimator and the empirical likelihoodratio test, also for the over-determined case. Simulation studiesand two examples are provided to demonstrate the potentialapplication of the results.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Empirical likelihood,Survival analysis,,,,,,,31-Oct-10,yijiang@umich.edu,,Yijiang (John),,Li,"2222 Fuller Court, Apt. 1012A",3128044043,,yijiang@umich.edu,Approaches to Optimization in Micro-Simulation KPD Program,1,Yijiang (John),,Li,"Department of Biostatistics, The University of Michigan, Ann Arbor",Yan,,Zhou,"Department of Biostatistics, The University of Michigan, Ann Arbor",John,D.,Kalbfleisch,"Department of Biostatistics, The University of Michigan, Ann Arbor",Peter,X.K.,Song,"Department of Biostatistics, The University of Michigan, Ann Arbor",,,,,,,,,,,,,,,,,,,,,,,,,"This talk will focus on the computational aspect of themicro-simulation KPD program.  Approaches required for constrainedgraphic optimization will be discussed in detail.  In particular, Inparticular, integer programming recipes are utilized in thedevelopment of software that implements statistical methods concerningthe generation of the pool of incompatible donor-recipient pairs,chance of success in virtual cross-match, chance of success in labcross-match, and prediction of graft survival. Numerical illustrationon the software will be presented during the presentation.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Health policy applications,Computational methods,,,,,,,15-Nov-10,yili@jimmy.harvard.edu,,Yi Li,,Harvard University,"44 Binney St, cls 11007",617-632-5134,,yili@jimmy.harvard.edu,Survival analysis with ultra-high-dimensional covariates: identifying predictive genes for cancer survival,2,Dave,,Zhao,Harvard,Yi,,Li,Harvard,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Current variable selectors are unable to handle situations where the number of covariates under consideration is ultra-high.  Consider a  motivating clinical study of  170  myeloma patients, each with  measurements on the expression level of more than 25000 genesas well as progression free survival. The dataset defies analysiseven with regularized regression. Some remedies have been proposed for the linear model and for generalized linear models, but there are few solutions in the surival setting and, to our knowledge, no theoretical justifications. In this paper we propose a method for handling ultra-high-dimensional covariates in the analysis of censored data and give theoretical support. Simulation studies show that our method performs well even under model misspecification. We apply theproposed procedure to analyze the aforementioned  myeloma study and have identified biologically important and predictive genes.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Variable subset selection/model selection,Survival analysis,,,,,,,26-Oct-10,Yimei.Li@stjude.org,,Yimei Li,,St. Jude Children's research hospital,56 S. Arcadian Circle,919-824-6161,,Yimei.Li@stjude.org,TwinMARM: Two-stage Multiscale adaptive regression methods for twin neuroimaging data,1,Yimei,,Li,"Department of Biostatistics,St. Jude Children's research Hospital",Hongtu,,Zhu,"Department of Biostatistics,University of North Carolina, Chapel Hill",John,H,Gilmore,"Department of Psychiatry,University of North Carolina, Chapel Hill",Martin,,Styner,"Department of Psychiatry,University of North Carolina, Chapel Hill",,,,,,,,,,,,,,,,,,,,,,,,,"Twin imaging studies have been valuable for understanding the interactions of environmental and genetic influences on brain structure and function. We will introduce a two-stage multiscale adaptive regression method (TwinMARM) for spatial and adaptive analysis of twin neuroimaging and behavior data. TwinMARM consists of two stages and its each stage is a spatial, hierarchical, and adaptive procedure. The first stage is to establish the association between twin neuroimaging data and a set of covariates of interest, such as age and gender. The second stage is to reveal the environmental and genetic influences on brain structure and function.  In each stage, TwinMARM is to build hierarchically nested spheres with increasing radii at each location, to analyze all observations in the sphere of each voxel using weighted probability distributions, and to use the consecutively connected sphere across all voxels to capture spatial dependence among imaging observations. Simulation studies shows that our TwinMARM significantly outperforms the voxel-wise approach, which is to independently run structural equation model at each location (called voxel) and then apply multiple comparison methods. We apply our methods to the detection of statistical significance of the effects of genetic variation on the brain structure in a neonatal twin study.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Imaging,Estimating equations,,,,,,,09-Nov-10,ying.yang@fda.hhs.gov,,Ying Yang,,FDA,10903 New Hamphsire Ave.,301-796-7595,,ying.yang@fda.hhs.gov,Blinding Assessment in Randomized Controlled Trial: A Regulatory Reviewers Perspective,1,Ying,,Yang,FDA,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The issue of blinding has been addressed as a design technique to minimize bias in the International Conference on Harmonization (ICH) E9. However blinding can be very hard to establish and maintain. Methods of assessing and reporting the effectiveness of blinding are debatable and no clear guidance for analyzing and reporting the blinding exits. This presentation will review the current available methods for analyzing and reporting the blinding.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,TRUE,Agreement,Clinical trials,,,,,,,04-Oct-10,yingy@email.unc.edu,,ying yuan,,Department of Statistics University of North Carol,113 Britt court,9192593858,,yingy@email.unc.edu,Local Polynomial Regression for Symmetric Positive Definite Matrices,1,ying,,yuan,"Department of Statistics and Operations ResearchUniversity of North Carolina at Chapel Hill",Hongtu,,Zhu,"Department of Biostatistics University of North Carolina at Chapel Hill",Weili,,Lin,"Department of RadiologyUniversity of North Carolina at Chapel Hill",J,S,Marron,"Department of Statistics and Operations ResearchUniversity of North Carolina at Chapel Hill",,,,,,,,,,,,,,,,,,,,,,,,,"Local polynomial regression has received extensive attention for thenonparametric estimation of regression functions when both  responseand covariate are in Euclidean space. However, little has been donewhen the response is in a Riemannian manifold. We develop an intrinsiclocal polynomial regression (ILPR) and its associated ILPR estimatefor the analysis of symmetric positive definite (SPD) matrices asresponses that lie in a Riemannian manifold with covariate inEuclidean space. The primary motivation and application of theproposed methodology are in computer vision and medical imaging. Weexamine two commonly used metrics including the Riemannian metric andthe Log-Euclidean metric on the space of SPD matrices. Under eachmetric, we develop an associated cross-validation bandwidth selectionmethod, and derive the asymptotic bias, variance, and normality of theintrinsic local constant and local linear estimators and compare theirasymptotic mean square errors. Simulation studies are further used toompare the estimators under the two metrics and examine their finitesample performance. We apply our method to detect the diagnosticdifferences by smoothing diffusion tensors along fiber tracts in astudy of human immunodeficiency virus.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Nonparametric methods,Imaging,,,,,,,15-Nov-10,yiq@amgen.com,,yi qian,senior biostatistics manager,Amgen,one amgen center dr.,8054477030,,yiq@amgen.com,Bayesian Joint Modeling of Longitudinal and Event-Time Data in Clinical Trials,1,Yi,,Qian,"US Clinical Development Biostatistics, Amgen",Jeesun,,Jung,"School of Medicine, Indiana University",Deukwoo,,Kwon,"Division of Cancer Epidemiology & Genetics, NCI",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Joint modeling of longitudinal and event-time data is of increasinginterest in clinical trials, especially cancer trials where thelongitudinal outcome, for example, the quality of life measures orbiomarkers, could be associated with the time to the event ofinterest. Here we propose a Bayesian approach for the joint analysisof longitudinal and event-time data such as competing risks failuretime and recurrent events time data, and we incorporate copula toallow for the flexibility of the dependence structure of the randomprocesses in the joint model. We apply the proposed approach in theanalysis of the clinical trial data, and also conduct simulationstudies to evaluate its operating characteristics including therobustness of the estimates.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Clinical trials,Joint models for longitudinal and survival data,,,,,,,15-Nov-10,yiwu2008@u.northwestern.edu,,YI WU,,Northwestern University,800 Hinman Ave Apt 507,2244202935,,yiwu2008@u.northwestern.edu,Flexible Group Sequential Clinical Trials Using Sample Size Re-estimation,1,YI,,WU,Northwestern University,Ajit,C.,Tamhane,Northwestern University,Cyrus,,Mehta,"Cytel, Inc.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Cui, Hung and Wang (1999) (CHW) gave a simple modification of the teststatistics in a group sequential clinical trial that use the samepre-planned critical boundaries and still maintain  the type I errorrate at a pre-assigned level alpha.  The CHW statistics are not functionsof the sufficient statistics , i.e., the sample means. We study twoimprovements of their method. First, we consider test statistics thatare functions of the sample means and show how to alter the criticalboundaries under different sample size re-estimation rules to maintainthe type I error rate at the pre-assigned level alpha. We study viasimulation the power gains due to using sample mean based teststatistics. Second, the CHW statistics have a restriction that samplesizes for all the groups being re-estimated in the same proportion asthe original sample sizes. By using a different family of weightedtest statistics, we remove this restriction which permits arbitraryre-estimated sample sizes for different group thus making the adaptivegroup sequential clinical trial design more flexible. The powerperformance of this family of test statistics is under study.",FALSE,FALSE,,FALSE,FALSE,TRUE,T2,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Adaptive design/adaptive randomization,Clinical trials,,,,,,,28-Oct-10,yizhang78@gmail.com,,Yi Zhang,,Biostatistician,603 Ivyshaw Rd,919-9467259,,yizhang78@gmail.com,Statistical Methods for Evaluating Diagnostic Accuracy of Incomplete Multiple Tests,1,Yi,,Zhang,"Department of Biostatistics, University of North Carolina at Chapel Hill",Haitao,,Chu,"Division of Biostatistics,University of Minnesota",Donglin,,Zeng,"Department of Biostatistics, University of North Carolina at Chapel Hill",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Accurate diagnosis of a disease condition such as a sub-type of a cancer is often the first step toward its control and prevention. When a gold standard measurement is not available or too invasive, disease status is usually measured by multiple imperfect diagnostic tests. However in many studies, some subjects may only be measured by a subset of diagnostic tests and the missing probabilities may depend on the unknown disease status. In this paper, we propose novel statistical methods based on EM algorithm to evaluate incomplete multiple imperfect diagnostic tests under the missing at random (MAR) and missing not at random (MNAR) assumptions. We apply the proposed methods to a real data set from the NCI Colon Cancer Family Registry (C-CFR) on diagnosing MSI for hereditary nonpolyposis colorectal cancer (HNPCC) and estimate diagnostic accuracy (i.e. sensitivities and specificities), prevalence, and differential missing probabilities for the 11 biomarker tests. Simulations are conducted to evaluate the performance of our methods. Advantages and limitations of our methods are examined. Motivations of future research topics are also discussed.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,TRUE,Diagnostic and screening tests,Missing data,,,,,,,14-Nov-10,ykim7stat@kangwon.ac.kr,,Young-Ju Kim,,Kangwon National University,Hyo-ja dong,82-33-250-8431,,ykim7stat@kangwon.ac.kr,Nonparametric estimation in semivarying  coefficient model,1,Young-Ju,,Kim,Kangwon National University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The semivarying coefficient models are natural extensions of classical linear models and become popular in data analysis for its flexibility and interpretability. We employ a penalized likelihood estimation method for estimating both regression parameters and nonparametric varying coefficient functions simultaneously in the semivarying coefficient model. Adapting a lower-dimensional approximation, smoothing parameter selections are dicussed and Bayesian confidence intervals are derived. The methods are illustrated with simulations and real data analysis.",FALSE,FALSE,,FALSE,FALSE,FALSE,,contributedposter,,,,FALSE,FALSE,FALSE,FALSE,Nonparametric methods,Computational methods,,,,,,,15-Nov-10,ykim96@uic.edu,,Yoonsang Kim,,University of Illinois at Chicago,40 Adams Street #2,3193515329,,ykim96@uic.edu,Random-effects regression models for analyzing asbestos data with heteroscedastic errors,1,Yoonsang,,Kim,University of Illinois at Chicago,Dulal,,Bhaumik,University of Illinois at Chicago,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We present some statistical methodologies for analyzing airborne asbestos fiber counts, amosite fibers measured by Transmission Electron Microscopy (TEM), and interval estimation for true concentrations. It is commonly observed that the variability of asbestos measurements increases with the true concentration levels. We also observe large coefficient of variations at low-level concentrations and approximately constant coefficient of variations at higher levels.  In order to account for the heteroscedasticity and inter-laboratory variation in the data, we use a two-component random-effects model as well as a gamma random-effects regression model. We derive calibration confidence intervals for true concentrations based on these two models. The performances of our proposed methodologies and calibration confidence intervals are studied via simulation.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Environmental and ecological applications,Random effects,,,,,,,12-Nov-10,ylai@gwu.edu,,Yinglei Lai,,The George Washington University,2140 Pennsylvania Ave. NW,(202) 994-6664,(202) 994-6917,ylai@gwu.edu,Concordant gene set enrichment analysis of two large-scale expression data sets,1,Yinglei,,Lai,The George Washington University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The recent large-scale technologies like microarrays and RNA-seq allow us to collect genome-wide expression profiles for biomedical studies.  Genes showing significant differential expression are potentially important biomarkers.  A gene set enrichment analysis enables us to identify groups of genes (e.g. pathways) showing coordinate differential expression.  Genes and gene sets showing consistent behavior in two related studies can be of great biological interest.  However, since the sample sizes are usually small but the numbers of genes are large, it is difficult to identify truly differentially expressed genes and determine whether a gene or a gene set behaves concordantly in two related studies.  We have recently shown that the mixture model based approach can be an efficient solution for the concordant analysis of differential expression in two two-sample large-scale expression data sets.  The advantage of the mixture model based approach is that the probability of a particular behavior (up-regulated or down-regulated) can be estimated for a given gene.  Thus, it is feasible to address how likely this gene shows a concordant behavior in both data sets.  In this study, we extend this approach for the concordant gene set enrichment analysis.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Microarray analysis,Genomics,bioinformatics,,,,,,02-Nov-10,ymunoz@mtu.edu,,Yolanda Munoz Maldonado,Assistant Professor,Michigan Tech Unviersity,SAMSI,(979) 219 2489,(919) 685-9360,ymunoz@mtu.edu,Sample Size Calculation for Comparison of Two Functional Means,1,Yolanda,,Munoz Maldonado,Michigan Tech University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Sample size calculation is a key component in designing experiments.It has both economic and ethical implications in experimental design.A too small sample size can lead to a lack of power in detectingdepartures from the null hypothesis, whereas a large sample size mayexpose experimental units to unnecessary risks and/or becost-prohibitive. Despite its importance, only a few modificationshave been made over the years in the way that statisticians calculatesample size even though the complexity of research questions hasdramatically increased. An example of this, is the lack of statisticalmethodology for sample size calculation for designing experiments whenthe data has functional form. This research develops a methodology tocalculate the sample size when it is of interest to compare thefunctional means of two groups of curves. Employing a u-statistic, theauthor develops a two sample t-test for comparing the equality of twomean functions. The methodology is exemplified by calculating thesample size necessary to compare the ganglioside profiles in groups ofold and young rats. The test power is explored with a Monte Carlo study.",FALSE,FALSE,,FALSE,FALSE,TRUE,ENAR Diversity Workshop,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Functional data analysis,Experimental design,,,,,,,10-Nov-10,yning@jhsph.edu,,Yang Ning,student,"Department of biostatistics, JHU","15 Charles Plaza, Apt 803",4437990939,,yning@jhsph.edu,Adjustment to the pseudolikelihood,1,Yang,,Ning,"Department of Biostatistics, Johns Hopkins Bloomberg School of Public Health, Baltimore, Maryland, USA",Kung-Yee,,Liang,"President, National Yang-Ming University, Taiwan",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In a parametric model, the parameters are typically partitioned as theparameters of interest and the nuisance parameters. It is well knownthat the validity of the inference on the parameters of interest couldbe undermined due to the presence of nuisance parameters. In thelikelihood based framework, several authors have suggested that theinference should be based on the modified or adjusted profilelikelihood. However, in many cases, the profile likelihood itself iscomputationally difficult to derive or a convenient consistentestimator for the nuisance parameters is available. The inferencebased on the so called pseudo likelihood is more natural from bothpractical and theoretical point of view (Gong and Samaniego, 1981).Unfortunately, the modification of the pseudo likelihood in thepresence of nuisance parameters is rarely mentioned in the literature.The purpose of the current paper is to suggest a simple modificationof the pseudo likelihood with the desired property. The modificationis still novel even if we restrict our attention to the profilelikelihood which could be viewed as a specific example of the pseudolikelihood. Finally, the advantage of the modification is confirmed byseveral examples and the simulation studies.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Other,Estimating equations,likelihood theory,,,,,,15-Oct-10,yongpark@umich.edu,,Yong Seok Park,,Biostatistics/University of Michigan,1667 McIntyre ST,734-272-5547,734-763-2215,yongpark@umich.edu,Pointwise Nonparametric MLE of Stochastically Ordered Survivor Functions,1,Yong Seok,,Park,Biostatistics/University of Michigan,Jeremy,MG,Taylor,Biostatistics/University of Michigan,Jack,D,Kalbfleisch,Biostatistics/University of Michigan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In this paper, we consider estimators of survivor functions fromgroups of observations with right censored data when the groups aresubject to a stochastic ordering constraint. Many methods andalgorithms have been proposed in the literature to estimatedistribution functions under this restriction, however, none of theseestimators has satisfactory properties when the observations arecensored.  We propose the pointwise constrained NPMLE (pointwiseC-NPMLE), which is defined at each time t by the estimates of thesurvivor functions subject to constraints at time t only.  We alsopropose an efficient method to obtain the estimators. The consistencyand the asymptotic distribution of the estimators are presented.Simulation studies show better small and large sample propertiescompared with alternative estimators. An example using prostate cancerdata is provided to illustrate the method.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,TRUE,Constrained estimation/order restricted inference,Survival analysis,,,,,,,08-Nov-10,yongtao.guan@yale.edu,,Yongtao Guan,,Yale University,60 College Street,203-785-6125,,yongtao.guan@yale.edu,Estimating individual-level risk in spatial epidemiology using spatially aggregated information on the population at risk,1,Yongtao,,Guan,Lancaster University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We propose a novel alternative to case-control sampling for the estimation of individual-level risk in spatial epidemiology. Our approach uses weighted estimating equations to estimate regression parameters in the intensity function of an inhomogeneous spatial point process, when information on risk-factors is available at the individual level for cases, but only at a spatially aggregated level for the population at risk. We develop data-driven methods to select the weights used in the estimating equations and show through simulation thatthe choice of weights can have a major impact on e±ciency of estimation. We develop a formal test to detect non-Poisson behaviour in the underlying point process and assess the performance of the test using simulations of Poisson and Poisson cluster point processes. We apply our methods to data on the spatial distribution of childhood meningococcal disease cases in Merseyside, UK between 1981 and 2007.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Epidemiologic methods,Spatial/temporal modeling,,,,,,,12-Nov-10,yoon@hcp.med.harvard.edu,,Frank B Yoon,Research Fellow,Harvard Medical School,180 Longwood Ave Bldg A,617-432-0006,,yoon@hcp.med.harvard.edu,Joint models and tests of multiple non-commensurate outcomes,1,Frank,B,Yoon,Harvard Medical School,Stuart,R,Lipsitz,Harvard Medical School,Garrett,M,Fitzmaurice,"Harvard Medical SchoolHarvard School of Public Health",Nicholas,J,Horton,Smith College,Sharon-Lise,T,Normand,"Harvard Medical SchoolHarvard School of Public Health",,,,,,,,,,,,,,,,,,,,,"Multiple outcomes in randomized and observational studies inpsychiatry are often non-commensurate, for example, measured ondifferent scales or constructs.  Standard multiplicity adjustments cancontrol for Type I error, though such procedures can be overlyconservative when the outcomes are highly correlated.  Recentliterature demonstrates that joint tests can capitalize on thecorrelation among the outcomes and are more powerful than univariateprocedures using Bonferroni adjustments.  However, joint tests arelittle used in practice, perhaps, due in part, to the specification ofa joint model for the non-commensurate outcomes.  Additionally,software routines to estimate joint models have not been widelypublicized despite their wide availability.  This work presents anevaluation of likelihood and quasi-likelihood methods for jointlytesting treatment effects in a simulation study.  Applications to aclinical trial and an observational study of mental health careillustrate their benefits. Adoption of these methods will lead to moreefficient psychiatric clinical trials.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,TRUE,Multivariate methods,Clinical trials,,,,,,,03-Nov-10,york60@gmail.com,,Simina M Boca,,Johns Hopkins Bloomberg School of Public Health,615 N. Wolfe St.,2177144736,,york60@gmail.com,A decision-theory approach to interpretable set analysis for high-dimensional data,1,Simina,M,Boca,Johns Hopkins Bloomberg School of Public Health,Hector,,Corrada Bravo,University of Maryland at College Park,Jeffrey,T,Leek,Johns Hopkins Bloomberg School of Public Health,Giovanni,,Parmigiani,Dana Farber Cancer Institute and Harvard School of Public Health,,,,,,,,,,,,,,,,,,,,,,,,,"A ubiquitous problem in the analysis of high-dimensional data is to identify predefined sets of features that are enriched for features that show an association of interest. In this situation, inference is performed on the sets, not the individual features. Here we discuss an approach to the analysis of sets which results from a decision-theoretic framework. We also define a new false discovery rate called the atomic false discovery rate for non-overlapping sets. We show that the loss function which weights the number of false discoveries and the number of missed discoveries has a simple analytic solution based on thresholding the atomic false discovery rate at a fixed level.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Genomics,Bayesian methods,,,,,,,29-Oct-10,ypan5@sph.emory.edu,,Yi Pan,,Emory University,1518 Clifton Rd,404-727-8210,,ypan5@sph.emory.edu,Evaluating the Agreement between Two Observers with Replicated Quantitative Measurements Using the Coefficient of Individual Equivalence,1,Yi,,Pan,Emory University,Jingjing,,Gao,"Center for Comprehensive Informatics, Emory University",Michael,,Haber,Emory University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The coefficient of individual equivalence is a scaled measure of agreement between two observers making replicated readings on each subject. It compares the observed disagreement between the observers to the expected disagreement under individual equivalence. Individual equivalence of observers requires that for each study subject, the conditional distributions of the readings of the observers are identical. Under individual equivalence it does not matter, which observer is making a particular reading on a given subject. Both nonparametric and parametric methods will be introduced to estimate the coefficient as well as its standard error. The new approach will be illustrated using data from a study comparing two non-invasive techniques for measuring carotid stenosis to an invasive gold standard. The performance of new coefficient will be evaluated via simulations.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Agreement,Biopharmaceutical research,,,,,,,12-Oct-10,yqzhao@email.unc.edu,,Yingqi,,Zhao,11102 Spring Meadow Dr,9192659537,,yqzhao@email.unc.edu,Detecting Disease Surveillance Using Local Spatiotemporal Methods,1,Yingqi,,Zhao,"Department of Biostatistics,University of North Carolina at Chapel Hill",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"A real-time surveillance method is developed with emphasis on rapid and accurate detection of emerging outbreaks. We develop a model with relatively weak assumptions regarding the latent processes generating the observed data, ensuring a robust prediction of the spatiotemporal incidence surface. Estimation occurs via a local linear fitting combined with day-of-week effects, where spatial smoothing is handled by a novel distance metric that adjusts for population density.  Detection of emerging outbreaks is carried out via residual analysis. Both daily residuals and AR model-based de-trended residuals are used for detecting abnormalities in the data given that either a large daily residual oran increasing temporal trend in the residuals signals a potentialoutbreak, with the threshold for statistical significance determined using a resampling approach.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Infectious disease models,Environmental and ecological applications,,,,,,,13-Nov-10,ythuang@hsph.harvard.edu,,Yen-Tsung Huang,,Harvard School of Public Health,"I-1406W, 665 Huntington Avenue",617-777-0165,,ythuang@hsph.harvard.edu,Gene Set Analyses Using the Variance Component Test,1,Yen-Tsung,,Huang,Harvard University,Xihong,,Lin,Harvard University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Gene set analyses have become increasingly important in geneticresearch given the belief that most diseases are contributed jointlyby alterations of numerous genes. How to perform gene set analyses onthe high-dimensional gene expression microarray data with small samplesize remains a challenging task. Here we developed a score test forthe variance component in the multivariate linear regression setting.With multiple gene expression values as the continuous and correlatedoutcomes, the number of regression coefficients for the predictor isusually greater than the sample size. We develop a variance componenttest for testing for the gene set effects under linear regressionmodels by assuming a common distribution for regression coefficientsand assuming a working covariance matrix to account for correlationamong genes. The null distribution of the test statistics can begenerated via permutation and approximated by the scaled Chi-squaredistribution. We showed using simulation that the type I error isprotected under different choices of the working covariance matrix andthe power is improved as the working covariance approaches the truecovariance. In both simulation data and a published diabetes dataset,our test outperforms the commonly used approach, gene-set enrichmentanalysis.",FALSE,FALSE,,FALSE,FALSE,FALSE,,contributedposter,,,,FALSE,FALSE,FALSE,FALSE,Genomics,Microarray analysis,gene set analysis,,,,,,13-Nov-10,yuanji@mdanderson.org,,Yuan Ji,Associate Professor,UT MD Anderson Cancer Center,1400 Pressler Street,713-794-4153,,yuanji@mdanderson.org,Bayesian network models with application to high-throughput  sequence data,3,Riten,,Mitra,UT MD Anderson Cancer Center,Peter,,Mueller,UT Austin,Yuan,,Ji,UT MD Anderson Cancer Center,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We propose a class of Bayesian hierarchical network models describing dependent structure in a graph. We apply the models to the next-generation sequence data for histone modifications. There are 39 different types of histone modifications with a complex dependent relationship. We construct discrete Markov random field models with each type of histone modification being a node in the random field. The dependence between histone modifications is modeled as an auto-logistic regression. We incorporate covariates in the regression to accommodate differential structure in the dependence. The computation is carried out using Markov chain Monte Carlo simulations. Posterior graphs will be presented with false discovery control, thanks to the full probabilistic inference.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,High dimensional data,Bayesian methods,Next Generation Sequencing Data,,,,,,09-Oct-10,yuan-wu@uiowa.edu,,Yuan Wu,,Univeristy of Iowa,216 hawkeye court,3194006955,,yuan-wu@uiowa.edu,Partially Monotone Tensor Spline Estimation of the Joint Distribution Function with Bivariate Current Status Data,1,Yuan,,Wu,"Department of Epidemiology,University of Iowa",Ying,,Zhang,"Department of Biostatistics,University of Iowa",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The analysis of the joint distribution function with bivariate currentstatus data  is a very challenging problem.This paper develops a tensor spline-based sieve maximum likelihoodestimation method to estimate the joint distribution function withbivariate current status data. The I-spline basis functions are usedin approximating the joint distribution function in order to simplifythe numerical computation of the constrained maximum likelihoodestimation problem. The generalized gradient projection algorithm isused to compute the constrained optimization problem. The simulationstudies with moderate sample sizes are carried out to demonstrate thatthe finite sample performance of the proposed estimator is generallysatisfactory.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Survival analysis,Nonparametric methods,,,,,,,15-Nov-10,yuehui.2.wu@gsk.com,,Yuehui Wu,Principal Statistician,GSK,2517 Condor Dr.,6109174264,,yuehui.2.wu@gsk.com,Adaptive optimal designs for correlated binary responses,1,Yuehui,,Wu,GlaxoSmithKline,Valerii,V,Fedorov,GlaxoSmithKline,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The goal of dose-finding trials is to locate the best dose to be tested in the later phase trials. A best dose can be defined as the dose with high efficacy and acceptable toxicity. We proposed an adaptive design based on optimal design framework to locate the best dose when there are two correlated binary endpoints: efficacy and toxicity. Bivariate probit model is assumed for it is a parsimonious model which covers many dose-response relationship scenarios.  Locally, two-stage, and fully adaptive optimal designs are discussed for single drug and drug combination studies under various constraints.  Simulation studies are critical in conducting adaptive designs and we collaborated with professional software company to develop a nice user-friendly interface for statisticians to run the simulations with point and click features which is a good example to popularize an innovative design within project statisticians. Both the methods and examples using the software will be presented.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Adaptive design/adaptive randomization,Biopharmaceutical research,,,,,,,31-Oct-10,yunbai@umich.edu,,Yun Bai,,University of Michigan,"7752 montgomery Rd, unit 70",734-660-4566,,yunbai@umich.edu,An Efficient Composite Likelihood Approach to Spatial-Clustered Data,1,Yun,,Bai,"Biostatistics Department, University of Michigan",Peter,X.-K.,Song,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Spatial-clustered data are frequently encountered in epidemiologystudies where subjects are sampled within geographic units. Besidesthe within-cluster correlations, it is also critical to account forthe between-cluster spatial variations in making valid statisticalinference. However, when the number of spatial locations is large,likelihood based methods often require either high-dimensionalintegrations or large matrix manipulations. To circumvent thisdifficulty, we proposed an efficient composite likelihood approach toanalyze such data. We build two sets of pairwise composite estimatingequations based on within- and between-group pairs separately. Then wejoin them into a quadratic inference function through a weight matrixfor estimation. Simulation experiments show that our method improvesstatistical efficiency compared to conventional composite likelihoodmethods for Gaussian and binary data. The method is then applied toanalyze the prevalence of malaria among a sample of village childrenin Gambia.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Estimating equations,Random effects,,,,,,,11-Oct-10,yunlong-xie@uiowa.edu,,YUNLONG XIE,,Department of Statistics and Actuarial Science,"241 Schaeffer Hall, The University of Iowa",319-335-2009,,yunlong-xie@uiowa.edu,Methods for Determining the Order of Antedependence in Binary Longitudinal Data,1,YUNLONG,,XIE,"Department of Statistics and Actuarial ScienceThe University of IowaIowa City, IA 52242",Dale,L.,Zimmerman,"Department of Statistics and Actuarial ScienceThe University of IowaIowa City, IA 52242",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Antedependence (AD) of order p, also known as the Markov property of order p, is a property of index-ordered random variables in which each variable, given at least p immediately preceding variables, is independent of all further preceding variables. Zimmerman and Nunez-Anton (2010) present statistical methodology for fitting and performing inference for AD models for continuous (primarily normal) longitudinaldata. But analogous AD-model methodology for binary longitudinal data has not yet been developed. In this article, we present methods for determining the order of antedependence of binary longitudinal data. Specifically, we derive the likelihood ratio test, score test, and Wald test for pth-order antedependence against the unstructured (saturated) multinomial model. Simulation studies show that the likelihood ratio testperforms better than the others for samples of small and moderate size. We extend the tests for use in testing for pth-order antedependence against qth-order antedependence, where q > p, and we develop a penalized likelihood method for determining variable orderantedependence structure. The methods are illustrated using two data sets.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Longitudinal data,Categorical data,,,,,,,15-Nov-10,yy@math.asu.edu,,Yan Yang,Asst Prof,Arizona State University,School of Mathematical and Statistical Sciences,480-965-6475,,yy@math.asu.edu,Conditional Decomposition Diagnostics for Regression Analysis of Zero-inflated and Left-censored Data,1,Yan,,Yang,Arizona State University,Douglas,,Simpson,University of Illinois,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Health and safety studies that entail both incidence and magnitudeof effects produce semi-continuous outcomes in which the responseis either zero or a continuous positive value. Zero-inflatedleft-censored models typically employ latent mixture constructions toallow different covariate processes to impact the incidence versus themagnitude. Assessment of the model, however, requires a focus on theobservable characteristics. We employ a conditional decompositionapproach in which the model assessment is partitioned into twoobservable components: the adequacy of the marginal probability modelfor the boundary value, and the adequacy of the conditional model forvalues strictly above the boundary. A conditional likelihooddecomposition facilitates the statistical assessment. Forcorresponding residual and graphical analysis, the conditional meanand quantile functions for events above the boundary and the marginalprobabilities of boundary events are investigated. Large samplestandard errors for these quantities are derived for enhancedgraphical assessment, and simulation is conducted to investigate thefinite-sample behavior. The methods are illustrated with data from twohealth-related safety studies. In each case the conditionalassessments identify the source for lack of fit of the previouslyconsidered model and thus lead to an improved model.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Hierarchical models,Nonlinear models,zero-inflated model,,,,,,15-Nov-10,yy62@duke.edu,,Yeonjoo Yi,,Duke University,15305 Rose Garden Lane,5049757888,,yy62@duke.edu,Proportional hazards regression with missing covariates,1,Yeonjoo,,Yi,Duke University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"When survival times with covariates are modeled using the Cox proportional hazards regression model, researchers often encounter missing covariates. In this study, the missing data mechanism depends on the failure indicator, the observed time as well as the observed covariates. Tsai (2009) suggests pseudo-partial likelihood for proportional hazards models. Also, Luo, Tsai, and Xu (2009) propose pseudo-partial likelihood for proportional hazards models with missing covariates. The current study investigates the performance of this approach for data collected with different censoring rates, different sample sizes, and different levels of missing data.  Simulations are used to assess the performance of the proportional hazards model in terms of bias and coverage.",FALSE,FALSE,,FALSE,FALSE,FALSE,,contributedposter,,,,FALSE,FALSE,FALSE,FALSE,Missing data,Survival analysis,,,,,,,09-Nov-10,yychi@biostat.ufl.edu,,Yueh-Yun Chi,Assistant Professor,University of Florida,1329 SW 16th Street Room 5232,352-265-0111 ext. 85854,,yychi@biostat.ufl.edu,Principal Component Analysis When the Number of Variables Exceeds the Sample Size,1,Yueh-Yun,,Chi,"Department of Biostatistics, University of Florida",Keith,E,Muller,"Department of Health Outcomes and Policy, University of Florida",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Medical images and genetic assays typically generate High Dimension,Low Sample Size (HDLSS) data, namely data with more variables thansubjects.  Scientists often use a two step approach for testinghypotheses about Gaussian mean vectors.  In the first step, PrincipalComponents Analysis (PCA) selects a set of sample components fewer innumber than the sample size.  In the second step, applying classicalmultivariate ANOVA methods to the reduced set of variables providesthe desired hypothesis tests.  We address two questions:  does the PCAstep work well, and does the testing step work well?  Analytic andsimulation results presented here indicate that success of the PCA inthe first step requires nearly all variation to occur in populationcomponents far fewer in number than the number of subjects.  In thesecond step, multivariate tests fail to attain reasonable power exceptin favorable cases such as with 1)Êa small number of dominantpopulation components, 2)Êthe dominant components capturing nearly allof the mean differences, 3)Êthe number of variables not much largerthan the sample size, 4)Êa small number of sample components selected.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Multivariate methods,High dimensional data,,,,,,,12-Nov-10,yyuan@mdanderson.org,,Ying Yuan,,The University of Texas MD Anderson Cancer Center,"1400 Pressler Street, Unit 1411",7135634271,,yyuan@mdanderson.org,Robust EM Continual Reassessment Method in Oncology Dose Finding,1,Ying,,Yuan,The University of Texas MD Anderson Cancer Center,Guosheng,,Yin,The University of Hong Kong,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The continual reassessment method (CRM) is a commonly used dose-finding design for phase I clinical trials. Applications of this method have been restricted by two practical limitations: (1) the requirement that the toxicity outcome needs to be observed shortly after treatment initiation; and (2) the potential sensitivity to the prespecified toxicity probability at each dose. To overcome these limitations, we naturally treat the unobserved toxicity outcomes as missing data, and show that such missing data are nonignorable in the sense that the missingness depends on the unobserved outcomes. We use the expectation-maximization (EM) algorithm to estimate the dose toxicity probabilities based on the incomplete data to direct dose assignment. To make the design more robust, we propose prespecifying multiple sets of toxicity probabilities, each set corresponding to an individual CRM model. We carry out these multiple CRMs in parallel, across which model selection and model averaging procedures are used to make inference. We evaluate the operating characteristics of the proposed robust EM-CRM designs through simulation studies and show that the proposed designs satisfactorily resolve both limitations of the CRM. Besides improving the MTD selection percentage, the new designs dramatically shorten the duration of the trial, and arerobust to the prespecification of the toxicity probabilities.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Adaptive design/adaptive randomization,Biopharmaceutical research,,,,,,,11-Oct-10,zguo2@ncsu.edu,,Zifang Guo,,North Carolina State University,"Department of Statistics, North Carolina State University",6179597852,919-515-7591,zguo2@ncsu.edu,Forward Stagewise Shrinkage and Addition for High and Ultrahigh Dimensional Censored Regression,1,Zifang,,Guo,"Department of Statistics, North Carolina State University",Wenbin,,Lu,"Department of Statistics, North Carolina State University",Lexin,,Li,"Department of Statistics, North Carolina State University",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Despite the thriving development of variable selection methods inrecent years, modeling and selection of high and ultrahigh dimensionalcensored regression remain challenging. When the number of predictorsp far exceeds the number of observational units n, computations ofmany methods become difficult or even infeasible, and performancesdeteriorate noticeably. Censoring of the outcome variable adds furthercomplications. In this article, we propose a forward stagewiseshrinkage and addition method for simultaneous model estimation andvariable selection in Cox proportional hazards models with high andultrahigh dimensional covariates. Our proposal extends a popularstatistical learning technique, the boosting method, by explicitlyperforming variable selection and substantially reducing the number ofiterations for algorithm convergence. It also inherits the flexiblenature of the boosting and is straightforward to extend to nonlinearCox models. Our intensive numerical analyses demonstrate that the newmethod enjoys an equally competitive performance as the best playersof the existing solutions in Cox models with p < n, whereas itachieves a considerably superior performance than the alternativesolutions when p > n.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,High dimensional data,Survival analysis,,,,,,,14-Nov-10,zhanghy@vt.edu,,Inyoung Kim,Assistant Professor,Virginia Tech,"Department of Statistics, Virginia Tech.,",(540) 231-5366,(540) 231-3863,zhanghy@vt.edu,Marginal Likelihood and Bayes Factor for Nonlinear Mixed Effects Model with Dirichlet Process Mixture Prior,1,Huaiye,,ZHANG,Virginia Tech,Inyoung,,Kim,Virginia Tech,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We present a framework for comparing two types of nonlinear mixed effects models, constructed with Dirichlet Process Mixture priors, with alternative parametric Bayesian models. Dirichlet Process Mixture prior is an attractive option to solve longitudinal mixed effects model, but it is not fully discussed under nonlinear model setting. We give the fitting procedure for estimating two types of nonlinear mixed effects model with Dirichlet Process Mixture priors, especially for non-conjugate posterior. Nonlinear mixed effects model is rarely involved in earlier work for Bayes factor. The difficulty is the unknown likelihood constants for some parameters. We note that, given a sample simulated from the posterior distribution, the required marginal likelihood may be simulation-consistently estimated by the harmonic mean of the associated likelihood values; a modification of this estimator that reduces instability is proposed. More work is involved in the framework for estimating the likelihood of Dirichlet Process Mixture model. Simulated and real data involving longitudinal nonlinear mixed effects model are used to illustrate the implementation. Keywords: Nonlinear mixed effects model, Bayes factor, Dirichlet Process Mixture, Marginal likelihood, Longitudinal data.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Bayesian methods,Longitudinal data,,,,,,,13-Oct-10,zhangk@wharton.upenn.edu,,Kai Zhang,,Department of Statistics/University of Pennsylvani,"3730 Walnut Street, Suite 400",215-898-1249,,zhangk@wharton.upenn.edu,A Powerful and Robust Test Statistic for Randomization Inference in Group-Randomized Trials with Matched Pairs of Groups,1,Kai,,Zhang,"Department of Statistics, University of Pennsylvania",Mikhail,,Traskin,"Department of Statistics, University of Pennsylvania",Dylan,,Small,"Department of Statistics, University of Pennsylvania",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"For group-randomized trials, randomization inference based on rankstatistics provides robust, exact inference against non-normaldistributions. However, in a matched-pair design, the currentlyavailable rank-based statistics lose significant power compared tonormal linear mixed model (LMM) test statistics when the LMM is true.In this research, we investigate and develop an optimal test statisticover all statistics in the form of the weighted sum of signedMann-Whitney-Wilcoxon statistics under certain assumptions. This testis almost as powerful as the LMM even when the LMM is true, but it ismuch more powerful for heavy tailed distributions. A simulation studyis conducted to examine the power.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,TRUE,Causal inference,Nonparametric methods,,,,,,,12-Nov-10,zhangweiwz@lilly.com,,Wei Zhang,,Eli Lilly and Company,Lilly Corporate Center,317-651-9314,,zhangweiwz@lilly.com,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,FALSE,FALSE,,FALSE,FALSE,FALSE,,,,,,FALSE,FALSE,FALSE,FALSE,,,,,,,,,13-Oct-10,zhangyue@usc.edu,,Yue Zhang,,University of Southern California,2723 S Hoover St Apt 2,213-608-6479,,zhangyue@usc.edu,Bayesian Mixed Hidden Markov Models: A Multi-Level Approach to Modeling Childhood Asthma with Differential Misclassification,1,Yue,,Zhang,University of Southern California,Kiros,,Berhane,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Questionnaire-based health status responses are often prone tomisclassification. When studying the effect of risk factors on suchresponses, ignoring the possible misclassifications may lead to biasedeffect estimates. Analytical challenges posed by these misclassifiedresponses are further complicated when simultaneously exploring thefactors for both misclassification and health process in a multi-levelsetting. We propose a fully Bayesian Mixed Hidden Markov Model (BMHMM)for handling differential misclassification in discrete responses in amulti-level setting. The BMHMM generalizes the Hidden Markov Model(HMM) by introducing random effects into three sets of HMM parametersfor prevalence, transition and emission probabilities. Thisformulation captures cluster level heterogeneity under a multi-levelmodel structure. Using this approach, both the true health statusprevalence and transition probability between the health states duringfollow-up are modeled as functions of covariates. The observed,possibly misclassified, health states are related to the true, butunobserved, health states and covariates. We apply our method to theSouthern California Children's Health Study, where questionnaire basedinformation on asthma diagnosis in children may be observed withmisclassification. Risk factors for both asthma transition andmisclassification are examined.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Bayesian methods,Epidemiologic methods,,,,,,,15-Nov-10,zhaohui.qin@emory.edu,,Steve Qin,Associate Professor,Emory University,Department of Biostatistics and Bioinformatics,4047129576,,zhaohui.qin@emory.edu,Statistical Modeling of RNA-seq Data,2,Ming,,Hu,"Department of StatisticsHarvard University",Zhaohui,S,Qin,"Department of Biostatistics and Bioinformatics Rollins School of Public HealthEmory University",Yu,M,Zhu,"Department of StatisticsPurdue University",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"RNA sequencing (RNA-seq) is a powerful new technology for mapping andquantifying transcriptomes using ultra high-throughput next generationsequencing technologies. Using deep sequencing, gene expression levelscan be quantified thus providing a digital measure of the presence andprevalence of all transcripts including novel ones. Although extremelypromising, the massive amounts of data that are generated by RNA-seq,substantial biases, and uncertainty in short read alignment posedaunting challenges for data analysis. In particular, largebase-specific variations and between-base correlations make naiveapproaches, such as averaging to normalizing RNA-seq data andquantifying gene expressions, ineffective. We propose to developPoisson mixed effects models to characterize RNA-seq data. Thesemodels will accommodate the biases, variations, and correlationspresent in RNA-seq data so as to accurately estimate gene expressionlevels and to facilitate gene expression comparison and noveltranscript structure or activities discovery.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Genomics,Bayesian methods,,,,,,,11-Nov-10,zheng@stt.msu.edu,,Shuzhuan Zheng,,"Department of Statistics and Probability, Michigan",A413 Wells Hall,517-884-1491,,zheng@stt.msu.edu,A confidence corridor for sparse longitudinal data curves,1,shuzhuan,,zheng,"Department of Statistics and Probability, Michigan State University",Lijian,,Yang,"Center for Advanced Statistics and Econometrics Research, Soochow University, People's Republic of China and Department of Statistics and Probability, Michigan State University",Wolfgang,K,Hardle,"Center for Applied Statistics and Economics, Humboldt-University zu Berlin",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Longitudinal data analysis is a central piece of statistics. The data are curves and they are observed at random locations. This makes the construction of a simultaneous confidence corridor (SCC) (confidence band) for the mean function a challenging task on both the theoretical and the practical side. Here we propose a method based on local linear smoothing that is implemented in the sparse (i.e., low number of nonzero coefficients) modelling situation. An SCC is constructed based on recent results obtained in applied probability theory. The precision and performance is demonstrated in a spectrum of simultaneous and applied to growth curve data. Technically speaking, our paper intensively uses recent insights into extreme value theory that are also employed to construct a shoal of confidence intervals (SCI).",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Functional data analysis,Longitudinal data,,,,,,,12-Nov-10,zhiguo.li@duke.edu,,Zhiguo Li,Assistant Professor,"Department of Biostatistics and Bioinformatics, Du","Department of Biostatistics and Bioinformatics, Duke University Medical Center",919-668-7805,,zhiguo.li@duke.edu,Inference for Dynamic Treatment Strategies from Observational Data with Failure Time Outcomes,1,Zhiguo,,Li,"Department of Biostatistics and Bioinformatics, Duke University Medical Center",Marcia,,Valenstein,"Department of Psychiatry, University of Michigan",Paul,,Pfeiffer,"Department of Psychiatry, University of Michigan",Dara,,Ganoczy,"SMITREC, HSR&D Center of Excellence, Department of Veterans Affairs, Ann Arbor, MI, USA",,,,,,,,,,,,,,,,,,,,,,,,,"Dynamic treatment strategies adaptively adjust treatments according to patient characteristics and performance over time and appear frequently in treating chronic diseases or conditions. Usually randomized trials, especially SMART trials, are conducted to assess different treatment strategies.  There has been little work on data analysis based on observational data when the outcome is a failure time.  At first, the proportional hazards assumption is likely to be violated because the same group of subjects can be consistent with different strategies. Because of this we choose to use the logrank test (for multiple groups) to test for equivalence of the strategies and potentially select the best strategy. Care needs to be taken to account for the dependence between the strategies that share the same group of subjects. Secondly, to adjust for potential confounding and selection bias, we propose to use the inverse probability weighting (IPW) method . We use a similar strategy for data analysis as in the SMART trials. The difference is that the weights here are unknown and are obtained by fitting models for the probabilities of selecting treatments at different stages.  The method is justified theoretically and assessed via a simulation study. It is also illustrated by analyzing data from an observational database on antidepressant adherence at the Veterans Administration.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Survival analysis,Causal inference,"survival analysis, dynamic treatment regimes, observational study",,,,,,09-Nov-10,zhiwei.zhang@nih.gov,,Zhiwei Zhang,Investigator,"NICHD, NIH",6100 Executive Blvd. 7B07H,301-443-7041,,zhiwei.zhang@nih.gov,Marginal Analysis of Longitudinal Count Data in Long Sequences,1,Zhiwei,,Zhang,Eunice Kennedy Shriver National Institute of Child Health and Human Development,Paul,S,Albert,Eunice Kennedy Shriver National Institute of Child Health and Human Development,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"This research was motivated by the Naturalistic Teenage Driving Study (NTDS), which followed 42 newly licensed teenage drivers continuously during their first 18 months of independent driving using in-vehicle data recording systems. The instrumentation included accelerometers, cameras, a global positioning system, a front radar, and a lane tracker. Counts of kinematic events (longitudinal/lateral acceleration/deceleration and yaw) are available for each trip, and their incidence rates represent different aspects of driving behavior. Appropriate analysis of the kinematic event data should account for over-dispersion, population heterogeneity and serial correlation. In addition, the unique structure of the NTDS dataset (thousands of trips for most drivers) poses challenges to standard methods for longitudinal count data. We discuss these challenges and propose methods for marginal analysis using generalized estimating equations. The methods are compared in different scenarios and illustrated with the NTDS data.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Longitudinal data,Estimating equations,,,,,,,13-Nov-10,zhiwenislucky@gmail.com,,Zhi Wen,Dr.,"Office of Biostatistics and Epidemiology, FDA/CBER",107 Elmcroft Square,9197936158,,zhiwenislucky@gmail.com,Modeling Longitudinal Clinical Outcomes of Pancreatic Islet Transplant,1,Zhi,,Wen,"Office of Biostatistics and Epidemiology, Center of Biologics Evaluation and Research, Food and Drug Administration",Yang,,Hong,"Office of Biostatistics and Epidemiology, Center of Biologics Evaluation and Research, Food and Drug Administration",Steven,,Anderson,"Office of Biostatistics and Epidemiology, Center of Biologics Evaluation and Research, Food and Drug Administration",Richard,,Forshee,"Office of Biostatistics and Epidemiology, Center of Biologics Evaluation and Research, Food and Drug Administration",,,,,,,,,,,,,,,,,,,,,,,,,"Background:    HbA1c levels, insulin dependence status, and composite healthstates are important indicators of clinical efficacy of islettransplantation. This study evaluated the long-term effects of islettransplantation by analyzing the HbA1c values, insulin dependencestatus, and the composite health states following islettransplantation in patients from the Collaborative Islet TransplantRegistry (CITR).Methods: Data from 387 islet transplant recipients were analyzedincluding 102 recipients of only one transplant and 285 who received atotal of either two or three transplants. HbA1c levels and insulindependence status were assessed during the 36-month follow up of themost recent transplant with a joint model for longitudinal data andtime-to-event data. And a Semi-Markov multi-state survival model isdeveloped to estimate the long term transition process between thecomposite health states. Results: The clinical indicators largely improved in the monthimmediately following the most recent islet transplant with an averagereduction of 0.65 in HbA1c levels, and average reductions of 32% and28% in the occurrence of insulin dependence and severe hypoglycemia,respectively. However, transplanted islet cells gradually lose theirfunction as indicated by increases in HbA1c levels and in theoccurrence of severe hypoglycemia and insulin dependence.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Longitudinal data,Applied data analysis,,,,,,,14-Oct-10,zhj4@pitt.edu,,Zhen Jiang,,University of Pittsburgh,141 N. Dithridge Street Apt21,4124452992,,zhj4@pitt.edu,Joint modeling of ordinal and binary longitudinal outcomes using GEE: application to medication adherence,1,Zhen,,Jiang,"Department of Biostatistics University of Pittsburgh",Abdus,S.,Wahed,"Department of Biostatistics University of Pittsburgh",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Adherence to medication is critical in achieving effectiveness of any treatment. Determining factors that influence adherence behavior have been the subject of many clinical studies. Analyzing adherence data is complicated because adherence is often measured on multiple drugs on multiple occasions, resulting in multivariate mixed longitudinal data.  This work is motivated by the Virahep-C study, where adherence is measured on two drugs, one resulting in a binary outcome and the other in a three-category ordinal outcome. We propose a joint model which assumes ordered outcomes to have arisen from a partitioned latent multivariate normal process. This joint model provides a framework for analyzing multivariate ordered longitudinal data with a general multilevel association structure, covering both between and within outcome correlation within individuals. We demonstrate how to draw inference from the joint model using generalized estimating equations. Simulation studies show that the estimators of regression parameters are unbiased, and are more efficient than those obtained through fitting separate standard GEE for each outcome. The proposed method also yields unbiased estimators for correlation parameters given the correct correlation structure. We illustrate the application of the proposed method to the Virahep-C data.",FALSE,FALSE,,FALSE,FALSE,TRUE,(1) Invited Preliminary Program: Analysis of Multivariate Non-Gaussian Longitudinal Data; and (2) SC8: Methodological Considerations for Clinical Trial Design Including an Active Control,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Longitudinal data,Latent variables,,,,,,,15-Nov-10,zhouxchong@gmail.com,,Xianchong Zhou,,Johns hopkins biostatics center,615 N Wolfe St.,786-218-0467,,zhouxchong@gmail.com,Analysis of longitudinal data on cognitive scores controlling for missingness due to death,1,Xianchong,,Zhou,"Johns Hopkins University Department of BiostatisticsJohns Hopkins Biostatistics Consulting Center",Richard,,Thompson,Johns Hopkins Biostatistics Consulting Center,Scott,,Zeger,Johns Hopkins University Department of Biostatistics,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The purpose of this study is to model the trajectory of cognitive function scores in 9 domains over time in different stroke risk groups. The analysis of the association between risk of stroke and cognitive performance over time is complicated by a direct association between stroke risk and the hazard of death as well as an inverse association between cognitive scores and hazard of death. Logistic regression models also demonstrate that death and loss-to-follow at time t are statistically associated with cognitive scores at time t-1. We propose creating linear mixed models that will impute cognitive scores for the loss to follow-up patients, while excluding these imputed values of cognitive function for those who died. These mixed models will give robust estimates under assumed MAR.   Differences in cognitive trajectory over time by risk group are then compared assuming that those who died have the lowest possible cognitive scores. Overall mean group differences for all 9 domains are  then calculated by a linear combination of the actual and imputed scores for participants with complete data and those lost to follow-up, and the lowest possible cognitive scores weighed by the probability of death.  The confidence intervals for differences are calculated from bootstrapping.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,TRUE,Joint models for longitudinal and survival data,Missing data,,,,,,,15-Nov-10,zhouyan@umich.edu,,Yan Zhou,,"Dept of Biostatistics,University of Michigan","2027 Medford Rd, Apt K283",7344787421,,zhouyan@umich.edu,Development of Objective Quadratic Inference Functions Based On Gaussian Graphic Models,1,Yan,,Zhou,"Dept. of Biostatistics, Univ. of Michigan",Yijiang,,Li,"Dept. of Biostatistics, Univ. of Michigan",Peter,X. K.,Song,"Dept. of Biostatistics, Univ. of Michigan",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Quadratic inference function (QIF) has received increasing attentionin the recent literature to perform the longitudinal data analysisbased on marginal models. The formulation of the QIF is heavilydependent on the choice of basis matrices determined by the chosenworking correlation structure in the marginal model. To determine aset of objective basis matrices, we propose a data-driven procedure tolearn the inherent serial dependence of repeated measurements usingGaussian graphic models. The proposed learner builds upon the graphicLASSO method, which allows us to determine the basic features ofdependence, with regularization of sparsity, in the fashion of graphicmodel. The identified objective basis matrices are then applied toform the QIF, and the resulting QIF is termed as the objective QIF. We show that the proposed objective QIF appears to improve estimationefficiency and numerically more stable than the subjective QIF wherethe working correlation is misspecified. We also compare thisobjective QIF method to the classic GEE approach in the cases oflongitudinal normal responses, Poisson responses and binary responses.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Longitudinal data,Graphical models,,,,,,,15-Oct-10,zhua@email.unc.edu,,Zhaowei Hua,,UNC-Chapel Hill,28 AUDLEY LN,9192590102,,zhua@email.unc.edu,SBLFM: Semiparametric Bayesian Local Functional Models for Diffusion Tensor  Tract Statistics,1,Zhaowei,,Hua,"Departments of Biostatistics, University of North Carolina at Chapel Hill, Chapel Hill, NC 27599, USA",David,B.,Dunson,"Department of Statistical Science, Duke University,Durham, NC 27708, USA",Hongtu,,Zhu,"Departments of Biostatistics, University of North Carolina at Chapel Hill, Chapel Hill, NC 27599, USA",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Diffusion tensor imaging (DTI) is a modality to visualize and quantify the structure of white matters in human brain. In this article, we propose a semiparametric Bayesian local additive model to analyze fiber tract data. A local partition process is used to address the variability of multiple diffusion properties along major white fiber bundles and its association with a set of covariates of interests, such as gestational age. Two types of statistical inferences are provided: (1) global hypothesis testing to test the overall significance of a hypothesis of interest (2) local hypothesis testing to identify the region of significance. Posterior computation proceeds via anefficient MCMC algorithm using the exact block Gibbs sampler. A simulation study is performed to evaluate the performance of SBLFM. Our method is applied to analyze a fiber track data set of two fiber tracts from a clinical study of neurodevelopment: the splenium of the corpus callosum tract and the right internal capsule tract. The growth of white matter fiber diffusivities along these two tracts are addressed.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Imaging,Bayesian methods,,,,,,,12-Nov-10,ziad@chalmers.se,,ziad,taib,department of mathematical sciences,chalmers university of technology,+46-31 776 13 10,,ziad@chalmers.se,STOCHASTIC APPROACHES TO PHARMAKOKINETIC MODELLING,1,Ziad,,taib,"Department of Mathematical SciencesChalmers University of Technology412 96 GšteborgSweden",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Pharmacokinetics (PK) is the study of the fate of various substances once they enter the body. The traditional approach to model the time course of the concentration of such a substance in the blood after intake by e.g. injection is based on compartment models and differential equations. We will present stochastic alternatives in terms of Markov- and semi-Markov processes and stochastic differential equations. The solutions to these equations are usually treated as non-linear mixed effect models in order to estimate the underlying parameters. In this talk, we will present the actual models, discuss their performance and apply them to data on Insulin and Glucose concentrations.Keywords: PK model - Markov process - Non-linear mixed effects model - Insulin Sensitivity.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Pharmacokinetic/pharmacodynamics (PK/PD) modeling,Biopharmaceutical research,,,,,,,01-Nov-10,zj7@columbia.edu,,Zhezhen Jin,,Columbia University,722 W 168th Street Room 634,2123059404,,zj7@columbia.edu,Inference on survival models with induced smoothing,1,Zhezhen,,Jin,"Department of Biostatistics, Columbia University",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"A challenge with many semiparametric survival models for inference is the difficulty in variance estimation for the  parameter estimators, for example, accelerated failure time models and censored quantile regression models.  In  this talk,  a general induced smoothing approach will be introduced and will beillustrated with semiparametric survival models .",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Survival analysis,Nonparametric methods,,,,,,,13-Oct-10,zkhondke@bios.unc.edu,,Zakaria Khondker,PhD Student,Biostatistics/University of North Carolina at Chap,1600 Baity Hill Dr Apt 219,919-381-2736,,zkhondke@bios.unc.edu,The Bayesian Covariance Lasso,1,Zakaria,S,Khondker,"PhD Student, BiostatisticsUniversity of North Carolina at Chapel Hill",Hongtu,,Zhu,"Associate Professor, BiostatisticsUniversity of North Carolina at Chapel Hill",Haitao,,Chu,"Associate Professor, Division of Biostatistics          School of Public Health, University of Minnesota",Weili,,Lin,"Interim Director of the BRICProfessor, Radiology, Neurology, and Biomedical EngineeringAssociate Director, Biomedical Research Imaging CenterUniversity of North Carolina at Chapel Hill",Joseph,G,Ibrahim,"Alumni Distinguished ProfessorDirector of Grad Studies, BiostatisticsUniversity of North Carolina at Chapel Hill",,,,,,,,,,,,,,,,,,,,,"Estimation of sparse covariance matrices and their inverse subject to positive definiteness constraints has drawn a lot of attention in recent years. The abundance of high-dimensional data, where the sample size (n) is less than the dimension (d), requires shrinkage estimation methods since the maximum likelihood estimator is not positive definite in this case. Furthermore, when n is larger than d but not sufficiently larger, shrinkage estimation is more stable than maximum likelihood as it reduces the condition number of the precision matrix. Frequentist methods have utilized penalized likelihood methods, whereas Bayesian approaches rely on matrix decompositions or Wishart priors for shrinkage. In this paper we propose a new method, called the Bayesian Covariance Lasso (BCLASSO), for the shrinkage estimation of a precision matrix. We consider a class of priors for the precision matrix that leads to the popular frequentist penalties as special cases and propose an efficient sampling. The proposed method is permutation invariant and performs shrinkage and estimation simultaneously for high-dimensional data. Simulations show that the proposed BCLASSO performs similarly or better than frequentist methods for high-dimensional data.",FALSE,FALSE,,FALSE,TRUE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,TRUE,High dimensional data,Bayesian methods,,,,,,,15-Nov-10,zlfang@vt.edu,,Zaili Fang,,"Department of Statistics, Virginia Polytechnic Ins","Department of Statistics, Virginia Polytechnic Institute and State University, 410A Hutcheson Hall,",9194518498,,zlfang@vt.edu,Semiparametric Mixed Model for Evaluating Pathway-Environment Interaction,1,Zaili,,Fang,"Department of Statistics, Virginia Polytechnic Institute and State University, Blacksburg, Virginia, U.S.A.",Inyoung,,Kim,"Department of Statistics, Virginia Polytechnic Institute and State University, Blacksburg, Virginia, U.S.A.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"A biological pathway represents a set of genes that serves a particular cellular or physiological function. The genes within the same pathway are expected to function together and hence may interact with each other. It is also known that many genes are interacted with other environment variables. Therefore pathway can also interact with other environment variables. However, no formal procedure is yet to evaluate the pathway-environment interaction. In this article, we propose a semiparametric method to evaluate the pathway-environment interaction. Our approach is developed by connecting a least square kernel machine and a semiparametric mixed effects model. We model the environmental effect nonparametrically via a natural cubic spline. Both pathway effect and interaction between pathway and environment are modeled nonparametrically via kernel machine and we estimate variance components under semiparametric mixed effects model. We then employ the likelihood ratio test and the score test to test the pathway effect and the pathway-environment interaction, respectively. By applying our approach to a microarray study of Type II diabetes, we identified the pathways with significant overall effects, which are consistent with the results of other methods, and we discovered that not all the overall significant pathways have the significant pathway-environment interaction effect.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Nonparametric methods,Random effects,,,,,,,15-Nov-10,zouyuanshu@gmail.com,,Yuanshu Zou,,PhD student,2971 Deckebach Ave,734-358-6182,,zouyuanshu@gmail.com,Robustifying a Non-Linear Model using Wavelets with an application to PK Modeling,1,Yuanshu,,Zou,University of Cincinnati,Siva,,Sivaganesan,University of Cincinnati,Peter,,Mueller,"University of Texas, MD Anderson Cancer Center",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We propose a non-parametric extension to robustify parametric non-linear regression models. We consider in particular pharmacokinetic models that define the non-linear regression function indirectly as solution of an ODE system.   We begin with a tentative parametric model, e.g., a compartment model, and define a non-parametric neighborhood of the tentative model using wavelet decomposition. We do this by defining a suitable prior for the wavelet decomposition derived from the parametric model with the wavelet based non-parametric neighborhood as the support. We use Bayesian approach to fit the model implementing wavelet thresholding proposed by Muller and Vidakovic (1998). Our method is flexible enough to adapt to deviations from a standard non-linear drug concentration profile allowing robust modeling and predictions.  We illustrate the proposed approach using simulated data and a real dataset.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Pharmacokinetic/pharmacodynamics (PK/PD) modeling,Bayesian methods,,,,,,,26-Oct-10,ztan@stat.rutgers.edu,,zhiqiang tan,,rutgers univ,110 frelinghuysen road,908-230-1692,,ztan@stat.rutgers.edu,"Bounded, efficient, and doubly robust estimation with inverse weighting",1,zhiqiang,,tan,rutgers university,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Consider estimating the mean of an outcome in the presence of missing data or estimatingpopulation average treatment effects in causal inference. A doubly robust estimator remainsconsistent if an outcome regression model or a propensity score model is correctly specified. Webuild on a previous nonparametric likelihood approach and propose new doubly robust estimators,which have desirable properties in efficiency if the propensity score model is correctly specified,and in boundedness even if the inverse probability weights are highly variable. We comparethe new and existing estimators in a simulation study and find that the robustified likelihoodestimators yield overall the smallest mean squared errors.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Causal inference,Missing data,,,,,,,12-Oct-10,ztang@bios.unc.edu,,Zhengzheng Tang,,University of North Carolina at Chapel Hill,"316 Summerwalk Circle, Chapel Hill, NC, 27517",9192659551,,ztang@bios.unc.edu,Estimating and improving next-generation sequence-based genotype accuracy,1,Zhengzheng,,Tang,"Biostatistics, University of North Carolina at Chapel Hill, NC, USA",Matthew,R,Nelson,"GlaxoSmithKline Research and Development, RTP, NC, USA",Claudio,J,Verzilli,"Imperial College London, UK",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Genotyping errors occur at some rate in all studies and aredeleterious to subsequent analyses (for example, error rate canseriously distort rare variant association analysis). Sangersequencing has commonly been regarded as Gold Standard. Whereasnext-generation sequencing (NGS) has raised concerns as having a higherror rate (~1%). As a result, methods to estimate and improve NGSaccuracy are welcomed. In this paper, we propose a procedure toestimate NGS error rate and improve NGS accuracy by setting amodel-based genotype filter based on duplicate sample. The procedureis demonstrated by applying on a large-scale NGS study with 133subjects sequenced in duplicate across ~850,000 target bases. Overalldiscordance from routine quality control of variable sites is 0.013%and the optimal post-filtered estimated heterozygous error rate is0.3%, which is considerably lower than Sanger sequence error rateestimated based on ~1000 subjects.",FALSE,FALSE,,FALSE,FALSE,FALSE,,studentaward_submission_oral,,,,FALSE,FALSE,FALSE,FALSE,Measurement error,Applied data analysis,,,,,,,12-Nov-10,zubovic@ipfw.edu,,Yvonne Zubovic,Associate Professor,Indiana University Purdue University Fort Wayne,2101 E. Coliseum Blvd.,260-481-6037,260-481-0155,zubovic@ipfw.edu,Using Rank Based Tests for Treatment Effects in Combined Designs,1,Yvonne,M,Zubovic,Indiana University Purdue University Fort Wayne,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Consider an investigation in which two experimental designs are performed: a one-way layout and a completely randomized block design to test the effects of several different treatments.  In this study we consider several nonparametric methods based on ranks to test for differences between treatment effects by combining the data from the one-way layout and the complete block designs.  Using simulation we compare the performance of tests based on aligned ranks, rank transformation, and a linear combination of nonparametric tests when the usual distributional assumption of Normality is not met.  We share our investigation of properties of the proposed hypothesis tests and consider an extension to the case of combining complete block and incomplete block designs.",FALSE,FALSE,,FALSE,FALSE,FALSE,,contributedposter,,,,FALSE,FALSE,FALSE,TRUE,Nonparametric methods,Experimental design,,,,,,,15-Nov-10,zuoguoxin@gmail.com,,Guoxin Zuo,,Department of Biostatistics and computational Biol,601 Elmwood Avenue Box 630,585-275-2591,,zuoguoxin@gmail.com,Statistical inference in partial linear model with double smoothing method,3,Wan,,Tang,University of Rochester,Hua,,He,University of Rochester,Guoxin,,Zuo,University of Rochester,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Statistical inference about the partial linear model includes twoparts, one for the linear part, and another for the nonparametricpart. Double smoothing method proposed by He and Huang(2009) is a improved local smoothing method for nonparametric curve estimation. We discussed its extension in the partial linear model, accompanying with difference based estimation method for the linear part. The performance of the proposed method is studied in theory.Furthermore, the results of simulation and real data analysis demonstrate its effectiveness.",FALSE,FALSE,,FALSE,FALSE,FALSE,,presentation_or_poster,,,,FALSE,FALSE,FALSE,FALSE,Nonparametric methods,Computational methods,,,,,,,15-Nov-10,zwu@stat.brown.edu,,zhijin wu,,Brown University,Box G-S-121-7,4018631230,,zwu@stat.brown.edu,Empirical Bayes Analysis of Sequencing-based Transcriptional Profiling without Replicates,1,Zhijin,,Wu,Brown University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Recent technological advancements have made high throughput sequencingan increasingly popular approach for transcriptome analysis.Advantages of sequencing-based transcriptional proling overmicroarrays have been reported, including lower technical variability.However, advances in technology do not removebiological variation between replicates and this variation is oftenneglected in many analyses. We propose an empirical Bayes method,titled Analysis of Sequence Counts (ASC), to detectdierential expression based on sequencing technology. ASC borrowsinformation across sequences to establishprior distribution of sample variation, so that biological variationcan be accounted for even when replicates arenot available. Compared to current approaches that simply tests forequality of proportions in two samples, ASCis less biased towards highly expressed sequences and can identifymore genes with a greater log fold change atlower overall abundance.",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Genomics,High dimensional data,,,,,,,12-Nov-10,zzhang@ChristianaCare.org,,Zugui Zhang,Dr.,Christiana Care Health System,"131 Continental Drive, Suite 202",302-623-0673,,zzhang@ChristianaCare.org,Multi-nomial Logistic Regression for Health-Related Outcomes in Clinical Trail,1,Zugui,,Zhang,"Christiana Care Health System, Newark, Delaware",Paul,,Kolm,Christiana Care Health System,William,S,Weintraub,Christiana Care Health System,John,A,Spertus,"Mid-America Heart Institute/University of Missouri  Kansas City",,,,,,,,,,,,,,,,,,,,,,,,,"Patient-centered health status outcomes are emerging as important outcomes in clinical trials, however, they are often represented categorically to facilitate clinical interpretation. The purpose of this study was to investigate whether change in angina severity over time can be predicted by demographic and clinical risk factors, angina-specific and general health-related quality of life.  Patients with stable coronary artery disease in the COURAGE Trial (n = 2,287) were randomized to an initial strategy of percutaneous coronary intervention (PCI) plus optimal medical therapy versus optimal medical therapy alone. Angina severity was assessed by the Canadian Cardiovascular Society (CCS) classification, and the Seattle Angina Questionnaire (SAQ) at 1, 3, 6 and 12 months and annually thereafter.  The CCS is a 5-level, physician-evaluated assessment of a patients angina severity, whereas the SAQ is a patient-evaluated assessment of his/her angina severity.  SAQ scores were analyzed as a 4-level ordinal variable.  The proportional odds model was applied to the ordinal angina severity data to investigate a manageable way to predict angina severity and develop a foundation for a shared decision-making tool.",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Health services research,Applied data analysis,,,,,,,14-Nov-10,zzhang@stat.brown.edu,,Zheng Zhang,Assistant Professor,Brown University,"121 South Main Street,",401-863-2578,,zzhang@stat.brown.edu,Rank-based agreement or reproducibility indices,1,Zheng,,Zhang,Brown University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Evaluating agreement or reproducibility of clinical measurements is an important aspect of medical research. For continuous outcomes, intraclass correlation coefficient (ICC) or concordance correlation coefficient (CCC) are popular indices for such purpose. However, both are based on normality assumption of the data, hence are sensitive to the presence of extreme values. Here we propose two new indices, rank-based ICC (rICC) and rank-based CCC (rCCC), both are based on the combined ranks of the measurements.Simulation studies have shown the new indices perform well under a variety of distributions and are easy to use. We apply the method to a real data set for demonstration.",FALSE,FALSE,,FALSE,FALSE,TRUE,T5: Essentials for success in research,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Agreement,Nonparametric methods,,,,,,,,hb@biostat.ucsf.edu,,Henrik Bengtsson,,"University of California, San Francisco ",,,,hb@biostat.ucsf.edu,"Improved interpretation of post-segmentation parent-specificcopy numbers from a single heterogeneous tumor-normal pair",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We have achieved another milestone toward obtaining geneticallyinterpretable parent-specific copy numbers (PSCNs) from a single pairof tumor-normal microarrays.  Single-array CRMAv2 provides us withtotal copy numbers (TCNs) and allelic ratios (BAFs) at the locuslevel. PSCBS segments these estimates into genomic regions of constantminor and major CNs (PSCNs), which allows for a first order of geneticinterpretation.  Contamination of normal cells as well as tumor ploidycomplicates the interpretation and few models controlling for thesehave been proposed.  Fewer methods consider the existence of tumorclonality.  In addition, there are also often overlooked systematiceffects such as remaining allelic crosstalk and saturation thatfurther complicates the interpretation.  We propose additionalstatistical methods that leverage the inference of the underlyinggenetic PSCN states also under these conditions.  We show that in manycases this is possible even with a single heterogeneous tumor-normalpair in hand.",,,,,,,,,,,,,,,,,,,,,,,,,ddegras@samsi.info,,David Degras,,Statistical and Applied Mathematical Sciences Institute,,,,ddegras@samsi.info,Adaptive survey sampling for functional data,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"This work addresses the estimation of a population mean or total function by stratified sampling methods  in the context of distributed sensors. Specifically, we deal with situations in which large numbers of data streams are observable in real time but where observation of the entire population would require major investments, both for transmission of the signals through networks and for storage. This type of problem is of increasing importance e.g. for utility companies having digital meters installed at the customersÕ sites. See Cardot and Josserand (2010) for an example with the french electricity company EDF. The functional framework of the survey calls for innovative sampling techniques that capture efficiently both transversal and longitudinal information in the population. In this paper, our goal is to devise time-varying sampling schemes that allow for optimal estimation (i.e. unbiased with minimum variance) with the popular Horvitz-Thompson (HT) estimator at each observation point. We propose two sampling schemes based on optimal allocation with partial or full resampling, in relation  to the ideas of repeated survey and split panel survey. We study the bias and variance of these estimators and compare them to HT estimators with optimal, time-invariant allocation in simulations. The simulation results indicate a significant decrease in the Average Squared Error of the adaptive estimators at the design points in comparison to the classical estimators, which motivates further theoretical and methodological developments in this recent field of research.",,,,,,,,,,,,,,,,,,,,,,,,,FLiang@mdanderson.org,,FU-WEN LIANG,,"Department of Epidemiology, The University of Texas M.D. Anderson Cancer Center",,,,FLiang@mdanderson.org,Evaluating the Effect of Haplotypes on Quantitative Traits When Linkage Phase Is Unknown,,Fu-Wen,,Liang,"Department of Epidemiology, The University of Texas M.D. Anderson Cancer Center",Yanhong,, Liu,"Department of Epidemiology, The University of Texas M.D. Anderson Cancer Center",Georgina ,,Armstrong,"Department of Epidemiology, The University of Texas M.D. Anderson Cancer Center",Xifeng ,,Wu,"Department of Epidemiology, The University of Texas M.D. Anderson Cancer Center",Qingyi ,,Wei,"Department of Epidemiology, The University of Texas M.D. Anderson Cancer Center",Melissa ,L. ,Bondy,"Department of Epidemiology, The University of Texas M.D. Anderson Cancer Center",Carol ,J. ,Etzel,"Department of Epidemiology, The University of Texas M.D. Anderson Cancer Center",,,,,,,,,,,,,"Haplotype analyses provide important information regarding the genetic association to complex diseases. When unrelated subjects are sampled, haplotypes are often ambiguous because linkage phase of the measured loci are unknown. To account for this ambiguity in case-control studies, inferred haplotype frequencies between the diseased cases and healthy controls are often compared by use of a likelihood approach; however, this traditional method is limited to a binary trait (case vs. control), and it does not provide a method of predicting estimates of quantitative traits for specific haplotypes. To address these limitations, we developed a method to examine the statistical association between inferred haplotypes and quantitative traits. The method provides parameter estimates in a regression model framework when the distribution of inferred haplotypes for each participant involves more than two haplotypes with frequency greater than 5% without causing the singular correlation matrix in a multiple linear regression model with correlated predictor variables. To illustrate the use of our new method, we applied to a glioma study of the association of haplotypes with mutagen sensitivity. In addition, the correlation between these predictor variables was calculated using a Dirichlet distribution for verification of this method.",,,,,,,,Oral Presentation,,,,,,,,,,,,,,,,,mrbrich@googlemail.com,,Benjamin Rich,,McGill University,,,,mrbrich@googlemail.com,Optimal dynamic treatment regime estimation in the presence of partial model misspecification,,Benjamin ,,Rich,"Department of Epidemiology, Biostatistics and Occupational Health, McGill",Erica, E. M. ,Moodie,"Department of Epidemiology, Biostatistics and Occupational Health, McGill",David ,A. ,Stephens,"Department of Mathematics and Statistics, McGill University",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Optimal dynamic treatment regimes concern sequential treatment decisions based on how a patient evolves over time. Optimal dynamic regime structural nested mean models were introduced by Robins, who also developed locally e_cient doubly robust semiparametric estimators for these models. While these estimators are robust to misspeciÞcation of a particular nuisance model in the consistency sense, the impact on their e_ciency can be substantial as observed in simulation. This can be exacerbated when the data contain observations that come close to violating the experimental treatment assignment assumption. Our belief is that standard inßuence diagnostics based on case deletion, that have not previously been applied in this context, can provide valuable clues as to where the model misspeciÞcation is doing the most harm. We develop a weighted estimation procedure that leverages this information and, in simulation, improves on the variance of the standard estimator.",,,,,,,,oral_presentation,,,,,,,,,,,,,,,,,demets@biostat.wisc.edu,,David DeMets,Professor,Department of Biostatistics and Medical Informatic,University of Wisconsin,6082632947,6082631059,demets@biostat.wisc.edu, Leadership in Biostatistics: A required skill to have an impact,1,David DeMets,L,DeMets,University of Wisconsin-Madison,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Training programs in biostatistics provide students with a background in both statistical theory and methods with many giving students practical experience as well.  However, biostatisticians in their consulting and collaboration interact with a v",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Biostatistics Education,Consulting,,,,,,,,lwaller@emory.edu,,Lance Waller,Professor,Emory University,Department of Biostatistics and Bioinformatics,404 727 1057,404 727 1370,lwaller@emory.edu,Spatial analysis in disease ecology,1,Lance,A,Waller,Emory University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Disease ecology seeks to quantify associations between disease outcomes and key elements of the disease process including environmental reservoirs, multiple hosts and potential vectors.  Spatial patterns are of particular interest but confounded b",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Spatial/temporal modeling,Infectious disease models,,,,,,,,p.congdon@qmul.ac.uk,,Peter Congdon,Professor,Queen Mary University of London,Dept of Geography,0207 882 2778,,p.congdon@qmul.ac.uk,Spatial common factor models with multiple causes,1,Peter,,Congdon,Queen Mary University of London,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"As well as using multiple health indicators to measure a commonspatial factor, it is likely to be of interest to understand sources('causes') of variation in that common factor linked to populationrisk factors. For example, multiple indicators of CH",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Spatial/temporal modeling,Bayesian methods,,,,,,,,tokdar@stat.duke.edu,,Surya Tokdar,Assistant Professor,Duke University,214 Old Chem Bldg Box 90251,919 684 2152,919 684 8594,tokdar@stat.duke.edu,Varying Coefficient Regression with Adaptive Predictive Process,,Surya,T,Tokdar,Duke University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,bellamys@mail.med.upenn.edu,,Scarlett Bellamy,Associate Professor,University of Pennsylvania,612 Blockley Hall,2155735152,2155734865,bellamys@mail.med.upenn.edu,A novel extension of max-id copulas to longitudinal binary couple's shared HIV risk behavior,2,Seunghee,,Baek,University of Pennsylvania,Scarlett,L,Bellamy,University of Pennsylvania,Andrea,B,Troxel,University of Pennsylvania,Thomas,R,Ten Have,University of Pennsylvania,John,B,Jemmott III,University of Pennsylvania,,,,,,,,,,,,,,,,,,,,,"This talk presents an extension of the mixture of max-infinitelydivisible (max-id) bivariate copulas to model longitudinal,couple-based binary data. A complex correlation structure (e.g.,within couple dependence at the same time and over time as wel",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Other,Clustered data methods,Invited Session,,,,,,,kdickers@jhsph.edu,,Kay Dickersin,Professor,Johns Hopkins School of Public Health,"615 N Wolfe St, Mail Rm W5010",410-502-4421,,kdickers@jhsph.edu,Standards proposed by the Institute of Medicine for Conducting Systematic Reviews,1,Kay,,Dickersin,Johns Hopkins Bloomberg School of Public Health,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The Institute of Medicine's (IOM's) Committee on Standards for Systematic Reviews of Clinical Effectiveness Research proposes a rigorous approach to systematic reviews and meta-analysis that should be applied, at a minimum, to publicly funded revi",FALSE,FALSE,,FALSE,FALSE,FALSE,This paper is part of a series of linked papers coordinated by Chris Schmid. Topic is meta-analysis and network meta-analaysis,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Other,Epidemiologic methods,meta-analysis and network meta-analysis,,,,,,,etchetge@hsph.harvard.edu,,Tchetgen Tchetgen,,Harvard University,677 Huntington Avenue,617 899 8401,,etchetge@hsph.harvard.edu,Multiply robust estimation of statistical interaction,1,Eric,,Tchetgen Tchetgen,"Departments of epidemiology and Biostatistics Harvard University ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"A primary focus of an increasing number of scientific studies is todetermine whether two exposures interact in the effect that theyproduce on an outcome of interest. Interaction is commonly assessed byfitting regression models in which the linear pr",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Estimating equations,Statistical genetics,,,,,,,,cschmid@tuftsmedicalcenter.org,,Christopher Schmid,Statistician,Tufts Medical Center,800 Washington St Box 63,6176365179,,cschmid@tuftsmedicalcenter.org,Multiple Treatments Meta-Analysis for Ordered and Unordered Categorical Outcomes,1,Christopher,H,Schmid,Tufts Medical Center,Thomas,,Trikalinos,Tufts Medical Center,Ingram,,Olkin,Stanford University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Comparative effectiveness research requires synthesis of evidence onthe effects of multiple, competing treatments that influence multipleoutcomes related to safety and efficacy and that may be evaluatedmultiple times over and after courses of treatm",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,TRUE,Multivariate methods,Bayesian methods,,,,,,,,tli@jhsph.edu,,Tianjing Li,,Johns Hopkins Bloomberg School of Public Health,"615 N. Wolfe Street, Mail Room W5010",410-502-4630,,tli@jhsph.edu,Challenges of network meta-analysis for comparative effectiveness research: resolving discrepancies between systematic reviews,1,Tianjing,,Li,"Center for Clinical Trials, Department of Epidemiology, Johns Hopkins Bloomberg School of Public Health",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Using statistical methods such as network meta-analysis to combine findings from individual studies in a systematic review can provide useful information for clinical decision-making. In order to minimize error, bias, and to ensure validity of findi",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Other,Epidemiologic methods,meta-analysis and network meta-analysis,,,,,,,stijn.vansteelandt@ugent.be,,Stijn Vansteelandt,,Ghent University,Dept. Applied Mathematics,00322644776,00322644995,stijn.vansteelandt@ugent.be,Mendelian randomisation analysis of case-control data using Structural Mean Models,2,Jack,,Bowden,"MRC Clinical Trials Unit, U.K.",Stijn,,Vansteelandt,"Ghent University, Belgium, and London School of Hygiene and Tropical Medicine, U.K.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Instrumental variable methods are becoming an increasingly popular analysis tool, since they provide a basis for estimating an exposures causal effect on the risk of disease. For practical reasons, most obviously if the disease of interest has a ",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Causal inference,Epidemiologic methods,,,,,,,,wiscstatman@gmail.com,,Michael Newton,,University of Wisconsin,Department of Statistics,262-0086,,wiscstatman@gmail.com,Ranking and selection of enriched gene sets,1,Michael,,Newton,"University of Wisconsin, Madison",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Having identified a possibly large list of genes with some experimental property of interest, a natural question is how to relate this list to exogenous functional classifications (gene sets).  Ranking sets by apparent enrichment disproportionately fa",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,High dimensional data,Genomics,,,,,,,,byron.wallace@tufts.edu,,Byron Wallace,,tufts,98 prospect street,413-512-0352,,byron.wallace@tufts.edu,Semi-Automated Classification of Biomedical Citations for Meta-Analysis Via Machine Learning,1,Byron,C,Wallace,"Tufts Medical CenterTufts University",Kevin,,Small,Tufts Medical Center,Carla,E,Brodley,Tufts University,Joseph,,Lau,Tufts Medical Center,Chris,H,Schmid,Tufts Medical Center,Thomas,A,Trikalinos,Tufts Medical Center,,,,,,,,,,,,,,,,,"Screening abstracts for eligibility is a vitally important, buttedious step in the systematic review process. Typically, electronicsearches for a review yield several thousands of abstracts, which arethen perused by the reviewers and either excluded",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Machine learning,Clinical trials,,,,,,,,mkchung@wisc.edu,,Moo K. Chung,,University of Wisconsin,1500 Highland Ave 217,608-217-2452,,mkchung@wisc.edu,Heat kernel smoothing on manifolds and its application to longitudinal brain substructure modeling,1,Moo,K,Chung,University of Wisconsin-Madison,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"We present a novel kernel smoothing framework on an arbitrary manifold using the Laplace-Beltrami eigenfunctions. The Greens function of an isotropic diffusion equation on a manifold is analytically represented first using the eigenfunctions of the",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Imaging,Multivariate methods,,,,,,,,mpuhan@jhsph.edu,,Milo Puhan,Associate Professor,Johns Hopkins Bloomberg School of Public Health,615 N Wolfe St,443 287 8777,,mpuhan@jhsph.edu,Graphical displays to analyze and report network meta-analysis,2,Milo,,Puhan,"Johns Hopkins Bloomberg School of Public HealthDepartment of Epidemiology",Tianjing,,Li,"Johns Hopkins Bloomberg School of Public HealthDepartment of Epidemiology",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Network meta-analyses contain complex data structures because of the multiple treatments and, potentially, multiple outcomes involved. Graphical displays can be used to facilitate understanding of the evidence network and to guide a meaningful sta",FALSE,FALSE,,FALSE,FALSE,FALSE,,oral_presentation,,,,FALSE,FALSE,FALSE,FALSE,Other,Epidemiologic methods,network meta-analysis,,,,,,,im2131@columbia.edu,,Ian McKeague,,Columbia University,Department of Biostatistics,212-342-1242,,im2131@columbia.edu,Recovering gradients from sparsely observed functional data,1,Ian,W,McKeague,Columbia University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"This talk presents a new empirical Bayesian approach to the recoveryof gradients of sparsely observed functional data.  The data consist ofobservations of smooth curves (e.g., growth curves) at sparse timepoints, and the goal  is to estimate the b",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Functional data analysis,Bayesian methods,,,,,,,,hliang@bst.rochester.edu,,Hua Liang,Professor,University of Rochester,601 Elmwood Ave,585-2410704,,hliang@bst.rochester.edu,Assessment of Condom Use in HIV-infected Patients from South African,1,Hua,,Liang,University pf Rochester,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"To carefully explore significance of predictors of condom use, we investigated the data set  from an operational cohort of HIV-infectedadults conducted at Perinatal HIV Research Unit (PHRU), in SowetoSouth Africa by developing an advanced risk-facto",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Variable subset selection/model selection,Generalized linear models,,,,,,,,cfrangak@jhsph.edu,,Constantine Frangakis,Professor,Johns Hopkins University,Department of Biostatistics,4105021936,,cfrangak@jhsph.edu,Estimating effects by combining instrumental variables with case-control designs,2,Russell,T,Shinohara,Johns Hopkins University,Constantine,E,Frangakis,Johns Hopkins University,Konstantinos,,Tsilidis,Oxford University,Elizabeth,,Platz,,,,,,,,,,,,,,,,,,,,,,,,,,"The instrumental variables framework is commonly used for theestimation of causal effects from cohort samples. However, thecombination of instrumental variables with more efficient designs suchas case-control sampling requires new methodological con",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Causal inference,Statistical genetics,,,,,,,,rafa@jhu.edu,,Rafael A Irizarry,,Johns Hopkins University,2218 SULGRAVE AVE,4106145157,,rafa@jhu.edu,"Epigenetic variation as a driving force for development, evolutionary adaptation, cancer, and common disease",1,Rafael,A,Irizarry,Johns Hopkins Universtiy,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Epigenetics is the study of nonsequence-based changes, such as DNAmethylation, heritable during cell division. Previous attempts toincorporate epigenetics into evolutionary thinking have focused onenvironmentally directed epigenetic changes. In this",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Genomics,Applied data analysis,,,,,,,,nandy@psych.ucla.edu,,Rajesh Ranjan Nandy,Assistant Professor,"University of California, Los Angeles",Dept. of Psychology,206-3296441,,nandy@psych.ucla.edu,Regression for analyzing functional MRI data with custom contrasts,1,Rajesh,R,Nandy,"Departments of Biostatistics and PsychologyUniversity of California, Los Angeles",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In analyzing functional MRI (fMRI) data, it has been established thatCanonical Correlation Analysis (CCA) is a more sensitive approach todetect brain activation from external stimulus than the traditionalunivariate methods. This is primarily due to ",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Imaging,Multivariate methods,,,,,,,,ttrikalinos@tuftsmedicalcenter.org,,Tom Trikalinos,"Co Director, Tufts Evidence-based Practice Center",Tufts Medical Center and Tufts University,800 Washington St,6176360734,6176368628,ttrikalinos@tuftsmedicalcenter.org,"Open Meta-Analyst: Open Source, Cross-Platform Software for Meta-Analysis",1,Thomas,A,Trikalinos,Tufts Medical Center and Tufts University,Byron,C,Wallace,,Tom,,Trikalinos,Tufts Medical Center and Tufts University,Tom,,Trikalinos,,Issa,J,Dahabreh,Tufts Medical Center and Tufts University,Joseph,,Lau,Tufts Medical Center and Tufts University,Tom,,Trikalinos,,Christopher,H,Schmid,Tufts Medical Center and Tufts University,Tom,,Trikalinos,,,,,,"We present a new stand-alone, cross-platform, open-source meta-analysis program that combines the strengths of general statistical packages (flexibility) and dedicated meta-analysis programs (ease-of-use) for performing meta-analyses. Open Meta-Anal",TRUE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Other,Health services research,Modernizing CEr and meta-analysis -- software,,,,,,,daniel.rowe@marquette.edu,,Daniel B. Rowe,Professor,Marquette University,1313 W. Wisconsin Ave,414-288-5228,,daniel.rowe@marquette.edu,Signal and Noise in Complex-Valued SENSE MR Image Reconstruction,1,Daniel,B.,Rowe,"Department of Mathematics, Statistics, and Computer Science, Marquette University, Milwaukee, Wisconsin, USA 53233",Iain,P.,Bruce,"Department of Mathematics, Statistics, and Computer Science, Marquette University, Milwaukee, Wisconsin, USA 53233",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In fMRI, brain images are not measured instantaneously and a volume of images can take two seconds to acquire at a low 64x64 resolution. Significant effort has been put forth on many fronts to decrease image acquisition time including parallel ima",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Imaging,High dimensional data,,,,,,,,anindya@umbc.edu,,Anindya Roy,Professor,UMBC,Department of Math/Stat,4104552435,,anindya@umbc.edu,Testing Equality of Functional Features Across Groups of fMRI Images,1,Anindya,,Roy,University of Maryland Baltimore County,Hui,,Huang,Yale university,Tulay,,Adali,University of Maryland Baltimore County,Vince,,Calhoun,University of New Mexico,,,,,,,,,,,,,,,,,,,,,,,,,"Latent functional features/components are often obtained for functionaldata onindividual subject with the intention of comparing the latent featuresacross two or more groups of subjects. Testing for similarity offeatures has been largely limited t",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,High dimensional data,Imaging,,,,,,,,arotnitzky@utdt.edu,,Andrea Rotnitzky,Professor,Universidad Di Tella and Harvard University,"Dep. of Biostatistics, HSPH. 655 Huntington Ave",6174321056,,arotnitzky@utdt.edu,Enhanced double-robust locally-efficient estimation in regression models for longitudinal studies,1,Andrea,,Rotnitzky,Universidad di Tella,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Recently proposed double-robust estimators for a population mean withincomplete data have a number of advantageous efficiency propertiesover the usual double-robust estimator. Double-robust estimators forthe parameters of regression models with inco",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Causal inference,Longitudinal data,,,,,,,,jliu@stat.harvard.edu,,Jun Liu,Professor of Statistics,"Harvard University, Dept of Statistics","1 Oxford Street, 7th floor",617-495-1600,,jliu@stat.harvard.edu,Reconstructing 3-D Shapes of Chromosomes from Hi-C Data,4,Ming,,Hu,Harvard University,Ke,,Deng,Harvard University,Steve,Z,Qin,Emory University,Jun,S,Liu,Harvard University,,,,,,,,,,,,,,,,,,,,,,,,,"How human chromatin fits into a nucleus approximately ten micrometers in diameter remains largely unresolved. Understanding how chromosomes fold may provide insights into transcription regulation, and therefore functional state of the cell. A rece",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Genomics,Bayesian methods,,,,,,,,lawsonab@musc.edu,,Andrew B Lawson,Dr,Medical University of South Carolina,135 Cannon Street,8438761865,,lawsonab@musc.edu,Bayesian  Spatial Surveillance of small area Infectious Disease data,1,Andrew,B,Lawson,Medical University of South Carolina,Ana,,Corberan,Medical University of South Carolina ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In this talk we consider small area infectious disease data andappropriate development of online prospective surveillance tools. Webase our analysis on spatially structured Bayesian hierarchical modelswhere a lagged dependence on previous infection ",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Spatial/temporal modeling,Bayesian methods,,,,,,,,sholte@fhcrc.org,,Sarah Holte,Principal Staff Scientist,Fred Hutchinson Cancer Research Center,1100 Fairview Ave North,206 667 6975,,sholte@fhcrc.org,Functional Principal Components Analysis of CD4 Trajectories in African Women,1,Sarah,E,Holte,Fred Hutchinson Cancer Research Center,Timothy,W,Randolph,Fred Hutchinson Cancer Research Center,Jimin,,Ding,Washington University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"In this talk we will demonstrate the use of functional principle components (FPCA) to evaluate the relationship between CD4 count trajectories and survival outcomes in a cohort of African women infected with HIV-1.  Previous analysis of this data fa",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Functional data analysis,Applied data analysis,,,,,,,,pritch@uchicago.edu,,Jonathan Pritchard,,University of Chicago,920 E 58th St,773 834 5248,,pritch@uchicago.edu,Analysis of next generation sequencing data to study genetic variation in gene regulation,1,Jonathan,K,Pritchard,"Department of Human Genetics/ HHMIThe University of Chicago",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"I will discuss the analysis of next-generation sequencing data from a variety of different experimental protocols (RNA-seq, DNase1-seq, MNase-seq and ChIP-seq experiments) that our group has undertaken to understand the mechanisms by which human gen",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,FALSE,Genomics,Statistical genetics,,,,,,,,jfine@bios.unc.edu,,Jason Fine,Professor,"Department of Biostatistics, UNC-Chapel Hill",Campus Box 7420,919-428-3192,,jfine@bios.unc.edu,Analysis of Recurrent Episodes Data: the Length-Frequency Tradeof,1,Jason,,Fine,"Department of Biostatistics Department of StatisticsUNC-Chapel Hill",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"I consider a special type of recurrent event data, 'recurrentepisode data' in which when a event occurs it last for a randomlength of time. Recurrent episode data arise frequently instudies of episodic illness. A naive recurrent event analysisdisr",FALSE,FALSE,,FALSE,FALSE,FALSE,,invitedpaper,,,,FALSE,FALSE,FALSE,TRUE,Survival analysis,Clinical trials,,,,,,,,cdbustam@stanford.edu,,Carlos Bustamante,Professor,Stanford University,"300 Pasteur Drive Lane Bldg, Room L-301",(650) 723-6330,,cdbustam@stanford.edu,Population genetics in the personal genome era ,,Carlos,,Bustamante,Stanford University,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Understanding the contribution of rare and common genetic genetic variants to disease susceptibility will likely require multi- and trans-ethnic sequencing studies that compare the genomes of many individuals with and without a particular disease. Of particular importance will be accounting for the role of population stratification at fine scales both in terms of genomic and geographic location.  Here, we present results from sequencing, assembly, and genomic analysis of two diploid genomes from Phase 3 HapMap sequenced to ~20X coverage using SoLiD technology.  The donor individuals are of Mexican-American and African-American ancestry and represent the first ""admixed"" genomes to be sequenced to high coverage.  We demonstrate that genomic sequencing provides finer resolution of ""admixture breakpoints"" based on allele frequency estimates from HapMap and TGP.  For each admixed genome, we use the distribution of admixture breakpoints to infer the personal admixture history of the sample and patterns of genomic diversity to reconstruct the demographic history of European, African, and Native American continental populations. Furthermore, we compare the distribution of functional and putatively neutral genetic variation among dozens of sequenced genomes and find that difference in demographic history may account for statistically significant, differences in distributions of synonymous vs. benign, possibly damaging, and probably damaging non-synonymous coding variants.   Finally, we use the SoLiD comparative personal genomic data sets and TGP data to quantify the relative proportions of private, rare, and common functional and neutral genetic within and among populations. ",,,,,,,,invitedpaper,,,,,,,,,,,,,,,,